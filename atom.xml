<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>watson&#39;blogs</title>
  
  
  <link href="https://watsonlu6.github.io/atom.xml" rel="self"/>
  
  <link href="https://watsonlu6.github.io/"/>
  <updated>2024-08-04T08:23:07.444Z</updated>
  <id>https://watsonlu6.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>个人感悟</title>
    <link href="https://watsonlu6.github.io/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/"/>
    <id>https://watsonlu6.github.io/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/</id>
    <published>2022-08-04T08:18:06.000Z</published>
    <updated>2024-08-04T08:23:07.444Z</updated>
    
    <content type="html"><![CDATA[<h2 id="论学习"><a href="#论学习" class="headerlink" title="论学习"></a>论学习</h2><ol><li>多花点时间在自己专业上，不要分心旁骛太多。 </li><li>先做好本份工作，行有余力，再自学 。</li><li>及时总结心得经验。记录，总结做过的项目，能总结多少就多少。如果有扎实的理论基础，深刻的理解能力，坚强的毅力，无论什么新技术新东西都能很快学会，但最宝贵的东西——经验，解决问题的钥匙。是无法学会的，只能慢慢体会,慢慢总结。</li><li>技术不求新，涉及哪方面的技术&#x2F;知识，就去学习，想办法精通。先有深度，再求广度。</li></ol><h2 id="论生活"><a href="#论生活" class="headerlink" title="论生活"></a>论生活</h2><ol><li>生活应该简单，但不应该单调。电影，音乐，都是不错的消遣。适当放松，有不足才有期待。 </li><li>跑步能让我很开心，多去跑步。</li><li>别被一些俗事打乱了生活的节奏，要懂得把握生活的节奏。</li><li>每星期总结一周的活动。</li><li>维持7.5小时睡眠。</li><li>抓住该努力的时间去努力，该松弛的时候去松弛。</li><li>运动能使人变得开朗，有特长能使人变得自信。</li></ol><h2 id="论做人"><a href="#论做人" class="headerlink" title="论做人"></a>论做人</h2><ol><li>自视高谓之骄，怀激愤谓之躁。做人应该尽量避免骄傲，浮躁。</li><li>要在3年达到别人10年才能达到的高度，就意味着3年内要承受10年的苦。请你衡量。</li><li>不要拿社会标准来衡量自己的价值，而应该用心灵的意义去裁决。</li><li>实验室很浮躁，越是浮躁的地方，越要扎实下来，厚积薄发。</li><li>调整自己的心态，不要太在乎一得一失。你目前所努力的，其实不是为了成功，而是为了当成功的机会来临时，你能把握住而已。为了成功和为了成功把握机会，两者的区别很重要。</li><li>做人应该谦虚，而且不要有自虐狂的心理，并不是每个人都会针对你。</li><li>高手是别人认为的。不是自封的，不要自大。</li><li>坚持理想，理想不难，难的是坚持</li></ol><h2 id="论心理"><a href="#论心理" class="headerlink" title="论心理"></a>论心理</h2><ol><li>烦恼和焦虑：烦恼和焦虑表示你为一些事情担心着，而你目前并没有付出能够解决这些问题的努力。 </li><li>宽容面对自己的缺陷和不足。</li><li>把自己的消极想法都记下，逐点去分析，攻破。分析问题所在，制定方法去解决（生活与心理都是）</li><li>知足常乐</li></ol><h2 id="论工作"><a href="#论工作" class="headerlink" title="论工作"></a>论工作</h2><ol><li>对待补贴：不管导师发不发补贴，只要你还在这个实验室一天，就请努力专心的做事。 </li><li>对待每一件事：努力认真去做好每一件事。只要你想做，总有法子可以做到的。</li><li>做好本分工作。技术人员有时候对PM分配自己一些较没技术含量的工作会很不满。记住，都是做事而已。无论怎样，分配到你的工作，请你做好。孔子尚且养过马，薛仁贵尚且当过伙头军。我认为，做好一个茶叶蛋，比做砸了原子弹更有意义。不以技术难度定优劣，都是做事而已。</li><li>团队的交流,配合开发：<br> a. 别人的失误要及时指出，当然了，语气要婉转。这样才能调整进度，别发现了错误隐瞒不报。<br> b. 对于自己不懂的环节，勇敢承认自己的缺点，大胆去估计进度，并认真学习。<br> c. 如果可能，每天汇报进度，也许只是几分钟，让PM看看你的构思，你的代码，你的成果。PM是最熟悉业务的，他能指出你的程序流是否正确，页面是否恰当。根据这些，你和他才能估计进度，这样，整个项目的进度才算可控。<br> d. 学会承担更多的责任。把困难的任务交给你，通常意味着只有你才能完成。请你好好享受这种”唯一”的乐趣。</li><li>出了问题，努力想办法去解决。别人或者不在意你的能力，但很在意你的态度。</li></ol><h2 id="最佳印象"><a href="#最佳印象" class="headerlink" title="最佳印象"></a>最佳印象</h2><ol><li>早到。早到就显得你很重视这份工作。</li><li>不要过于固执。工作时时在扩展，不要老是以“这不是我份内的工作”为由来逃避责任。当前额外的工作指派到你头上时，不妨视之为考验。</li><li>苦中求乐。不管你接受的工作多么艰巨，鞠躬尽瘁也要做好，千万别表现出你做不来或不知从何入手的样子。</li><li>立刻动手。接到工作要立刻动手，迅速准确及时完成，反应敏捷给人的印象是金钱买不到的。</li><li>谨言。职务上的机密必须守口如瓶。</li><li>听从上司的临时指派。上司的时间比你的时间宝贵，不管他临时指派了什么工作给你，都比你手头上的工作来得重要。</li><li>荣耀归于上司。即让上司在人前人后永远光鲜。</li><li>保持冷静。面对任何状况都能处之泰然的人，一开始就取得了优势。老板、客户不仅钦佩那些面对危机声色不变的人，更欣赏能妥善解决问题的人。</li><li>别存在太多的希望。千万别期盼所有的事情都会照你的计划而行。相反，你得时时为可能产生的错误做准备。</li><li>敢于做出果断决定。遇事犹豫不决或过度依赖他人意见的人，是一辈子注定要被打入冷宫的。</li><li>广收资讯。要想成为一个成功的人，光是从影音媒体取得资讯是不够的，多看报章杂志才是最直接的知识来源。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;论学习&quot;&gt;&lt;a href=&quot;#论学习&quot; class=&quot;headerlink&quot; title=&quot;论学习&quot;&gt;&lt;/a&gt;论学习&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;多花点时间在自己专业上，不要分心旁骛太多。 &lt;/li&gt;
&lt;li&gt;先做好本份工作，行有余力，再自学 。&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="个人生活" scheme="https://watsonlu6.github.io/categories/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="个人生活" scheme="https://watsonlu6.github.io/tags/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_Cache-Tier源码实现</title>
    <link href="https://watsonlu6.github.io/Ceph-Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/</id>
    <published>2022-04-28T12:45:54.000Z</published>
    <updated>2024-07-28T13:44:52.484Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cache-Tier架构"><a href="#Cache-Tier架构" class="headerlink" title="Cache Tier架构"></a>Cache Tier架构</h2><p>Ceph存储集群如果采用廉价的PC和传统的机械硬盘进行搭建，磁盘的访问速度受到了一定的限制，无法达到理想的IOPS性能水平。为了优化系统的IO性能，可以考虑添加快速的存储设备作为缓存，以减少数据的访问延时。其中，Cache Tier分层存储机制是一种常见的解决方案，在Ceph服务端缓存中被广泛使用，可以有效提升后端存储层的I&#x2F;O性能。Cache Tier需要创建一个由高速且昂贵的存储设备（如SSD）组成的存储池作为缓存层，以及一个相对廉价的设备组成的后端存储池作为经济存储层。缓存层使用多副本模式，存储层可以使用多副本或纠删码模式。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="Cache Tier"><br>Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。</p><h2 id="Ceph-Cache-tier处理流程"><a href="#Ceph-Cache-tier处理流程" class="headerlink" title="Ceph Cache tier处理流程"></a>Ceph Cache tier处理流程</h2><p>使用命令add-cache 可以将一个cachepool作为base pool的tier。这时会设置pool的信息，在pool里面记录了cache pool和base pool的关系。客户端在获取pool信息的时候可知，目标base pool存在一个tier，叫做cache pool，那么操作base pool的请求都会发送给cache pool。请求达到cache pool中时，作为tier的pool会有一些特别的处理maybe_cache_handle，具体的流程如下图：<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B02.png" alt="Cache Tier"></p><ul><li>判断操作的object是否在cache pool中命中，如果命中，则直接在cache pool中处理，和在普通pool的请求一样处理。后续会有agent线程将缓存脏数据刷写到base pool中。</li><li>没有命中缓存的情况下，才会去判断缓存模式。如果命中缓存，不管是什么模式都会在cache pool中处理。下面的处理都是未命中缓存的情况。</li><li>判断是否是writeback模式，读操作，如果可以proxy_read，那就直接do_proxy_read读取数据即可，不可以proxy_read 就使用do_cache_redirect，告诉客户端去base pool中读取。写操作，如果当前是evict_full模式，说明现在缓存中已经达到了阈值，需要等待缓存淘汰一些object，在完成写操作，目前放在等待队列中等待，如果不是evict_full模式，则需要从base pool中promote对应的object到cache pool中，promote结束后继续处理本次的写操作。</li><li>判断是否是forward模式。在forward模式下，不再在cachepool中处理请求，会告诉客户端将请求全部发送到base pool中。</li><li>判断是不是readonly模式。写操作会告诉客户端直接想base pool写即可，如果是读操作，则会从base pool中promote该object。</li><li>判断是不是readforward模式。该模式读操作全部都告诉客户端直接去base pool中读取即可，写操作按着writeback模式处理。</li><li>判断是不是readproxy模式。该模式读操作都采用cachepool的proxy read方法，写操作按着writeback模式处理。</li></ul><p>针对其中涉及到的几个封装好的方法的操作： do_cache_redirect， do_proxy_read， do_proxy_write，promote_object<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B03.png" alt="Cache Tier"></p><ul><li><strong>do_cache_redirect</strong> ：客户端请求cache pool，cache pool告诉客户端你应该去base pool中请求，客户端收到应答后，再次发送请求到base pool中请求数据，由base pool告诉客户端请求完成。</li><li><strong>do_proxy_read</strong>：客户端发送读请求到cache pool，但是未命中，则cache pool自己会发送请求到base pool中，获取数据后，由cache pool将数据发送给客户端，完成读请求。但是值得注意的是，虽然cache pool读取到了该object，但不会保存在cache pool中，下次请求仍然需要调用函数promote_objectbasePool读取该对象请求，然后写入cachePool中。</li><li><strong>do_proxy_write</strong>：直接写数据到basePool中，同样，cachePool中并没有该数据对象，还需要后续调用promote_object函数把数据对象从basePool中读到cachePool中。</li><li><strong>promote_object</strong>：当客户端发送请求到cache pool中，但是cache pool未命中，cache pool会选择将该object从base pool中提升到cache pool中，然后在cache pool进行读写操作，操作完成后告知客户端请求完成，在cache pool会缓存该object，下次直接在cache中处理，和proxy_read存在的区别。构造PromoteCallback回调函数，然后调用函数start_copyk拷贝函数。</li></ul><p>无论是 Proxy Read 还是 Promote Object 操作最终都是调用了 objecter 的 read 方法来从base storage层读取对象数据</p><h2 id="Cache-Tier数据结构"><a href="#Cache-Tier数据结构" class="headerlink" title="Cache Tier数据结构"></a>Cache Tier数据结构</h2><p>由于 Tier cache 在 Ceph 中的存在形式是存储池，pg_pool_t保存了存储池的相关属性。(src&#x2F;osd&#x2F;osd_type.h&#x2F;struct pg_pool_t)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">set&lt;<span class="type">uint64_t</span>&gt; tiers;   <span class="comment">//如果当前pool是一个basePool，tiers就记录改basepool的cachePool层，一个base pool可以设置多个cachePool</span></span><br><span class="line"><span class="type">int64_t</span> tier_of;            <span class="comment">//如果当前pool是一个cachePool，那么tier_of记录了该cachePool的basePool</span></span><br><span class="line"><span class="type">int64_t</span> read_tier;       <span class="comment">//设置basePool的读缓存层，根据Ceph不同的Cache Tier模式来设置</span></span><br><span class="line"><span class="type">int64_t</span> write_tier;      <span class="comment">//设置basePool的写缓存层，根据Ceph不同的Cache Tier模式来设置</span></span><br><span class="line"><span class="type">cache_mode_t</span> cache_mode;  <span class="comment">//设置Cache Tier模式</span></span><br><span class="line"><span class="type">uint64_t</span> target_max_bytes;   <span class="comment">//设置了cachePool的最大字节数</span></span><br><span class="line"><span class="type">uint64_t</span> target_max_objects; <span class="comment">//设置了cachePool的最大对象数量</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_dirty_ratio_micro;   <span class="comment">// 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_dirty_high_ratio_micro;   <span class="comment">// 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_full_ratio_micro;   <span class="comment">// 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰</span></span><br><span class="line"><span class="type">uint32_t</span> cache_min_flush_age;      <span class="comment">// 对象在 cache 中被刷入到 storage 层的最小时间</span></span><br><span class="line"><span class="type">uint32_t</span> cache_min_evict_age;   <span class="comment">// 对象在 cache 中被淘汰的最小时间</span></span><br><span class="line">HitSet::Params hit_set_params; <span class="comment">// HitSet 相关参数</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_period;     <span class="comment">// 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的缓存统计信息</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_count;      <span class="comment">// 记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line"><span class="type">bool</span> use_gmt_hitset;        <span class="comment">// hitset archive 对象的命名规则 </span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_grade_decay_rate;    <span class="comment">//当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_search_last_n;      <span class="comment">//为温度累积，最多N次hit_sets</span></span><br></pre></td></tr></table></figure><h4 id="读写IO"><a href="#读写IO" class="headerlink" title="读写IO"></a>读写IO</h4><p><strong>Add Cache</strong><br>在 ceph&#x2F;src&#x2F;mon&#x2F;OSDMonitor.cc 中实现了 add-cache 命令，从命令行中获取对应的参数并绑定 Tier 关系</p><p><strong>选择 Cache Pool</strong><br>Cache Tier的应用主要体现在计算OSD的过程中，通过判断basepool的参数，来决定是否要更新targetpool：读操作时，如果有read_tier，则更新为read_tier pool；写操作时，如果有write_tier，则更新为write_tier pool。read_tier和write_tier与pool是否开启Cache Tier有关。</p><p>在 ceph&#x2F;src&#x2F;osdc&#x2F;Objecter.cc&#x2F;Objecter::_calc_target中指定目标存储池为 Cache Pool，设置之后由后续的代码在该 Pool 中执行 Crush 算法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//首先根据base_oloc.pool获取pool信息，获取pg_pool_t对象   </span></span><br><span class="line"><span class="type">const</span> <span class="type">pg_pool_t</span> *pi = osdmap-&gt;<span class="built_in">get_pg_pool</span>(t-&gt;base_oloc.pool);</span><br><span class="line"><span class="comment">// apply tiering 根据读写操作，分别设置需要操作的 tier</span></span><br><span class="line">t-&gt;target_oid = t-&gt;base_oid;         #base_oid        <span class="comment">//读取的对象              #target_oid;          //最终读取的目标对象</span></span><br><span class="line">t-&gt;target_oloc = t-&gt;base_oloc;     #base_oloc       <span class="comment">//对象的pool信息      #//target_oloc      //最终目标对象的pool信息</span></span><br><span class="line"><span class="keyword">if</span> ((t-&gt;flags &amp; CEPH_OSD_FLAG_IGNORE_OVERLAY) == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="comment">//检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值。</span></span><br><span class="line"><span class="keyword">if</span> (is_read &amp;&amp; pi-&gt;<span class="built_in">has_read_tier</span>())</span><br><span class="line">    t-&gt;target_oloc.pool = pi-&gt;read_tier;</span><br><span class="line">    <span class="comment">//如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值。</span></span><br><span class="line"><span class="keyword">if</span> (is_write &amp;&amp; pi-&gt;<span class="built_in">has_write_tier</span>())</span><br><span class="line">        t-&gt;target_oloc.pool = pi-&gt;write_tier;</span><br><span class="line">pi = osdmap-&gt;<span class="built_in">get_pg_pool</span>(t-&gt;target_oloc.pool);</span><br><span class="line"><span class="keyword">if</span> (!pi) &#123;</span><br><span class="line">    t-&gt;osd = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> RECALC_OP_TARGET_POOL_DNE;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>osd 先接收到客户端发送来的请求，然后OSD::dequeue_op()调用 PrimaryLogPG:: do_request()——&gt;PrimaryLogPG::do_op()中处理，这都是正常的一个 pool 处理请求的流程，在 do_op 中来看看不同于其他普通 pool 的处理。如果开启了Cache Tier，将会在do_op中执行以下操作：</p><ol><li>首先判断hit_set中是否包含待操作的对象（hit_set-&gt;contains(obc-&gt;obs.oi.soid)），如果不包含，则把对象添加到hit_set中。添加对象后，如果hit_set满了，或者hit_set超时，则调用hit_set_persist()。</li><li>执行agent_choose_mode()，设置agent相关参数，如flush_mode、num_objects、num_bytes等。</li><li>执行maybe_handle_cache()。这里处理cache执行逻辑。</li><li>如果maybe_handle_cache()中调用maybe_handle_cache_detail()，如果成功处理了op请求，则直接return，否则会继续执行后续操作（说明不需要从datapool读取数据或者转发请求到datapool，可以直接在此osd命中查询的对象），由本OSD执行读取操作。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B01.png" alt="Cache Tier"></li></ol><h4 id="HitSet"><a href="#HitSet" class="headerlink" title="HitSet"></a>HitSet</h4><p>在 write back&#x2F;read forward&#x2F;read proxy 模式下需要 HitSet 来记录缓存命中。</p><p>HitSet 用于跟踪和统计对象的访问行为，记录对象是否存在缓存中。定义了一个缓存查找到抽象接口，目前提供了三种实现方式：ExplicitHashHitSet，ExplicitObjectHitSet，BloomHitSet</p><p>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h 定义了抽象接口，同时该头文件中包含了具体的 HitSet 实现</p><ul><li><strong>ExplicitHashHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitHashHitSet</li><li>基于对象的 32 位 HASH 值的 set 来记录对象的命中，每个对象占用 4 bytes 内存空间</li><li>优点：空间占用相对较少，但需要根据 HASH 进行全局的扫描遍历比较</li></ul></li><li><strong>ExplicitObjectHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitObjectHitSet</li><li>使用一个基于 ceph&#x2F;src&#x2F;common&#x2F;hobject 的 set 来记录对象的命中，占用的内存取决于对象的关键信息的大小</li><li>使用内存中缓存数据结构来进行判断带来的优点就是实现相对简单直观，但占用的内存空间相对较大</li></ul></li><li><strong>BloomHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class BloomHitSet</li><li>采用了压缩的 Bloom Filter 的方式来记录对象是否在缓存中，进一步减少了内存占用空间</li></ul></li></ul><h3 id="Cache-Tier的初始化"><a href="#Cache-Tier的初始化" class="headerlink" title="Cache Tier的初始化"></a>Cache Tier的初始化</h3><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::hit_set_setup()用来创建并初始化HisSet对象</li><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_setup()完成agent相关的初始化工作</li></ul><h2 id="Cache-Pool-请求处理"><a href="#Cache-Pool-请求处理" class="headerlink" title="Cache Pool 请求处理"></a>Cache Pool 请求处理</h2><p>Cache 的相关请求处理可以通过do_op()进行梳理，主要包含了 agent_choose_mode()和 maybe_handle_cache() 两个主要方法。(src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;do_op(OpRequestRef &amp;))</p><p><strong>agent_choose_mode(bool restart, OpRequestRef op)</strong></p><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;agent_choose_mode</li><li>该函数主要计算一个 PG 的 flush_mode 和 evic_mode 的参数值。</li><li>返回值如果为 True，表明该请求 Op 被重新加入请求队列（由于 EvictMode 为 Full），其他情况返回 false。</li></ul><p><strong>maybe_handle_cache(…)</strong></p><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;maybe_handle_cache()调用maybe_handle_cache_detail(）</li><li>处理有关cache的读写请求</li></ul><!-- 图解maybe_handle_cache_detail()缓存策略将以上缓存策略的处理流程转换为流程图如下所示（注：流程细节随着Ceph版本的迭代已经有锁改变，此处重点关注最终的调用）![Cache Tier](/images/缓存基础与Ceph分层存储/Cache-Tier源码实现2.png)针对其中涉及到的几个封装好的方法的操作： do_cache_redirect， do_proxy_read， do_proxy_write，promote_object![Cache Tier](/images/缓存基础与Ceph分层存储/Cache-Tier源码实现3.png)- **do_cache_redirect** ：客户端请求cache pool，cache pool告诉客户端你应该去base pool中请求，客户端收到应答后，再次发送请求到base pool中请求数据，由base pool告诉客户端请求完成。- **do_proxy_read**：客户端发送读请求到cache pool，但是未命中，则cache pool自己会发送请求到base pool中，获取数据后，由cache pool将数据发送给客户端，完成读请求。但是值得注意的是，虽然cache pool读取到了该object，但不会保存在cache pool中，下次请求仍然需要调用函数promote_objectbasePool读取该对象请求，然后写入cachePool中。- **do_proxy_write**：直接写数据到basePool中，同样，cachePool中并没有该数据对象，还需要后续调用promote_object函数把数据对象从basePool中读到cachePool中。- **promote_object**：当客户端发送请求到cache pool中，但是cache pool未命中，cache pool会选择将该object从base pool中提升到cache pool中，然后在cache pool进行读写操作，操作完成后告知客户端请求完成，在cache pool会缓存该object，下次直接在cache中处理，和proxy_read存在的区别。构造PromoteCallback回调函数，然后调用函数start_copyk拷贝函数。无论是 Proxy Read 还是 Promote Object 操作最终都是调用了 objecter 的 read 方法来从base storage层读取对象数据 --><h4 id="Cache-flush-evict"><a href="#Cache-flush-evict" class="headerlink" title="Cache flush &amp; evict"></a>Cache flush &amp; evict</h4><p>cachePool空间不够时，需要选择一些脏数据对象会刷到数据层，即flush操作；将一些clean对象从缓存层剔除，以释放更多的缓存空间，即evict操作。这两种操作都是在后台线程完成的。<strong>flush操作和evict操作算法的好坏决定了Cache Tier的缓存命中率</strong>。evict是针对cachepool中已经过期或过冷的数据，只需要把它从cachepool中删除即可，evict操作通常会影响缓存命中率。flush是把脏数据刷新到storagePool，flush操作通常不会直接影响缓存命中率。flush操作是将缓存中的数据写回到持久存储介质中，从而保证数据的一致性，但并不会直接影响缓存的访问，脏数据是只保存在cachePool中，经过修改后，还未写入storagePool的数据。</p><p><strong>数据结构</strong><br>src&#x2F;osd&#x2F;osd.h&#x2F;OSDServices ：定义了 AgentThread 后台线程，用于完成 flush 和 evict 操作：一是把脏对象从cachePool层适时地会刷到basePool层；二是从cachePool层剔除掉一些不经常访问的clean对象。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Mutex agent_lock;     <span class="comment">// agent 线程锁，保护下面所有数据结构</span></span><br><span class="line">Cond agent_cond;     <span class="comment">// 线程相应的条件变量</span></span><br><span class="line">map&lt;<span class="type">uint64_t</span>, set&lt;PGRef&gt; &gt; agent_queue;   <span class="comment">// agent线程的工作队列，保存了OSD中所有归属于cachePool的淘汰或者回刷所需的 PG 集合，根据PG集合的优先级，保存在不同的map中</span></span><br><span class="line">set&lt;PGRef&gt;::iterator agent_queue_pos;   <span class="comment">//当前在扫描的PG集合的一个位置</span></span><br><span class="line"><span class="type">bool</span> agent_valid_iterator;  <span class="comment">//只有agent_valid_iterator为true时，agent_queue_pos指针才有效，否则从集合的起始处开始扫描</span></span><br><span class="line"><span class="type">int</span> agent_ops;            <span class="comment">// 所有正在进行的回刷和淘汰操作</span></span><br><span class="line"><span class="type">int</span> flush_mode_high_count;      <span class="comment">//一旦FLUSH_MODE_HIGH有了一个pg，就可以高速刷新对象</span></span><br><span class="line">set&lt;<span class="type">hobject_t</span>&gt; agent_oids;    <span class="comment">// 所有正在进行的 agent 操作（回刷或者淘汰）的对象</span></span><br><span class="line"><span class="type">bool</span> agent_active;    <span class="comment">// agent 是否有效</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">AgentThread</span> : <span class="keyword">public</span> Thread&#123;&#125; agent_thread;    <span class="comment">// agent 线程，专门用来处理cache tier数据迁移的线程，线程名叫：osd_srv_agent。其作用就是循环遍历agent_queue中的所有pg，并对他们执行agent_work()操作。osd_srv_agent线程是一个OSD上所有PG公用的，为了保证效率，设置了严格的限流参数：osd_pool_default_cache_max_evict_check_size限制依次遍历对象的总数，达到后立刻切换退出循环在osd_srv_agent中切换PG；osd_agent_max_ops设置了一个循环中最多能够处理几次flush或者evict操作。</span></span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> agent_stop_flag;   <span class="comment">// agent 停止的标志</span></span><br><span class="line">    SafeTimer agent_timer;   <span class="comment">//agent相关定时器：当扫描一个 PG 对象时，该对象既没有剔除操作，也没有回刷操作，就停止 PG 的扫描，把该 PG 加入到定时器中，5S 后继续</span></span><br></pre></td></tr></table></figure><p>src&#x2F;osd&#x2F;TierAgentState.h：TierAgentState用来保存PG相关的agent信息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">hobject_t</span> position;    <span class="comment">//PG内扫描的对象位置</span></span><br><span class="line"><span class="type">int</span> started;    <span class="comment">//PG里所有对象扫描完成后，所发起的所有的agent操作数目。如果没有agent操作，就需要延迟一段时间</span></span><br><span class="line"><span class="type">hobject_t</span> start;    <span class="comment">//本次扫描起始位置</span></span><br><span class="line"><span class="type">bool</span> delaying;    <span class="comment">//是否延迟</span></span><br><span class="line"><span class="type">pow2_hist_t</span> temp_hist;   <span class="comment">//历史统计信息</span></span><br><span class="line"><span class="type">int</span> hist_age;</span><br><span class="line">map&lt;<span class="type">time_t</span>,HitSetRef&gt; hit_set_map;   <span class="comment">//Hitset的历史记录</span></span><br><span class="line">list&lt;<span class="type">hobject_t</span>&gt; recent_clean;   <span class="comment">//最近处于clean的对象</span></span><br><span class="line"><span class="type">unsigned</span> evict_effort;      <span class="comment">//应该驱逐的对象的大致比例（假设它们均匀分布）</span></span><br></pre></td></tr></table></figure><h4 id="flush-evict-执行入口"><a href="#flush-evict-执行入口" class="headerlink" title="flush&#x2F;evict 执行入口"></a>flush&#x2F;evict 执行入口</h4><p>src&#x2F;osd&#x2F;osd.cc&#x2F;OSDService::agent_entry：agent_entry 是 agent_thread 的入口函数，它在后台调用pg-&gt;agent_work()，agent_queue的改变是在PrimaryLogPG::agent_choose_mode函数中改变的</p><p>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_work：遍历PG中所有对象，去寻找已经过期的、失效的需要flush或者evict的对象并对它们执行相应操作。</p><ol><li><p>扫描本PG的对象，从 agent_state-&gt;position 开始扫描，结果保存在 ls 中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">hobject_t</span>&gt; ls;</span><br><span class="line"><span class="type">int</span> r = pgbackend-&gt;<span class="built_in">objects_list_partial</span>(agent_state-&gt;position, ls_min, ls_max, &amp;ls, &amp;next); </span><br></pre></td></tr></table></figure></li><li><p>对扫描的 ls 对象做相应的检查，执行 evict 操作和 flush 操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (vector&lt;<span class="type">hobject_t</span>&gt;::iterator p = ls.<span class="built_in">begin</span>();p != ls.<span class="built_in">end</span>(); ++p)     </span><br><span class="line"><span class="keyword">if</span> (agent_state-&gt;evict_mode != TierAgentState::EVICT_MODE_IDLE &amp;&amp; <span class="built_in">agent_maybe_evict</span>(obc, <span class="literal">false</span>))</span><br><span class="line">    ++started;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (agent_state-&gt;flush_mode!=TierAgentState::FLUSH_MODE_IDLE&amp;&amp;agent_flush_quota&gt;<span class="number">0</span>&amp;&amp;<span class="built_in">agent_maybe_flush</span>(obc)) &#123;</span><br><span class="line">    ++started;</span><br><span class="line">    --agent_flush_quota;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li></ol><p>真正执行操作的方法</p><ul><li><strong>evict</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_evict</li><li><strong>flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_flush</li><li><strong>start_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_flush 该函数完成实际的 flush 操作</li><li><strong>start_manifest_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_manifest_flush  真正刷回数据之前的数据准备</li><li><strong>do_manifest_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::do_manifest_flush 真正刷回数据的过程</li></ul><p>flush 操作最终是以 Op 请求的方式传递到底层存储层的，也就意味着需要再执行一次 Ceph 存储池写数据的相关逻辑。<br>Ceph的Cache Tier功能目前在对象访问频率和热点统计上的实现都比较简单，可以通过基于自学习的Cache算法提升缓存命中率。</p><p><strong>agent_state在每个函数中都起到决定性地位</strong>：在agent_work中，agent_state-&gt;evict_mode和agent_state-&gt;flush_mode的值决定要不要进行evict和flush判断。在agent_maybe_evict和agent_maybe_flush中agent_state-&gt;evict_mode的值决定要不要直接执行evict或者flush。而agent_state值的计算过程是在agent_choose_mode函数中。agent_choose_mode函数计算一个PG的flush和evict行为的相关参数。该函数主要完成以下任务：</p><ul><li>统计当前PG中dirty object数量和当前PG中所有的object数量；（dirty object指的是脏数据对象)</li><li>统计当前PG中dirty object占用的字节数和当前PG中所有object占用的总的字节数；</li><li>分别从object数量角度和object占用的字节数角度计算dirty占比和full占比；</li><li>计算当前flush mode和evict mode；</li><li>更新agent_state-&gt;flush_mode和agent_state-&gt;evict_mode；</li><li>根据当前flush mode和evict mode决定是要将当前PG加入到待处理的PG队列中；</li></ul><p>从agent_choose_mode最后可以看到，如果缓存池需要flush或者evict，需要将待处理的PG加入到agent_queue队列中，这一动作是最终通过调用_enqueue函数实现，该函数主要完成以下任务：</p><ul><li>src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_enqueue</li><li>判断是否需要调整agent线程要处理哪个pg set；</li><li>将待处理的pg加入到pg set中；</li><li>唤醒agent线程，执行flush或者evict任务；</li></ul><p>从agent_choose_mode最后可以看到，如果缓存池需不需要flush或者evict，但是如果之前agent线程有处理过该PG，需要将待处理的PG从agent_queue队列中移除掉，这一动作最终通过调用_dequeue函数实现，该函数主要完成以下任务：</p><ul><li>src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_dequeue</li><li>根据old_priority从agent_queue队列中获取到相应的pg set；</li><li>在pg set中查找要移除的PG；如果找到了，从pg set中删除，并调整下一个要处理的PG；</li><li>如果删除之后的pg set没有任何一个PG，需要从agent_queue队列中移除，并调整下一个要处理的pg set；</li></ul><p><strong>agent_choose_mode流程图</strong><br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B04.jpg" alt="Cache Tier"><br><strong>agent_entry流程图</strong><br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B05.jpg" alt="Cache Tier"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Cache-Tier架构&quot;&gt;&lt;a href=&quot;#Cache-Tier架构&quot; class=&quot;headerlink&quot; title=&quot;Cache Tier架构&quot;&gt;&lt;/a&gt;Cache Tier架构&lt;/h2&gt;&lt;p&gt;Ceph存储集群如果采用廉价的PC和传统的机械硬盘进行搭建，</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>缓存基础与Ceph分层存储</title>
    <link href="https://watsonlu6.github.io/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/"/>
    <id>https://watsonlu6.github.io/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/</id>
    <published>2022-04-10T11:59:00.000Z</published>
    <updated>2024-07-28T13:18:06.630Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存基础"><a href="#缓存基础" class="headerlink" title="缓存基础"></a>缓存基础</h2><ol><li><p><strong>缓存命中率</strong>：表示从缓存中获取数据的成功率，即缓存命中的次数与总访问次数的比值。缓存命中率越高，表示缓存系统的效率越高，能够更快地响应用户的请求。</p></li><li><p><strong>缓存失效率</strong>：表示从缓存中获取数据失败的次数与总访问次数的比值。缓存失效率越高，表示缓存系统的效率越低，需要从持久存储介质中读取数据的次数也越多，可能会导致系统的响应速度变慢。</p></li><li><p><strong>缓存容量</strong>：指缓存系统能够存储数据的最大容量。缓存容量的大小会影响缓存系统的性能和可靠性，如果缓存容量不足，可能会导致缓存系统频繁地进行evict操作，从而影响系统的响应速度和可用性。</p></li><li><p><strong>缓存算法</strong>：指缓存系统用于决定哪些数据被缓存，哪些数据被删除的算法。常见的缓存算法包括LRU（最近最少使用）、LFU（最不经常使用）、FIFO（先进先出）等。</p></li><li><p><strong>脏数据（Dirty Data）</strong>：指缓存中已经被修改但尚未被写回到持久存储介质（如磁盘）中的数据。这些数据需要及时写回到持久存储介质中以保证数据的一致性。常见的处理策略包括写回（write-back）和写直达（write-through）策略。</p></li><li><p><strong>干净数据（Clean Data）</strong>：指缓存中未被修改或已经被写回到持久存储介质中的数据。干净数据在缓存系统中可以快速读取，减少写入操作，优先选择删除干净数据可以避免写回操作带来的额外开销。</p></li><li><p><strong>evict操作</strong>：从缓存中移除某些数据，以释放缓存空间供其他数据使用。常用的策略包括LRU（Least Recently Used）等，根据最近最少使用的数据进行移除。</p></li><li><p><strong>flush操作</strong>：将缓存中的数据立即写回到持久性存储介质（例如硬盘），以确保缓存中的数据与存储介质中的数据保持一致。</p></li></ol><h4 id="数据一致性和性能考虑"><a href="#数据一致性和性能考虑" class="headerlink" title="数据一致性和性能考虑"></a>数据一致性和性能考虑</h4><ul><li><p><strong>脏数据的处理</strong>：存在脏数据可能导致数据一致性问题和性能问题，因此需要及时处理脏数据。选择适当的写回策略可以平衡数据一致性和系统性能。</p></li><li><p><strong>干净数据的优先删除</strong>：在缓存系统中，干净数据的存在可以提高系统性能，因为它们可以快速读取而不需要进行额外的写入操作。当需要从缓存中删除对象时，通常优先选择删除干净数据。</p></li><li><p><strong>flush操作的选择</strong>：通常在以下情况下使用flush操作：</p><ul><li>数据一致性要求高的场景，如数据库应用</li><li>性能要求不高或系统关闭时需要保证数据的持久性</li></ul></li><li><p><strong>evict操作的选择</strong>：通常在以下情况下使用evict操作：</p><ul><li>缓存空间不足，需要释放空间</li><li>数据访问模式固定或数据访问频率低</li><li>基于缓存替换算法（如LRU、LFU、FIFO等）</li></ul></li></ul><h4 id="缓存替换算法"><a href="#缓存替换算法" class="headerlink" title="缓存替换算法"></a>缓存替换算法</h4><ul><li><strong>LRU（Least Recently Used）</strong>：根据最近的访问时间来决定删除哪些数据。</li><li><strong>LFU（Least Frequently Used）</strong>：基于数据的访问频率选择删除数据。</li><li><strong>FIFO（First In First Out）</strong>：按照数据进入缓存的时间顺序移除数据。</li><li><strong>Random（随机）</strong>：随机选择数据进行删除，简单但效果不如其他算法。</li></ul><h4 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h4><ul><li><p><strong>优化evict操作</strong>：通过使用动态策略（基于数据使用情况）和静态策略（基于数据属性），可以提升缓存性能。了解系统的负载和压力情况也有助于优化evict操作。</p></li><li><p><strong>缓存命中率影响</strong>：evict操作可能导致缓存命中率下降，因为被删除的数据可能被访问到。flush操作通常不会直接影响缓存命中率，但需要高效的实现以避免影响系统性能。</p></li></ul><p>这些基本要素和策略可以帮助优化缓存系统的性能和可靠性，根据具体的应用需求进行适当的调整和选择。</p><h2 id="Ceph分层存储Cache-Tier"><a href="#Ceph分层存储Cache-Tier" class="headerlink" title="Ceph分层存储Cache Tier"></a>Ceph分层存储Cache Tier</h2><p>分层存储是存储领域中的一个重要分支，其思想基石是存储的金字塔模型——描述了快速设备通常容量小而性能高，慢速设备通常容量大而性能低。对于数据访问而言，通常在一段时间内，真实数据的访问是具有时间局部性和空间局部性的。时间局部性是指被访问的数据在短时间内可能再次被访问，空间局部性是指与被访问数据临近的数据有更大的概率被访问。故基于时间局部性理论产生了通常所说的缓存，如：cpu缓存、内存等；而基于空间局部性原理，产生了数据预取，如：指令预取（prefetch）、数据预读（read ahead）等。</p><p>目前Ceph的OSD主要可以基于SSD或者HDD的裸盘进行构建，机械盘通常比固态盘容量大、价格比固态盘低、但读写比固态盘慢，如何用机械盘和固态盘来提供一个高可靠、高性能、高性价比的分布式存储是需要解决的重要问题。如果全部基于SSD进行构建，其性能一定会最优，但是SSD价格昂贵，出于成本考虑，不可能全部采用SSD进行构建，那么SSD与HDD混合硬件架构就显得很有必要。</p><p>Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8.jpg" alt="Cache Tier"></p><p>Ceph Cache Tier提供了快速存储池与慢速存储池间的分层缓存特性。通常来说，对于块存储用户而言，数据访问会有明显的时间局部性与空间局部性，故可以通过分层存储思想，改善资源配置及效率。Ceph提供了Cache Tier的解决方案，能够融合两种存储，通过合理配比提供容量与性能介于SSD与HDD之间的虚拟存储资源池。对于对象存储而言，目前主要对外提供基于S3与Swift restful api的访问接口。RGW对象存储可以通过对数据池进行Cache Tier，从而提高其访问效率。</p><p>在Ceph中，分层存储系统通过缓存和存储池的方式实现，热资源池可以将数据存储至那些管理SSD磁盘的OSD上，而冷资源池可以将数据存储至那些管理HDD磁盘的OSD上。若客户命中被访问的数据落在热资源池中，可以直接被访问，此时IO速度最快，接近SSD磁盘的性能。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A81.jpg" alt="Cache Tier命中"></p><p>若客户被访问的数据不落在热资源池中，出现缓存丢失的情况，需要转向去HDD盘上读取数据，而HDD盘处理请求访问速度为毫秒级别，故网络延时与请求处理延时可以近似忽略，认为其访问速度接近HDD磁盘的性能。这时候的处理分为两种：代理读写和数据拉取。当读写请求出现缓存丢失时，代理读写向后端请求冷数据，但缓存池不对数据进行缓存，直接将请求内容返回给客户端。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A82.jpg" alt="缓存池的代理读写"></p><p>读写请求出现缓存丢失时，缓存池向后端请求冷数据，在向后端请求冷数据后，会将数据读入缓存池，继续处理客户端请求并返回请求内容。此外，短时间内被多次访问的数据会被认为是热数据而拉取到热池中，这将消耗HDD磁盘的读带宽与SSD磁盘的写入带宽。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A83.jpg" alt="缓存池的数据拉取"></p><p>另一方面，在热池中的数据，需要定期回写入冷池，此时，回写数据将暂用SSD与HDD磁盘的部分带宽，这个过程叫数据回写。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A84.jpg" alt="缓存池的数据回写"></p><p>还未回写入冷资源池的数据，在热资源池中再次被修改，这种情况越多，缓存效率越高，即相当于热资源池带宽充分利用，帮助冷资源池挡掉了大量的写入带宽。可以简单的认为，有1%的数据是需要脏回刷的（即回刷后的1%数据为clean状态，所以后续的命中会是非脏命中），如果所有数据都不脏回刷，且都访问命中的话，那么脏命中率为100%。</p><p>根据上述原理，不难发现，Ceph Cache Tier的性能取决于访问命中率。访问命中率越高时，存储系统越接近SSD磁盘的性能；反之，访问命中率越低时，越接近HDD磁盘的性能。另一方面，在Ceph中，缓存粒度以对象方式进行拉取与回写，故在实际情况下，如果缓存丢失过多，将会有大量的数据会被拉取，从而占用SSD磁盘的带宽，使得其访问带宽比SATA磁盘更差。然而，在实际生产使用过程中，数据总使用量总是逐步增加的，与此同时，热数据的量也将逐步的增加。那么，在整个使用周期中，随着数据量的增加，就必然会经历以下过程：首先刚刚开始使用时，数据量还很少。此时，所有数据全部能够被缓存，数据命中率为100%，效果很好。随着总数据量与热数据量不断的增加，缓存池已经无法容纳所有数据，只能容纳较多的热数据，此时缓存命中率会随之逐步的下降。随着数据的进一步增加，缓存命中率低于某个临界值了，此时保持同样大小的缓存池已经无法给使用带来足够好的收益。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;缓存基础&quot;&gt;&lt;a href=&quot;#缓存基础&quot; class=&quot;headerlink&quot; title=&quot;缓存基础&quot;&gt;&lt;/a&gt;缓存基础&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缓存命中率&lt;/strong&gt;：表示从缓存中获取数据的成功率，即缓存命中的次数与总访问次数的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>存储系统缓存/分层相关论文</title>
    <link href="https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/"/>
    <id>https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/</id>
    <published>2022-02-10T07:31:33.000Z</published>
    <updated>2024-08-04T07:59:18.239Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TDC-Pool-level-object-cache-replacement-algorithm-based-on-temperature-density"><a href="#TDC-Pool-level-object-cache-replacement-algorithm-based-on-temperature-density" class="headerlink" title="TDC: Pool-level object cache replacement algorithm based on temperature density"></a>TDC: Pool-level object cache replacement algorithm based on temperature density</h2><ul><li>在原生Ceph系统的基础上，提出缓存池的基于热度密度缓存替换算法，计算每个对象消耗空间的热度密度，并以最低的热度密度驱逐对象。通过驱逐对命中率贡献不大的对象，提高缓存池的命中率以及分层存储性能。</li><li>在 Ceph 中，Cache Tier通过缓存机制和存储池方式的实现，其将热数据存储SSD池，冷数据存储HDD池。若客户访问的数据直接命中落在SSD池中，可以直接被访问，此时IO速度最快 ，接近SSD磁盘的性能。但如果被访问的数据不在SSD池中，需要转向去HDD池上读取数据，而HDD盘处理请求访问速度为毫秒级别，则认为其访问速度接近HDD磁盘的性能。</li><li>目前 Cache Tier 采用的是基于频率估计的类 LRU缓存替换算法，并未充分利用数据对象所携带的元数据信息，这种频率估计概率存在误差，缓存命中率性能有限，且很难达到理论极限。因此实际使用时缓存命中率较低，导致较长的 IO 路径，使得Cache Tier性能表现较差。为进一步提升缓存命中率，考虑 Cache Tier 数据对象可以携带更多信息的特点，提出基于热度密度的缓存替换算法(TDC)。对象的热度计算基于访问频率，而热度密度计算基于热度和缓存对象占用时空的比例。通过引入热度密度计算，可以更准确地评估对象对命中率贡献，从而更有效地驱逐对命中率贡献不大的对象。</li><li>在用户文件上传到Ceph集群时，Ceph通过调用file_to_extents()函数将文件分割成若干个对象。面对数目庞大的对象，为了计算每个对象的访问热度值，采用Multiple Bloomfilter记录存储池每个对象访问的频率，通过这种方式有效地捕获更细粒度的最近性和频率。</li><li>将数据对象在缓存池中花费的时间和占用缓存空间视为缓存成本，这样，将缓存池中的对象对缓存命中率的贡献转化成一种成本效益分析。热度密度就是一种综合考虑对象大小、访问频率和访问时间等因素的指标，可以用来评估每个对象对缓存命中率的贡献，并根据热度密度来进行缓存替换。整个图形的热度密度可以表示为所有命中对象的贡献之和除以所有对象的占用缓存资源之和。通过比较已缓存对象的热度密度，并按一定比例删除热度密度较低的对象。</li></ul><h2 id="A-Survey-on-Tiering-and-Caching-in-High-Performance-Storage-Systems"><a href="#A-Survey-on-Tiering-and-Caching-in-High-Performance-Storage-Systems" class="headerlink" title="A Survey on Tiering and Caching in High-Performance Storage Systems"></a>A Survey on Tiering and Caching in High-Performance Storage Systems</h2><ul><li>论文讨论了针对高性能存储系统的缓存和分层解决方案研究。在第2节中，简要介绍了存储设备及其技术。在第3节中，讨论关于缓存解决方案及缓存算法的研究。在第4节中，讨论关于存储分层解决方案的研究。缓存和分层已被长期用于隐藏存储层次结构中慢速设备的长延迟。</li><li>基于响应时间，计算机存储系统被设计为有组织的多级层次结构，旨在提高整体性能和存储管理。不同类型的存储介质根据其性能、容量和控制技术指定为级别。通常，层次结构中级别越低，其带宽越小，存储容量越大。层次结构中有四个主要级别：处理器寄存器和缓存（SRAM、触发器或锁存缓冲区）、主存储器（DRAM）、辅助存储（SSD、HDD）、第三级存储（可移动存储设备）。图1概述了当前可用的和新兴的存储技术。表1比较了不同的计算机存储技术。</li><li>硬盘驱动器由固定在主轴周围的刚性快速旋转磁盘和使用致动器臂重新定位的磁头组成。数字数据以磁材料薄膜磁化转变的形式存储在每个磁盘上。HDD的机电方面和存储数据的串行化使得HDD比所提到的非易失性存储器技术慢几个数量级。然而，它的低价格和极高的密度使它成为二级和三级存储级别的理想选择。根据表1，HDD的容量可以比DRAM大1000倍，而操作延迟大约慢106倍。</li><li>IDC报告[58]预测到2020年，云将只触及数字世界的24%，13%将存储在云中，63%可能根本无法触及[58]。需要保护的数据的速度超过40%，甚至比数字世界本身还要快。因此，大部分数据通常存储在更便宜、更可靠和更大的设备中，而未经处理的部分数据则保存在快速存储介质中。因此，无疑需要具有缓存&#x2F;分层机制的混合存储系统</li><li>为了减轻慢设备的长延迟，可以在混合存储系统中使用缓存机制。缓存子系统有两个主要原则：1）在将原始数据保持在层次结构的中等级别时，缓存中存在一个处理不足的数据副本；以及2）缓存层中数据的生命周期短，并且它是临时的。</li><li>分层ARC（H-ARC）[12]缓存是一种基于NVM的缓存，它优化了ARC算法，以考虑最近、频率、脏和干净四种状态，并首先将缓存拆分为脏&#x2F;干净页缓存，然后将每个部分拆分为最近&#x2F;频率页缓存。基于与ARC类似的机制，它在每个级别上按层次调整每个部分的大小。因此，H-ARC在缓存中保持较高频率的脏页的时间更长。</li><li>如今，多层存储系统中使用了许多具有不同特性和容量的存储介质。缓存和分层之间的主要区别在于，在缓存系统中，数据的副本保存在缓存中，而在分层系统中，原始数据通过升级和降级两种操作在多个层之间迁移。数据根据应用程序需求和可用层的特性进行分类，通常分为热层和冷层。热数据驻留在性能层，冷数据留在容量层。考虑到随机性、传输速度等多种因素，可能有两个以上的层。</li></ul><h2 id="eMRC-Efficient-Miss-Ratio-Approximation-for-Multi-Tier-Caching"><a href="#eMRC-Efficient-Miss-Ratio-Approximation-for-Multi-Tier-Caching" class="headerlink" title="eMRC: Efficient Miss Ratio Approximation for Multi-Tier Caching"></a>eMRC: Efficient Miss Ratio Approximation for Multi-Tier Caching</h2><ul><li>研究高效的多层缓冲命中率分析技术</li><li>未命中率曲线（MRC）是捕获工作负载特性和调整系统行为的有用工具。MRC表示缓存大小和相应的缓存未命中率之间的关系。假设随着时间的推移，工作负载相对稳定，从观察到的IO跟踪得出的MRC对于单层缓存有效工作[13]。</li><li>许多存储缓存分配方法使用未命中率曲线（MRC）来提高缓存效率。然而，他们只关注单层缓存架构，并需要整个MRC作为缓存管理的输入，而现代数据中心采用分层缓存架构以最大限度地提高资源利用率。由于每个缓存层的逐出策略和容量不同，为多层缓存生成MRC（我们称之为未命中率函数）要困难得多。我们引入eMRC，一种多维未命中率近似技术，以实现多层缓存的高效MRC生成。论文使用了一种新颖的多维性能悬崖去除方法和凸包近似技术，以使用少量采样点有效地生成没有悬崖的多维MRC。</li><li>多层缓存需要一种有效的、低开销的缓存管理方案，因为多层的任意缓存配置可能会因其副作用而对租户不利[27]。为具有不同服务级别目标（SLO）的租户配置缓存需要对缓存的每一层进行高效、准确的缓存性能分析。</li><li>扩展：已经有很多关于MRC(miss ratio curves)的理论，来对上层缓存进行建模，得出程序分配缓存大小和性能的关系模型：MissRatio&#x3D;F(capacity)。基本分为两种方法：1、通过数据重新访问距离(reuse distance)，来建立MRC模型。2、通过数据重新访问时间(reuse time)，来建立MRC模型。</li></ul><h2 id="PHOEBE-Reuse-Aware-Online-Caching-with-Reinforcement-Learning-for-Emerging-Storage-Models"><a href="#PHOEBE-Reuse-Aware-Online-Caching-with-Reinforcement-Learning-for-Emerging-Storage-Models" class="headerlink" title="PHOEBE: Reuse-Aware Online Caching with Reinforcement Learning for Emerging Storage Models"></a>PHOEBE: Reuse-Aware Online Caching with Reinforcement Learning for Emerging Storage Models</h2><ul><li>NVMe和SSD是新兴存储技术的公认代表，具有数据持久性、高访问速度、低功耗和字节寻址能力。高性能采用这些技术的一个关键问题是如何正确定义智能缓存层，以便能够很好地弥补新兴技术和主存储器之间的性能差距。快速的主机端内存和慢速的后端存储驱动器之间的延迟差异很大，存储I&#x2F;O仍然是性能瓶颈，这导致了难以置信的长I&#x2F;O等待时间和大量CPU闲置浪费。为了缓解这种延迟差异，缓存层被广泛用于驻留在主存储器和后端存储驱动器之间。缓存系统的性能通常受到三个因素的影响：数据分配策略、数据热识别的准确性和数据驱逐策略。数据分配策略基本上控制数据流，并确定各种数据的接纳，例如只读、只读或两者兼而有之；数据热识别的高精度可以防止不必要数据对缓存的污染，通过局部保护提高缓存性能；数据驱逐策略决定在缓存已满时驱逐哪个数据块，从而间接增加了缓存的有效容量。这三个因素关注三个不同的方面，具有高度相关性。值得一提的是，传统的缓存策略，如LRU和LFU，并不是一个符合所有这些因素的通用解决方案（Li等人2019；Li和Gu 2020；Liu等人2020）。</li><li>PHOEBE是一种基于强化学习的在线缓存的可重用优化方案，适用于广泛的新兴存储模型。通过与缓存环境和数据流的持续交互，PHOEBE能够从单个跟踪中提取关键的时间数据依赖性和相对位置信息，随着时间的推移变得越来越智能。实验结果表明，PHOEBE能够将LRU和最先进的基于在线学习的缓存策略Belady最优策略之间的缓存未命中率差距分别缩小70.3%和52.6%。</li><li>PHOEBE预测了一个新定义的指标，即停留优先级，以表示每个数据块的相对重要性，而不是显式预测重用距离，重用距离可能是无界值，从而增加了高精度预测的难度和复杂性。当驱逐事件发生时，缓存根据其停留优先级值替换数据块（驱逐具有最低停留优先级的数据块），旨在最大化缓存命中率。停留优先级值具有时间滞后特性，在过时时间戳处的高优先级值不能在最新时间戳处保持同样高，因此它们通常与相应的时间戳组合以得出最终驱逐决定。PHOEBE关注9个特征来提取同时考虑全局和局部模式的重用信息。前六个特征和最后一个是全局特征；第7和第8特征是从当前数据块之前的滑动窗口收集的局部特征。数据块地址、数据块地址增量、频率、重复使用距离、最终重复使用距离、平均重复使用距离、滑动窗口中的频率、滑动窗口中的缓存未命中数、优先级值</li><li>将在线缓存问题建模为马尔可夫决策过程</li><li>LeCaR（Vietri等人，2018）：一种基于在线学习的缓存策略，根据学习到的概率在LRU和LFU缓存算法之间切换。</li><li>相关工作：将机器学习应用于缓存优化有两个主要途径：设计智能预取策略或改进缓存替换策略。</li></ul><h2 id="Sprout-A-functional-caching-approach-to-minimize-service-latency-in-erasure-coded-storage"><a href="#Sprout-A-functional-caching-approach-to-minimize-service-latency-in-erasure-coded-storage" class="headerlink" title="Sprout: A functional caching approach to minimize service latency in erasure-coded storage"></a>Sprout: A functional caching approach to minimize service latency in erasure-coded storage</h2><ul><li>利用缓存优化纠删码存储的性能，没有优化缓存策略。</li><li>论文提出一种新的具有纠删码存储的缓存框架，称为功能缓存。功能缓存涉及在缓存中使用纠删码块，使得存储节点中的块和缓存组合形成的代码是最大距离可分离（MDS）纠删码。</li></ul><h2 id="SSD-HDD混合存储中基于顺序封装的缓存取出"><a href="#SSD-HDD混合存储中基于顺序封装的缓存取出" class="headerlink" title="SSD-HDD混合存储中基于顺序封装的缓存取出"></a>SSD-HDD混合存储中基于顺序封装的缓存取出</h2><ul><li>论文提出了一种基于顺序打包的缓存逐出技术，该技术将垃圾收集（GC）块中的相邻冷数据页与位于其他SSD块中的相邻冷数据页数据分组。然后，打包这些数据页一起flush到较低级别的HDD存储中，以充分利用HDD的高顺序带宽。该方法可以减少写放大对SSD缓存的负面影响，并有助于提高SSD-HDD混合存储的I&#x2F;O性能。</li><li>Shi等人[13]提出了SSDUP+，该SSDUP＋采用SSD设备来缓冲随机访问的数据，并且顺序访问的数据被刷新到磁盘的低级别存储。在SSDUP+中，需要SSD缓存来缓存热读数据，尽管它们揭示了序列特征并直接刷新到HDD上。也就是说，如果SSD缓存已满，SSDUP+必须使用最近最少使用（LRU）策略来处理缓存逐出。</li><li>将热数据放在快速存储中，将冷数据放在慢速存储中并不是一个新想法，分层存储管理通常采用快速存储作为慢速存储的缓冲[5]。已经推出了许多结合HDD和SSD的混合存储解决方案，以提高读写吞吐量[11、12、14、15]。Chen等人[11]提出Hystor将低成本HDD和高速SSD相结合，以识别关键数据（例如元数据），从而将其保存在SSD中以快速响应。此外，它利用SSD作为回写缓冲区来吸收写请求，从而产生更好的写性能。HotDataTrap[20]建议仅缓冲SSD缓存中的热数据，并将冷数据直接刷新到HDD，这为热数据存储在缓存空间中提供了更多机会。类似地，Zhang等人[21]提出了一种基于机器学习的混合存储系统写策略。具体来说，它使用机器学习来识别只写数据，并将其直接刷新到HDD中，以最大限度地减少SSD的写入流量。混合存储系统的性能受到数据刷新例程或缓存逐出方案的严重影响[2，8]。</li><li>SeqPack的Hot Read&#x2F;Write Separate模块维护两个固定长度的LRU链接列表，以分别记录最近读取和写入的数据页，用于筛选热读取数据页而不是热写入。具体而言，在发生读或写访问之后，可以将数据页插入或移动到相应链接列表的开头。然后，两个LRU链接列表都维护最近访问的读写页，这样我们可以筛选热读数据页，但不筛选热写数据页，它们可以始终缓存在SSD缓存中，同时其他数据页被视为顺序打包的候选页。sequential packer模块依赖于所提出的顺序打包模型，通过将GC块中的弹出页面与其他SSD块中的冷数据页面打包，将许多随机写入分组为大型顺序写入。GC Selector模块以较小的成本释放SSD空间，引入了一种基于成本的选择方法来定位GC目标块，<ul><li>性能指标：I&#x2F;O响应时间、缓存命中率、长尾延迟。</li></ul></li></ul><h2 id="Improving-in-memory-file-system-reading-performance-by-fine-grained-user-space-cache-mechanisms（大数据场景的缓存优化）"><a href="#Improving-in-memory-file-system-reading-performance-by-fine-grained-user-space-cache-mechanisms（大数据场景的缓存优化）" class="headerlink" title="Improving in-memory file system reading performance by fine-grained user-space cache mechanisms（大数据场景的缓存优化）"></a>Improving in-memory file system reading performance by fine-grained user-space cache mechanisms（大数据场景的缓存优化）</h2><ul><li>随着服务器的内存容量越来越大，分布式内存文件系统已被广泛使用，该系统使应用程序能够快速与数据交互。然而，现有的分布式内存文件系统在小数据读取中仍然面临数据访问性能低的问题（非混合存储），这严重降低了它们在许多重要的大数据场景中的可用性。论文分析了影响内存文件读取性能的因素，并提出了一种两层用户空间缓存管理机制：在第一层，我们缓存数据包引用以减少频繁的页面故障中断（包级缓存）；在第二层，我们缓存和管理小文件数据单元，以避免冗余的进程间通信（对象级缓存）。设计了一个基于子模块函数优化理论的细粒度缓存模型，以有效地管理客户端具有部分重叠片段的可变长度缓存单元，更准确地识别热碎片，避免不必要的RPC通信。。重点是设计可变长度缓存块的管理机制和替换策略。</li><li>[15]提出了一种缓存模型，该模型使用不同的LRU队列来管理不同大小的文件。因此，它可以减少小文件被部分锁定的频率。为了使应用程序能够从客户端节点读取和写入数据，而不会失去全局文件系统命名空间的优势。传统的缓存替换策略包括FIFO、LRU[17]、LFU[18]、ARC[19]、FBR[20]和2Q[21]。根据[19]的结果，ARC通过复杂的自调整机制改进了基本的LRU策略，在各种工作负载上优于上述算法。然而，对大数据工作负载的实验表明，即使使用非常大的缓存空间，传统的缓存方法仍然遭受相对较低的命中率[22]。为了进一步提高I&#x2F;O性能，研究人员提出了大量方法，这些方法通过专门的指标来替代缓存候选[23–26]。</li><li>许多智能技术应用于广泛领域[33-35]。受此启发，一些研究人员采用了先进的数学方法或机器学习模型来描述和分析缓存问题。例如，[24，36]考虑马尔可夫决策过程背景下的缓存替换问题，[37，38]提出了基于强化学习和长短期记忆神经网络的更复杂场景下的智能缓存替换框架。特别是，在这些算法中，基于概率模型的EVA[24]通过充分利用所有缓存单元的命中、逐出和年龄分布，实现了最佳性能。</li><li>数据压缩是另一种常用于优化缓存空间利用率的策略。通常，压缩用于优化存储级别的访问性能。事实上，压缩也可以用于优化缓存性能[45–48]。压缩可以扩大有效的缓存容量，因此，通过保存更多对象可以减少缓存未命中。然而，由于压缩&#x2F;解压缩过程，压缩方案引入了额外的访问延迟。更糟糕的是，由于压缩比不可预测，这可能会导致性能下降。</li><li>数据包级缓存机制：在分布式文件系统中，要读取的数据被拆分为数据包，以便在多次小规模读取时容错和提高性能。当读取文件时，客户端调用mmap()将数据包映射到进程的虚拟地址空间，并调用munmap()读取后立即释放映射区域。在某种情况下，每个计算任务都将调用mmap()和munmap()，导致多页错误中断。为了提高读取性能，论文设计了一种包级缓存机制：在读取后不会立即释放它们，而是设法存储读取数据包的引用以供后续使用。数据包级缓存机制维护缓存队列。如果数据包的引用被减少到0，则该数据包的参考被放入队列。当队列大小超过阈值, 包将由munmap()根据缓存迁移策略调用。（带有优先级计数和缓存队列的数据包级缓存机制）</li><li>对象级缓存机制：哈希表：在第一级，整个文件被分成几个桶；每个文件片段根据其起始地址和结束地址被放入特定的存储桶中。红黑树：当单个存储桶中的单元数量超过限制时，缓存模型会根据当前存储桶中所有元素的地址将其放入红黑树中。当存储桶中的单元数小于限制时，原始红黑树将被删除。双重链接列表：文件片段自然按其起始地址和结束地址排序。每个缓存单元包含指向最近单元的前指针和后指针。</li><li>为了获得对象级缓存模型中缓存管理问题的近似解，论文实现了[53]提出的两种Greedy和ISK算法</li></ul><h2 id="Improving-NAND-Flash-Based-Disk-Caches"><a href="#Improving-NAND-Flash-Based-Disk-Caches" class="headerlink" title="Improving NAND Flash Based Disk Caches"></a>Improving NAND Flash Based Disk Caches</h2><ul><li>论文介绍了Flash在当今的服务器平台中用作磁盘缓存的研究。提出了两项改进。第一种方法通过将基于Flash的磁盘缓存拆分为单独的读写区域来提高性能和可靠性。第二种通过采用可编程闪存控制器来提高可靠性。它可以根据应用的需求改变错误码强度（可纠正位的数量）和存储单元可以存储的位的数量（单元密度）。Flash的可管理性和可靠性是一个具有挑战性的问题，需要解决这些问题才能将Flash完全集成到数据中心。提出了一种用于NAND闪存的硬件辅助软件管理磁盘缓存。</li><li>为了减轻磨损，对基于闪存的磁盘缓存的闪存擦除执行磨损级别管理。对于读缓存和写缓存，首先使用LRU策略选择要逐出的块，该策略针对磁盘缓存容量未命中（对于读缓存）或容量写入（对于写缓存，需要首先擦除块的异地写入）。然而，如果该块的磨损超过最新块的磨损预定阈值，则驱逐与最小磨损相对应的块（最新块）以平衡磨损水平。从整个闪存块集合中选择最新的块。在驱逐最新的块之前，它的内容被迁移到旧块。</li></ul><h2 id="Optimizing-the-SSD-Burst-Buffer-by-Traffic-Detection（细粒度缓存替换策略）"><a href="#Optimizing-the-SSD-Burst-Buffer-by-Traffic-Detection（细粒度缓存替换策略）" class="headerlink" title="Optimizing the SSD Burst Buffer by Traffic Detection（细粒度缓存替换策略）"></a>Optimizing the SSD Burst Buffer by Traffic Detection（细粒度缓存替换策略）</h2><ul><li>HPC存储系统仍然使用硬盘驱动器（HDD）作为其主要存储设备。固态驱动器（SSD）被广泛部署为HDD的缓冲区。还提出了突发缓冲器来管理突发写入请求的SSD缓冲。虽然突发缓冲区在许多情况下可以提高I&#x2F;O性能，但它具有一些限制，例如需要大的SSD容量以及计算阶段和数据flush阶段之间的和谐重叠。提出了一种称为SSDUP+的方案。SSDUP+旨在通过解决上述限制来改善突发缓冲区。首先，为了减少对SSD容量的需求，只选择一部分数据写入SSD，而其余数据则直接写入HDD，而不牺牲I&#x2F;O性能。开发了一种新的方法来检测和量化写入流量中的数据随机性。此外，提出了一种自适应算法来动态地对随机写入进行分类。通过这样做，需要更少的SSD容量来实现与其他突发缓冲方案类似的性能。然后，为了克服计算阶段和flush阶段完美重叠的困难，提出了SSD缓冲区的流水线机制，在流水线机制中，SSD缓冲区被分成两半。当一半接收写入数据时，另一半完全占用将数据从SSD刷新到HDD。其中数据缓冲和刷新在流水线中执行。为了提高I&#x2F;O吞吐量，采用了流量感知刷新策略来减少HDD中的I&#x2F;O干扰。最后，为了进一步提高SSD中缓冲随机写入的性能，SSDUP+通过使用日志结构存储数据，将SSD中的随机写入转换为顺序写入。此外，SSDUP+使用AVL树结构来存储数据的序列信息。SSDUP+以减少满足突发性大规模I&#x2F;O访问性能所需的SSD容量，从另一个角度来看，在相同的SSD容量下提高I&#x2F;O性能。</li><li>硬盘驱动器（HDD）仍然被用作HPC存储系统中的主要永久存储设备，部分原因是其成本低，可以在访问大型连续数据块时提供高带宽。然而，HDD有一个主要缺点：当随机访问数据时，由于磁盘头的缓慢机械移动，它们的性能很差。固态驱动器（SSD）等新的存储设备由于其接近零的寻道延迟和优异的性能（特别是对于随机访问）而被广泛部署在HPC环境中。然而，SSD比HDD昂贵得多。因此，在大规模生产HPC系统中使用SSD作为唯一的存储设备并不是一个经济高效的解决方案，更不用说SSD的技术限制，例如磨损和寿命有限的问题。解决HDD随机数据访问问题的一个流行解决方案是使用SSD缓冲HDD和计算节点之间的数据流。另一方面，对HDD的突发随机写入可能会显著降低HPC存储系统上运行的数据密集型应用程序的性能。为了解决上述问题，引入了突发缓冲器，它使用SSD缓冲器作为计算节点和基于HDD的存储服务器之间的中间层，以吸收突发写入请求。</li></ul><h2 id="Exploration-and-Exploitation-for-Buffer-Controlled-HDD-Writes-for-SSD-HDD-Hybrid-Storage-Server（细粒度缓存替换策略）"><a href="#Exploration-and-Exploitation-for-Buffer-Controlled-HDD-Writes-for-SSD-HDD-Hybrid-Storage-Server（细粒度缓存替换策略）" class="headerlink" title="Exploration and Exploitation for Buffer-Controlled HDD-Writes for SSD-HDD Hybrid Storage Server（细粒度缓存替换策略）"></a>Exploration and Exploitation for Buffer-Controlled HDD-Writes for SSD-HDD Hybrid Storage Server（细粒度缓存替换策略）</h2><ul><li>结合固态驱动器（SSD）和硬盘驱动器（HDD）的混合存储服务器为应用程序提供了成本效益和μ级响应能力。会导致HDD通常利用不足，而SSD使用过度，特别是在密集写入下。这会导致SSD的快速磨损和高尾部延迟。HDD的一系列顺序和连续写入呈现出周期性、阶梯状的写入延迟模式，即低（35μs）、中（55μs）和高延迟（12毫秒），这是由HDD控制器内的缓冲写入导致的。可以利用HDD的潜在μs级IO延迟，以吸收过多的SSD写入，而不会降低性能。论文建立了一个描述阶梯行为的HDD写入模型，并设计了一个配置过程来初始化和动态重新校准模型参数。然后，提出了一种缓冲区控制写入方法（BCW），以主动控制缓冲区写入，从而用应用程序数据调度低延迟和中延迟时段，并用填充数据填充高延迟时段。利用BCW，设计了一个混合IO调度器（MIOS），以自适应地将传入数据引导到SSD和HDD。进一步设计了多HDD调度以最小化HDD写入延迟</li></ul><h2 id="Cache-Replacement-Policy-Based-on-Expected-Hit-Count"><a href="#Cache-Replacement-Policy-Based-on-Expected-Hit-Count" class="headerlink" title="Cache Replacement Policy Based on Expected Hit Count"></a>Cache Replacement Policy Based on Expected Hit Count</h2><ul><li>现有处理器采用最近最少使用（LRU）策略的变体来确定替换的缓存块。不幸的是，LRU提供的服务与Belady的MIN之间存在很大差距，这是最佳的更换策略。Belady的MIN要求选择具有最长重用距离的缓存块，因此，由于需要了解未来，这是不可行的。在论文研究中，发现缓存块的预期命中数与其重用距离的倒数之间存在很强的相关性。论文提出了用于替换缓存中的缓存块的预期命中计数（EHC）策略，在现有低成本替换策略的基础上，采用基于命中计数的缓存块选择程序，以显著提高最后一级缓存中缓存块选择的质量，而无需相应的区域开销。</li><li>现代处理器经常需要从最后一级缓存中移出一段数据，以便为新数据留出空间。替换策略决定了在所有可能的候选项中，在新数据到达时应该从缓存中删除哪个候选项。</li><li>使用第二届缓存替换锦标赛（CRC2）发布的模拟框架评估预期命中计数（EHC）策略。</li></ul><h2 id="Hystor-Making-the-best-use-of-solid-state-drives-in-high-performance-storage-systems（分层存储）"><a href="#Hystor-Making-the-best-use-of-solid-state-drives-in-high-performance-storage-systems（分层存储）" class="headerlink" title="Hystor: Making the best use of solid state drives in high performance storage systems（分层存储）"></a>Hystor: Making the best use of solid state drives in high performance storage systems（分层存储）</h2><ul><li>由于SSD相对较高的价格和较低的容量，需要解决的一个主要系统研究问题是如何以成本和性能有效的方式使SSD在高性能存储系统中发挥最有效的作用。论文设计和实现Hystor高性能混合存储系统，Hystor将SSD和HDD作为一个单块设备进行管理，Hystor可以有效地识别（1）可能导致长延迟或（2）语义关键的块（例如文件系统元数据），并将其存储在SSD中以供将来访问，从而实现显著的性能改进。为了进一步利用最先进SSD中极高的写入性能，Hystor还充当回写缓冲区，以加快写入请求。</li><li>将高容量SSD视为存储的一部分，而不是缓存位置。相应地，与基于缓存的传统策略不同，基于缓存的策略在每次数据访问时频繁更新缓存内容，论文只定期和异步地重新组织设备之间的块布局，以实现长期优化。Hystor通过三个主要组件实现其数据管理的优化目标。首先，通过实时监控I&#x2F;O流量，Hystor自动学习工作负载访问模式并识别性能关键块。只有能够带来最大性能优势的块才能从HDD重新映射到高速SSD。第二，通过有效利用现有接口中可用的高级信息，Hystor识别语义关键块（例如文件系统元数据），并及时为它们提供高优先级，使其留在SSD中，这进一步提高了系统性能。第三，传入的写入被缓冲到低延迟SSD中，以提高写入密集型工作负载的性能。</li></ul><h2 id="Back-to-the-Future-Leveraging-Belady’s-Algorithm-for-Improved-Cache-Replacement"><a href="#Back-to-the-Future-Leveraging-Belady’s-Algorithm-for-Improved-Cache-Replacement" class="headerlink" title="Back to the Future: Leveraging Belady’s Algorithm for Improved Cache Replacement"></a>Back to the Future: Leveraging Belady’s Algorithm for Improved Cache Replacement</h2><ul><li>缓存是减少数据访问的长延迟的重要机制，其有效性受到其替换策略的显著影响。论文解释了缓存替换算法如何通过将其应用于过去的缓存访问来学习Belady的算法，以告知未来的缓存替换决策。并提出了基于Belady的缓存替换算法，将Belady方法的变体应用于过去的内存访问历史。如果过去的行为是未来行为的良好预测，论文提出的策略将接近Belady算法的行为。新缓存替换策略由两部分组成。第一个使用OPTgen算法重构了Belady对过去缓存访问的最佳解决方案。第二个是一个预测器，它可以学习OPT对过去PC的行为，以告知同一PC对未来负载的驱逐决定。</li><li>在缺乏明确反馈的情况下，现有的替换策略基于启发式方法，如最近最少使用（LRU）和最近最多使用（MRU），这两种方法都适用于不同的工作负载。然而，即使使用越来越聪明的技术来优化和组合这些策略，这些基于启发式的解决方案也仅限于特定类别的访问模式，无法在更复杂的场景中表现良好。</li><li>将缓存替换视为一个二进制分类问题，其目标是确定传入的行是缓存友好的还是缓存厌恶的：缓存友好的行以高优先级插入，而缓存厌恶的行被标记为未来冲突的驱逐候选行。为了确定传入线路应如何分类，Hawkeye重构了Belady对过去访问的最优解决方案，以了解单个加载指令的行为。</li></ul><h2 id="Performance-Evaluation-of-Traditional-Caching-Policies-on-A-Large-System-with-Petabytes-of-Data"><a href="#Performance-Evaluation-of-Traditional-Caching-Policies-on-A-Large-System-with-Petabytes-of-Data" class="headerlink" title="Performance Evaluation of Traditional Caching Policies on A Large System with Petabytes of Data"></a>Performance Evaluation of Traditional Caching Policies on A Large System with Petabytes of Data</h2><ul><li>大多数现有的缓存性能研究都评估填充相对较小缓存的、相当小的文件。很少有报告讨论了传统缓存替换策略在超大系统上的性能。论文在PB级存储系统中，全面评估了几种缓存策略的性能，包括先进先出（FIFO）、最近最少使用（LRU）和最不频繁使用（LFU）。研究表明当应用于大型数据集和小型数据集时，传统缓存策略能够提高性能。</li><li>在整个评估过程中，FIFO缓存替换策略经常导致比LRU或LFU显著更低的命中率，尽管有一小部分数据点的FIFO命中率较高。LRU缓存替换策略在所有测试的替换策略中获得了最高的比率，但与LFU策略相比，LRU导致平均命中率的标准偏差更高。当排除攻击性用户时，LFU缓存替换策略的平均命中率最高，而当LRU包含攻击性用户后，该策略的命中率仅超过0.29%。</li><li>将可用缓存的大小增加一倍，最多可以提高12%的命中率。论文建议额外的需求可以通过简单地扩展缓存大小来降低性能增益的价值。论文认为，对专用缓存策略进行更彻底的检查能够专注于大规模缓存大小的优化。通过将所使用的缓存大小增加一倍，命中率发生了相对较小的变化，这表明，在使用更有效的缓存策略的同时，缩小总体缓存大小将节省大量空间，并减少用作缓存所需的活动磁盘数。</li><li>预取是另一种有可能显著提高缓存性能的技术[24]，[25]，[26]，[27]，[28]。事实上，预取比简单地用流行文档加载缓存更有效[33]。有效的预取策略可以帮助缓存将命中率提高50%[32]。智能地预加载数据可以在不增加成本的情况下实现性能提高，因为使用预取的缓存可以与不使用预取缓存的两倍缓存一样有效[30]。已经证明，使用有效的预取方案可以显著减少不同缓存替换策略的命中率之间的差异，增强了格式良好的预取算法的重要性[33]。</li></ul><h2 id="Improving-Cache-Management-Policies-Using-Dynamic-Reuse-Distances"><a href="#Improving-Cache-Management-Policies-Using-Dynamic-Reuse-Distances" class="headerlink" title="Improving Cache Management Policies Using Dynamic Reuse Distances"></a>Improving Cache Management Policies Using Dynamic Reuse Distances</h2><ul><li>论文提出了一种新的PDP缓存管理策略，一种使用动态重用距离来进一步改进缓存替换策略，该策略防止替换缓存线，直到对其缓存集进行一定数量的访问，称为保护距离（PD）。该策略保护缓存线足够长，可以重复使用，但不能超过该长度，以避免缓存污染。这可以与旁路机制相结合，该机制也依赖于动态重用分析，以绕过预期重用较少的管线。如果没有未保护的行，则忽略未命中提取。提出了一种基于动态重用历史的命中率模型，并动态计算了使命中率最大的PD。PD会定期重新计算，以跟踪程序的内存访问行为和阶段。</li></ul><h2 id="Optimum-Caching-versus-LRU-and-LFU-Comparison-and-Combined-Limited-Look-Ahead-Strategies"><a href="#Optimum-Caching-versus-LRU-and-LFU-Comparison-and-Combined-Limited-Look-Ahead-Strategies" class="headerlink" title="Optimum Caching versus LRU and LFU: Comparison and Combined Limited Look-Ahead Strategies"></a>Optimum Caching versus LRU and LFU: Comparison and Combined Limited Look-Ahead Strategies</h2><ul><li>将基于最近最少使用（LRU）和最不频繁使用（LFU）替换原则的web缓存策略与根据Belady算法的最佳缓存进行比较。研究了一种结合LRU、LFU或其他非预测方法的有限前瞻最优策略的组合方法。、通过模拟，根据请求跟踪和独立参考模型（IRM）的前瞻性程度来评估命中率增益，并对观察到的行为进行分析确认。</li><li>将常用缓存策略的命中率和更新工作量与最佳缓存作为性能上限进行比较。缓存策略性能评估的三种基本方法是通过跟踪模拟、根据综合模型模拟运行生成的请求模式和分析。</li><li>对一种组合缓存方法的评估表明，优化缓存不仅可以提供缓存命中率上限，而且可以部分用于视频流的缓存和服务于巨大请求工作负载的缓存。对缓存和请求特定参数对有限前瞻方案适用性的影响进行更详细的分析，以供将来研究。</li></ul><h2 id="A-Distributed-Block-Storage-Optimization-Mechanism-Based-on-Ceph"><a href="#A-Distributed-Block-Storage-Optimization-Mechanism-Based-on-Ceph" class="headerlink" title="A Distributed Block Storage Optimization Mechanism Based on Ceph"></a>A Distributed Block Storage Optimization Mechanism Based on Ceph</h2><ul><li>为了应对企业在提高块存储服务的资源利用率和读&#x2F;写速率方面面临的挑战，Ceph提供了缓存分层，以提高异构存储环境中的群集性能。然而，由于缓存污染，缓存分层中最近最少使用的（LRU）算法会驱逐更多有价值的数据，这会导致某些请求的延迟更高；同时，当在存储节点上分配数据时，可扩展哈希下的受控复制（CRUSH）算法只考虑存储节点容量，这使得Ceph无法动态平衡节点的I&#x2F;O负载。为了解决这些问题，提出了一种基于预测模型的存储选择策略，以提高缓存池中对象访问的命中率，提高集群的整体I&#x2F;O性能；此外，还提出了缓存池I&#x2F;O负载平衡策略。与原生机制相比，所提出的块存储优化机制可以实现更高的I&#x2F;O吞吐量和更均衡的I&#x2F;O负载。</li><li>当数据在缓存层被逐出时，缓存分层中的LRU算法仅基于最近的访问记录逐出数据，这可能会由于偶尔的冷数据访问而导致逐出更有价值的热数据[3]。基于Ceph的缓存分层机制，论文提出了一种基于预测模型的存储选择策略，该策略根据对象访问频率确定对象请求是访问SSD OSD池还是访问后端HDD OSD池。该策略可以减少冷数据处理所造成的不必要开销，从而提高集群的总体I&#x2F;O性能。</li><li>为了有效利用缓存分层中有限的缓存池资源，冷数据应该存储在后端存储池中，而热数据应该存储到缓存池中。因此，在海量数据存储的背景下，区分数据的热量（即访问频率）并采用不同的处理策略可以充分利用Cache Tiering中的存储资源，并减少冷数据处理（例如冷数据从后端存储池进入缓存池，LRU驱逐冷数据）所造成的不必要开销。提出了一种基于预测模型的存储选择策略。该策略适应海量数据存储的特点，分析存储对象的长期访问记录。同时，根据某一时间段内的对象热度，判断是选择访问SSD缓存池还是后端HDD存储池，以减少冷数据处理带来的不必要开销，最终提高集群性能。</li></ul><h2 id="Maximizing-Cache-Performance-Under-Uncertainty（提出EVA）2017-HPCA"><a href="#Maximizing-Cache-Performance-Under-Uncertainty（提出EVA）2017-HPCA" class="headerlink" title="Maximizing Cache Performance Under Uncertainty（提出EVA）2017 HPCA"></a>Maximizing Cache Performance Under Uncertainty（提出EVA）2017 HPCA</h2><ul><li>指出Belady理论假设了对未来的完全了解，但这在实践中是不可用的，其明显在信息不完善的情况下是次优的。并建议：对于实际的缓存替换，应该根据其经济增加值（即其预期命中率与平均值的差异）来替代。缓存替换中的两个主要权衡：命中概率和缓存空间，并描述了EVA如何在一个直观的度量中协调它们。通过借鉴马尔可夫决策过程（MDP）理论，证明了EVA最大化了缓存命中率。</li><li>最常见的缓存替换策略是使用最近性和频率启发式。大多数缓存替换策略采用某种形式的最近性，有利于最近被引用的候选人：例如，LRU仅使用最近性，而RRIP[17，39]预测较老的候选人需要更长的时间才能被引用。类似地，一些不假设最近的政策仍然基于候选人最后被引用的时间：PDP[14]保护候选人直到某个年龄；IRGD[35]使用年龄的启发式函数。另一种常见的缓存替换策略解释动态行为的方式是通过频率，倾向于先前重用的候选：例如，LFU单独使用频率，ARC[26]和SRRIP[17]等“抗扫描”策略倾向于至少重用一次的候选。</li><li>EVA缓存替换策略：本质上是一种成本效益分析，即候选数据的命中概率是否值得其所消耗的缓存空间。EVA将每个候选数据选视为一项投资，试图留住利润最高的候选候选（以命中率衡量）。首先，EVA奖励每个候选数据预期的未来命中率。然后，由于缓存空间是一种稀缺资源，EVA需要考虑每个候选将消耗多少空间。EVA通过对每个候选数据在缓存中花费的时间“收费”来实现这一点。具体而言，EVA以单行的平均命中率（即缓存的命中率除以其大小）对候选项收费，因为这是消耗缓存空间的长期机会成本。<br>EVA &#x3D; Expected hits - (Cache hit rate&#x2F; Cache size) * Expected time</li><li>EVA策略的实现主要包括以下几个步骤：<ol><li>计算每个缓存行的经济增值（EVA）：EVA是一个衡量缓存行价值的指标，它考虑了缓存行的命中概率和占用缓存空间的时间成本。具体地，EVA等于缓存行的期望命中次数减去缓存的命中率乘以缓存行在缓存中的时间。 </li><li>选择EVA最小的缓存行进行替换：当需要替换缓存行时，EVA策略会选择EVA最小的缓存行进行替换。这是因为EVA最小的缓存行对缓存的贡献最小，替换它可以最大化缓存的命中率。</li><li>更新缓存行的EVA值：当缓存行被访问时，EVA策略会更新它的EVA值。具体地，EVA策略会根据缓存行的命中情况和占用缓存空间的时间，重新计算缓存行的EVA值。 </li><li>调整缓存大小：EVA策略还可以根据缓存的命中率和缓存行的EVA值，动态调整缓存的大小。具体地，当缓存的命中率较低时，EVA策略会增加缓存的大小；当缓存的命中率较高时，EVA策略会减小缓存的大小。 EVA策略的实现比较简单，只需要对每个缓存行维护一个EVA值，并选择EVA最小的缓存行进行替换即可。</li></ol></li></ul><h2 id="LHD-Improving-Cache-Hit-Rate-by-Maximizing-Hit-Density-2018-NSDI"><a href="#LHD-Improving-Cache-Hit-Rate-by-Maximizing-Hit-Density-2018-NSDI" class="headerlink" title="LHD: Improving Cache Hit Rate by Maximizing Hit Density  2018 NSDI"></a>LHD: Improving Cache Hit Rate by Maximizing Hit Density  2018 NSDI</h2><ul><li>云应用程序的性能严重依赖于数据中心键值缓存的命中率。键值缓存通常使用最近最少使用（LRU）作为其逐出策略，但在实际工作负载下，LRU的命中率远不是最佳的。论文提出最小命中密度（LHD）缓存替换算法，这是一种针对键值缓存的新驱逐策略。LHD预测每个对象每消耗空间的预期命中率（命中密度），过滤对缓存命中率贡献不大的对象。与先前的驱逐策略不同，LHD不依赖启发式，而是使用条件概率严格地模拟对象的行为，以实时调整其行为。</li><li>缓存命中率的小幅增加会对应用程序性能产生巨大影响。例如，将命中率从98%提高到99%，只需1%，就可以将对数据库的请求数量减半。使用上面使用的延迟数，这将平均服务时间从210µs减少到110µs（接近2倍），并且对于云应用程序来说，重要的是，将长延迟请求的尾部减半[21]。为了提高缓存命中率，云提供商通常会扩展服务器数量，从而增加缓存总容量[37]。从长远来看，添加缓存容量是不可行的，因为命中率随着缓存容量的增加呈对数增长[3，13，20]。需要大量内存才能显著影响命中率。在一定的缓存空间条件下，可以采用高效的缓存替换策略来提高缓存命中率。</li><li>流行的内存缓存使用最近最少使用（LRU）或LRU的变体作为其逐出策略。然而，LRU远不是缓存工作负载的最佳选择，因为：当工作负载具有可变的对象大小时，LRU的性能会受到影响，以及常见的访问模式暴露了LRU中的病态，导致命中率低。LRU的这些缺点已经得到了充分的记录，先前的工作已经提出了许多针对LRU的驱逐政策[4，14，16，25，35，38，40]。然而，这些策略并没有被广泛采用，因为它们通常需要大量的参数调整，这使得它们的性能不可靠，并且全局同步状态会影响它们的请求吞吐量。</li><li>论文提出命中密度的概念，用它衡量对象对缓存命中率的贡献程度。根据每个对象的信息（其年龄或大小）推断出每个对象的命中密度，然后以最小的命中密度（LHD）驱逐该对象。最小命中密度（LHD）是一种基于命中密度的缓存替换策略。LHD在线监控对象，并使用条件概率预测其可能的行为。LHD利用了许多不同的对象特性（例如，年龄、频率、应用程序id和大小），并且很容易支持其他对象。动态排名使LHD能够随时间调整其替换策略，以适应不同的应用程序工作负载，而无需任何手动调整。例如，在某个工作负载上，LHD可能最初接近LRU，然后切换到最近使用的（MRU）、最不频繁使用的（LFU）或其组合。LHD动态预测每个对象每消耗空间的预期命中率或命中密度，并以最低的命中率驱逐对象。通过过滤掉对缓存命中率贡献不大的对象，LHD逐渐提高了平均命中率。</li><li>根据Memcachier[36]提供的为期一周的商业memcached跟踪和Microsoft Research提供的存储跟踪对LHD进行了评估[48]。LHD显著提高了先前策略的命中率，例如，与LRU相比，将未命中率减少了一半，与最近的策略相比，减少了四分之一，并且还避免了诸如影响先前策略的性能悬崖等问题。图1显示了实现与LHD相同命中率所需的缓存大小，Memcachier上为256 MB，Microsoft跟踪上为64 GB。LHD需要的空间比以前的驱逐策略少得多，从而节省了现代数据中心数千台服务器的成本。</li><li>先前的缓存替换策略以许多不同的方式改进了LRU。几乎所有的政策都通过额外的机制来改善其最坏的病理状况。例如，ARC[35]使用两个LRU列表来区分新进入的对象，并限制来自不常访问对象的污染。类似地，AdaptSize[9]在LRU列表前面添加了一个概率过滤器，以限制大型物体的污染。最近的一些策略将访问划分为多个LRU列表，以消除性能悬崖[6，18，51]或在不同大小的对象之间分配空间[10，17，18，37，41，43，49]。所有这些策略都使用LRU列表作为核心机制，因此保留了最近性作为内置假设。此外，他们增加的机制可以引入新的假设和病理。例如，ARC通过将频繁访问的对象与新允许的对象放在一个单独的LRU列表中，并倾向于驱逐新允许的物体，从而假设频繁访问的物体更有价值。这通常是LRU的改进，但可能表现为病态。</li><li>EVA，一种最近针对处理器缓存的驱逐策略[7，8]，引入了使用条件概率来平衡命中与消耗的资源的想法。LHD和EVA之间有几个显著的差异，使LHD能够在关键价值工作负载上表现出色。首先，LHD和EVA使用不同的排名功能。EVA根据对象的命中率（而不是命中密度）对其进行排名。</li><li>LHD算法的实现过程如下：<ol><li>首先，需要为每个对象计算其期望的命中率。这可以通过以下公式计算： Hit density &#x3D; Hit probability * Object size &#x2F; Expected time in cache 其中，Hit probability是对象在其生命周期内被访问的概率，Object size是对象的大小，Expected time in cache是对象在缓存中的期望时间。在LHD算法中，Expected time in cache是通过对象的访问模式和缓存的大小等因素来计算的。具体地，可以使用以下公式计算对象的Expected time in cache： Expected time in cache &#x3D; (Cache size &#x2F; Object size) * (1 &#x2F; Hit probability) 其中，Cache size是缓存的大小，Object size是对象的大小，Hit probability是对象在其生命周期内被访问的概率。这个公式的意思是，如果缓存中有足够的空间来存储对象，那么对象在缓存中的期望时间就是对象被访问的平均间隔时间的倒数。这个期望时间可以用来计算对象的期望命中率，从而帮助LHD算法更好地预测对象的命中率。</li><li>然后，需要为每个对象维护一个命中率分布。这可以通过记录对象的命中和驱逐时间来实现。当对象被命中时，将其命中时间添加到命中率分布中。当对象被驱逐时，将其驱逐时间添加到驱逐率分布中。 </li><li>当需要驱逐一个对象时，LHD算法会选择命中率分布最小的对象进行驱逐。这可以通过计算每个对象的命中率分布的加权平均值来实现。具体地，对于每个对象，将其命中率分布的每个时间点乘以其命中率，然后将所有时间点的乘积相加，得到该对象的加权平均命中率。然后，选择加权平均命中率最小的对象进行驱逐。</li><li>在实现过程中，还可以使用其他技术来优化LHD算法的性能。例如，可以使用分类来改进预测，以便更好地考虑对象的特征。还可以使用并发技术来提高算法的吞吐量。 总之，LHD算法的实现过程包括计算对象的期望命中率，维护命中率分布，选择命中率分布最小的对象进行驱逐等步骤。通过这些步骤，LHD算法可以更好地预测对象的命中率，从而提高缓存</li></ol></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;TDC-Pool-level-object-cache-replacement-algorithm-based-on-temperature-density&quot;&gt;&lt;a href=&quot;#TDC-Pool-level-object-cache-replacement-al</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>存储性能测试工具</title>
    <link href="https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    <id>https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</id>
    <published>2021-10-11T05:26:35.000Z</published>
    <updated>2024-08-03T06:56:02.287Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FIO简介"><a href="#FIO简介" class="headerlink" title="FIO简介"></a>FIO简介</h2><p>FIO是Linux下开源的一款IOPS测试工具，主要用来对磁盘进行压力测试和性能验证。它可以产生许多线程或进程来执行用户特定类型的I&#x2F;O操作，通过编写作业文件或者直接命令去执行测试动作，相当于是一个 多线程的io生成工具，用于生成多种IO模式来测试硬盘设备的性能（大多情况用于测试裸盘性能）。<br>硬盘I&#x2F;O测试主要有以下类型：</p><ul><li>随机读</li><li>随机写</li><li>顺序读</li><li>顺序写</li><li>混合读写 （可根据需求设置70%读，30%写或100%读等等）</li></ul><h2 id="FIO的安装与使用"><a href="#FIO的安装与使用" class="headerlink" title="FIO的安装与使用"></a>FIO的安装与使用</h2><p>github地址：github.com&#x2F;axboe&#x2F;fio<br>下载安装方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1</span></span><br><span class="line">yum -i install fio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2</span></span><br><span class="line">yum -y install libaio-devel   <span class="comment">#安装libaio引擎，不然执行fio会报“fio: engine libaio not loadable”，必须要在fio安装前安装，不然还要重新编译安装一遍fio</span></span><br><span class="line">wget https://github.com/axboe/fio/archive/refs/tags/fio-3.10.zip</span><br><span class="line"><span class="built_in">cd</span> /root/fio-fio-3.10</span><br><span class="line">./configure</span><br><span class="line">mke &amp;&amp; make install</span><br></pre></td></tr></table></figure><h2 id="常用参数介绍"><a href="#常用参数介绍" class="headerlink" title="常用参数介绍"></a>常用参数介绍</h2><ul><li>filename&#x3D;&#x2F;dev&#x2F;sdb  要测试盘的名称，支持文件系统或者裸设备，&#x2F;dev&#x2F;sda2或&#x2F;dev&#x2F;sdb</li><li>direct&#x3D;1  测试过程绕过机器自带的buffer，使测试结果更真实（Linux在读写时，数据会先写到缓存，再在后台写到硬盘，读的时候也是优先从缓存中读，这样访问速度会加快，但是一旦掉电，缓存中数据就会清空，所有一种模式为DirectIO，可以跳过缓存，直接读写硬盘）</li><li>ioengine&#x3D;libaio  定义使用什么io引擎去下发io请求<ul><li>sync：同步IO引擎，使用Linux系统调用实现IO操作，可以测试磁盘性能的上限。</li><li>mmap：使用内存映射技术实现IO操作，可以测试文件系统的缓存和文件的预读能力。</li><li>libaio：异步IO引擎，使用Linux系统调用libaio实现IO操作，可以测试磁盘的随机读写性能。</li><li>posixaio：类似于libaio的异步IO引擎，但使用POSIX AIO接口实现IO操作。</li><li>pvsync：使用Linux系统调用实现IO操作，但对写操作进行缓存，并且只在需要时进行刷新，可以提高IO性能。</li><li>rbd：用于测试Ceph集群中rados block device (RBD)的性能，支持异步IO和同步IO操作。</li></ul></li><li>iodepth&#x3D;16  队列的深度为16，在异步模式下，CPU不能一直无限的发命令到硬盘设备。比如SSD执行读写如果发生了卡顿，那有可能系统会一直不停的发命令，几千个，甚至几万个，这样一方面SSD扛不住，另一方面这么多命令会很占内存，系统也要挂掉了。这样，就带来一个参数叫做队列深度。</li><li>bs&#x3D;4k   单次io的块文件大小为4k</li><li>numjobs&#x3D;10   并发工作线程数</li><li>size&#x3D;5G      每个线程读写的数据量是5GB</li><li>runtime&#x3D;60   测试时间为60秒，可以设置2m为两分钟。如果不配置此项，会将设置的size大小全部写入或者读取完为止</li><li>rw&#x3D;randread   测试随机读的I&#x2F;O</li><li>rw&#x3D;randwrite  测试随机写的I&#x2F;O</li><li>rw&#x3D;randrw     测试随机混合写和读的I&#x2F;O</li><li>rw&#x3D;read       测试顺序读的I&#x2F;O</li><li>rw&#x3D;write      测试顺序写的I&#x2F;O</li><li>rw&#x3D;rw         测试顺序混合写和读的I&#x2F;O</li><li>thread        使用pthread_create创建线程，另一种是fork创建进程。进程的开销比线程要大，一般都采用thread测试</li><li>rwmixwrite&#x3D;30   在混合读写的模式下，写占30%（即rwmixread读为70%，单独配置这样的一个参数即可）</li><li>group_reporting 关于显示结果的，汇总每个进程的信息</li><li>name&#x3D;”TDSQL_4KB_read_test”  定义测试任务名称<br>扩展</li><li>lockmem&#x3D;1g       只使用1g内存进行测试</li><li>zero_buffers     用全0初始化缓冲区，默认是用随机数据填充缓冲区</li><li>random_distribution&#x3D;random    #默认情况下，fio 会在询问时使用完全均匀的随机分布，有需要的话可以自定义访问区域，zipf、pareto、normal、zoned</li><li>nrfiles&#x3D;8        每个进程生成文件的数量</li></ul><h2 id="测试场景示例"><a href="#测试场景示例" class="headerlink" title="测试场景示例"></a>测试场景示例</h2><p>100%随机读，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randread -group_reporting -name=<span class="string">&quot;TDSQL_4KB_randread_test&quot;</span></span><br></pre></td></tr></table></figure><p>100%顺序读，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=<span class="built_in">read</span> -group_reporting -name=<span class="string">&quot;TDSQL_4KB_write_test&quot;</span></span><br></pre></td></tr></table></figure><p>70%随机读，30%随机写，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=<span class="string">&quot;TDSQL_4KB_randread70-write_test&quot;</span></span><br></pre></td></tr></table></figure><p>70%顺序读，30%随机写，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=rw -rwmixread=70 -group_reporting -name=<span class="string">&quot;TDSQL_4KB_read70-write_test&quot;</span></span><br></pre></td></tr></table></figure><h2 id="输出报告"><a href="#输出报告" class="headerlink" title="输出报告"></a>输出报告</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]# fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=<span class="string">&quot;local_randrw_test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">local_randrw_test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16</span><br><span class="line">...</span><br><span class="line">fio-3.10</span><br><span class="line">Starting 10 threads</span><br><span class="line">Jobs: 10 (f=10): [m(10)][100.0%][r=19.4MiB/s,w=8456KiB/s][r=4969,w=2114 IOPS][eta 00m:00s]</span><br><span class="line">local_randrw_test: (groupid=0, <span class="built_in">jobs</span>=10): err= 0: pid=11189: Mon Oct 25 11:01:46 2021</span><br><span class="line">   <span class="built_in">read</span>: IOPS=5230, BW=20.4MiB/s (21.4MB/s)(1226MiB/60031msec)</span><br><span class="line">    slat (usec): min=2, max=342637, avg=1266.82, stdev=7241.29</span><br><span class="line">    clat (usec): min=4, max=459544, avg=20056.81, stdev=24888.90</span><br><span class="line">     lat (usec): min=134, max=459586, avg=21329.16, stdev=25378.16</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  1467],  5.00th=[  1844], 10.00th=[  2147], 20.00th=[  2606],</span><br><span class="line">     | 30.00th=[  3032], 40.00th=[  3556], 50.00th=[  4359], 60.00th=[  6063],</span><br><span class="line">     | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507],</span><br><span class="line">     | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[152044],</span><br><span class="line">     | 99.99th=[219153]</span><br><span class="line">   bw (  KiB/s): min=  795, max= 4494, per=9.91%, avg=2072.23, stdev=744.04, samples=1195</span><br><span class="line">   iops        : min=  198, max= 1123, avg=517.74, stdev=186.00, samples=1195</span><br><span class="line">  write: IOPS=2243, BW=8972KiB/s (9188kB/s)(526MiB/60031msec)</span><br><span class="line">    slat (usec): min=2, max=311932, avg=1272.76, stdev=7272.09</span><br><span class="line">    clat (usec): min=6, max=458031, avg=20206.30, stdev=24897.71</span><br><span class="line">     lat (usec): min=974, max=459755, avg=21484.12, stdev=25400.41</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  1500],  5.00th=[  1860], 10.00th=[  2147], 20.00th=[  2606],</span><br><span class="line">     | 30.00th=[  3064], 40.00th=[  3621], 50.00th=[  4424], 60.00th=[  6194],</span><br><span class="line">     | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507],</span><br><span class="line">     | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[149947],</span><br><span class="line">     | 99.99th=[200279]</span><br><span class="line">   bw (  KiB/s): min=  357, max= 1944, per=9.90%, avg=888.57, stdev=325.49, samples=1195</span><br><span class="line">   iops        : min=   89, max=  486, avg=221.80, stdev=81.37, samples=1195</span><br><span class="line">  lat (usec)   : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.02%, 500=0.01%</span><br><span class="line">  lat (usec)   : 750=0.01%, 1000=0.01%</span><br><span class="line">  lat (msec)   : 2=7.45%, 4=38.36%, 10=18.10%, 20=1.09%, 50=22.31%</span><br><span class="line">  lat (msec)   : 100=11.42%, 250=1.24%, 500=0.01%</span><br><span class="line">  cpu          : usr=0.26%, sys=19.41%, ctx=12026, majf=0, minf=18</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=100.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=313975,134655,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=16</span><br><span class="line"></span><br><span class="line">Run status group 0 (all <span class="built_in">jobs</span>):</span><br><span class="line">   READ: bw=20.4MiB/s (21.4MB/s), 20.4MiB/s-20.4MiB/s (21.4MB/s-21.4MB/s), io=1226MiB (1286MB), run=60031-60031msec</span><br><span class="line">  WRITE: bw=8972KiB/s (9188kB/s), 8972KiB/s-8972KiB/s (9188kB/s-9188kB/s), io=526MiB (552MB), run=60031-60031msec</span><br><span class="line"></span><br><span class="line">Disk stats (<span class="built_in">read</span>/write):</span><br><span class="line">  sdb: ios=314008/134653, merge=0/0, ticks=189470/89778, in_queue=279286, util=99.75%</span><br></pre></td></tr></table></figure><p>输出报告分析<br>下面是每个执行的数据方向的I&#x2F;O统计数据信息的代表值含义</p><ul><li><p>read&#x2F;write： 读&#x2F;写的IO操作（还有一个trim没用过）</p><ul><li>salt： 提交延迟，这是提交I&#x2F;O所花费的时间（min:最小值，max:最大值，avg:平均值，stdev:标准偏差）</li><li>chat： 完成延迟，表示从提交到完成I&#x2F;O部分的时间</li><li>lat： 相应时间，表示从fio创建I&#x2F;O单元到完成I&#x2F;O操作的时间</li><li>bw： 带宽统计</li><li>iops： IOPS统计</li></ul></li><li><p>lat(nsec&#x2F;usec&#x2F;msec)： I&#x2F;O完成延迟的分布。这是从I&#x2F;O离开fio到它完成的时间。与上面单独的读&#x2F;写&#x2F;修剪部分不同，这里和其余部分的数据适用于报告组的所有I&#x2F; o。10&#x3D;0.01%意味着0.01%的I&#x2F;O在250us以下完成。250&#x3D;0.02%意味着0.02%的I&#x2F;O需要10到250us才能完成。</p></li><li><p>cpu： cpu使用率</p></li><li><p>IO depths： I&#x2F;O深度在作业生命周期中的分布</p><ul><li>IO submit： 在一个提交调用中提交了多少个I&#x2F;O。每一个分录表示该数额及其以下，直到上一分录为止——例如，4&#x3D;100%意味着我们每次提交0到4个I&#x2F;O调用</li><li>IO complete： 和上边的submit一样，不过这个是完成了多少个</li><li>IO issued rwt： 发出的read&#x2F;write&#x2F;trim请求的数量，以及其中有多少请求被缩短或删除</li><li>IO latency： 满足指定延迟目标所需的I&#x2F;O深度</li></ul></li><li><p>bw： 总带宽以及最小和最大带宽</p></li><li><p>io： 该组中所有线程执行的累计I&#x2F;O</p></li><li><p>run： 这组线程中最小和最长的运行时。</p></li><li><p>ios： 所有组的I&#x2F; o个数</p></li><li><p>merge： I&#x2F;O调度器执行的总合并数</p></li><li><p>ticks： 使磁盘繁忙的滴答数（仅供参考，原文是Number of ticks we kept the disk busy）</p></li><li><p>in_queue： 在磁盘队列中花费的总时间</p></li><li><p>util： 磁盘利用率。值为100%意味着我们保留了磁盘，如果一直很忙，那么50%的时间磁盘就会闲置一半的时间</p></li></ul><h2 id="FIO通过配置文件运行"><a href="#FIO通过配置文件运行" class="headerlink" title="FIO通过配置文件运行"></a>FIO通过配置文件运行</h2><p>除了命令行直接执行命令外，也可以通过写配置到xxx.fio文件中，每次只用修改配置即可，使用更方便些，执行方式为fio xxx.fio</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">jobs</span>]# <span class="built_in">cat</span> test.fio</span><br><span class="line">[global]</span><br><span class="line">filename=/dev/sdb</span><br><span class="line">ioengine=libaio</span><br><span class="line">direct=1</span><br><span class="line">thread</span><br><span class="line">group_reporting</span><br><span class="line"></span><br><span class="line">[randread-4k-128M]</span><br><span class="line">rw=randread</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line">[randwrite-4k-128M]</span><br><span class="line">rw=randwrite</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line">[write-4k-128M]</span><br><span class="line">rw=write</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行fio命令测试</span></span><br><span class="line">[root@localhost <span class="built_in">jobs</span>]# fio test.fio</span><br><span class="line">randread-4k-128M: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">randwrite-4k-128M: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">write-4k-128M: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.10</span><br><span class="line">Starting 15 threads</span><br><span class="line">Jobs: 6 (f=6): [_(3),r(1),_(1),w(5),E(1),_(4)][92.1%][r=10.8MiB/s,w=29.2MiB/s][r=2777,w=7483 IOPS][eta 00m:05s]</span><br></pre></td></tr></table></figure><h2 id="性能关注的重点"><a href="#性能关注的重点" class="headerlink" title="性能关注的重点"></a>性能关注的重点</h2><ol><li><strong>顺序读写和随机读写</strong>：顺序读写指对大块数据进行读写操作，随机读写则是对随机位置的小块数据进行读写操作。顺序读写通常比随机读写更快，因为它可以利用SSD的顺序读写优势。然而，随机读写需要处理更多的数据以找到所需数据，因此其IOPS和带宽通常低于顺序读写。</li><li><strong>SSD与HDD性能比较</strong>：<ul><li><strong>HDD</strong>：顺硬盘驱动器 (HDD) 的顺序读写和随机读写性能是不同的。顺序读写操作是指读写大块连续的数据，这是硬盘驱动器的强项。因为磁头可以直接读写连续的数据块，因此顺序读写速度快。随机读写操作是指读写随机位置的小块数据，这是硬盘驱动器的弱点。因为磁头需要频繁移动以读写不同的数据块，因此随机读写速度较慢。因此，硬盘驱动器的顺序读写速度通常比随机读写速度快。在评估硬盘驱动器性能时，需要考虑两种读写方式的结果。</li><li><strong>SSD</strong>：SSD 具有很高的随机读写性能，但顺序读写性能仍然不如随机读写性能。因为 SSD 需要管理大量的块，因此对大块连续的数据的读写可能不如对随机位置的小块数据的读写快。但需要注意的是，SSD 的顺序读写性能仍然高于硬盘驱动器 (HDD)。因此，即使是 SSD 的顺序读写性能不如随机读写性能，它仍然具有很高的性能。</li></ul></li></ol><h3 id="测试配置建议"><a href="#测试配置建议" class="headerlink" title="测试配置建议"></a>测试配置建议</h3><ol><li><strong>numjobs和iodepth设置</strong>：<ul><li>numjobs过大可能导致任务等待时间过长，建议设置为1、2、4、8。</li><li>iodepth可以设置大一些，建议为64、128，以增加IO任务队列。</li></ul></li><li><strong>利用率观察</strong>：通过<code>iostat -x -m 5 /dev/sdb</code>查看磁盘的utilize是否达到百分百。如果未达到，可继续增加numjobs直到utilize达到百分百。</li><li><strong>关闭写缓存</strong>：<ul><li>关闭写缓存可以提高数据持久性测试的准确性。</li><li>使用<code>hdparm -W /dev/device</code>查看当前状态，<code>hdparm -W 0 /dev/device</code>关闭写缓存。</li></ul></li></ol><h3 id="其他建议"><a href="#其他建议" class="headerlink" title="其他建议"></a>其他建议</h3><ol><li><strong>获取设备信息</strong>：使用<code>smartctl -a /dev/device</code>获取设备型号、连接版本和速度。</li><li><strong>numjobs大小</strong>:FIO的多线程调度其实还是一个进程，numjobs过大的话会导致任务等待时间过长，任务一直在排队。numjobs不能开太大，建议是1、2、4、8；iodepth任务可以开大点，建议是64、128，因为队列任务相当于IO任务，进行压测时，numjobs从1、2、4、8往上调，同时使用<code>iostat -x -m 5 /dev/sdb</code>查看磁盘的utilize是否达到百分百；如果当前numjobs的utilize还不是百分百，表示不是压测，numjobs再往上加，直到utilize达到百分百为止。</li><li><strong>多个fio进程测一个SSD和一个fio进程多线程测一个SSD的区别</strong><ul><li>多个fio进程测一个SSD和一个fio进程多线程测一个SSD的主要区别在于并发性和资源利用率。多个fio进程可以并发地访问SSD并生成更多的负载，这可以更好地测试SSD的并行读写能力和响应时间，但同时也会占用更多的CPU和内存资源。此外，由于多个fio进程之间的I&#x2F;O请求存在竞争关系，可能会影响测试结果的准确性和一致性。</li><li>相比之下，一个fio进程多线程测一个SSD可以更好地利用系统资源并模拟真实的应用程序I&#x2F;O模式。在这种情况下，每个线程可以并发地访问SSD并生成负载，同时避免了多个fio进程之间的竞争关系。这可以更好地测试SSD的性能和稳定性，并提供更准确的测试结果。</li><li>总的来说，两种方法都有其优缺点和适用场景。需要根据实际情况选择适当的测试方法来评估SSD的性能和可靠性。</li></ul></li><li><strong>磁盘性能摸底时需要关闭写缓存？</strong><ul><li>在使用fio进行性能测试时，是否需要关闭写缓存取决于具体的测试需求和测试方案。如果测试场景需要模拟真实应用程序中的写操作，并希望测试结果反映出SSD的真实性能水平，那么建议关闭写缓存，以便更准确地衡量SSD的写性能和数据持久性。然而，在某些情况下，为了测试SSD的I&#x2F;O性能而不是数据持久性，或者为了测试SSD的读性能，可能需要保持写缓存打开。因此，是否需要关闭写缓存取决于具体的测试需求和测试方案，需要根据实际情况进行决定。</li><li>关闭写缓存会使得磁盘的性能更具可预测性，因为每次写入都会立即被持久化到磁盘上，可以更准确地测试磁盘的写入性能和数据持久性。然而，关闭写缓存会使得写入操作变慢，因为每个写入操作都必须等待磁盘确认数据已经被永久写入。</li><li>不关闭写缓存会使得磁盘的写入性能更高，因为数据可以先被缓存起来，减少了写入操作对磁盘的访问次数，从而提高了写入性能。然而，数据可能会在缓存中存储一段时间，而不是立即写入磁盘，这可能会导致数据丢失或不一致。</li></ul></li></ol><p>通过合理配置fio参数，可以有效测试存储系统的性能。需要根据实际需求选择适当的测试方法和参数设置，确保测试结果的准确性和代表性。在测试过程中，需特别注意顺序读写和随机读写性能的差异，以及SSD和HDD在不同读写模式下的表现。</p><h1 id="Ceph-Rados性能测试工具"><a href="#Ceph-Rados性能测试工具" class="headerlink" title="Ceph Rados性能测试工具"></a>Ceph Rados性能测试工具</h1><p>Ceph 提供了 <code>rados bench</code> 和 <code>rados load-gen</code> 两个命令，用于测试和评估集群的性能。以下是这两个命令的用法和选项。</p><h2 id="rados-bench-命令"><a href="#rados-bench-命令" class="headerlink" title="rados bench 命令"></a>rados bench 命令</h2><p><code>rados bench</code> 命令用于对 Ceph 集群进行基准测试，以评估集群的读写性能。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench &#123;seconds&#125; &#123;operation&#125; [options]</span><br></pre></td></tr></table></figure><h3 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h3><ul><li><code>&#123;seconds&#125;</code>：测试运行的持续时间，单位为秒。</li><li><code>&#123;operation&#125;</code>：指定测试的操作类型，包括 <code>write</code>、<code>seq</code>（顺序读）、<code>rand</code>（随机读）。</li></ul><h3 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li><code>-p &#123;pool&#125;</code> 或 <code>--pool &#123;pool&#125;</code>：指定使用的存储池名称。</li><li><code>-b &#123;block_size&#125;</code> 或 <code>--block-size &#123;block_size&#125;</code>：指定块大小，默认值为 4MB。</li><li><code>-t &#123;threads&#125;</code> 或 <code>--threads &#123;threads&#125;</code>：指定使用的线程数，默认值为 16。</li><li><code>-n &#123;num_objects&#125;</code> 或 <code>--num-objects &#123;num_objects&#125;</code>：指定创建的对象数量。</li><li><code>-c</code> 或 <code>--no-cleanup</code>：在测试结束后保留测试数据。</li><li><code>-D</code> 或 <code>--verify</code>：启用数据验证。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="写入测试"><a href="#写入测试" class="headerlink" title="写入测试"></a>写入测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 write --pool testpool</span><br></pre></td></tr></table></figure><h4 id="顺序读测试"><a href="#顺序读测试" class="headerlink" title="顺序读测试"></a>顺序读测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 <span class="built_in">seq</span> --pool testpool</span><br></pre></td></tr></table></figure><h4 id="随机读测试"><a href="#随机读测试" class="headerlink" title="随机读测试"></a>随机读测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 rand --pool testpool</span><br></pre></td></tr></table></figure><h4 id="使用自定义块大小和线程数"><a href="#使用自定义块大小和线程数" class="headerlink" title="使用自定义块大小和线程数"></a>使用自定义块大小和线程数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 write --pool testpool --block-size 8192 --threads 32</span><br></pre></td></tr></table></figure><h2 id="rados-load-gen-命令"><a href="#rados-load-gen-命令" class="headerlink" title="rados load-gen 命令"></a>rados load-gen 命令</h2><p><code>rados load-gen</code> 命令用于生成负载，以测试和评估 Ceph 集群在不同负载下的性能。</p><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen [options]</span><br></pre></td></tr></table></figure><h3 id="常用选项-1"><a href="#常用选项-1" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li><code>-b &#123;bytes&#125;</code> 或 <code>--block-size &#123;bytes&#125;</code>：指定块大小，默认值为 4096 字节。</li><li><code>-t &#123;threads&#125;</code> 或 <code>--threads &#123;threads&#125;</code>：指定使用的线程数，默认值为 16。</li><li><code>-o &#123;objects&#125;</code> 或 <code>--objects &#123;objects&#125;</code>：指定创建的对象数量，默认值为 100。</li><li><code>-p &#123;pool&#125;</code> 或 <code>--pool &#123;pool&#125;</code>：指定使用的存储池名称，默认值为 <code>rbd</code>。</li><li><code>-c &#123;clients&#125;</code> 或 <code>--clients &#123;clients&#125;</code>：指定客户端数量，默认值为 1。</li><li><code>-d &#123;seconds&#125;</code> 或 <code>--duration &#123;seconds&#125;</code>：指定测试运行的持续时间，单位为秒。</li><li><code>--num-objects</code>：指定对象的总数</li><li><code>--min-object-size</code>：指定最小object尺寸</li><li><code>--max-object-size</code>：指定最大object尺寸</li><li><code>--min-op-len</code>：指定操作的最小 io 长度</li><li><code>--max-op-len</code>：指定操作的最大 io 长度</li><li><code>--max-ops</code>：指定最大操作数</li><li><code>--max-backlog</code>：指定最大压测规模</li><li><code>--read-percent</code>：指定读取操作的百分比</li><li><code>--target-throughput</code>：指定目标吞吐量（以字节为单位）</li><li><code>--run-length</code>：指定总时间（以秒为单位）</li></ul><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><h4 id="使用默认参数测试"><a href="#使用默认参数测试" class="headerlink" title="使用默认参数测试"></a>使用默认参数测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen</span><br></pre></td></tr></table></figure><h4 id="指定块大小和对象数量测试"><a href="#指定块大小和对象数量测试" class="headerlink" title="指定块大小和对象数量测试"></a>指定块大小和对象数量测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --block-size 8192 --objects 500</span><br></pre></td></tr></table></figure><h4 id="在指定存储池中测试"><a href="#在指定存储池中测试" class="headerlink" title="在指定存储池中测试"></a>在指定存储池中测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --pool mypool</span><br></pre></td></tr></table></figure><h4 id="使用多个线程和客户端测试"><a href="#使用多个线程和客户端测试" class="headerlink" title="使用多个线程和客户端测试"></a>使用多个线程和客户端测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --threads 32 --clients 4</span><br></pre></td></tr></table></figure><h4 id="指定时间的测试"><a href="#指定时间的测试" class="headerlink" title="指定时间的测试"></a>指定时间的测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --duration 60</span><br></pre></td></tr></table></figure><h4 id="指定object大小范围的测试"><a href="#指定object大小范围的测试" class="headerlink" title="指定object大小范围的测试"></a>指定object大小范围的测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p hdd_pool load-gen --num-objects 200 --min-object-size 4K --max-object-size 4M --max-ops 20 --read-percent 0 --min-op-len 4K --max-op-len 1M --target-throughput 20G --run-length 20 --num-threads 64</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;FIO简介&quot;&gt;&lt;a href=&quot;#FIO简介&quot; class=&quot;headerlink&quot; title=&quot;FIO简介&quot;&gt;&lt;/a&gt;FIO简介&lt;/h2&gt;&lt;p&gt;FIO是Linux下开源的一款IOPS测试工具，主要用来对磁盘进行压力测试和性能验证。它可以产生许多线程或进程来执行</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>rbd相关运维命令</title>
    <link href="https://watsonlu6.github.io/rbd%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/"/>
    <id>https://watsonlu6.github.io/rbd%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</id>
    <published>2021-09-22T16:31:00.000Z</published>
    <updated>2024-08-04T08:03:25.937Z</updated>
    
    <content type="html"><![CDATA[<h4 id="创建-rbd-镜像"><a href="#创建-rbd-镜像" class="headerlink" title="创建 rbd 镜像"></a>创建 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rbd create &#123;pool-name&#125;/&#123;image-name&#125; [--size &#123;size&#125;] [--image-format &#123;format&#125;] [--features &#123;feature-list&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>参数说明</p><ul><li>{pool-name}&#x2F;{image-name}：指定存储池名称和镜像名称。</li><li>–size {size}：设置镜像的大小。</li><li>–image-format {format}：指定镜像的格式。有效的格式包括 1（兼容旧版格式）和 2（支持更多特性）。</li><li>–features {feature-list}：启用镜像特性，特性名称之间用逗号分隔。例如，layering,exclusive-lock。</li></ul><h4 id="查看-rbd-镜像列表"><a href="#查看-rbd-镜像列表" class="headerlink" title="查看 rbd 镜像列表"></a>查看 rbd 镜像列表</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">ls</span> &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="获取-rbd-镜像信息"><a href="#获取-rbd-镜像信息" class="headerlink" title="获取 rbd 镜像信息"></a>获取 rbd 镜像信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd info &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="删除-rbd-镜像"><a href="#删除-rbd-镜像" class="headerlink" title="删除 rbd 镜像"></a>删除 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="映射-rbd-镜像到本地设备"><a href="#映射-rbd-镜像到本地设备" class="headerlink" title="映射 rbd 镜像到本地设备"></a>映射 rbd 镜像到本地设备</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd map &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="取消映射-rbd-镜像"><a href="#取消映射-rbd-镜像" class="headerlink" title="取消映射 rbd 镜像"></a>取消映射 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd unmap /dev/rbd/&#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="扩展-rbd-镜像大小"><a href="#扩展-rbd-镜像大小" class="headerlink" title="扩展 rbd 镜像大小"></a>扩展 rbd 镜像大小</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd resize &#123;pool-name&#125;/&#123;image-name&#125; --size &#123;new-size-in-MB&#125;</span><br></pre></td></tr></table></figure><h4 id="从ceph导出-RBD-镜像"><a href="#从ceph导出-RBD-镜像" class="headerlink" title="从ceph导出 RBD 镜像"></a>从ceph导出 RBD 镜像</h4><p>用于将镜像的数据导出到一个本地文件中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">export</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;output-file&#125;</span><br></pre></td></tr></table></figure><h4 id="向ceph导入-RBD-镜像"><a href="#向ceph导入-RBD-镜像" class="headerlink" title="向ceph导入 RBD 镜像"></a>向ceph导入 RBD 镜像</h4><p>用于将本地文件导入到ceph rbd中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd import &#123;input-file&#125; &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用rbd特性"><a href="#启用rbd特性" class="headerlink" title="启用rbd特性"></a>启用rbd特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125;</span><br></pre></td></tr></table></figure><p><strong>rbd镜像特性</strong></p><ul><li>layering：支持图层（Layering）</li><li>exclusive-lock：独占锁（Exclusive Locking）</li><li>object-map：对象映射（Object Map）</li></ul><h4 id="禁用rbd特性"><a href="#禁用rbd特性" class="headerlink" title="禁用rbd特性"></a>禁用rbd特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用和禁用所有特性"><a href="#启用和禁用所有特性" class="headerlink" title="启用和禁用所有特性"></a>启用和禁用所有特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; --all</span><br><span class="line">rbd feature <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125; --all</span><br></pre></td></tr></table></figure><h4 id="RBD-复制命令"><a href="#RBD-复制命令" class="headerlink" title="RBD 复制命令"></a>RBD 复制命令</h4><p>用于复制 RBD 镜像到同一存储池中的新镜像，或复制到不同存储池中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">cp</span> &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启RBD-深度复制命令"><a href="#启RBD-深度复制命令" class="headerlink" title="启RBD 深度复制命令"></a>启RBD 深度复制命令</h4><p>用于执行深度复制，包括镜像的所有快照和元数据。这个命令是 RADOS 镜像的完整复制工具。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd deep-copy &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-差异命令"><a href="#RBD-差异命令" class="headerlink" title="RBD 差异命令"></a>RBD 差异命令</h4><p>用于查看两个 RBD 镜像之间的差异，包括哪些块已更改、已删除或已新增。它可以帮助识别镜像之间的更改。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd diff &#123;pool-name&#125;/&#123;image-name&#125; [--snap &#123;snapshot-name&#125;] [--diff &#123;other-image&#125;]</span><br></pre></td></tr></table></figure><h4 id="RBD-磁盘使用命令"><a href="#RBD-磁盘使用命令" class="headerlink" title="RBD 磁盘使用命令"></a>RBD 磁盘使用命令</h4><p>用于显示 RBD 镜像的磁盘使用情况，包括镜像占用的总磁盘空间和其他相关信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">du</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-状态命令"><a href="#RBD-状态命令" class="headerlink" title="RBD 状态命令"></a>RBD 状态命令</h4><p>用于显示 RBD 镜像的状态信息，包括镜像的健康状态和其他相关信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd status &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-观察命令"><a href="#RBD-观察命令" class="headerlink" title="RBD 观察命令"></a>RBD 观察命令</h4><p>用于观察镜像的实时更改，这个命令允许用户跟踪镜像的变化，包括数据的写入、删除和其他操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd watch &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-稀疏化命令"><a href="#RBD-稀疏化命令" class="headerlink" title="RBD 稀疏化命令"></a>RBD 稀疏化命令</h4><p>用于将 RBD 镜像的已分配但未使用的空间标记为稀疏。通过稀疏化，可以释放磁盘上未使用的空间，从而优化存储资源。<br><strong>注意事项</strong></p><ul><li>影响：稀疏化操作会扫描镜像并更新其内部元数据，可能会占用一定的 I&#x2F;O 带宽和计算资源。</li><li>稀疏化条件：只有在镜像的写入操作完成后，才建议执行稀疏化，以避免在镜像空间仍在使用时进行操作。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd sparsify &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="创建-rbd-快照"><a href="#创建-rbd-快照" class="headerlink" title="创建 rbd 快照"></a>创建 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap create &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h4 id="保护-rbd-快照"><a href="#保护-rbd-快照" class="headerlink" title="保护 rbd 快照"></a>保护 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap protect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125;</span><br></pre></td></tr></table></figure><h4 id="取消保护-rbd-快照"><a href="#取消保护-rbd-快照" class="headerlink" title="取消保护 rbd 快照"></a>取消保护 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap unprotect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125;</span><br></pre></td></tr></table></figure><h4 id="列出-rbd-快照"><a href="#列出-rbd-快照" class="headerlink" title="列出 rbd 快照"></a>列出 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap <span class="built_in">ls</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="回滚到-rbd-快照"><a href="#回滚到-rbd-快照" class="headerlink" title="回滚到 rbd 快照"></a>回滚到 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap rollback &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h4 id="删除-rbd-快照"><a href="#删除-rbd-快照" class="headerlink" title="删除 rbd 快照"></a>删除 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h2 id="rbd-trash"><a href="#rbd-trash" class="headerlink" title="rbd trash"></a>rbd trash</h2><p>rbd trash 功能允许管理员在删除 rbd 镜像时先将其移动到 trash，而不是立即永久删除。这为误删除的镜像提供了恢复的机会。以下是 rbd trash 的详细说明和常用操作指南。<br>rbd trash 功能的主要特点包括：</p><ul><li>安全性：防止意外删除镜像。</li><li>可恢复性：在一定时间内可以恢复已删除的镜像。</li><li>定期清理：可以设置镜像在 trash 中的过期时间，自动清理过期的镜像。</li></ul><h4 id="查看-rbd-trash-中的镜像"><a href="#查看-rbd-trash-中的镜像" class="headerlink" title="查看 rbd trash 中的镜像"></a>查看 rbd trash 中的镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">ls</span> &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="将-rbd-镜像移动到-trash"><a href="#将-rbd-镜像移动到-trash" class="headerlink" title="将 rbd 镜像移动到 trash"></a>将 rbd 镜像移动到 trash</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">mv</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="恢复-trash-中的-rbd-镜像"><a href="#恢复-trash-中的-rbd-镜像" class="headerlink" title="恢复 trash 中的 rbd 镜像"></a>恢复 trash 中的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash restore &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="永久删除-trash-中的-rbd-镜像"><a href="#永久删除-trash-中的-rbd-镜像" class="headerlink" title="永久删除 trash 中的 rbd 镜像"></a>永久删除 trash 中的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看-trash-中镜像的详细信息"><a href="#查看-trash-中镜像的详细信息" class="headerlink" title="查看 trash 中镜像的详细信息"></a>查看 trash 中镜像的详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash info &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="设置-trash-镜像的过期时间"><a href="#设置-trash-镜像的过期时间" class="headerlink" title="设置 trash 镜像的过期时间"></a>设置 trash 镜像的过期时间</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">mv</span> &#123;pool-name&#125;/&#123;image-name&#125; --expire &#123;time-spec&#125;</span><br></pre></td></tr></table></figure><p>其中，<code>&#123;time-spec&#125;</code> 可以是以下格式之一：</p><ul><li><code>1d</code>：1天</li><li><code>1h</code>：1小时</li><li><code>1m</code>：1分钟</li></ul><h4 id="查看-trash-镜像的过期时间"><a href="#查看-trash-镜像的过期时间" class="headerlink" title="查看 trash 镜像的过期时间"></a>查看 trash 镜像的过期时间</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash list &#123;pool-name&#125; --long</span><br></pre></td></tr></table></figure><h4 id="清空-trash"><a href="#清空-trash" class="headerlink" title="清空 trash"></a>清空 trash</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash purge &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="克隆-rbd-镜像"><a href="#克隆-rbd-镜像" class="headerlink" title="克隆 rbd 镜像"></a>克隆 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">clone</span> &#123;pool-name&#125;/&#123;parent-image&#125;@&#123;snap-name&#125; &#123;pool-name&#125;/&#123;clone-name&#125;</span><br></pre></td></tr></table></figure><h4 id="合并克隆的-rbd-镜像"><a href="#合并克隆的-rbd-镜像" class="headerlink" title="合并克隆的 rbd 镜像"></a>合并克隆的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd flatten &#123;pool-name&#125;/&#123;clone-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用镜像同步"><a href="#启用镜像同步" class="headerlink" title="启用镜像同步"></a>启用镜像同步</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;mode&#125;</span><br></pre></td></tr></table></figure><h4 id="禁用镜像同步"><a href="#禁用镜像同步" class="headerlink" title="禁用镜像同步"></a>禁用镜像同步</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看镜像同步状态"><a href="#查看镜像同步状态" class="headerlink" title="查看镜像同步状态"></a>查看镜像同步状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image status &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看镜像配置"><a href="#查看镜像配置" class="headerlink" title="查看镜像配置"></a>查看镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image list &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="修改镜像配置"><a href="#修改镜像配置" class="headerlink" title="修改镜像配置"></a>修改镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image <span class="built_in">set</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125; &#123;value&#125;</span><br></pre></td></tr></table></figure><h4 id="删除镜像配置"><a href="#删除镜像配置" class="headerlink" title="删除镜像配置"></a>删除镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;创建-rbd-镜像&quot;&gt;&lt;a href=&quot;#创建-rbd-镜像&quot; class=&quot;headerlink&quot; title=&quot;创建 rbd 镜像&quot;&gt;&lt;/a&gt;创建 rbd 镜像&lt;/h4&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph相关运维命令</title>
    <link href="https://watsonlu6.github.io/Ceph%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/"/>
    <id>https://watsonlu6.github.io/Ceph%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</id>
    <published>2021-09-07T12:01:00.000Z</published>
    <updated>2024-08-02T17:38:18.260Z</updated>
    
    <content type="html"><![CDATA[<h4 id="查看-Ceph-的守护进程"><a href="#查看-Ceph-的守护进程" class="headerlink" title="查看 Ceph 的守护进程"></a>查看 Ceph 的守护进程</h4><p>使用以下命令查看所有 Ceph 守护进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl list-unit-files | grep ceph</span><br></pre></td></tr></table></figure><h4 id="按类型在-Ceph-节点上启动特定类型的所有守护进程"><a href="#按类型在-Ceph-节点上启动特定类型的所有守护进程" class="headerlink" title="按类型在 Ceph 节点上启动特定类型的所有守护进程"></a>按类型在 Ceph 节点上启动特定类型的所有守护进程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start/restart/stop ceph-osd.target</span><br><span class="line">systemctl start/restart/stop ceph-mon.target</span><br><span class="line">systemctl start/restart/stop ceph-mds.target</span><br><span class="line">systemctl start/restart/stop ceph-radosgw.target</span><br></pre></td></tr></table></figure><h4 id="启动特定守护进程实例"><a href="#启动特定守护进程实例" class="headerlink" title="启动特定守护进程实例"></a>启动特定守护进程实例</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start/status/restart/stop ceph-osd@&#123;<span class="built_in">id</span>&#125;</span><br><span class="line">systemctl start/status/restart/stop ceph-mon@&#123;hostname&#125;</span><br><span class="line">systemctl start/status/restart/stop ceph-mds@&#123;hostname&#125;</span><br><span class="line">systemctl start/restart/stop ceph-radosgw@&#123;hostname&#125;</span><br></pre></td></tr></table></figure><h4 id="查看-Ceph-集群状态"><a href="#查看-Ceph-集群状态" class="headerlink" title="查看 Ceph 集群状态"></a>查看 Ceph 集群状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ceph health detail</span><br></pre></td></tr></table></figure><p>输出信息包括：</p><ul><li>集群的 ID</li><li>集群健康状况</li><li>monitor map 版本和 mon 法定人数状态</li><li>OSD map 版本和 OSD 状态摘要</li><li>PG map 版本</li><li>PG 和 Pool 的数量</li><li>集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量</li><li>客户端的 IOPS 信息</li></ul><h4 id="观察集群中的状态"><a href="#观察集群中的状态" class="headerlink" title="观察集群中的状态"></a>观察集群中的状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph -w</span><br></pre></td></tr></table></figure><p>输出信息包含：</p><ul><li>集群的 ID</li><li>集群健康状况</li><li>monitor map 版本和 mon 法定人数状态</li><li>OSD map 版本和 OSD 状态摘要</li><li>PG map 版本</li><li>PG 和 Pool 的数量</li><li>集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量</li><li>客户端的 IOPS 信息</li></ul><h4 id="检查集群的容量情况"><a href="#检查集群的容量情况" class="headerlink" title="检查集群的容量情况"></a>检查集群的容量情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph <span class="built_in">df</span></span><br></pre></td></tr></table></figure><h3 id="修改集群配置"><a href="#修改集群配置" class="headerlink" title="修改集群配置"></a>修改集群配置</h3><h4 id="查看默认配置"><a href="#查看默认配置" class="headerlink" title="查看默认配置"></a>查看默认配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph --show-config</span><br></pre></td></tr></table></figure><h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><p>Ceph 支持在运行时更改 ceph-osd、ceph-mon、ceph-mds 守护进程的配置。</p><h4 id="使用-tell-的方式"><a href="#使用-tell-的方式" class="headerlink" title="使用 tell 的方式"></a>使用 tell 的方式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ceph tell &#123;daemon-type&#125;.&#123;<span class="built_in">id</span> or *&#125; injectargs --&#123;name&#125; &#123;value&#125; [--&#123;name&#125; &#123;value&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：</span></span><br><span class="line">ceph tell osd.0 injectargs --debug-osd 20 --debug-ms 1</span><br></pre></td></tr></table></figure><h4 id="使用-daemon-的方式设置"><a href="#使用-daemon-的方式设置" class="headerlink" title="使用 daemon 的方式设置"></a>使用 daemon 的方式设置</h4><p>在设置的角色所在主机上进行设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看配置</span></span><br><span class="line">ceph daemon osd.1 config get mon_osd_full_ratio</span><br><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">ceph daemon osd.1 config <span class="built_in">set</span> mon_osd_full_ratio 0.97</span><br></pre></td></tr></table></figure><h4 id="在线调整日志级别"><a href="#在线调整日志级别" class="headerlink" title="在线调整日志级别"></a>在线调整日志级别</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph tell osd.0 injectargs --debug-osd 0/5</span><br></pre></td></tr></table></figure><h4 id="修改配置文件进行调整"><a href="#修改配置文件进行调整" class="headerlink" title="修改配置文件进行调整"></a>修改配置文件进行调整</h4><p>编辑 <code>/etc/ceph/ceph.conf</code> 中的 [global] 字段添加配置，重启相应服务生效。</p><h4 id="查看-mon-状态"><a href="#查看-mon-状态" class="headerlink" title="查看 mon 状态"></a>查看 mon 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph mon <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="查看-mon-的详细状态"><a href="#查看-mon-的详细状态" class="headerlink" title="查看 mon 的详细状态"></a>查看 mon 的详细状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon mon.ceph-xx-mon00 mon_status</span><br></pre></td></tr></table></figure><h4 id="mon-法定人数状态"><a href="#mon-法定人数状态" class="headerlink" title="mon 法定人数状态"></a>mon 法定人数状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph quorum_status -f json-pretty</span><br></pre></td></tr></table></figure><h4 id="查看-mon-选举状态"><a href="#查看-mon-选举状态" class="headerlink" title="查看 mon 选举状态"></a>查看 mon 选举状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph quorum_status</span><br></pre></td></tr></table></figure><h4 id="查看-mon-的映射信息"><a href="#查看-mon-的映射信息" class="headerlink" title="查看 mon 的映射信息"></a>查看 mon 的映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph mon dump</span><br></pre></td></tr></table></figure><h4 id="查看-mon-的-admin-socket"><a href="#查看-mon-的-admin-socket" class="headerlink" title="查看 mon 的 admin socket"></a>查看 mon 的 admin socket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-conf --name mon.ceph-xx-mon00 --show-config-value admin_socket</span><br><span class="line">/var/run/ceph/ceph-mon.ceph-xx-mon00.asok</span><br></pre></td></tr></table></figure><h2 id="CRUSH-Map"><a href="#CRUSH-Map" class="headerlink" title="CRUSH Map"></a>CRUSH Map</h2><h4 id="创建-bucket"><a href="#创建-bucket" class="headerlink" title="创建 bucket"></a>创建 bucket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush add-bucket host-xx host</span><br></pre></td></tr></table></figure><h4 id="移动-bucket"><a href="#移动-bucket" class="headerlink" title="移动 bucket"></a>移动 bucket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush move host-xx room=default</span><br></pre></td></tr></table></figure><h4 id="提取-CRUSH-Map"><a href="#提取-CRUSH-Map" class="headerlink" title="提取 CRUSH Map"></a>提取 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd getcrushmap -o crush</span><br></pre></td></tr></table></figure><h4 id="反编译-crush-map"><a href="#反编译-crush-map" class="headerlink" title="反编译 crush map"></a>反编译 crush map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool -d crush -o de_crush </span><br></pre></td></tr></table></figure><h4 id="编译-crush-map"><a href="#编译-crush-map" class="headerlink" title="编译 crush map"></a>编译 crush map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool -c de_crush -o new_crush</span><br></pre></td></tr></table></figure><h4 id="测试新的-CRUSH-Map"><a href="#测试新的-CRUSH-Map" class="headerlink" title="测试新的 CRUSH Map"></a>测试新的 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool --<span class="built_in">test</span> -i new_crush --num-rep 3 --rule 1 --show-mappings </span><br></pre></td></tr></table></figure><h4 id="注入-CRUSH-Map"><a href="#注入-CRUSH-Map" class="headerlink" title="注入 CRUSH Map"></a>注入 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd setcrushmap -i new_crush</span><br></pre></td></tr></table></figure><h4 id="列出-crush-rule"><a href="#列出-crush-rule" class="headerlink" title="列出 crush_rule"></a>列出 crush_rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush rule <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><h4 id="查看-crush-rule"><a href="#查看-crush-rule" class="headerlink" title="查看 crush_rule"></a>查看 crush_rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush rule dump &#123;rule&#125;</span><br></pre></td></tr></table></figure><h2 id="PG-和-PGP"><a href="#PG-和-PGP" class="headerlink" title="PG 和 PGP"></a>PG 和 PGP</h2><h4 id="查看-PG-状态"><a href="#查看-PG-状态" class="headerlink" title="查看 PG 状态"></a>查看 PG 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="查看-PG-组映射信息"><a href="#查看-PG-组映射信息" class="headerlink" title="查看 PG 组映射信息"></a>查看 PG 组映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump</span><br></pre></td></tr></table></figure><h4 id="查看一个-PG-的-map"><a href="#查看一个-PG-的-map" class="headerlink" title="查看一个 PG 的 map"></a>查看一个 PG 的 map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg map 1.2f6</span><br></pre></td></tr></table></figure><h4 id="查看-PG-详细信息"><a href="#查看-PG-详细信息" class="headerlink" title="查看 PG 详细信息"></a>查看 PG 详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg 1.2f6 query</span><br></pre></td></tr></table></figure><h4 id="显示集群所有-PG-统计"><a href="#显示集群所有-PG-统计" class="headerlink" title="显示集群所有 PG 统计"></a>显示集群所有 PG 统计</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump --format plain</span><br></pre></td></tr></table></figure><h4 id="显示非正常状态的-PG"><a href="#显示非正常状态的-PG" class="headerlink" title="显示非正常状态的 PG"></a>显示非正常状态的 PG</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump_stuck inactive|unclean|stale</span><br></pre></td></tr></table></figure><h2 id="OSD"><a href="#OSD" class="headerlink" title="OSD"></a>OSD</h2><h4 id="查看-OSD-状态"><a href="#查看-OSD-状态" class="headerlink" title="查看 OSD 状态"></a>查看 OSD 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="检查-OSD-容量是否均衡"><a href="#检查-OSD-容量是否均衡" class="headerlink" title="检查 OSD 容量是否均衡"></a>检查 OSD 容量是否均衡</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">df</span> tree</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-映射信息"><a href="#查看-OSD-映射信息" class="headerlink" title="查看 OSD 映射信息"></a>查看 OSD 映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd dump</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-目录树"><a href="#查看-OSD-目录树" class="headerlink" title="查看 OSD 目录树"></a>查看 OSD 目录树</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd tree</span><br></pre></td></tr></table></figure><h4 id="定位-OSD-在集群中的节点位置"><a href="#定位-OSD-在集群中的节点位置" class="headerlink" title="定位 OSD 在集群中的节点位置"></a>定位 OSD 在集群中的节点位置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd find [osd]</span><br></pre></td></tr></table></figure><h4 id="查看对象在哪些-OSD-上"><a href="#查看对象在哪些-OSD-上" class="headerlink" title="查看对象在哪些 OSD 上"></a>查看对象在哪些 OSD 上</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd map test-pool object1</span><br></pre></td></tr></table></figure><h4 id="下线某个-OSD"><a href="#下线某个-OSD" class="headerlink" title="下线某个 OSD"></a>下线某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd down 0</span><br></pre></td></tr></table></figure><h4 id="拉起某个-OSD"><a href="#拉起某个-OSD" class="headerlink" title="拉起某个 OSD"></a>拉起某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd up 0</span><br></pre></td></tr></table></figure><h4 id="将某个-OSD-逐出集群"><a href="#将某个-OSD-逐出集群" class="headerlink" title="将某个 OSD 逐出集群"></a>将某个 OSD 逐出集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd out 0</span><br></pre></td></tr></table></figure><h4 id="将某个-OSD-加入集群"><a href="#将某个-OSD-加入集群" class="headerlink" title="将某个 OSD 加入集群"></a>将某个 OSD 加入集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="keyword">in</span> 0</span><br></pre></td></tr></table></figure><h4 id="删除某个-OSD"><a href="#删除某个-OSD" class="headerlink" title="删除某个 OSD"></a>删除某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">rm</span> 0</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-延迟"><a href="#查看-OSD-延迟" class="headerlink" title="查看 OSD 延迟"></a>查看 OSD 延迟</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd perf</span><br></pre></td></tr></table></figure><h4 id="查看当前-OSD-的状态"><a href="#查看当前-OSD-的状态" class="headerlink" title="查看当前 OSD 的状态"></a>查看当前 OSD 的状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon osd.14 perf dump</span><br></pre></td></tr></table></figure><h2 id="Pool"><a href="#Pool" class="headerlink" title="Pool"></a>Pool</h2><h4 id="查看-pool-信息"><a href="#查看-pool-信息" class="headerlink" title="查看 pool 信息"></a>查看 pool 信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd lspools</span><br></pre></td></tr></table></figure><h4 id="查看-pool-详细信息"><a href="#查看-pool-详细信息" class="headerlink" title="查看 pool 详细信息"></a>查看 pool 详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">ls</span> detail</span><br></pre></td></tr></table></figure><h4 id="查看-pool-状态"><a href="#查看-pool-状态" class="headerlink" title="查看 pool 状态"></a>查看 pool 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool stats</span><br></pre></td></tr></table></figure><h3 id="创建-pool"><a href="#创建-pool" class="headerlink" title="创建 pool"></a>创建 pool</h3><h4 id="创建副本-pool"><a href="#创建副本-pool" class="headerlink" title="创建副本 pool"></a>创建副本 pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; replicated &#123;crush-ruleset-name&#125; </span><br></pre></td></tr></table></figure><h4 id="创建-EC-pool"><a href="#创建-EC-pool" class="headerlink" title="创建 EC pool"></a>创建 EC pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; erasure &#123;erasure-code-profile&#125;</span><br></pre></td></tr></table></figure><h4 id="创建-erasure-code-profile"><a href="#创建-erasure-code-profile" class="headerlink" title="创建 erasure-code-profile"></a>创建 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile <span class="built_in">set</span> ec-4-2 k=4 m=2 ruleset-failure-domain=host ruleset-root=hddRoom</span><br></pre></td></tr></table></figure><h4 id="列出-erasure-code-profile"><a href="#列出-erasure-code-profile" class="headerlink" title="列出 erasure-code-profile"></a>列出 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><h4 id="查看-erasure-code-profile"><a href="#查看-erasure-code-profile" class="headerlink" title="查看 erasure-code-profile"></a>查看 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile get [name]</span><br></pre></td></tr></table></figure><h4 id="删除-pool"><a href="#删除-pool" class="headerlink" title="删除 pool"></a>删除 pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除 pool 前需要执行</span></span><br><span class="line">ceph tell mon.* injectargs --mon-allow-pool-delete=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 删除pool</span></span><br><span class="line">ceph osd pool delete test_pool test_pool --yes-i-really-really-mean-it  <span class="comment">#pool的名字需要重复两次</span></span><br></pre></td></tr></table></figure><h4 id="设置-pool-的-PG-数量"><a href="#设置-pool-的-PG-数量" class="headerlink" title="设置 pool 的 PG 数量"></a>设置 pool 的 PG 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool pg_num 100</span><br></pre></td></tr></table></figure><h4 id="查看-pool-的-PG-数量"><a href="#查看-pool-的-PG-数量" class="headerlink" title="查看 pool 的 PG 数量"></a>查看 pool 的 PG 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool pg_num</span><br></pre></td></tr></table></figure><h4 id="设置-pool-的-PGP-数量"><a href="#设置-pool-的-PGP-数量" class="headerlink" title="设置 pool 的 PGP 数量"></a>设置 pool 的 PGP 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool pgp_num 100</span><br></pre></td></tr></table></figure><h4 id="查看-pool-的-PGP-数量"><a href="#查看-pool-的-PGP-数量" class="headerlink" title="查看 pool 的 PGP 数量"></a>查看 pool 的 PGP 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool pgp_num</span><br></pre></td></tr></table></figure><h4 id="设置-pool-池副本数"><a href="#设置-pool-池副本数" class="headerlink" title="设置 pool 池副本数"></a>设置 pool 池副本数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool size 3</span><br></pre></td></tr></table></figure><h4 id="查看-pool-池副本数"><a href="#查看-pool-池副本数" class="headerlink" title="查看 pool 池副本数"></a>查看 pool 池副本数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool size</span><br></pre></td></tr></table></figure><h4 id="设置存储池-crush-rule"><a href="#设置存储池-crush-rule" class="headerlink" title="设置存储池 crush rule"></a>设置存储池 crush rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> &lt;poolname&gt; crush_ruleset &lt;ruleset&gt;</span><br></pre></td></tr></table></figure><h4 id="查看存储池-crush-rule"><a href="#查看存储池-crush-rule" class="headerlink" title="查看存储池 crush rule"></a>查看存储池 crush rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get &lt;poolname&gt; crush_rule</span><br></pre></td></tr></table></figure><h2 id="RADOS"><a href="#RADOS" class="headerlink" title="RADOS"></a>RADOS</h2><h4 id="查看对象信息"><a href="#查看对象信息" class="headerlink" title="查看对象信息"></a>查看对象信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool <span class="built_in">stat</span> test-object-1</span><br></pre></td></tr></table></figure><h4 id="获取对象内容"><a href="#获取对象内容" class="headerlink" title="获取对象内容"></a>获取对象内容</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool get test-object-1 test.txt</span><br></pre></td></tr></table></figure><h4 id="将指定文件作为对象写入到资源池"><a href="#将指定文件作为对象写入到资源池" class="headerlink" title="将指定文件作为对象写入到资源池"></a>将指定文件作为对象写入到资源池</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool put test-object-2 test.txt</span><br></pre></td></tr></table></figure><h4 id="删除对象"><a href="#删除对象" class="headerlink" title="删除对象"></a>删除对象</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool <span class="built_in">rm</span> test-object-1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;查看-Ceph-的守护进程&quot;&gt;&lt;a href=&quot;#查看-Ceph-的守护进程&quot; class=&quot;headerlink&quot; title=&quot;查看 Ceph 的守护进程&quot;&gt;&lt;/a&gt;查看 Ceph 的守护进程&lt;/h4&gt;&lt;p&gt;使用以下命令查看所有 Ceph 守护进程：&lt;/p&gt;
</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph线程池实现</title>
    <link href="https://watsonlu6.github.io/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-27T14:26:42.000Z</published>
    <updated>2024-07-28T10:16:50.698Z</updated>
    
    <content type="html"><![CDATA[<p>线程池和工作队列是紧密相连的，基本流程就是将任务送入到对应的工作队列中，线程池中的线程从工作队列中取出任务并进行处理。Ceph 为了支持高并发读写，源码设计中大量采用线程池来进行io的推进。Ceph的线程池实现了多种不同的工作队列。一般情况下，一个线程池对应一个类型的工作队列。在要求不高的情况下，也可以一个线程池对应多种类型的工作队列，让线程池处理不同类型的任务。</p><h2 id="mutex的实现"><a href="#mutex的实现" class="headerlink" title="mutex的实现"></a>mutex的实现</h2><p>src&#x2F;common&#x2F;mutex.h<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B01.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B02.png"></p><p>condition variable的实现<br>src&#x2F;common&#x2F;cond.h<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B03.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B04.png"></p><h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><p>Ceph中线程的在src&#x2F;common&#x2F;Thread.h中定义<br>线程编程接口中，一个线程在创建时调用pthread_create函数来传入entry函数，杀死线程调用pthread_kill函数，当线程被杀死之后，必须调用pthread_join函数来进行线程资源的回收，如果不调用此函数，就会出现类似zombie process。如果要想让系统自己回收线程资源，就要将线程与父线程分离即调用pthread_detach。通过接口对比，src&#x2F;common&#x2F;Thread.h中定义的class thread，实际上是Ceph自己封装了一个线程类，这个线程类其实就是对Linux线程接口的一层封装。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B05.png"></p><p>Ceph中所有要用的线程必须继承Thread类，通过查找发现如下一些线程：</p><ol><li>Accepter.h (src\msg)：class Accepter : public Thread  &#x2F;&#x2F;用来socket bind的线程,   accepter线程入口函数里定义了poll的网络通讯结构，用来放入管道</li><li>Admin_socket.h (src\common)：class AdminSocket : public Thread</li><li>Ceph_context.cc (src\common)：class CephContextServiceThread : public Thread</li><li>DispatchQueue.h (src\msg):  class DispatchThread : public Thread   &#x2F;&#x2F;用来进行消息分发的线程，  在simpleMessenger中有dispatch_queue成员变量,</li><li>FileJournal.h (src\os):  class Writer : public Thread     &#x2F;&#x2F;用来进行写数据到journal中的线程</li><li>FileJournal.h (src\os):  class WriteFinisher : public Thread   &#x2F;&#x2F;当用aio异步模式写数据到journal完成后，此线程用来接管其他剩余操作</li><li>FileStore.h (src\os):  struct SyncThread : public Thread    &#x2F;&#x2F;用来同步数据执行同步的线程，主要是将已经完成的journal的序列号写入到文件中</li><li>Finisher.h (src\common):  struct FinisherThread : public Thread   &#x2F;&#x2F;公用的finisher线程，用来查看某些特定的操作是否结束，结束后进行后续处理工作</li><li>MDLog.h (src\mds):  class ReplayThread : public Thread </li><li>OSD.h (src\osd):  struct T_Heartbeat : public Thread   &#x2F;&#x2F;维系osd进程之间互相心跳连接的线程</li><li>OutputDataSocket.h (src\common):class OutputDataSocket : public Thread</li><li>Pipe.h (src\msg): class Reader : public Thread   &#x2F;&#x2F;用来处理所有对socket的读操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理</li><li>Pipe.h (src\msg): class Writer : public Thread   &#x2F;&#x2F;用来处理所有对socket的写操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理</li><li>Pipe.h (src\msg):    class DelayedDelivery: public Thread    &#x2F;&#x2F;用来处理所有对socket的延时操作</li><li>Signal_handler.cc (src\global)：struct SignalHandler : public Thread </li><li>SimpleMessenger.h (src\msg):  class ReaperThread : public Thread &#x2F;&#x2F;用来进行消息通信的主要线程 reaper是用来在通讯完成时拆除管道，其中成员有accepter线程（用来bind，accept socket文件放入管道），还有dispatch_queue线程</li><li>Throttle.cc (src\test\common):  class Thread_get : public Thread </li><li>Timer.cc (src\common)：class SafeTimerThread : public Thread </li><li>WorkQueue.h (src\common):  struct WorkThread : public Thread</li></ol><p>可以将这些线程分为四类线程</p><ol><li>普通类线程：<br> 使用此类线程类直接申明继承自Thread，重写一个entry函数，在进程启动最初时，调用了create函数创建了线程，同时使用它的人必须自己定义消息队列。上面大部分线程都是此类，比如FileJournal::write_thread就是一个FileJournal::Writer类对象，它自己定义了消息队列FileJournal::writeq</li><li>SafeTimerThread类线程:<br> 此类线程使用者可以直接申明一个SafeTimer成员变量，因为SafeTimer中已经封装了SafeTimerThread类和一个消息队列（成员是Context回调类），并完成了entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过SafeTimer::add_event_after函数将钩子埋入，等待规定时间到达后执行。</li><li>FinisherThread类线程:<br> 此类线程使用者可以直接申明一个Finisher成员变量，因为Finsher中已经封装了FinisherThread类和一个消息队列（成员是Context回调类），并完成entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过Finisher::queue函数将钩子埋入，等待某类操作完成后执行。</li><li>ThreadPool内部线程：<br> 这类线程由于是具体工作类线程，所以他们一般都是以线程池形式一下创建多个。ThreadPool类内部有多个线程set&lt;WorkThread*&gt;和多个消息队列vector&lt;WorkQueue_*&gt;组成。工作流程就是线程不断的轮询从队列中拿去数据进行操作。</li></ol><p>可以看到Ceph线程的所有接口都只是对相应的Linux接口的封装。继承其的子类主要在于实现entry()函数：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B06.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B07.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B08.png"></p><h2 id="线程池的实现"><a href="#线程池的实现" class="headerlink" title="线程池的实现"></a>线程池的实现</h2><p>Ceph中线程池的在src&#x2F;common&#x2F;WorkQueue.h中定义<br>线程池和工作队列其实是密不可分的，从Ceph的代码中也可以看出来。让任务推入工作队列，而线程池中的线程负责从工作队列中取出任务进行处理。工作队列和线程池的关系，类似于狡兔和走狗的关系，正是因为有任务，所以才需要雇佣线程来完成任务，没有了狡兔，走狗也就失去了存在的意义。而线程必须要可以从工作队列中认领任务并完成，这就类似于猎狗要有追捕狡兔的功能。正因为两个数据结构拥有如此紧密的关系，因此，Ceph中他们的相关函数都位于WorkQueue.cc和WorkQueue.h中。</p><p><strong>void ThreadPool::start()</strong><br>函数ThreadPool::start()用来启动线程池，其在加锁的情况下，调用函数start_threads()，start_threads()检查当前的线程数，如果小于配置的线程池线程数，就创建新的工作线程。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B09.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B010.png"></p><p><strong>struct WorkThread : public Thread</strong><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B011.png"></p><p><strong>ThreadPool::worker()</strong><br>线程池的关键在于线程的主函数做的事情。首先是工作线程。线程池中会有很多的WorkThread，它的基类就是Thread。线程的主函数为pool-&gt;worker，即ThreadPool::worker函数。其entry函数其实就是调用线程池的worker函数进行具体的工作。</p><p>ThreadPool::worker函数内定义了WorkThread类线程的操作逻辑。基本流程就是轮询所有WorkQueue_，当发现某种类型WorkQueue_中有数据时拿出，然后依次调用该WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。（worker函数的主要实现其实很常规，就是遍历work_queues，从其中找出每一个消息队列实例，并调用WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。）<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B012.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B013.png"></p><p>线程池是支持动态调整线程个数的。所谓调整，有两种可能性，一种是线程个数增加，一种线程个数减少。当添加OSD的时候，数据会重分布，恢复的速度可以调节，其中一个重要的参数为osd-max-recovery-threads，该值修改可以实时生效。</p><p><strong>ThreadPool::join_old_threads()</strong><br>线程本身是一个loop，不停地处理WorkQueue中的任务，在一个loop的开头，线程个数是否超出了配置的个数，如果超出了，就需要自杀，所谓自杀即将自身推送到_old_threads中，然后跳出loop，直接返回了。线程池中的其他兄弟在busy-loop开头的join_old_threads函数会判断是否存在自杀的兄弟，如果存在的话，执行join，为兄弟收尸。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B014.png"></p><p><strong>ThreadPool::start_threads()</strong><br>start_threads函数不仅仅可以用在初始化时启动所有工作线程，而且可以用于动态增加，它会根据配置要求的线程数_num_threads和当前线程池中线程的个数，来创建WorkThread，当然了，他会调整线程的io优先级。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B015.png"></p><p><strong>ThreadPool::handle_conf_change()</strong><br>线程池的线程个数如果不够用，也可以动态的增加，通过配置的变化来做到：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B016.png"></p><p><strong>ThreadPool::pause()</strong><br>线程池的工作线程，绝大部分时间内，自然是busy－loop中处理工作队列上的任务，但是有一种场景是，需要让工作暂时停下来，停止工作，不要处理WorkQueue中的任务。线程池提供了一个标志为_pause,只要_pause不等于0，那么线程池中线程就在loop中就不会处理工作队列中的任务，而是空转。为了能够及时的醒来，也不是sleep，而是通过条件等待，等待执行的时间。</p><p>当下达pause指令的时候，很可能线程池中的某几个线程正在处理工作队列中的任务，这种情况下并不是立刻就能停下的，只有处理完手头的任务，在下一轮loop中检查_pause标志位才能真正地停下。那么pause指令就面临选择，要不要等工作线程WorkThread处理完手头的任务。pause函数是等，pauser_new函数并不等，pause_new函数只负责设置标志位，当其返回的时候，某几个线程可能仍然在处理工作队列中的任务。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B017.png"></p><p><strong>struct WorkQueue_</strong><br>在ThreadPool这个类中，set&lt;WorkThread*&gt; _threads保存着线程池中的多个线程，vector&lt;WorkQueue_*&gt; work_queues保存着线程池中的待线程处理的消息队列。整个线程池的原理思想比较简单就是生成一定数目的线程，然后线程从队列中遍历获取队列实例，调用实例自带的处理函数_void_process和_void_process_finish处理。 ThreadPool中的WorkQueue_，这是一种抽象的类，只定义了一个队列应该有的一些特定的函数，这些函数几乎都是虚函数，目的是为了调用到自己三个子类BatchWorkQueue、WorkQueueVal、WorkQueue自己定义的函数。而在三个子类中对应函数_void_process、_void_process_finish中又分别调用了使用者自己继承它们而自己实现的具体操作函数如_process,_process_finish。存放在work_queues里面的WorkQueue_类：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B018.png"></p><p>这是一个纯虚基类，也就是说不同的线程池要实现自己的队列，继承WorkQueues_并且实现其接口。线程池已经有4个纯虚基类继承这个类：</p><ul><li>BatchWorkQueue<br>  批量处理队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B019.png"></li><li>WorkQueueVal<br>  存值队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B020.png"></li><li>WorkQueue<br>  存指针队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B021.png"></li><li>PointerWQ<br>  存指针队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B022.png"></li></ul><p><strong>add_work_queue()&#x2F;remove_work_queue()</strong><br>ThreadPool中的add_work_queue和remove_work_queue就是用来建立和移除与WorkQueue关联的函数<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B023.png"></p><p><strong>TPHandle</strong><br>超时检查，每次线程函数执行时，都会设置一个grace超时时间，当线程执行超过该时间，就认为是unhealthy的状态。当执行时间超过suicide_grace时，OSD就会产生断言而导致自杀。heartbeat_handle_d记录了相关信息，并把该结构添加到HeartbeatMap的系统链表中保存。OSD会有一个定时器，定时检查是否超时。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B024.png"></p><p>线程池使用步骤<br>先创建线程池，然后创建WorkQueue的时候，将线程池作为参数传递给WorkQueue，就能建立关系。</p><ol><li>声明线程池成员ThreadPool *_tp</li><li>声明队列类型ThreadPool::WorkQueue_*_wq</li><li>重写WorkQueue中对应函数_void_process,_void_process_finish</li><li>调用*_tp.add_work_queue(*_wq)将队列传入</li></ol><h2 id="基本线程池扩展"><a href="#基本线程池扩展" class="headerlink" title="基本线程池扩展"></a>基本线程池扩展</h2><p>在Ceph中有不少线程池会实现继承以上基类：<br>ThreadPool op_tp: 处理client请求<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B025.png"></p><p>struct recovery_tp: 处理recovery_tp操作<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B026.png"></p><p>struct command_tp: 处理命令行来的操作<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B027.png"></p><p>ShardedThreadPool: Ceph还实现了另外一种线程池ShardedThreadPool，这种线程池与上面的线程池不同之处在于这种线程池是多线程共享队列的方式。只有一个队列，多个线程同时对这个队列进行处理。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B028.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B029.png"></p><p>SharededWQ: shardedThreadPool类型线程池内部有个比较重要的消息队列SharededWQ，该队列将多种OP放入其中<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B030.png"></p><p>Ceph 在实际使用中，会用到这种线程池<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B031.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B032.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;线程池和工作队列是紧密相连的，基本流程就是将任务送入到对应的工作队列中，线程池中的线程从工作队列中取出任务并进行处理。Ceph 为了支持高并发读写，源码设计中大量采用线程池来进行io的推进。Ceph的线程池实现了多种不同的工作队列。一般情况下，一个线程池对应一个类型的工作队</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_rbd客户端实现</title>
    <link href="https://watsonlu6.github.io/Ceph-rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-15T14:26:55.000Z</published>
    <updated>2024-07-28T09:48:58.097Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-RBD介绍"><a href="#Ceph-RBD介绍" class="headerlink" title="Ceph RBD介绍"></a>Ceph RBD介绍</h2><p>随着云计算的发展，Ceph已经成为目前最为流行的分布式存储系统，俨然存储界的Linux操作系统。Ceph集块存储、文件存储和对象存储于一身，适用场景广泛，用户众多。RBD是 Ceph 分布式存储系统中提供的块存储服务，Ceph的块存储通过一个客户端模块实现，这个客户端可以直接从数据守护进程读写数据（不需要经过一个网关）。根据客户端整合生态系统的差异，使用Ceph的块设备有两种实现方式：librbd (用户态)和krbd (内核态)。RBD：RADOS Block Devices. Ceph block devices are thin-provisioned, resizable and store data striped over multiple OSDs in a Ceph cluster.<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B01.png"></p><p>使用Ceph的块设备有两种路径（内核态与用户态）：(rbd map就是内核使用ceph块设备，调用librbd&#x2F;librados API访问ceph块设备是用户态)</p><ul><li>通过Kernel Module(内核态RBD)：即创建了RBD设备后，把它映射到内核中（使用rbd map命令映射到操作系统上），成为一个虚拟的块设备，这时这个块设备同其他通用块设备一样，设备文件一般为&#x2F;dev&#x2F;rbd0，后续直接使用这个块设备文件就可以了，可以把&#x2F;dev&#x2F;rbd0格式化后挂载到某目录，也可以直接作为裸设备进行使用。krbd是一个内核模块。其在内核中以一个块设备的方式加以实现。这整个Ceph客户端都是以内核模块的方式实现（没有与之相关的用户态进程或者守护进程）。krbd在内核的源码目录源文件:drivers&#x2F;block&#x2F;rbd.c、drivers&#x2F;block&#x2F;rbd_types.h、net&#x2F;ceph&#x2F;、include&#x2F;linux&#x2F;ceph<ul><li><a href="https://www.likecs.com/show-203739919.html">https://www.likecs.com/show-203739919.html</a></li><li><a href="https://github.com/torvalds/linux/blob/cfb92440ee71adcc2105b0890bb01ac3cddb8507/drivers/block/rbd.c">https://github.com/torvalds/linux/blob/cfb92440ee71adcc2105b0890bb01ac3cddb8507/drivers/block/rbd.c</a></li><li><a href="https://github.com/torvalds/linux/tree/85c7000fda0029ec16569b1eec8fd3a8d026be73/include/linux/ceph">https://github.com/torvalds/linux/tree/85c7000fda0029ec16569b1eec8fd3a8d026be73/include/linux/ceph</a></li></ul></li><li>通过librbd(用户态RBD)：即创建了RBD设备后，使用librbd&#x2F;librados库访问和管理块设备。这种方式直接调用librbd提供的接口，实现对RBD设备的访问和管理，不会在客户端产生设备文件。应用方案有：SPDK+librbd&#x2F;librados<ul><li><a href="https://github.com/ceph/ceph/tree/acf835db0376b1b71152949fdfec36e68f4a8474/src/librbd">https://github.com/ceph/ceph/tree/acf835db0376b1b71152949fdfec36e68f4a8474/src/librbd</a></li><li><a href="https://github.com/spdk/spdk/tree/cff525d336fb2c4c087413d4c53474b9e61cbdbe/module/bdev/rbd">https://github.com/spdk/spdk/tree/cff525d336fb2c4c087413d4c53474b9e61cbdbe/module/bdev/rbd</a><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B02.png"></li></ul></li></ul><p>RBD 的块设备由于元数据信息少而且访问不频繁，故 RBD 在 Ceph 集群中不需要单独的守护进程将元数据加载到内存进行元数据访问加速，所有的元数据和数据操作直接与集群中的 Monitor 服务和 OSD 服务进行交互。</p><h2 id="RBD-模块相关IO流图"><a href="#RBD-模块相关IO流图" class="headerlink" title="RBD 模块相关IO流图"></a>RBD 模块相关IO流图</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B03.png"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B04.png"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B05.png"></p><p>客户端写数据osd过程：</p><ol><li>采用的是 librbd 的形式，使用 librbd 创建一个块设备，向这个块设备中写入数据</li><li>在客户端本地同过调用 librados 接口，然后经过 pool，rbd，object，pg 进行层层映射（CRUSH 算法）,在 PG 这一层中，可以知道数据保存在哪几个 OSD 上，这几个 OSD 分为主从的关系</li><li>客户端与 primary OSD 建立 SOCKET 通信，将要写入的数据传给 primary OSD，由 primary OSD 再将数据发送给其他 replica OSD 数据节点。</li></ol><h2 id="IO-时序图"><a href="#IO-时序图" class="headerlink" title="IO 时序图"></a>IO 时序图</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B06.png"><br>librbd提供了针对image的数据读写和管理操作两种访问接口，其中数据读写请求入io_work_queue，然后由线程池中的线程将io请求以object粒度切分并分别调用rados层的aio接口（IoCtxImpl）下发，当所有的object请求完成时，调用librbd io回调（librbd::io::AioCompletion）完成用户层的数据io。而对image的管理操作通常需要涉及单个或多个对象的多次访问以及对内部状态的多次更新，其第一次访问将从用户线程调用至rados层 aio 接口或更新状态后入 op_work_queue 队列进行异步调用，当 rados aio 层回调或 Context 完成时再根据实现逻辑调用新的 rados aio 或构造 Context 回调，如此反复，最后调用应用层的回调完成管理操作请求。<br>      此外为了支持多客户端共享访问 image，librbd 提供了构建于 rados watch&#x2F;notify 之上的通知、远程执行以及 exclusive lock 分布式锁机制。每个 librbd 客户端在打开 image 时（以非只读方式打开）都会 watch image 的 header 对象，从远程发往本地客户端的通知消息或者内部的 watch 错误消息会通过 RadosClient 的 Finisher 线程入 op_work_queue 队列进行异步处理。</p><h2 id="RBD读写流程"><a href="#RBD读写流程" class="headerlink" title="RBD读写流程"></a>RBD读写流程</h2><p>对于任何RBD客户端的读写都要经过以下步骤：</p><ol><li>集群句柄创建、读取配置<br> 集群句柄的创建即是librados:Rados的创建，初始化，读取配置<br> 创建：librados::Rados rados;<br> 初始化：librados::Rados::init(const char * const id)<br>     主要是初始化librados::RadosClient<br>     读取配置：<br>     librados::Rados::conf_read_file(const char * const path) const<br>     librados::Rados::conf_parse_argv(int argc, const char ** argv) const</li><li>集群连接<br> librados::Rados::connect()</li><li>IO上下文环境初始化（pool创建读写等）<br> librados::Rados::ioctx_create(const char *name, IoCtx &amp;io)<br> 主要是IoCtxImpl即librados::IoCtx</li><li>rbd创建<br> librbd::RBD rbd;<br> RBD::create2(IoCtx&amp; io_ctx, const char *name, uint64_t size,uint64_t features, int *order)</li><li>rbd的读写<br> librbd::Image image;<br> RBD::open(IoCtx&amp; io_ctx, Image&amp; image, const char *name)<br> Image::write(uint64_t ofs, size_t len, bufferlist&amp; bl)<br> Image::read(uint64_t ofs, size_t len, bufferlist&amp; bl)</li><li>IO上下文环境关闭<br> librbd::Image::close()<br> librados::IoCtx::close()</li><li>集群句柄关闭<br> librados::Rados::shutdown()</li></ol><h2 id="RBD源码介绍"><a href="#RBD源码介绍" class="headerlink" title="RBD源码介绍"></a>RBD源码介绍</h2><p>librbd以及librados都是属于ceph 的客户端，其提供ceph的接口向上提供块存储服务。<br>librados提供客户端访问Ceph集群的原生态统一接口。其它接口或者命令行工具都基于该动态库实现。在librados中实现了Crush算法和网络通信等公共功能，数据请求操作在librados计算完成后可以直接与对应的OSD交互进行数据传输。<br>librbd 是Ceph提供的在librados上封装的块存储接口的抽象。</p><p>librados主要的类是Rados和IoCtx<br>librados::Rados负责初始化集群、读取配置、连接集群<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B07.jpg"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B08.jpg"></p><p>librados::IoCtx负责创建IO上下文环境<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B09.jpg"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B010.jpg"></p><p>librados::bufferlist负责读写缓存<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B011.jpg"></p><p>librbd最主要的两个类是：RBD和Image<br>librbd::rbd主要负责 Image 的创建、删除、重命名、克隆映像等操作，包括对存储池的元数据的管理，针对部分操作提供异步接口<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B012.jpg"></p><p>librbd::image负责image的读写(read&#x2F;write)，以及快照相关的操作等等。同时提供了相关异步操作的接口。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B013.png"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B014.png"></p><h2 id="rbd-Image的创建"><a href="#rbd-Image的创建" class="headerlink" title="rbd Image的创建"></a>rbd Image的创建</h2><p>rbd卷的创建接口：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B015.jpg"></p><p>函数输入参数：</p><ul><li>io_ctx: 针对pool的上下文环境，对pool的操作都要首先建立一个相应的上下文环境</li><li>*name：rbd卷名字</li><li>size：rbd卷大小</li><li>features: rbd卷的特性</li><li>order: rbd卷的分块大小<br>其具体实现在internal.cc中：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B016.jpg"></li></ul><p>继续往下调用：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B017.jpg"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B018.jpg"></p><p>根据format格式调用不同的创建接口，现在主流采用新的format2，所用调用新的接口：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">create_v2</span><span class="params">(IoCtx&amp; io_ctx, <span class="type">const</span> <span class="type">char</span> *imgname, <span class="type">uint64_t</span> bid, <span class="type">uint64_t</span> size,<span class="type">int</span> order, <span class="type">uint64_t</span> features, <span class="type">uint64_t</span> stripe_unit,<span class="type">uint64_t</span> stripe_count, <span class="type">uint8_t</span> journal_order,<span class="type">uint8_t</span> journal_splay_width, <span class="type">const</span> std::string &amp;journal_pool,<span class="type">const</span> std::string &amp;non_primary_global_image_id,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="type">const</span> std::string &amp;primary_mirror_uuid,<span class="type">bool</span> negotiate_features)</span></span></span><br></pre></td></tr></table></figure><p>这个接口会做如下工作：<br>创建rbd_id.{volume_name}的object：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B019.png"></p><p>然后想这个object写入block_name_prefix中的id号：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B020.png"></p><p>然后向rbd_directory写入卷名和id的一一映射。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B021.jpg"></p><p>创建名为rbd_header.id的object，并向这个object写入size,order,features,RBD_DATA_PREFIX等信息。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B022.png"></p><p>如果有条带化，则会设置条带化信息：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B023.png"></p><p>创建名为rbd_object_map.{id}的对象：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B024.jpg"></p><h2 id="rbd-Image的打开"><a href="#rbd-Image的打开" class="headerlink" title="rbd Image的打开"></a>rbd Image的打开</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B025.jpg"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B026.jpg"></p><p>其实就是生成一个ImageCtx实例，调用其open接口。</p><h2 id="rbd-Image的写"><a href="#rbd-Image的写" class="headerlink" title="rbd Image的写"></a>rbd Image的写</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B027.jpg"></p><h2 id="rbd-Image的读"><a href="#rbd-Image的读" class="headerlink" title="rbd Image的读"></a>rbd Image的读</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B028.jpg"></p><h2 id="rbd-Image的快照"><a href="#rbd-Image的快照" class="headerlink" title="rbd Image的快照"></a>rbd Image的快照</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B029.jpg"></p><h2 id="rbd-Image的克隆"><a href="#rbd-Image的克隆" class="headerlink" title="rbd Image的克隆"></a>rbd Image的克隆</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B030.jpg"></p><h2 id="rbd-Image的删除"><a href="#rbd-Image的删除" class="headerlink" title="rbd Image的删除"></a>rbd Image的删除</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B031.jpg"></p><h2 id="rbd的读写"><a href="#rbd的读写" class="headerlink" title="rbd的读写"></a>rbd的读写</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B032.png"></p><p>要使用librbd, 需要先安装下面两个包。可以通过yum安装, 也可以通过下载ceph源码编译后, 通过make install进行安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  yum list | grep librbd</span></span><br><span class="line">librbd1.x86_64                  1:0.80.7-3.el7                    base</span><br><span class="line">librbd1-devel.x86_64            1:0.80.7-3.el7                    base</span><br></pre></td></tr></table></figure><p>至于如何使用librbd来编程, 请参考下面的代码, 这是使用librbd的一般流程。<br>编译时记得加上链接参数: g++ librbdtest.cpp -lrados -lrbd。<br>更多函数的使用请参考 librbd.hpp。 另外 这里 有一些不错的示例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rbd/librbd.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-RBD介绍&quot;&gt;&lt;a href=&quot;#Ceph-RBD介绍&quot; class=&quot;headerlink&quot; title=&quot;Ceph RBD介绍&quot;&gt;&lt;/a&gt;Ceph RBD介绍&lt;/h2&gt;&lt;p&gt;随着云计算的发展，Ceph已经成为目前最为流行的分布式存储系统，俨然存储界的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_crush算法实现</title>
    <link href="https://watsonlu6.github.io/Ceph-crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-02T14:26:17.000Z</published>
    <updated>2024-07-28T09:23:25.673Z</updated>
    
    <content type="html"><![CDATA[<p>分布式存储系统的数据分布算法要解决数据如何分布到集群中的各个节点和磁盘上，其面临： 数据分布和负载均衡、灵活应对集群伸缩、大规模集群计算速率三方面的挑战。 </p><ol><li>数据分布和负载均衡：数据分布均衡，使数据能均匀地分布在各个节点和磁盘上，使数据访问的负载在各个节点和磁盘上。</li><li>灵活应对集群伸缩：系统可以方便地增加或者删除存储设备，当增加或删除存储设备后，能自动实现数据的均衡，并且迁移的数据尽可能减少。</li><li>大规模集群算法计算速率：要求数据分布算法维护的元数据相对较小，并且计算量不能太大。</li></ol><p>在分布式存储系统中，数据分布算法由两种基本实现方法，一种是<code>基于集中式的元数据查询的方式</code>，如HDFS的实现：文件的分布信息是通过访问集中元数据服务器获得；另一种是<code>基于哈希算法计算的方式</code>。例如一致性哈希算法(DHT)。Ceph的数据分布算法CRUSH属于后者。CRUSH(Controlled Replication Under Scalable Hashing)，是一种基于哈希的数据分布算法。与另一种基于集中式的元数据查询的存储方式(文件的分布信息需要先通过访问集中元数据服务器获得)不同。CRUSH算法以数据唯一标识符、当前存储集群的拓扑结构以及数据分布策略作为CRUSH的输入，经过计算获得数据分布位置，直接与OSD进行通信，从而避免集中式查询操作，实现去中心化和高度并发。</p><p>Ceph 作为分布式存储系统，采用多节点多副本的数据存放方式，必然要解决数据如何分布到集群中各个节点和磁盘上。Ceph使用CRUSH数据分布算法。例如一个Ceph集群三副本，就存在着如何映射3个OSD存储这3个副本的数据，Ceph写数据时，即写object时，首先需要计算出object属于哪个PG，然后根据PG id 计算出存放的OSD位置。过程分两步：PG id的计算 ；OSD位置的计算。结合rbd的代码介绍这两个过程：</p><h2 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h2><p>rbd的写接口（src&#x2F;linrbd&#x2F;librbd.cc）<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B01.png"><br>接口传入的参数是起始写位置（ofs）以及写数据大小（len）和要写入的数据（bl），调用io_work_queue-&gt;write()，生成Object写入请求对象，发送到ImageRequestWQ任务队列中，等待工作线程处理。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B02.png"><br>现在看看ImageRequest的数据类型<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B03.png"></p><p>因为Image的ImageWriteRequest继承AbstractImageWriteRequest类，重点关注AbstractImageWriteRequest类<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B04.png"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B05.png"></p><p>发送写请求时调用void AbstractImageWriteRequest<I>::send_request()函数，在这个函数进行切分数据，分成大小同等（可设定，一般为4M）的object(最后一块object可能大小小于块大小)。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B06.png"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B07.png"></p><p>file_to_extents就是将数据段切分各个object，具体怎么分割就不深入看源码了。然后调用send_object_requests()将分片各个object分别构造写请求<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B08.png"></p><h2 id="Op请求处理"><a href="#Op请求处理" class="headerlink" title="Op请求处理"></a>Op请求处理</h2><p>此后会构造objecter的Op请求，发送出去；转到src&#x2F;librados&#x2F;IoCtxImpl.cc，深入了解Op请求的处理。类IoCtxImpl是pool相关的上下文信息，一个pool对应一个IoCtxImpl对象，可以在该pool里创建、删除对象，完成对象数据读写等各种操作，包括同步和异步的实现。类IoCtxImpl把请求封装成ObjectOperation类。然后再添加pool的地址信息，封装成Obejcter::Op对象。Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。类IoCtxImpl的write&#x2F;read等同步操作函数通过调用operate()来调用op_submit()，类IoCtxImpl的aio_write&#x2F;aio_read&#x2F;aio_operate等异步函数直接调用了op_submit(），说明op_submit(）是object读写操作的入口。调用函数objeter-&gt;op_submit发送给相应的OSD，如果是同步操作，就等待操作完成。如果是异步操作，就不用等待，直接返回，当操作完成后，调用相应的回调函数通知。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B09.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B010.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B011.png"></p><p>Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B012.png"></p><h2 id="发送数据op-submit"><a href="#发送数据op-submit" class="headerlink" title="发送数据op_submit"></a>发送数据op_submit</h2><p>在op_submit()调用_op_submit_with_budget()处理Throttle相关流量的限制<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B013.png"><br>在_op_submit_with_budget()中，如果osd_timeout大于0，就是设置定时器，当操作超时，就调用定时器回调函数op_ cancel取消操作，然后通过调用_op_submit(op, sul, ptid)。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B014.png"></p><p>_op_submit函数完成了关键的地址寻址和发送工作，比如_calc_target()、_get_session()、_send_op()等，调用函数_calc_target()计算对象的目标OSD；调用函数_get_session()获取目标OSD的链接，如果返回值为-EAGAIN，就升级为写锁，重新获取。检查当前的状态标志，如果当前是CEPH_OSDMAP_PAUSEWR或者OSD空间满，就暂时不发送，否则调用函数_prepare_osd_op准备请求的信息，调用函数_send_op发送出去。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B015.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B016.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B017.png"></p><h2 id="对象寻址-calc-target"><a href="#对象寻址-calc-target" class="headerlink" title="对象寻址_calc_target"></a>对象寻址_calc_target</h2><p>重点详细分析下_calc_target函数：首先调用函数osdmap-&gt;get_pg_pool()根据t-&gt;base_oloc.pool获取pool信息，获取pg_pool_t对象；检查pi-&gt;last_force_op_resend是否强制重发，如果强制重发，force_resend设置为true；检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值；如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值；调用函数osdmap-&gt;object_locator_to_pg()获取目标对象所在的PG；调用函数osdmap-&gt;pg_to_up_acting_osds()通过CRUSH算法，获取该PG对应的OSD列表，即pg_to_up_acting_osds()通过CRUSH算法计算OSD；判断读写操作：读操作，如果设置了CEPH_OSD_FLAG_BALANCE_READS标志，调用rand() 取余随机选择一个副本读取；读操作，如果设置了CEPH_OSD_FLAG_LOCALIZE_READS标志，尽可能从本地副本读取；写操作，target的OSD就设置为主OSD。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B018.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B019.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B020.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B021.png"></p><p>首先获取pool信息，判断是否有效：<br>        <code>const pg_pool_t *pi = osdmap-&gt;get_pg_pool(t-&gt;base_oloc.pool);</code><br>然后根据获取pgid，注意pgid是一个结构体pg_t<br>pg_t 的结构如下：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B022.png"></p><p>m_pool 是pool id， m_seed是函数根据object id算出来的哈希值，m_preferred赋值-1。<br>接下来就是调用osdmap-&gt;pg_to_up_acting_osds()，获取该PG对应的OSD列表，即选择OSD：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B023.png"></p><p>pg_to_up_acting_osds()函数在src\osd\OSDMap.cc中，函数功能是选出up osds以及 acting osds, 两个都是数组类型，大小为副本数<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B024.png"></p><p>继续跟踪这个函数：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B025.png"></p><p>进入_pg_to_raw_osds：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B026.png"></p><p>上面函数crush-&gt;do_rule()就是真正调用crush算法计算出相应的osd列表。<br>这里重点解释下参数pps：对象到PG的映射：任何程序通过客户端访问集群时，首先由客户端生成一个字符串形式的对象名，然后基于对象名和命名空间计算得出一个32位哈希值。针对此哈希值，对该存储池的PG总数量pg_num取模(掩码计算)，得到该对象所在的PG的id号。<br><code>ps_t pps = pool.raw_pg_to_pps(pg);  // placement ps</code><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B027.jpg"></p><p>可以看出pps这是一个哈希值，这个哈希值根据pool id，函数中pg.ps()就是我们object哈希算出的m_seed：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B028.jpg"></p><h2 id="调用CRUSH算法"><a href="#调用CRUSH算法" class="headerlink" title="调用CRUSH算法"></a>调用CRUSH算法</h2><p>下面就是进入do_rule 进行CRUSH算法的处理了：src&#x2F;crush&#x2F;CrushWrapper.h<br>调用crush_do_rule()函数<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B029.png"></p><p>继续调用crush_do_rule()算法，执行CEUSH算法<br><strong>CRUSH算法：</strong>针对指定输入x(要计算PG的pg_id)，CRUSH将输出一个包含n个不同目标存储对象(例如磁盘)的集合(OSD列表)。CRUSH的计算过程使用x、cluster map、placement rule作为哈希函数输入。因此如果cluster map不发生变化(一般placement rule不会轻易变化)，那么结果就是确定的。算法输入需要3个输入参数：</p><ol><li>输入x 即PG id的哈希值</li><li>crush_map即集群的拓扑结构，集群的层级化描述，形如”数据中心-&gt;机架-&gt;主机-&gt;磁盘”这样的层级拓扑。用树来表示，每个叶子节点都是真实的最小物理存储设备，称为devices；所有中间节点统称为bucket，每个bucket可以是一些devices的集合，也可以是低一级的buckets集合；根节点称为root，是整个集群的入口。</li><li>ruleno 即选择策略，就rule规则，这里用编号表示；它决定一个PG的对象副本如何选择(从定义的cluster map的拓扑结构中)的规则，以此完成数据映射。palcement rule可以包含多个操作，这些操作共有3种类型：take(root)、select(replicas, type)、emit(void)<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B030.png"></li></ol><p>crush 算法输入需要3个输入参数：</p><ol><li>输入x 即PG id的哈希值</li><li>crush_map即集群的拓扑结构</li><li>ruleno 即选择策略，就rule规则，这里用编号表示</li></ol><p>可以通过集群输出crush_map:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B031.jpg"></p><p>vim crush_map如下：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B032.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B033.jpg"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B034.jpg"></p><p>显示的结构和代码中的结构还是有着映射的关系：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B035.jpg"></p><p>其中crush_bucket:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B036.jpg"><br>对应：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B037.0.jpg"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B037.jpg"></p><p>crush_rule:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B038.jpg"><br>对应于：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B039.png"></p><p>逐一对比分析其数据结构。<br>这里分析下其选择OSD的过程：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> *a = scratch;</span><br><span class="line"><span class="type">int</span> *b = scratch + result_max;</span><br><span class="line"><span class="type">int</span> *c = scratch + result_max*<span class="number">2</span>;</span><br><span class="line">w = a;</span><br><span class="line">o= b;</span><br></pre></td></tr></table></figure><p>a, b, c 分别指向 scratch向量的0, 1, 2的位置.<br>w &#x3D; a; o &#x3D; b; </p><ul><li>w被用作一个先入先出队列来在CRUSH map中进行横向优先搜索(BFS traversal). </li><li>o存储crush_choose_firstn选择的结果. </li><li>c存储最终的OSD选择结果.</li></ul><p>crush_do_rule函数里面最重要的是函数里面的for循环，这个循环就是筛选osd的过程，</p><p>for循环中：</p><ol><li>首先从rule规则中当前执行的步骤，首次就执行第一条步骤：<br> <code>struct crush_rule_step *curstep = &amp;rule-&gt;steps[step];</code></li><li>然后根据当前执行步骤的操作类型，选择不同的分支操作，首先一般是take操作，而且是take fault。即crush map树根节点。这个过程就是根据step 逐步选择bucket 知道知道叶子节点，即OSD。</li><li>这个过程中，crush_choose_firstn 函数, 递归的选择特定bucket或者设备,并且可以处理冲突,失败的情况.</li><li>如果当前是choose过程,通过调用crush_bucket_choose来直接选择. </li><li>如果当前是chooseleaf选择叶子节点的过程,该函数将递归直到得到叶子节点.<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B040.png"></li></ol><p>在for循环中的crush_choose_firstn()计算后如果结果不是OSD类型, o 交给w。以便于 w成为下次crush_choose_firstn的输入参数。在crush_choose_firstn()中，for(){}：副本选择循环判断条件rep是否等于副本数numrep，rep叠加。do{}while (retry_descent)：选择OSD冲突或故障域失效时循环，随机因子r改变。do{}while (retry_bucket)：进行bucket层级选择，当前item type不是OSD时循环，当前进行选择的bucket，即in改变。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B041.png"></p><p>在crush_choose_firstn()函数中有crush_bucket_choose函数，这个函数根据bucket类型选择不同的权重计算方法刷选出bucket。如果采用straw2，就会采用bucket_straw2_choose接口进行筛选。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B042.jpg"></p><p>bucket_straw2_choose()功能是通过调用伪随机算法计算伪随机数，以伪随机数最高的作为选择出的节点<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B043.png"></p><p>generate_exponential_distribution()产生随机数的思想是：采用逆变换采样的思想，先调用crush_hash32_3()计算哈希值，然后取随机数的低16位。计算指数随机变量。作为参考，请参阅指数分布示例：<a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling#Examples%E3%80%82">https://en.wikipedia.org/wiki/Inverse_transform_sampling#Examples。</a> 由于某种原因，略小于 0x10000 会产生更准确的分布……可能是舍入效果。 自然对数查找表映射 [0,0xffff]（对应实数 [1&#x2F;0x10000, 1] 到 [0, 0xffffffffffff]（对应实数 [-11.090355,0]）。除以 16.16 定点权重。 请注意，ln 值为负数，因此较大的权重意味着较大的（较小的负数）draw值。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B044.png"></p><p>CRUSH算法的一些缺陷： </p><ol><li>CRUSH算法提供了uniform、list和tree等bucket类型作为straw bucket类型的替代方案，但这些算法在添加或删除服务器时需要进行不必要的重排，这使它们不适合用于大规模存储系统。 </li><li>CRUSH算法的查找函数需要进行O(log n)的二分查找，以找到与给定对象ID最接近的虚拟ID。这个计算对于系统中的每个对象都需要进行，因此在系统中有大量对象时，计算成本会很高。 </li><li>CRUSH算法在重建过程中可能会出现瓶颈，因为它需要在placement groups中进行数据放置，这可能会导致数据重建速度变慢。</li><li>CRUSH算法的计算复杂度较高，需要进行大量的计算，这可能会影响系统的性能。 综上所述，CRUSH算法虽然是一种灵活的对象放置算法，但它也存在一些缺陷，需要进一步改进和优化。</li></ol><p>由于CRUSH算法的计算复杂度较高，需要进行大量的计算，因此使用多线程来加速计算是一种可行的方法。具体来说，可以将CRUSH算法的计算任务分配给多个线程，每个线程负责计算一部分任务，然后将结果合并起来。这样可以充分利用多核处理器的计算能力，提高计算效率。但是，需要注意的是，多线程计算也会带来一些额外的开销，如线程间的同步和通信开销，因此需要进行合理的线程调度和优化，以达到最佳的性能提升效果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;分布式存储系统的数据分布算法要解决数据如何分布到集群中的各个节点和磁盘上，其面临： 数据分布和负载均衡、灵活应对集群伸缩、大规模集群计算速率三方面的挑战。 &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据分布和负载均衡：数据分布均衡，使数据能均匀地分布在各个节点和磁盘上，使数据访问的负载在</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_Bufferlist的设计与使用</title>
    <link href="https://watsonlu6.github.io/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>https://watsonlu6.github.io/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8/</id>
    <published>2021-07-14T05:19:06.000Z</published>
    <updated>2024-07-27T14:37:12.169Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-Bufferlist的设计与使用"><a href="#Ceph-Bufferlist的设计与使用" class="headerlink" title="Ceph Bufferlist的设计与使用"></a>Ceph Bufferlist的设计与使用</h2><p>做为主要和磁盘、网络打交道的分布式存储系统，序列化是最基础的功能之一。当一个结构通过网络发送或写入磁盘时，它被编码为一串字节。可序列化结构具encode 和 decode方法，将结构体<strong>序列化</strong>后存入bufferlist和从bufferlist读出字节串<strong>反序列化</strong>出结构体。bufferlist是ceph的底层组件，用于存储二进制数据，其存储的数据可以直接写入磁盘，在代码中有很广泛的使用。</p><p><strong>为什么要用bufferlist？</strong></p><p>为了免拷贝。发送数据时，传统的socket接口通常需要读取一段连续的内存。但是我们要发的数据内存不连续，所以以前的做法是申请一块大的内存，然后将不连续的内存内的数据拷贝到大内存块中，然后将大内存块地址给发送接口。但是找一块连续的大内存并不容易，系统可能会为此做各种腾挪操作，而将数据拷贝的大内存中，又是一个拷贝操作。RDMA的发送支持聚散表，不需要读取连续的内存。有bufferlist之后，我们可以通过bufferlist，将不连续的物理内存管理起来，形成一段“连续”的虚拟内存，然后将bufferlist的内存指针传递给聚散表，再把聚散表交给RDMA 发送接口即可。整个过程免去了内存拷贝操作。大大降低了CPU的消耗。</p><p>在ceph中经常需要将一个bufferlist编码(encode)到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和copy，效率较高。</p><p>补充：</p><ol><li>传统内存访问需要通过CPU进行数据copy来移动数据，通过CPU将内存中的Buffer1移动到Buffer2中。</li><li>DMA(直接内存访问)是一种能力，允许在计算机主板上的设备直接把数据发送到内存中去，数据搬运不需要CPU的参与。</li><li>DMA模式：可以同DMA Engine之间通过硬件将数据从Buffer1移动到Buffer2，而不需要操作系统CPU的参与，大大降低了CPU Copy的开销。</li><li>RDMA是一种概念，在两个或者多个计算机进行通讯的时候使用DMA， 从一个主机的内存直接访问另一个主机的内存。RDMA是一种新的直接内存访问技术，RDMA让计算机可以直接存取其他计算机的内存，而不需要经过处理器的处理。RDMA将数据从一个系统快速移动到远程系统的内存中，而不对操作系统造成任何影响。</li></ol><h2 id="bufferlist的设计"><a href="#bufferlist的设计" class="headerlink" title="bufferlist的设计"></a>bufferlist的设计</h2><p>Bufferlist负责管理Ceph中所有的内存。整个Ceph中所有涉及到内存的操作，无论是msg分配内存接收消息，还是OSD构造各类数据结构的持久化表示（encode&#x2F;decode），再到实际磁盘操作，都将bufferlist作为基础。bufferlist对应的类为buffer::list(using bufferlist &#x3D; buffer::list;)，而buffer::list又基于buffer::ptr和buffer::raw实现，探讨buffer::list的实现，不能跳过它们。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> ceph &#123;</span><br><span class="line">    <span class="keyword">namespace</span> buffer &#123;</span><br><span class="line">    <span class="keyword">inline</span> <span class="keyword">namespace</span> v14_2_0 &#123;</span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">ptr</span>;</span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">list</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">hash</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">using</span> bufferptr = buffer::ptr;</span><br><span class="line">    <span class="keyword">using</span> bufferlist = buffer::list;</span><br><span class="line">    <span class="keyword">using</span> bufferhash = buffer::hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ceph::buffer是ceph非常底层的实现，负责管理ceph的内存。ceph::buffer的设计较为复杂，但本身没有任何内容，主要包含buffer::list、 buffer::ptr、 buffer::raw、 buffer::hash。这三个类都定义在src&#x2F;include&#x2F;buffer.h和src&#x2F;common&#x2F;buffer.cc中。</p><ol><li>buffer::raw：负责维护物理内存的引用计数nref和释放操作。</li><li>buffer::ptr：指向buffer::raw的指针。</li><li>buffer::list：表示一个ptr的列表（std::list<bufferptr>），相当于将N个ptr构成一个更大的虚拟的连续内存。</li><li>buffer::hash：一个或多个bufferlist的有效哈希。</li></ol><p>buffer这三个类的相互关系可以用下面这个图来表示：<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_1.png"><br>图中蓝色的表示bufferlist，橙色表示bufferptr，绿色表示bufferraw。</p><pre><code>在这个图中，实际占用的系统内存一共就三段，分别是raw0，raw1和raw2代表的三段内存。raw0被ptr0，ptr1，ptr2使用raw1被ptr3，ptr4，ptr6使用raw2被ptr5，ptr7使用而list0是由ptr0-5组成的，list1是由ptr6和ptr7组成的。</code></pre><p>从这张图上我们就可以看出bufferlist的设计思路： </p><ul><li>对于bufferlist来说，仅关心一个个ptr。bufferlist将ptr连在一起，当做是一段连续的内存使用。因此，可以通过bufferlist::iterator一个字节一个字节的迭代整个bufferlist中的所有内容，而不需要关心到底有几个ptr，更不用关心这些ptr到底和系统内存是怎么对应的；也可以通过bufferlist::write_file方法直接将bufferlist中的内容出到一个文件中；或者通过bufferlist::write_fd方法将bufferlist中的内容写入到某个fd中。</li><li>bufferraw负责管理系统内存的，bufferraw只关心一件事：维护其所管理的系统内存的引用计数，并且在引用计数减为0时——即没有ptr再使用这块内存时，释放这块内存。</li><li>bufferptr负责连接bufferlist和bufferraw。bufferptr关心的是如何使用内存。每一个bufferptr一定有一个bufferraw为其提供系统内存，然后ptr决定使用这块内存的哪一部分。bufferlist只用通过ptr才能对应到系统内存中，而bufferptr而可以独立存在，只是大部分ptr还是为bufferlist服务的，独立的ptr使用的场景并不是很多。<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_2.png"><br>通过引入ptr这样一个中间层次，bufferlist使用内存的方式可以非常灵活。</li></ul><ol><li>快速encode&#x2F;decode。在Ceph中经常需要将一个bufferlist编码（encode）到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和Copy，效率较高。</li><li>一次分配，多次使用。调用malloc之类的函数申请内存是非常重量级的操作。利用ptr这个中间层可以缓解这个问题，可以一次性申请一块较大的内存，也就是一个较大的bufferraw，然后每次需要内存的时候，构造一个bufferptr，指向这个bufferraw的不同部分。这样就不再需要向系统申请内存了。最后将这些ptr都加入到一个bufferlist中，就可以形成一个虚拟的连续内存。</li><li>减少内存分配次数和碎片。利用bufferptr这个中间层进行内存的多次使用，多个bufferptr可以引用同一段bufferraw的不同区域，这个bufferraw可以预先一次性申请较大一段连续内存，从而避免了多次申请内存以及内存碎片的产生。</li></ol><h4 id="buffer-raw"><a href="#buffer-raw" class="headerlink" title="buffer::raw"></a>buffer::raw</h4><p>raw的数据成员部分代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">char</span> *data;    <span class="comment">//数据指针</span></span><br><span class="line">    <span class="type">unsigned</span> len;     <span class="comment">//数据长度</span></span><br><span class="line">    std::atomic&lt;<span class="type">unsigned</span>&gt; nref&#123;<span class="number">0</span>&#125;;      <span class="comment">//引用计数</span></span><br><span class="line">    <span class="type">int</span> mempool; </span><br><span class="line">    <span class="keyword">mutable</span> ceph::spinlock crc_spinlock;     <span class="comment">//读写锁</span></span><br><span class="line">    map&lt;pair&lt;<span class="type">size_t</span>, <span class="type">size_t</span>&gt;, pair&lt;<span class="type">uint32_t</span>, <span class="type">uint32_t</span>&gt;&gt; crc_map;    <span class="comment">//crc校验信息</span></span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>最基本的成员：data是指向具体数据的指针，len是数据的长度，nref是引用计数。而mempool是其对应的内存池的index，这个和data空间的分配有关，暂时不去管它。</p><p>data指向的数据有很多来源，直接通过malloc从内存分配只是最基础的一种，可能还来自mmap内存映射的空间，甚至可以通过pipe管道＋splice实现零拷贝获取空间。有些时候，分配的空间时，会提出对齐的要求，比如按页对齐等等。对于每一种数据来源，需要不同逻辑的数据分配和释放函数，所以raw对应了很多子类，分别表示不同的数据。</p><p>下列类都继承了buffer::raw，实现了对data对应内存空间的申请</p><ol><li>类raw_malloc实现了用malloc函数分配内存空间的功能</li><li>类class buffer::raw_mmap_pages实现了通过mmap来把内存匿名映射到进程的地址空间</li><li>类class buffer::raw_posix_aligned调用了函数posix_memalign来申请内存地址对齐的内存空间。</li><li>类class buffer::raw_hack_aligned是在系统不支持内存对齐申请的情况下自己实现了内存地址的对齐</li><li>类class buffer::raw_pipe实现了pipe做为Buffer的内存空间</li><li>类class buffer::raw_char使用了C++的new操作符来申请空间</li></ol><p>这是因为这些来源不同，要求不同，buffer::raw也就有了一些变体，举个例子，对应于malloc的raw子类为buffer::raw_malloc，构造和析构函数中实现了使用malloc进行数据分配和释放的逻辑：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw_malloc : <span class="keyword">public</span> buffer::raw</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">raw_malloc</span><span class="params">(<span class="type">unsigned</span> l)</span> : raw(l)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">    <span class="keyword">if</span> (len)</span><br><span class="line">    &#123;</span><br><span class="line">        data = (<span class="type">char</span> *)<span class="built_in">malloc</span>(len);</span><br><span class="line">        <span class="keyword">if</span> (!data)</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">bad_alloc</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        data = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">    <span class="built_in">inc_history_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">raw_malloc</span>(<span class="type">unsigned</span> l, <span class="type">char</span> *b) : <span class="built_in">raw</span>(b, l)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">raw_malloc</span>() <span class="keyword">override</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">free</span>(data);</span><br><span class="line">    <span class="built_in">dec_total_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; free &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">raw *<span class="title">clone_empty</span><span class="params">()</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">raw_malloc</span>(len);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>对应于malloc的raw子类为buffer::raw_mmap_pages，顾名思义，也能够猜到，这个数据的来源是通过mmap分配的匿名内存映射。因此析构的时候，毫不意外，掉用munmap解除映射，归还空间给系统：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw_mmap_pages : <span class="keyword">public</span> buffer::raw &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">raw_mmap_pages</span><span class="params">(<span class="type">unsigned</span> l)</span> : raw(l) &#123;</span></span><br><span class="line">        data = (<span class="type">char</span>*)::<span class="built_in">mmap</span>(<span class="literal">NULL</span>, len, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (!data)</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">bad_alloc</span>();</span><br><span class="line">        <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">        <span class="built_in">inc_history_alloc</span>(len);</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;raw_mmap &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">raw_mmap_pages</span>() &#123;</span><br><span class="line">        ::<span class="built_in">munmap</span>(data, len);</span><br><span class="line">        <span class="built_in">dec_total_alloc</span>(len);</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;raw_mmap &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; free &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">raw* <span class="title">clone_empty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">raw_mmap_pages</span>(len);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="buffer-ptr"><a href="#buffer-ptr" class="headerlink" title="buffer::ptr"></a>buffer::ptr</h3><p>buffer::ptr是在buffer::raw系列的基础上，这个类也别名bufferptr， 这个类是raw这个类的包装升级版本，它的_raw就是指向buffer::raw类型的变量。成员部分如下（include&#x2F;buffer.h）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> ptr</span><br><span class="line">&#123;</span><br><span class="line">    raw *_raw;</span><br><span class="line">    <span class="type">unsigned</span> _off, _len;</span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类buffer::ptr就是对于buffer::raw的一部分数据段，ptr是raw里的一个任意的数据段，_off是在_raw里的偏移量，_len是在ptr的长度。<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_3.png"><br>raw是真正存储数据的地方，而ptr只是指向某个raw中的一段的指针。其数据成员 _raw为指向raw的指针，_off表示数据起始偏移，_len表示数据长度。这边还有提一下ptr的append函数，直观上ptr不应该提供append函数，事实上ptr的append确实很局限，只有当ptr对应的raw区域后方有空闲空间的时候，才能append成功，至于空间不够的情况，应该是交给list等高层类来处理。代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> buffer::ptr::<span class="built_in">append</span>(<span class="type">const</span> <span class="type">char</span> *p, <span class="type">unsigned</span> l)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(l &lt;= <span class="built_in">unused_tail_length</span>());</span><br><span class="line">    <span class="type">char</span> *c = _raw-&gt;data + _off + _len;</span><br><span class="line">    <span class="built_in">maybe_inline_memcpy</span>(c, p, l, <span class="number">32</span>);</span><br><span class="line">    _len += l;</span><br><span class="line">    <span class="keyword">return</span> _len + _off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>buffer::ptr其他常见操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">buffer::ptr&amp; buffer::ptr::<span class="keyword">operator</span>= (<span class="type">const</span> ptr&amp; p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (p._raw) &#123;</span><br><span class="line">        p._raw-&gt;nref.<span class="built_in">inc</span>();</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;ptr &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; get &quot;</span> &lt;&lt; _raw &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    buffer::raw *raw = p._raw; </span><br><span class="line">    <span class="built_in">release</span>();</span><br><span class="line">    <span class="keyword">if</span> (raw) &#123;</span><br><span class="line">        _raw = raw;</span><br><span class="line">        _off = p._off;</span><br><span class="line">        _len = p._len;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        _off = _len = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">buffer::raw *buffer::ptr::<span class="built_in">clone</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">clone</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> buffer::ptr::<span class="built_in">swap</span>(ptr&amp; other)</span><br><span class="line">&#123;</span><br><span class="line">    raw *r = _raw;</span><br><span class="line">    <span class="type">unsigned</span> o = _off;</span><br><span class="line">    <span class="type">unsigned</span> l = _len;</span><br><span class="line">    _raw = other._raw;</span><br><span class="line">    _off = other._off;</span><br><span class="line">    _len = other._len;</span><br><span class="line">    other._raw = r;</span><br><span class="line">    other._off = o;</span><br><span class="line">    other._len = l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">char</span>&amp; buffer::ptr::<span class="keyword">operator</span>[](<span class="type">unsigned</span> n) <span class="type">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(n &lt; _len);</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">get_data</span>()[_off + n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span>&amp; buffer::ptr::<span class="keyword">operator</span>[](<span class="type">unsigned</span> n)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(n &lt; _len);</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">get_data</span>()[_off + n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> buffer::ptr::<span class="built_in">cmp</span>(<span class="type">const</span> ptr&amp; o) <span class="type">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> l = _len &lt; o._len ? _len : o._len;</span><br><span class="line">    <span class="keyword">if</span> (l) &#123;</span><br><span class="line">        <span class="type">int</span> r = <span class="built_in">memcmp</span>(<span class="built_in">c_str</span>(), o.<span class="built_in">c_str</span>(), l);</span><br><span class="line">        <span class="keyword">if</span> (r)</span><br><span class="line">            <span class="keyword">return</span> r;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (_len &lt; o._len)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (_len &gt; o._len)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;                 </span><br></pre></td></tr></table></figure><h3 id="buffer-list"><a href="#buffer-list" class="headerlink" title="buffer::list"></a>buffer::list</h3><p>类buffer::list是一个使用广泛的类，它是多个buffer::ptr的列表，也就是多个内存数据段的列表。多个bufferptr形成一个list，这就是bufferlist。简单来说，list就是一个ptr组成的链表：（include&#x2F;buffer.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> list</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// my private bits</span></span><br><span class="line">std::list&lt;ptr&gt; _buffers;    <span class="comment">//所有的ptr</span></span><br><span class="line"><span class="type">unsigned</span> _len;       <span class="comment">//所有的ptr的数据总长度</span></span><br><span class="line"><span class="type">unsigned</span> _memcopy_count; <span class="comment">//当调用函数rebuild用来内存对齐时，需要内存拷贝的数据量</span></span><br><span class="line">ptr append_buffer;       <span class="comment">// 当有小的数据就添加到这个buffer里</span></span><br><span class="line">    <span class="keyword">mutable</span> iterator last_p;       <span class="comment">//访问list的迭代器</span></span><br><span class="line">......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_4.png"><br>buffers是一个ptr的链表，_len是整个_buffers中所有的ptr的数据的总长度，_memcopy_count用于统计memcopy的字节数，append_buffer是用于优化append操作的缓冲区，可以看出bufferlist将数据以不连续链表的方式存储。</p><h3 id="bufferlist的迭代器"><a href="#bufferlist的迭代器" class="headerlink" title="bufferlist的迭代器"></a>bufferlist的迭代器</h3><p>迭代器中提供的seek(unsigned o)和advance(int o)等函数中的o都是指bufferlist的偏移，而不是单个ptr内的偏移。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> is_const&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> iterator_impl</span><br><span class="line">    : <span class="keyword">public</span> std::iterator&lt;std::forward_iterator_tag, <span class="type">char</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="type">bl_t</span> *bl;</span><br><span class="line">    <span class="type">list_t</span> *ls;   <span class="comment">// meh.. just here to avoid an extra pointer dereference..</span></span><br><span class="line">    <span class="type">unsigned</span> off; <span class="comment">// in bl</span></span><br><span class="line">    <span class="type">list_iter_t</span> p;</span><br><span class="line">    <span class="type">unsigned</span> p_off; <span class="comment">// in *p</span></span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其数据成员的含义如下：</p><ul><li>bl：指针，指向bufferlist</li><li>ls：指针，指向bufferlist的成员 _buffers</li><li>p: 类型是std::list::iterator，用来迭代遍历bufferlist中的bufferptr</li><li>p_off：当前位置在对应的bufferptr中的偏移量</li><li>off：当前位置在整个bufferlist中的偏移量</li></ul><h3 id="bufferlist常用函数"><a href="#bufferlist常用函数" class="headerlink" title="bufferlist常用函数"></a>bufferlist常用函数</h3><p>librados只给出bufferlist API</p><ol><li>clear()<br> 清空bufferlist中的内容</li><li>push_front(raw* &#x2F; ptr &amp;)<br>push_back(raw* &#x2F; ptr &amp;)<br> 在_buffers的前面或后面增加新的ptr</li><li>rebuild()<br>rebuild(ptr &amp;nb)<br> 将bufferlist中buffers链表中所有的ptr中的数据存到一个ptr中，并将_buffers原有数据clear，然后将新的单个ptr push到_buffers中。<br> 带参数时使用参数传入的ptr作为目标ptr，不带参数时自己创建一个ptr。</li><li>claim(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br> 将bl的数据拿过来，替换原有的数据。调用后bl数据被清空。</li><li>claim_append(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br>claim_prepend(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br> 将bl的数据拿过来，splice到_buffers的尾部&#x2F;头部。</li><li>append(…)<br> 将数据追加到_buffers尾部，已有ptr空间不够时，会自动分配新的ptr。</li><li>splice(unsigned off, unsigned len, list *claim_by &#x3D; 0)            bl.splice(10,10,&amp;bl2);<br> 将_buffers中总偏移off处长度为len的数据，move到claim_by对应的bufferlist的尾部。注意是move不是copy。</li><li>write(int off, int len, std::ostream &amp;out)<br> 将_buffers中总偏移量off处长度为len的数据，写入到ostream。注意是copy，不是move。</li><li>push_front(ptr&amp; pb)<br> 添加一个ptr到list头部</li><li>push_front(raw *r)<br>添加一个raw到list头部中，先构造一个ptr，后添加list中</li><li>is_aligned(align)<br>判断内存是否以参数align对齐，每一个ptr都必须以align对齐</li><li>read_fd()&#x2F;write_fd()<br>把数据写入文件描述符或者从文件描述符读取数据</li><li>read_file()&#x2F;write_file()<br>把数据写入文件或从文件读取数据的功能</li><li>write_stream()</li></ol><p>内存对齐：有些情况下，需要内存地址对齐，例如当以directIO方式写入数据至磁盘时，需要内存地址按照内存页面大小（page）对齐，也即buffer::list的内存地址都需按照page对齐。函数rebuild用来完成对齐的功能。其实现的方法也比较简单，检查没有对齐的ptr，申请一块新对齐的内存，把数据拷贝过去，释放内存空间就可以了。</p><p>相关链接：<br>    <a href="http://bean-li.github.io/bufferlist-in-ceph/">http://bean-li.github.io/bufferlist-in-ceph/</a><br>    <a href="https://www.jianshu.com/p/01e1f4e398df">https://www.jianshu.com/p/01e1f4e398df</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-Bufferlist的设计与使用&quot;&gt;&lt;a href=&quot;#Ceph-Bufferlist的设计与使用&quot; class=&quot;headerlink&quot; title=&quot;Ceph Bufferlist的设计与使用&quot;&gt;&lt;/a&gt;Ceph Bufferlist的设计与使用&lt;/</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph序列化</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2021-07-10T04:43:01.000Z</published>
    <updated>2024-07-27T14:36:56.441Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-数据序列化"><a href="#Ceph-数据序列化" class="headerlink" title="Ceph 数据序列化"></a>Ceph 数据序列化</h2><p>Ceph 作为主要处理磁盘和网络的分布式存储系统，数据序列化是其最基本的功能之一。当一个结构通过网络发送或写入磁盘时，它会被编码为一串字节。可序列化的结构体具有 encode 和 decode 方法，用于将结构体序列化后存入 bufferlist，或从 bufferlist 读取字节串并反序列化为结构体。</p><p>在 Ceph 中，经常需要将一个 bufferlist 编码（encode）到另一个 bufferlist 中。例如，在 msg 发送消息时，msg 通常会接收到由 OSD 等逻辑层传递给它的 bufferlist，然后 msg 需要给这个 bufferlist 添加消息头和消息尾，而消息头和消息尾也是用 bufferlist 表示的。在这种情况下，msg 通常会构造一个空的 bufferlist，然后将消息头、消息尾和内容都编码到这个空的 bufferlist 中。</p><p>在 bufferlist 之间进行编码实际上只需要进行指针的复制，而不涉及系统内存的申请和复制，因此效率较高。encode 和 decode 方法的主要作用是方便 Ceph 不同模块之间的参数传输。</p><p>在Ceph代码中有很多例子，这里有一个例子。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AcmeClass</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> member1;</span><br><span class="line">    std::string member2;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">encode</span><span class="params">(bufferlist &amp;bl)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">ENCODE_START</span>(<span class="number">1</span>, <span class="number">1</span>, bl);</span><br><span class="line">        ::<span class="built_in">encode</span>(member1, bl);</span><br><span class="line">        ::<span class="built_in">encode</span>(member2, bl);</span><br><span class="line">        <span class="built_in">ENCODE_FINISH</span>(bl);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">decode</span><span class="params">(bufferlist::iterator &amp;bl)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">DECODE_START</span>(<span class="number">1</span>, bl);</span><br><span class="line">        ::<span class="built_in">decode</span>(member1, bl);</span><br><span class="line">        ::<span class="built_in">decode</span>(member2, bl);</span><br><span class="line">        <span class="built_in">DECODE_FINISH</span>(bl);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>ENCODE_START</code>宏写入标头 说明version和 compat_version（初值均为 1）。每当对encode进行更改时，version就会增加。仅当更改会影响decode时compat_version才会增加  - 比如新结构体只在尾部添加字段，不会影响旧结构体的解析，因此在结构末尾添加字段的更改不需要增加 compat_version。<br><code>DECODE_START</code>宏采用一个参数，指定encode代码可以处理的最新消息版本。这与消息中编码的 compat_version 进行比较，如果消息太新，则会抛出异常。因为对 compat_verison 的更改很少，所以在添加字段时通常不需要担心。</p><h2 id="Ceph序列化的方式"><a href="#Ceph序列化的方式" class="headerlink" title="Ceph序列化的方式"></a>Ceph序列化的方式</h2><p>序列化（在 Ceph 中称为 encode）的目的是将数据结构表示为二进制流，以便通过网络传输或保存在磁盘等存储介质上。其逆过程称为反序列化（在 Ceph 中称为 decode）。例如，对于字符串“abc”，其序列化结果为7个字节（bytes）：03 00 00 00 61 62 63，其中前四个字节（03 00 00 00）表示字符串的长度为3个字符，后三个字节（61 62 63）分别是字符“abc”的 ASCII 码的十六进制表示。Ceph 采用 little-endian 的序列化方式，即低地址存放最低有效字节，因此32位整数0x12345678的序列化结果为78 56 34 12。</p><p>由于序列化在整个 Ceph 系统中是非常基础且常用的功能，Ceph 将其序列化方式设计为统一的结构，即任何支持序列化的数据结构都必须提供一对定义在全局命名空间中的序列化&#x2F;反序列化（encode&#x2F;decode）函数。例如，如果我们定义了一个结构体 inode，就必须在全局命名空间中定义以下两个方法：</p><ol><li><code>encode(struct inode, bufferlist bl);</code></li><li><code>decode(struct inode, bufferlist::iterator bl);</code></li></ol><p>在此基础上，序列化的使用变得非常简单。对于任意可序列化的类型 T 的实例 instance_T，可以通过如下语句将 instance_T 序列化并保存到 bufferlist 类的实例 instance_bufferlist 中。</p><p>bufferlist类（定义于include&#x2F;buffer.h）是ceph核心的缓存类，用于保存序列化结果、数据缓存、网络通信等，能够将bufferlist理解为一个可变长度的char数组。</p><p>如下代码演示了将一个时间戳以及一个inode序列化到一个bufferlist中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">utime_t</span> timestamp;</span><br><span class="line"><span class="type">inode_t</span> inode;</span><br><span class="line">bufferlist bl;</span><br><span class="line">::<span class="built_in">encode</span>(timetamp, bl)</span><br><span class="line">::<span class="built_in">encode</span>(inode, bl);</span><br></pre></td></tr></table></figure><p>序列化后的数据能够经过反序列化方法读取，例如如下代码片断从一个bufferlist中反序列化一个时间戳和一个inode（前提是该bl中已经被序列化了一个utime_t和一个inode，不然会报错）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bufferlist::iterator bl;</span><br><span class="line">::<span class="built_in">decode</span>(timetamp, bl)</span><br><span class="line">::<span class="built_in">decode</span>(inode, bl);</span><br></pre></td></tr></table></figure><h2 id="各种数据类型的序列化"><a href="#各种数据类型的序列化" class="headerlink" title="各种数据类型的序列化"></a>各种数据类型的序列化</h2><p>Ceph为其全部用到数据类型提供了序列化方法或反序列化方法，这些数据类型包括了绝大部分<code>基础数据类型（int、bool等）</code>、<code>结构体类型的序列化（ceph_mds_request_head等）</code>、<code>集合类型（vector、list、set、map等）</code>、以及<code>自定义的复杂数据类型（例如表示inode的inode_t等）</code>，如下分别介绍不一样数据类型的序列化实现方式。</p><h4 id="1、基本数据类型的序列化"><a href="#1、基本数据类型的序列化" class="headerlink" title="1、基本数据类型的序列化"></a>1、基本数据类型的序列化</h4><p>基本数据类型的序列化结果基本就是该类型在内存中的表示形式。基本数据类型的序列化方法使用手工编写，定义在include&#x2F;encoding.h中，包括如下类型：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__u8, __s8, <span class="type">char</span>, <span class="type">bool</span></span><br><span class="line">ceph_le64, ceph_le32, ceph_le16,</span><br><span class="line"><span class="type">float</span>, <span class="type">double</span>,</span><br><span class="line"><span class="type">uint64_t</span>, <span class="type">int64_t</span>, <span class="type">uint32_t</span>, <span class="type">int32_t</span>, <span class="type">uint16_t</span>, <span class="type">int16_t</span>,</span><br><span class="line">string, <span class="type">char</span>*</span><br></pre></td></tr></table></figure><p>在手工编写encode方法过程当中，为了不重复代码，借助了WRITE_RAW_ENCODER和WRITE_INTTYPE_ENCODER两个宏。</p><h4 id="2、结构体类型的序列化"><a href="#2、结构体类型的序列化" class="headerlink" title="2、结构体类型的序列化"></a>2、结构体类型的序列化</h4><p>结构体类型的序列化方法与基本数据类型的序列化方法一致，即便用结构体的内存布局做为序列化的形式。在结构体定义完成后，经过调用WRITE_RAW_ENCODER宏函数生成结构体的全局encode方法，例如结构体ceph_mds_request_head相关结构实现以下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ceph_mds_request_head</span> &#123;</span><br><span class="line">    __le64 oldest_client_tid;</span><br><span class="line">    __le32 mdsmap_epoch;</span><br><span class="line">    __le32 flags;</span><br><span class="line">    __u8 num_retry, num_fwd;</span><br><span class="line">    __le16 num_releases;</span><br><span class="line">    __le32 op;</span><br><span class="line">    __le32 caller_uid, caller_gid;</span><br><span class="line">    __le64 ino;</span><br><span class="line">&#125; __attribute__ ((packed));</span><br><span class="line"><span class="built_in">WRITE_RAW_ENCODER</span>(ceph_mds_request_head)</span><br></pre></td></tr></table></figure><p>其中：<br>    ceph_mds_request_head结构体定义在include&#x2F;ceph_fs.h . WRITE_RAW_ENCODER(ceph_mds_request_head)语句位于include&#x2F;types.h WRITE_RAW_ENCODER宏函数定义在include&#x2F;encoding.h WRITE_RAW_ENCODER宏函数其实是经过调用encode_raw实现的，而encode_raw调用bufferlist的append的方法，经过内存拷贝，将数据结构放入到bufferlist中。相关代码为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">encode_raw</span><span class="params">(<span class="type">const</span> T&amp; t, bufferlist&amp; bl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    bl.<span class="built_in">append</span>((<span class="type">char</span>*)&amp;t, <span class="built_in">sizeof</span>(t));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">decode_raw</span><span class="params">(T&amp; t, bufferlist::iterator &amp;p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    p.<span class="built_in">copy</span>(<span class="built_in">sizeof</span>(t), (<span class="type">char</span>*)&amp;t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、集合数据类型的序列化"><a href="#3、集合数据类型的序列化" class="headerlink" title="3、集合数据类型的序列化"></a>3、集合数据类型的序列化</h4><p>集合数据类型序列化的基本思路包括两步：</p><ul><li>序列化集合大小，</li><li>序列化集合内的全部元素</li></ul><p>例如vector<T>&amp; v的序列化方法：其中元素的序列化经过调用该元素的encode方法实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">encode</span><span class="params">(<span class="type">const</span> std::vector&lt;T&gt;&amp; v, bufferlist&amp; bl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __u32 n = v.<span class="built_in">size</span>();</span><br><span class="line">    <span class="built_in">encode</span>(n, bl);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">typename</span> std::vector&lt;T&gt;::const_iterator p = v.<span class="built_in">begin</span>(); p != v.<span class="built_in">end</span>(); ++p)</span><br><span class="line">    <span class="built_in">encode</span>(*p, bl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经常使用集合数据类型的序列化已经由Ceph实现，位于include&#x2F;encoding.h中，包括如下集合类型：pair, triple, list, set, vector, map, multimap, hash_map, hash_set, deque。集合类型的序列化方法皆为基于泛型（模板类）的实现方式，适用于全部泛型派生类。</p><h4 id="4、复杂数据类型的序列化"><a href="#4、复杂数据类型的序列化" class="headerlink" title="4、复杂数据类型的序列化"></a>4、复杂数据类型的序列化</h4><p>除以上两种业务无关的数据类型外，其它数据类型的序列化实现包括两部分： 在类型内部现实encode方法，将类型内部的encode方法重定义为全局方法。如下以utime_t类为例：utime_t内部实现了encode和decode两个方法，WRITE_CLASS_ENCODER宏函数将这两个方法转化为全局方法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">utime_t</span> &#123;</span><br><span class="line">    <span class="keyword">struct</span> &#123;</span><br><span class="line">    __u32 tv_sec, tv_nsec;</span><br><span class="line">    &#125; tv;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">encode</span><span class="params">(bufferlist &amp;bl)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    ::<span class="built_in">encode</span>(tv.tv_sec, bl);</span><br><span class="line">    ::<span class="built_in">encode</span>(tv.tv_nsec, bl);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">decode</span><span class="params">(bufferlist::iterator &amp;p)</span> </span>&#123;</span><br><span class="line">    ::<span class="built_in">decode</span>(tv.tv_sec, p);</span><br><span class="line">    ::<span class="built_in">decode</span>(tv.tv_nsec, p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">WRITE_CLASS_ENCODER</span>(<span class="type">utime_t</span>)</span><br></pre></td></tr></table></figure><p>复杂数据结构内部的encode方法的实现方式一般是调用其内部主要数据结构的encode方法，例如utime_t类的encode方法其实是序列化内部的tv.tv_sec和tv.tv_nsec两个成员。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-数据序列化&quot;&gt;&lt;a href=&quot;#Ceph-数据序列化&quot; class=&quot;headerlink&quot; title=&quot;Ceph 数据序列化&quot;&gt;&lt;/a&gt;Ceph 数据序列化&lt;/h2&gt;&lt;p&gt;Ceph 作为主要处理磁盘和网络的分布式存储系统，数据序列化是其最基本的功能</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph相关数据结构</title>
    <link href="https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-07-02T15:33:02.000Z</published>
    <updated>2024-07-27T14:36:43.411Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-相关数据结构"><a href="#Ceph-相关数据结构" class="headerlink" title="Ceph 相关数据结构"></a>Ceph 相关数据结构</h2><p>要想深入到Ceph的源码底层，就必须对代码通用库里的一些关键，常见的数据结构进行学习，这样才能更好的理解源代码。从最高的逻辑层次为<code>Pool</code>的概念，然后是<code>PG</code>的概念。其次是<code>OSDＭap</code>记录了集群的所有的配置信息。数据结构<code>OSDOp</code>是一个操作上下文的封装。结构<code>object_info_t</code>保存了一个元数据信息和访问信息。对象<code>ObjectState</code>是在<code>object_info_t</code>基础上添加了一些内存的状态信息。<code>SnapSetContext</code>和<code>ObjectContext</code>分别保存了快照和对象上下文相关的信息。<code>Session</code>保存了一个端到端的链接相关的上下文。</p><h3 id="Pool"><a href="#Pool" class="headerlink" title="Pool"></a>Pool</h3><p><code>Pool</code>是整个集群层面定义的一个逻辑的存储池。对一个Pool可以设置相应的数据冗余类型，目前有副本和纠删码两种实现。数据结构pg_pool_t用于保存Pool的相关信息。<br>Pool的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">pg_pool_t</span> &#123;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_CEPHFS;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_RBD;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_RGW;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">enum</span> &#123;</span><br><span class="line">    TYPE_REPLICATED = <span class="number">1</span>,     <span class="comment">// replication  副本   </span></span><br><span class="line">    <span class="comment">//TYPE_RAID4 = 2,   // raid4 (never implemented)   从来没实现的raid4</span></span><br><span class="line">    TYPE_ERASURE = <span class="number">3</span>,      <span class="comment">// erasure-coded   纠删码</span></span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">enum</span> &#123;</span><br><span class="line">    FLAG_HASHPSPOOL = <span class="number">1</span>&lt;&lt;<span class="number">0</span>, <span class="comment">// hash pg seed and pool together (instead of adding)</span></span><br><span class="line">    FLAG_FULL       = <span class="number">1</span>&lt;&lt;<span class="number">1</span>, <span class="comment">// pool is full</span></span><br><span class="line">    FLAG_EC_OVERWRITES = <span class="number">1</span>&lt;&lt;<span class="number">2</span>, <span class="comment">// enables overwrites, once enabled, cannot be disabled</span></span><br><span class="line">    FLAG_INCOMPLETE_CLONES = <span class="number">1</span>&lt;&lt;<span class="number">3</span>, <span class="comment">// may have incomplete clones (bc we are/were an overlay)</span></span><br><span class="line">    FLAG_NODELETE = <span class="number">1</span>&lt;&lt;<span class="number">4</span>, <span class="comment">// pool can&#x27;t be deleted</span></span><br><span class="line">    FLAG_NOPGCHANGE = <span class="number">1</span>&lt;&lt;<span class="number">5</span>, <span class="comment">// pool&#x27;s pg and pgp num can&#x27;t be changed</span></span><br><span class="line">    FLAG_NOSIZECHANGE = <span class="number">1</span>&lt;&lt;<span class="number">6</span>, <span class="comment">// pool&#x27;s size and min size can&#x27;t be changed</span></span><br><span class="line">    FLAG_WRITE_FADVISE_DONTNEED = <span class="number">1</span>&lt;&lt;<span class="number">7</span>, <span class="comment">// write mode with LIBRADOS_OP_FLAG_FADVISE_DONTNEED</span></span><br><span class="line">    FLAG_NOSCRUB = <span class="number">1</span>&lt;&lt;<span class="number">8</span>, <span class="comment">// block periodic scrub</span></span><br><span class="line">    FLAG_NODEEP_SCRUB = <span class="number">1</span>&lt;&lt;<span class="number">9</span>, <span class="comment">// block periodic deep-scrub</span></span><br><span class="line">    FLAG_FULL_QUOTA = <span class="number">1</span>&lt;&lt;<span class="number">10</span>, <span class="comment">// pool is currently running out of quota, will set FLAG_FULL too</span></span><br><span class="line">    FLAG_NEARFULL = <span class="number">1</span>&lt;&lt;<span class="number">11</span>, <span class="comment">// pool is nearfull</span></span><br><span class="line">    FLAG_BACKFILLFULL = <span class="number">1</span>&lt;&lt;<span class="number">12</span>, <span class="comment">// pool is backfillfull</span></span><br><span class="line">    FLAG_SELFMANAGED_SNAPS = <span class="number">1</span>&lt;&lt;<span class="number">13</span>, <span class="comment">// pool uses selfmanaged snaps</span></span><br><span class="line">    FLAG_POOL_SNAPS = <span class="number">1</span>&lt;&lt;<span class="number">14</span>,        <span class="comment">// pool has pool snaps</span></span><br><span class="line">    FLAG_CREATING = <span class="number">1</span>&lt;&lt;<span class="number">15</span>,          <span class="comment">// initial pool PGs are being created</span></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="type">utime_t</span> create_time;      <span class="comment">//Pool创建时间</span></span><br><span class="line">  <span class="type">uint64_t</span> flags;           <span class="comment">///&lt; FLAG_*   Pool的相关标志</span></span><br><span class="line">  __u8 type;                <span class="comment">///&lt; TYPE_*   类型</span></span><br><span class="line">  __u8 size, min_size;     <span class="comment">///&lt;Pool的size和min_size，即副本数和至少保证的副本数</span></span><br><span class="line">  __u8 crush_rule;          <span class="comment">///&lt; crush placement rule    rule的编号</span></span><br><span class="line">  __u8 object_hash;         <span class="comment">///&lt; hash mapping object name to ps   对象映射的hash函数</span></span><br><span class="line">  __u8 pg_autoscale_mode;   <span class="comment">///&lt; PG_AUTOSCALE_MODE_        PG数自动增减模式</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  __u32 pg_num = <span class="number">0</span>, pgp_num = <span class="number">0</span>;  <span class="comment">///&lt; pg、pgp的数量</span></span><br><span class="line">  __u32 pg_num_pending = <span class="number">0</span>;       <span class="comment">///&lt; pg_num we are about to merge down to</span></span><br><span class="line">  __u32 pg_num_target = <span class="number">0</span>;        <span class="comment">///&lt; pg_num we should converge toward</span></span><br><span class="line">  __u32 pgp_num_target = <span class="number">0</span>;       <span class="comment">///&lt; pgp_num we should converge toward</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  map&lt;string,string&gt; properties;  <span class="comment">///&lt; OBSOLETE</span></span><br><span class="line">  string erasure_code_profile; <span class="comment">///&lt; name of the erasure code profile in OSDMap</span></span><br><span class="line">  <span class="type">epoch_t</span> last_change;      <span class="comment">///&lt; most recent epoch changed, exclusing snapshot changes</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend (pre-nautilus clients only)</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend_prenautilus = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend (pre-luminous clients only)</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend_preluminous = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// metadata for the most recent PG merge</span></span><br><span class="line">  <span class="type">pg_merge_meta_t</span> last_pg_merge_meta;</span><br><span class="line">  </span><br><span class="line">  <span class="type">snapid_t</span> snap_seq;        <span class="comment">///&lt; seq for per-pool snapshot</span></span><br><span class="line">  <span class="type">epoch_t</span> snap_epoch;       <span class="comment">///&lt; osdmap epoch of last snap</span></span><br><span class="line">  <span class="type">uint64_t</span> auid;            <span class="comment">///&lt; who owns the pg</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> quota_max_bytes; <span class="comment">///&lt; maximum number of bytes for this pool</span></span><br><span class="line">  <span class="type">uint64_t</span> quota_max_objects; <span class="comment">///&lt; maximum number of objects for this pool</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Pool snaps (global to this pool).  These define a SnapContext for</span></span><br><span class="line"><span class="comment">   * the pool, unless the client manually specifies an alternate</span></span><br><span class="line"><span class="comment">   * context.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  map&lt;<span class="type">snapid_t</span>, <span class="type">pool_snap_info_t</span>&gt; snaps;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Alternatively, if we are defining non-pool snaps (e.g. via the</span></span><br><span class="line"><span class="comment">   * Ceph MDS), we must track @removed_snaps (since @snaps is not</span></span><br><span class="line"><span class="comment">   * used).  Snaps and removed_snaps are to be used exclusive of each</span></span><br><span class="line"><span class="comment">   * other!</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  interval_set&lt;<span class="type">snapid_t</span>&gt; removed_snaps;</span><br><span class="line"></span><br><span class="line">  <span class="type">unsigned</span> pg_num_mask, pgp_num_mask;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Tier cache : Base Storage = N : 1</span></span><br><span class="line">  <span class="comment">// ceph osd tier add &#123;data_pool&#125; &#123;cache pool&#125;</span></span><br><span class="line">  set&lt;<span class="type">uint64_t</span>&gt; tiers;      <span class="comment">///&lt; pools that are tiers of us</span></span><br><span class="line">  <span class="type">int64_t</span> tier_of;         <span class="comment">///&lt; pool for which we are a tier</span></span><br><span class="line">  <span class="comment">// Note that write wins for read+write ops</span></span><br><span class="line">  <span class="comment">// WriteBack mode, read_tier is same as write_tier. Both are cache pool.</span></span><br><span class="line">  <span class="comment">// Diret mode. cache pool is read_tier, not write_tier. </span></span><br><span class="line">  <span class="comment">// ceph osd tier set-overlay &#123;data_pool&#125; &#123;cache_pool&#125;</span></span><br><span class="line">  <span class="type">int64_t</span> read_tier;       <span class="comment">///&lt; pool/tier for objecter to direct reads to</span></span><br><span class="line">  <span class="type">int64_t</span> write_tier;      <span class="comment">///&lt; pool/tier for objecter to direct writes to</span></span><br><span class="line">  <span class="comment">// Set cache mode</span></span><br><span class="line">  <span class="comment">// ceph osd tier cache-mode &#123;cache-pool&#125; &#123;cache-mode&#125;</span></span><br><span class="line">  <span class="type">cache_mode_t</span> cache_mode;  <span class="comment">///&lt; cache pool mode</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> target_max_bytes;   <span class="comment">///&lt; tiering: target max pool size</span></span><br><span class="line">  <span class="type">uint64_t</span> target_max_objects; <span class="comment">///&lt; tiering: target max pool size</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_dirty_ratio_micro; <span class="comment">///&lt; cache: fraction of target to leave dirty</span></span><br><span class="line">  <span class="comment">// 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_dirty_high_ratio_micro; <span class="comment">///&lt; cache: fraction of  target to flush with high speed</span></span><br><span class="line">  <span class="comment">// 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_full_ratio_micro;  <span class="comment">///&lt; cache: fraction of target to fill before we evict in earnest</span></span><br><span class="line">  <span class="comment">// 对象在 cache 中被刷入到 storage 层的最小时间</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_min_flush_age;  <span class="comment">///&lt; minimum age (seconds) before we can flush</span></span><br><span class="line">  <span class="comment">// 对象在 cache 中被淘汰的最小时间</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_min_evict_age;  <span class="comment">///&lt; minimum age (seconds) before we can evict</span></span><br><span class="line">  <span class="comment">// HitSet 相关参数</span></span><br><span class="line">  HitSet::Params hit_set_params; <span class="comment">///&lt; The HitSet params to use on this pool</span></span><br><span class="line">  <span class="comment">// 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的h缓存统计信息</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_period;      <span class="comment">///&lt; periodicity of HitSet segments (seconds)</span></span><br><span class="line">  <span class="comment">// 记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_count;       <span class="comment">///&lt; number of periods to retain</span></span><br><span class="line">  <span class="comment">// hitset archive 对象的命名规则 </span></span><br><span class="line">  <span class="type">bool</span> use_gmt_hitset;        <span class="comment">///&lt; use gmt to name the hitset archive object</span></span><br><span class="line">  <span class="type">uint32_t</span> min_read_recency_for_promote;   <span class="comment">///&lt; minimum number of HitSet to check before promote on read</span></span><br><span class="line">  <span class="type">uint32_t</span> min_write_recency_for_promote;  <span class="comment">///&lt; minimum number of HitSet to check before promote on write</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_grade_decay_rate;   <span class="comment">///&lt; current hit_set has highest priority on objects</span></span><br><span class="line">                                       <span class="comment">///&lt; temperature count,the follow hit_set&#x27;s priority decay </span></span><br><span class="line">                                       <span class="comment">///&lt; by this params than pre hit_set</span></span><br><span class="line">                                       <span class="comment">//当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_search_last_n;   <span class="comment">///&lt; accumulate atmost N hit_sets for temperature  为温度累积最多N次hit_sets</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint32_t</span> stripe_width;        <span class="comment">///&lt; erasure coded stripe size in bytes</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> expected_num_objects; <span class="comment">///&lt; expected number of objects on this pool, a value of 0 indicates</span></span><br><span class="line">                                 <span class="comment">///&lt; user does not specify any expected value</span></span><br><span class="line">  <span class="type">bool</span> fast_read;            <span class="comment">///&lt; whether turn on fast read on the pool or not</span></span><br><span class="line">  <span class="type">pool_opts_t</span> opts; <span class="comment">///&lt; options</span></span><br><span class="line">  <span class="comment">/// application -&gt; key/value metadata</span></span><br><span class="line">  map&lt;string, std::map&lt;string, string&gt;&gt; application_metadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  vector&lt;<span class="type">uint32_t</span>&gt; grade_table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">get_grade</span><span class="params">(<span class="type">unsigned</span> i)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (grade_table.<span class="built_in">size</span>() &lt;= i)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> grade_table[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">calc_grade_table</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> v = <span class="number">1000000</span>;</span><br><span class="line">    grade_table.<span class="built_in">resize</span>(hit_set_count);        <span class="comment">// hit_set_count记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">unsigned</span> i = <span class="number">0</span>; i &lt; hit_set_count; i++) &#123;</span><br><span class="line">      v = v * (<span class="number">1</span> - (hit_set_grade_decay_rate / <span class="number">100.0</span>));</span><br><span class="line">      grade_table[i] = v;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>数据结构pg_pool_t的成员变量和方法较多，不一一介绍了。</p><h2 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h2><p><code>PG</code>可以认为是一组对象的集合，该集合里的对象有共同特征：副本都分布在相同的OSD列表中。结构体pg_t只是一个PG的静态描述信息（只有三个成员变量），类PG及其子类ReplicatedPG都是和PG相关的处理。<br>pg_t的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">pg_t</span> &#123;</span><br><span class="line">  <span class="type">uint64_t</span> m_pool;    <span class="comment">//pg所在的pool</span></span><br><span class="line">  <span class="type">uint32_t</span> m_seed;    <span class="comment">//pg的序号</span></span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">uint8_t</span> calc_name_buf_size = <span class="number">36</span>;  <span class="comment">// max length for max values len(&quot;18446744073709551615.ffffffff&quot;) + future suffix len(&quot;_head&quot;) + &#x27;\0&#x27;</span></span><br><span class="line">  <span class="function"><span class="type">hobject_t</span> <span class="title">get_hobj_start</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">hobject_t</span> <span class="title">get_hobj_end</span><span class="params">(<span class="type">unsigned</span> pg_num)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">generate_test_instances</span><span class="params">(list&lt;<span class="type">pg_t</span>*&gt;&amp; o)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="OSDMap"><a href="#OSDMap" class="headerlink" title="OSDMap"></a>OSDMap</h2><p><code>OSDMap类</code>定义了Ceph整个集群的全局信息。它由Monitor实现管理，并以全量或者增量的方式向整个集群扩散。每一个epoch对应的OSDMap都需要持久化保存在meta下对应对象的omap属性中。内部类Incremental以增量的形式保存了OSDMap新增的信息。OSDMap包含了四类信息：首先是集群的信息，其次是pool的信息，然后是临时PG相关信息，最后就是所有OSD的状态信息。<br>OSDMap类的数据结构如下：（src&#x2F;osd&#x2F;OSDMap.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OSDMap</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">typedef</span> interval_set&lt;</span><br><span class="line">    <span class="type">snapid_t</span>,</span><br><span class="line">    mempool::osdmap::flat_map&lt;<span class="type">snapid_t</span>,<span class="type">snapid_t</span>&gt;&gt; <span class="type">snap_interval_set_t</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Incremental</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line"><span class="comment">//系统相关的信息</span></span><br><span class="line">    <span class="comment">/// feature bits we were encoded with.  the subsequent OSDMap</span></span><br><span class="line">    <span class="comment">/// encoding should match.</span></span><br><span class="line">    <span class="type">uint64_t</span> encode_features;</span><br><span class="line">    uuid_d fsid;    <span class="comment">//当前集群的fsid值</span></span><br><span class="line">    <span class="type">epoch_t</span> epoch; <span class="comment">//当前集群的epoch值 new epoch; we are a diff from epoch-1 to epoch</span></span><br><span class="line">    <span class="type">utime_t</span> modified;   <span class="comment">//创建修改的时间戳</span></span><br><span class="line">    <span class="type">int64_t</span> new_pool_max; <span class="comment">//incremented by the OSDMonitor on each pool create</span></span><br><span class="line">    <span class="type">int32_t</span> new_flags;</span><br><span class="line">    <span class="type">int8_t</span> new_require_osd_release = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// full (rare)</span></span><br><span class="line">    bufferlist fullmap;  <span class="comment">// in lieu of below.</span></span><br><span class="line">    bufferlist crush;</span><br><span class="line">......</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">//集群相关的信息</span></span><br><span class="line">  uuid_d fsid;     <span class="comment">//当前集群的fsid值</span></span><br><span class="line">  <span class="type">epoch_t</span> epoch;        <span class="comment">//当前集群的epoch值 what epoch of the osd cluster descriptor is this</span></span><br><span class="line">  <span class="type">utime_t</span> created, modified; <span class="comment">//创建、修改的时间戳 epoch start time   </span></span><br><span class="line">  <span class="type">int32_t</span> pool_max;     <span class="comment">//最大的pool数量 the largest pool num, ever</span></span><br><span class="line">  <span class="type">uint32_t</span> flags;       <span class="comment">//一些标志信息</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">//OSD相关的信息</span></span><br><span class="line">  <span class="type">int</span> num_osd;         <span class="comment">//OSD的总数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int</span> num_up_osd;      <span class="comment">//处于up状态的OSD的数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int</span> num_in_osd;      <span class="comment">//处于in状态的OSD的数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int32_t</span> max_osd;     <span class="comment">//OSD的最大数目</span></span><br><span class="line">  vector&lt;<span class="type">uint32_t</span>&gt; osd_state;      <span class="comment">//OSD的状态</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int32_t</span>,<span class="type">uint32_t</span>&gt; crush_node_flags; <span class="comment">// crush node -&gt; CEPH_OSD_* flags</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int32_t</span>,<span class="type">uint32_t</span>&gt; device_class_flags; <span class="comment">// device class -&gt; CEPH_OSD_* flags</span></span><br><span class="line"></span><br><span class="line">  <span class="type">utime_t</span> last_up_change, last_in_change;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// These features affect OSDMap[::Incremental] encoding, or the</span></span><br><span class="line">  <span class="comment">// encoding of some type embedded therein (CrushWrapper, something</span></span><br><span class="line">  <span class="comment">// from osd_types, etc.).</span></span><br><span class="line">  <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">uint64_t</span> SIGNIFICANT_FEATURES =</span><br><span class="line">    CEPH_FEATUREMASK_PGID64 |</span><br><span class="line">    CEPH_FEATUREMASK_PGPOOL3 |</span><br><span class="line">    CEPH_FEATUREMASK_OSDENC |</span><br><span class="line">    CEPH_FEATUREMASK_OSDMAP_ENC |</span><br><span class="line">    CEPH_FEATUREMASK_OSD_POOLRESEND |</span><br><span class="line">    CEPH_FEATUREMASK_NEW_OSDOP_ENCODING |</span><br><span class="line">    CEPH_FEATUREMASK_MSG_ADDR2 |</span><br><span class="line">    CEPH_FEATUREMASK_CRUSH_TUNABLES5 |</span><br><span class="line">    CEPH_FEATUREMASK_CRUSH_CHOOSE_ARGS |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_LUMINOUS |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_MIMIC |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_NAUTILUS;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">addrs_s</span> &#123;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; client_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; cluster_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; hb_back_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; hb_front_addrs;</span><br><span class="line">  &#125;;</span><br><span class="line">  </span><br><span class="line">  std::shared_ptr&lt;addrs_s&gt; osd_addrs;    <span class="comment">//OSD的地址</span></span><br><span class="line">  <span class="type">entity_addrvec_t</span> _blank_addrvec;</span><br><span class="line">  mempool::osdmap::vector&lt;__u32&gt;   osd_weight;   <span class="comment">//OSD的权重 16.16 fixed point, 0x10000 = &quot;in&quot;, 0 = &quot;out&quot;</span></span><br><span class="line">  mempool::osdmap::vector&lt;<span class="type">osd_info_t</span>&gt; osd_info;    <span class="comment">//OSD 的基本信息</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::vector&lt;uuid_d&gt; &gt; osd_uuid;  <span class="comment">//OSD对应的uuid</span></span><br><span class="line">  mempool::osdmap::vector&lt;<span class="type">osd_xinfo_t</span>&gt; osd_xinfo;   <span class="comment">//OSD一些扩展信息</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//PG相关的信息</span></span><br><span class="line">  std::shared_ptr&lt;PGTempMap&gt; pg_temp;  <span class="comment">// temp pg mapping (e.g. while we rebuild)</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::map&lt;<span class="type">pg_t</span>,<span class="type">int32_t</span> &gt; &gt; primary_temp;  <span class="comment">// temp primary mapping (e.g. while we rebuild)</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::vector&lt;__u32&gt; &gt; osd_primary_affinity; <span class="comment">///&lt; 16.16 fixed point, 0x10000 = baseline</span></span><br><span class="line">  <span class="comment">// remap (post-CRUSH, pre-up)</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">pg_t</span>,mempool::osdmap::vector&lt;<span class="type">int32_t</span>&gt;&gt; pg_upmap; <span class="comment">///&lt; remap pg</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">pg_t</span>,mempool::osdmap::vector&lt;pair&lt;<span class="type">int32_t</span>,<span class="type">int32_t</span>&gt;&gt;&gt; pg_upmap_items; <span class="comment">///&lt; remap osds in up set</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//pool的相关信息</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int64_t</span>,<span class="type">pg_pool_t</span>&gt; pools;   <span class="comment">//pool的id到pg_pool_t的映射</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int64_t</span>,string&gt; pool_name;  <span class="comment">//pool的id到pool的名字的映射</span></span><br><span class="line">  mempool::osdmap::map&lt;string,map&lt;string,string&gt; &gt; erasure_code_profiles;    <span class="comment">//pool的EC相关信息</span></span><br><span class="line">  mempool::osdmap::map&lt;string,<span class="type">int64_t</span>&gt; name_pool;  <span class="comment">//pool的名字到pool的id的映射</span></span><br></pre></td></tr></table></figure><h2 id="Op"><a href="#Op" class="headerlink" title="Op"></a>Op</h2><p><code>结构体Op</code>封装了完成一个操作的相关上下文信息，包括target地址信息(op_target_t)、链接信息(session)等</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Op</span> : <span class="keyword">public</span> RefCountedObject &#123;</span><br><span class="line">    OSDSession *session;   <span class="comment">//OSD相关的Session信息 </span></span><br><span class="line">    <span class="type">int</span> incarnation;    <span class="comment">//引用次数</span></span><br><span class="line">    <span class="type">op_target_t</span> target;   <span class="comment">//地址信息</span></span><br><span class="line">    ConnectionRef con;  <span class="comment">// for rx buffer only</span></span><br><span class="line">    <span class="type">uint64_t</span> features;  <span class="comment">// explicitly specified op features</span></span><br><span class="line">    vector&lt;OSDOp&gt; ops;   <span class="comment">// 对应多个操作的封装</span></span><br><span class="line">    <span class="type">snapid_t</span> snapid;     <span class="comment">//快照的ID</span></span><br><span class="line">    SnapContext snapc;   <span class="comment">//pool层级的快照信息</span></span><br><span class="line">    ceph::real_time mtime;</span><br><span class="line">    bufferlist *outbl;    <span class="comment">//输出的bufferlist</span></span><br><span class="line">    vector&lt;bufferlist*&gt; out_bl;     <span class="comment">//每个操作对应的bufferlist</span></span><br><span class="line">    vector&lt;Context*&gt; out_handler;    <span class="comment">//每个操作对应的回调函数</span></span><br><span class="line">    vector&lt;<span class="type">int</span>*&gt; out_rval;     <span class="comment">//每个操作对应的输出结果</span></span><br><span class="line">    <span class="type">int</span> priority;</span><br><span class="line">    Context *onfinish;</span><br><span class="line">    <span class="type">uint64_t</span> ontimeout;</span><br><span class="line">    <span class="type">ceph_tid_t</span> tid;</span><br><span class="line">    <span class="type">int</span> attempts;</span><br><span class="line">    <span class="type">version_t</span> *objver;</span><br><span class="line">    <span class="type">epoch_t</span> *reply_epoch;</span><br><span class="line">    ceph::coarse_mono_time stamp;</span><br><span class="line">    <span class="type">epoch_t</span> map_dne_bound;</span><br><span class="line">    <span class="type">int</span> budget;</span><br><span class="line">    <span class="comment">/// true if we should resend this message on failure</span></span><br><span class="line">    <span class="type">bool</span> should_resend;</span><br><span class="line">    <span class="comment">/// true if the throttle budget is get/put on a series of OPs,</span></span><br><span class="line">    <span class="comment">/// instead of per OP basis, when this flag is set, the budget is</span></span><br><span class="line">    <span class="comment">/// acquired before sending the very first OP of the series and</span></span><br><span class="line">    <span class="comment">/// released upon receiving the last OP reply.</span></span><br><span class="line">    <span class="type">bool</span> ctx_budgeted;</span><br><span class="line">    <span class="type">int</span> *data_offset;</span><br><span class="line"></span><br><span class="line">    <span class="type">osd_reqid_t</span> reqid; <span class="comment">// explicitly setting reqid</span></span><br><span class="line">    ZTracer::Trace trace;</span><br></pre></td></tr></table></figure><h2 id="op-target-t"><a href="#op-target-t" class="headerlink" title="op_target_t"></a>op_target_t</h2><p>数据结构op_target_t封装了对象所在的PG，以及PG对应的OSD列表等地址信息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//封装了对象所在的PG，以及PG对应的OSD列表等地址信息</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">op_target_t</span> &#123;</span><br><span class="line">    <span class="type">int</span> flags = <span class="number">0</span>;    <span class="comment">//标志</span></span><br><span class="line">    <span class="type">epoch_t</span> epoch = <span class="number">0</span>;  <span class="comment">///&lt; latest epoch we calculated the mapping</span></span><br><span class="line">    <span class="type">object_t</span> base_oid;   <span class="comment">//读取的对象</span></span><br><span class="line">    <span class="type">object_locator_t</span> base_oloc;   <span class="comment">//对象的pool信息</span></span><br><span class="line">    <span class="type">object_t</span> target_oid;     <span class="comment">//最终读取的目标对象</span></span><br><span class="line">    <span class="type">object_locator_t</span> target_oloc;   <span class="comment">//最终目标对象的pool信息</span></span><br><span class="line">    <span class="comment">///&lt; true if we are directed at base_pgid, not base_oid</span></span><br><span class="line">    <span class="type">bool</span> precalc_pgid = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">///&lt; true if we have ever mapped to a valid pool</span></span><br><span class="line">    <span class="type">bool</span> pool_ever_existed = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">///&lt; explcit pg target, if any</span></span><br><span class="line">    <span class="type">pg_t</span> base_pgid;</span><br><span class="line">    <span class="type">pg_t</span> pgid; <span class="comment">///&lt; last (raw) pg we mapped to</span></span><br><span class="line">    <span class="type">spg_t</span> actual_pgid; <span class="comment">///&lt; last (actual) spg_t we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num = <span class="number">0</span>; <span class="comment">///&lt; last pg_num we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num_mask = <span class="number">0</span>; <span class="comment">///&lt; last pg_num_mask we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num_pending = <span class="number">0</span>; <span class="comment">///&lt; last pg_num we mapped to</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; up; <span class="comment">///&lt; set of up osds for last pg we mapped to</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; acting; <span class="comment">///&lt; set of acting osds for last pg we mapped to</span></span><br><span class="line">    <span class="type">int</span> up_primary = <span class="number">-1</span>; <span class="comment">///&lt; last up_primary we mapped to</span></span><br><span class="line">    <span class="type">int</span> acting_primary = <span class="number">-1</span>;  <span class="comment">///&lt; last acting_primary we mapped to</span></span><br><span class="line">    <span class="type">int</span> size = <span class="number">-1</span>; <span class="comment">///&lt; the size of the pool when were were last mapped</span></span><br><span class="line">    <span class="type">int</span> min_size = <span class="number">-1</span>; <span class="comment">///&lt; the min size of the pool when were were last mapped</span></span><br><span class="line">    <span class="type">bool</span> sort_bitwise = <span class="literal">false</span>; <span class="comment">///&lt; whether the hobject_t sort order is bitwise</span></span><br><span class="line">    <span class="type">bool</span> recovery_deletes = <span class="literal">false</span>; <span class="comment">///&lt; whether the deletes are performed during recovery instead of peering</span></span><br><span class="line">    <span class="type">bool</span> used_replica = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">bool</span> paused = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">int</span> osd = <span class="number">-1</span>;      <span class="comment">///&lt; the final target osd, or -1</span></span><br><span class="line">    <span class="type">epoch_t</span> last_force_resend = <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h2 id="CRUSH-Map"><a href="#CRUSH-Map" class="headerlink" title="CRUSH Map"></a>CRUSH Map</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_step</span> &#123;</span><br><span class="line">__u32 op;    <span class="comment">//操作类型</span></span><br><span class="line">__s32 arg1;   <span class="comment">//操作数1</span></span><br><span class="line">__s32 arg2;    <span class="comment">//操作数2</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">crush_opcodes</span> &#123;</span><br><span class="line">CRUSH_RULE_NOOP = <span class="number">0</span>,</span><br><span class="line">CRUSH_RULE_TAKE = <span class="number">1</span>,          <span class="comment">/* arg1 = value to start with */</span></span><br><span class="line">CRUSH_RULE_CHOOSE_FIRSTN = <span class="number">2</span>, <span class="comment">/* arg1 = num items to pick */</span> <span class="comment">/* arg2 = type */</span>      </span><br><span class="line">CRUSH_RULE_CHOOSE_INDEP = <span class="number">3</span>,  <span class="comment">/* same */</span></span><br><span class="line">CRUSH_RULE_EMIT = <span class="number">4</span>,          <span class="comment">/* no args */</span></span><br><span class="line">CRUSH_RULE_CHOOSELEAF_FIRSTN = <span class="number">6</span>,</span><br><span class="line">CRUSH_RULE_CHOOSELEAF_INDEP = <span class="number">7</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSE_TRIES = <span class="number">8</span>, <span class="comment">/* override choose_total_tries */</span></span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_TRIES = <span class="number">9</span>, <span class="comment">/* override chooseleaf_descend_once */</span></span><br><span class="line">CRUSH_RULE_SET_CHOOSE_LOCAL_TRIES = <span class="number">10</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSE_LOCAL_FALLBACK_TRIES = <span class="number">11</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_VARY_R = <span class="number">12</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_STABLE = <span class="number">13</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 用于指定相对于传递给 do_rule 的 max 参数的选择 num (arg1)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_CHOOSE_N            0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_CHOOSE_N_MINUS(x)   (-(x))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 规则掩码用于描述规则的用途。</span></span><br><span class="line"><span class="comment"> * 给定规则集和输出集的大小，我们在规则列表中搜索匹配的 rule_mask。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_mask</span> &#123;</span><br><span class="line">__u8 ruleset;   <span class="comment">//ruleId</span></span><br><span class="line">__u8 type;   <span class="comment">//多副本还是纠删码</span></span><br><span class="line">__u8 min_size;   <span class="comment">//副本数大于等于时适用</span></span><br><span class="line">__u8 max_size;   <span class="comment">//副本数小于等于时适用</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule</span> &#123;</span><br><span class="line">__u32 len;   <span class="comment">//steps数组的长度</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_mask</span> mask;   <span class="comment">//releset相关的配置参数</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_step</span> steps[<span class="number">0</span>];   <span class="comment">//step集合</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> crush_rule_size(len) (sizeof(struct crush_rule) + \</span></span><br><span class="line"><span class="meta">      (len)*sizeof(struct crush_rule_step))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * A bucket is a named container of other items (either devices or</span></span><br><span class="line"><span class="comment"> * other buckets).</span></span><br><span class="line"><span class="comment"> * 桶是其他item（设备或其他存储桶）的命名容器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 使用三种算法中的一种来选择的，这些算法代表了性能和重组效率之间的权衡。 </span></span><br><span class="line"><span class="comment"> * 如果您不确定要使用哪种存储桶类型，我们建议您使用 ::CRUSH_BUCKET_STRAW2。</span></span><br><span class="line"><span class="comment"> * 该表总结了在添加或删除item时每个选项的速度如何与映射稳定性相比较。</span></span><br><span class="line"><span class="comment"> * Bucket Alg     Speed       Additions    Removals</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------</span></span><br><span class="line"><span class="comment"> * uniform         O(1)       poor         poor</span></span><br><span class="line"><span class="comment"> * list            O(n)       optimal      poor</span></span><br><span class="line"><span class="comment"> * straw2          O(n)       optimal      optimal</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">crush_algorithm</span> &#123;</span><br><span class="line">CRUSH_BUCKET_UNIFORM = <span class="number">1</span>,</span><br><span class="line">CRUSH_BUCKET_LIST = <span class="number">2</span>,</span><br><span class="line">CRUSH_BUCKET_TREE = <span class="number">3</span>,</span><br><span class="line">CRUSH_BUCKET_STRAW = <span class="number">4</span>,</span><br><span class="line">CRUSH_BUCKET_STRAW2 = <span class="number">5</span>,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">const</span> <span class="type">char</span> *<span class="title">crush_bucket_alg_name</span><span class="params">(<span class="type">int</span> alg)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_LEGACY_ALLOWED_BUCKET_ALGS (\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_UNIFORM) |\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_LIST) |\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_STRAW))</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> &#123;</span><br><span class="line">__s32 id;       <span class="comment">//bucket的编号。小于0 /*!&lt; bucket identifier, &lt; 0 and unique within a crush_map */</span></span><br><span class="line">__u16 type;      <span class="comment">//bucket的类型/*!&lt; &gt; 0 bucket type, defined by the caller */</span></span><br><span class="line">__u8 alg;        <span class="comment">//使用的crush算法/*!&lt; the item selection ::crush_algorithm */</span></span><br><span class="line">__u8 hash;       <span class="comment">//使用的hash算法/* which hash function to use, CRUSH_HASH_* */</span></span><br><span class="line">__u32 weight;   <span class="comment">//权重 /*!&lt; 16.16 fixed point cumulated children weight */</span></span><br><span class="line">__u32 size;      <span class="comment">//items的数量/*!&lt; size of the __items__ array */</span></span><br><span class="line">    __s32 *items;    <span class="comment">//子bucket/*!&lt; array of children: &lt; 0 are buckets, &gt;= 0 items */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_weight_set</span> &#123;</span><br><span class="line">  __u32 *weights; <span class="comment">/*!&lt; 16.16 fixed point weights in the same order as items */</span></span><br><span class="line">  __u32 size;     <span class="comment">/*!&lt; size of the __weights__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_choose_arg</span> &#123;</span><br><span class="line">  __s32 *ids;                           <span class="comment">/*!&lt; values to use instead of items */</span></span><br><span class="line">  __u32 ids_size;                       <span class="comment">/*!&lt; size of the __ids__ array */</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">crush_weight_set</span> *weight_set;  <span class="comment">/*!&lt; weight replacements for a given position */</span></span><br><span class="line">  __u32 weight_set_positions;           <span class="comment">/*!&lt; size of the __weight_set__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_choose_arg_map</span> &#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">crush_choose_arg</span> *args; <span class="comment">/*!&lt; replacement for each bucket in the crushmap */</span></span><br><span class="line">  __u32 size;                    <span class="comment">/*!&lt; size of the __args__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_uniform</span> &#123;</span><br><span class="line">       <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__u32 item_weight;  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_list</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__u32 *item_weights;  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">__u32 *sum_weights;   <span class="comment">/*!&lt; 16.16 fixed point sum of the weights */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_tree</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h;  <span class="comment">/* note: h.size is _tree_ size, not number of</span></span><br><span class="line"><span class="comment">   actual items */</span></span><br><span class="line">__u8 num_nodes;</span><br><span class="line">__u32 *node_weights;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_straw</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h;</span><br><span class="line">__u32 *item_weights;   <span class="comment">/* 16-bit fixed point */</span></span><br><span class="line">__u32 *straws;         <span class="comment">/* 16-bit fixed point */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_straw2</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__.  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_map</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> **buckets;  **类型，所有的bucket都存在这里</span><br><span class="line">        <span class="comment">/*! 一个大小为__max_rules__ 的crush_rule 指针数组。</span></span><br><span class="line"><span class="comment">         * 如果规则被删除，数组的一个元素可能为NULL（没有API 可以这样做，但将来可能会有一个）。 </span></span><br><span class="line"><span class="comment">         * 规则必须使用crunch_add_rule() 添加。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule</span> **rules;   <span class="comment">//**类型，多层嵌套的rules</span></span><br><span class="line">    __s32 max_buckets; <span class="comment">/*!&lt; the size of __buckets__ */</span>  <span class="comment">// bucket的总数</span></span><br><span class="line">__u32 max_rules; <span class="comment">/*!&lt; the size of __rules__ */</span>      <span class="comment">// rule的总数</span></span><br><span class="line">__s32 max_devices;   <span class="comment">// osd的总数</span></span><br><span class="line">__u32 choose_local_tries;   <span class="comment">//选择的总次数</span></span><br><span class="line">__u32 choose_local_fallback_tries;  </span><br><span class="line">__u32 choose_total_tries;</span><br><span class="line">__u32 chooseleaf_descend_once;</span><br><span class="line">__u8 chooseleaf_vary_r;</span><br><span class="line">__u8 chooseleaf_stable;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">该值是在构建器解码或构建后计算的。 它在此处公开（而不是具有“构建 CRUSH 工作空间”功能），以便调用者可以保留静态缓冲区、在堆栈上分配空间，或者在需要时避免调用堆分配器。 </span></span><br><span class="line"><span class="comment">        工作空间的大小取决于映射，而传递给映射器的临时向量的大小取决于所需结果集的大小。尽管如此，没有什么能阻止调用者在一个膨胀 foop 中分配两个点并传递两个点。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">size_t</span> working_size;</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-相关数据结构&quot;&gt;&lt;a href=&quot;#Ceph-相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;Ceph 相关数据结构&quot;&gt;&lt;/a&gt;Ceph 相关数据结构&lt;/h2&gt;&lt;p&gt;要想深入到Ceph的源码底层，就必须对代码通用库里的一些关键，常见的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph源码编译调试</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95/</id>
    <published>2021-06-20T07:24:13.000Z</published>
    <updated>2024-07-27T14:38:39.225Z</updated>
    
    <content type="html"><![CDATA[<p>对于一个ceph开发人员来说编译源码以及打rpm是其必备技能。无论是fix bug还是向社区提交pull request都离不开编译源码。</p><h2 id="编译环境"><a href="#编译环境" class="headerlink" title="编译环境"></a>编译环境</h2><p><strong>环境介绍</strong></p><ul><li>ceph version: N版 14.2.16</li><li>硬件环境：Centos7虚拟机</li></ul><p><strong>网络环境与源加速</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">额外软件源、生成新的缓存</span></span><br><span class="line">yum -y install centos-release-scl</span><br><span class="line">yum -y install epel-release        </span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line">yum list</span><br><span class="line">yum update</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更换pip源，创建 .pip 目录</span></span><br><span class="line">mkdir ~/.pip                      </span><br><span class="line">cd ~/.pip                                      </span><br><span class="line">vi pip.conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入以下配置</span></span><br><span class="line">[global]</span><br><span class="line">index-url = https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置yum源</span></span><br><span class="line">vim /etc/yum.repos.d/ceph.repo</span><br><span class="line"></span><br><span class="line">[norch]</span><br><span class="line">name=norch</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[x86_64]</span><br><span class="line">name=x86 64</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[SRPMS]</span><br><span class="line">name=SRPMS</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[aarch64]</span><br><span class="line">name=aarch64</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/aarch64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure><p><strong>安装编译环境及依赖包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">yum -y install rdma-core-devel systemd-devel keyutils-libs-devel openldap-devel leveldb-devel snappy-devel lz4-devel curl-devel nss-devel</span><br><span class="line">yum -y install libzstd zstd gcc cmake make git wget</span><br><span class="line">yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils       # 安装gcc 7.2</span><br><span class="line">scl enable devtoolset-7 bash      #临时生效</span><br><span class="line">source /opt/rh/devtoolset-7/enable</span><br><span class="line">echo &quot;source /opt/rh/devtoolset-7/enable&quot; &gt;&gt;/etc/profile  #长期生效</span><br><span class="line">gcc -v                         #查看环境gcc版本</span><br><span class="line">wget https://github.com/Kitware/CMake/releases/download/v3.18.2/cmake-3.18.2.tar.gz      #安装cmake3</span><br><span class="line">tar -zxvf cmake-3.18.2.tar.gz</span><br><span class="line">cd cmake-3.18.2 </span><br><span class="line">yum -y install ncurses-devel openssl-devel</span><br><span class="line">./bootstrap</span><br><span class="line">gmake &amp;&amp; gmake install</span><br><span class="line">ln -s /usr/local/share/cmake /usr/bin/</span><br><span class="line">cmake -version</span><br></pre></td></tr></table></figure><p><strong>安装 ccache 加速编译</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载安装包并解压</span></span><br><span class="line">mkdir /home/ccache        </span><br><span class="line">cd /home/ccache</span><br><span class="line">wget https://github.com/ccache/ccache/releases/download/v4.0/ccache-4.0.tar.gz</span><br><span class="line">tar -zxvf ccache-4.0.tar.gz</span><br><span class="line">cd ccache-4.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编译安装</span></span><br><span class="line">mkdir build     </span><br><span class="line">cd build</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=Release -DZSTD_FROM_INTERNET=ON ..</span><br><span class="line">make -j12</span><br><span class="line">make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置</span></span><br><span class="line">mkdir -p /root/.config/ccache/          </span><br><span class="line">vi /root/.config/ccache/ccache.conf</span><br><span class="line">max_size = 16G</span><br><span class="line">sloppiness = time_macros</span><br><span class="line">run_second_cpp = true</span><br></pre></td></tr></table></figure><h2 id="编译ceph代码"><a href="#编译ceph代码" class="headerlink" title="编译ceph代码"></a>编译ceph代码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 下载Ceph源码一</span></span></span><br><span class="line">mkdir /home/ceph</span><br><span class="line">cd /home/ceph</span><br><span class="line">git clone git://github.com/ceph/ceph.git       #(git clone https://github.com/ceph/ceph.git)</span><br><span class="line">cd ceph</span><br><span class="line">git checkout nautilus                            #切换分支，这里以 N 版本为例</span><br><span class="line">git submodule update --init --recursive          #进入ceph目录，下载ceph代码依赖</span><br><span class="line">   </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 下载Ceph源码二</span></span></span><br><span class="line">wget https://mirrors.aliyun.com/ceph/debian-nautilus/pool/main/c/ceph/ceph_14.2.22.orig.tar.gz</span><br><span class="line">tar -zxvf ceph_14.2.22.orig.tar.gz</span><br><span class="line">cd ceph_14.2.2</span><br><span class="line"></span><br><span class="line">./install-deps.sh                                #执行依赖安装脚本，ceph 自带的解决依赖的脚本</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 修改cmake参数，因为后面需要使用gdb debug客户端程序，客户端程序会依赖librados库，所以我们必须以debug的模式去编译ceph，否则编译器会优化掉很多参数，导致很多信息缺失，需要修改一下ceph cmake的参数。如图所示</span></span></span><br><span class="line">vim do_cmake.sh    </span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">&#123;CMAKE&#125; -DCMAKE_C_FLAGS=<span class="string">&quot;-O0 -g3 -gdwarf-4&quot;</span> -DCMAKE_CXX_FLAGS=<span class="string">&quot;-O0 -g3 -gdwarf-4&quot;</span> -DBOOST_J=$(<span class="built_in">nproc</span>) <span class="variable">$ARGS</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span> ..</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到这里修改了cmake的参数，增加了两个配置项，稍微解释一下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CMAKE_C_FLAGS=“-O0 -g3 -gdwarf-4” ： c 语言编译配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CMAKE_CXX_FLAGS=“-O0 -g3 -gdwarf-4” ：c++ 编译配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-O0 : 关闭编译器的优化，如果没有，使用GDB追踪程序时，大多数变量被优化,无法显示, 生产环境必须关掉</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-g3 : 意味着会产生大量的调试信息</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-gdwarf-4 : dwarf 是一种调试格式，dwarf-4 版本为4</span></span><br><span class="line">     </span><br><span class="line">./do_cmake.sh -DWITH_MANPAGE=OFF -DWITH_BABELTRACE=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DCMAKE_BUILD_TYPE=RelWithDebInfo -DWITH_CCACHE=ON --DWITH_PYTHON3=ON --DMGR_PYTHON_VERSION=3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行 cmake，解释一下，DWITH_MGR_DASHBOARD_FRONTEND=OFF 主要是因为 ceph dashboard 用到了一些国外的 nodejs源，国内无法下载，会导致编译失败超时。-DWITH_CCACHE=ON 如果你没有安装 步骤 2-2 的 ccache 的话，可以去掉这个参数。</span></span><br><span class="line">    </span><br><span class="line">cd build</span><br><span class="line">make -j20 #（线程数等于cpu core的2倍，可以提高编译的速度，20核CPU、32G内存的服务器）</span><br></pre></td></tr></table></figure><p>修改do_cmake.sh<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_1.png"><br>编译进度<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_2.png"></p><p>自此已经编译完ceph源代码！</p><h2 id="运行测试集群"><a href="#运行测试集群" class="headerlink" title="运行测试集群"></a>运行测试集群</h2><p>发行版的 ceph 安装包安装的集群默认是没有办法debug调试。这里推荐 ceph 内置的debug调试——vstart，非常方便模仿特殊场景进行debug调试。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /home/watson/ceph/build        # 进入build目录</span><br><span class="line">make vstart                       # 编译模拟启动环境（make help 查看有哪些target可以单独编译）</span><br><span class="line">MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore         # (模拟启动，指令前半部分的MDS=0 RGW=1之类的就是设定你想要模拟的集群结构（集群的配置文件在ceph/build/ceph.conf）)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动完成后，可以在模拟集群环境下执行各种 ceph 指令(模拟集群所有的指令都在 build/bin 目录)</span></span><br><span class="line">bin/ceph -s                       # 查看 ceph 集群状态</span><br><span class="line">bin/radosgw-admin user list       # 查看用户</span><br><span class="line">../src/stop.sh                    # 关闭测试集群</span><br></pre></td></tr></table></figure><p>编译vstasrt环境<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_3.png"><br>启动vstart环境<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_4.png"><br>查看 ceph 集群状态<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_5.png"><br>查看Ceph用户<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_6.png"></p><h2 id="运行单元测试用例"><a href="#运行单元测试用例" class="headerlink" title="运行单元测试用例"></a>运行单元测试用例</h2><p>更改了代码准备提交到公司内部repo或者社区repo都需要先执行一下最小测试集，看看自己修改的代码有没有影响到别的模块(社区也会进行同样的测试)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd build</span><br><span class="line">make                       #修改代码后先编译，可以模块编译</span><br><span class="line">man ctest                  #查看ctest的功能</span><br><span class="line">ctest -j20                 #运行所有测试（使用所有处理器并行）</span><br><span class="line">ctest -R [regex matching test name(s)]                  #运行部分模块测试，使用 -R（正则表达式匹配）</span><br><span class="line">ctest -V -R [regex matching test name(s)]               #使用 -V（详细）标志运行</span><br><span class="line">ctest -j20 -V -R [regex matching test name(s)]          #运行正则表达式匹配的模块测试，显示详细信息，并发进行</span><br></pre></td></tr></table></figure><p>注意：许多从 src&#x2F;test 构建的目标不是使用ctest运行的。以 “unittest” 开头的目标在其中运行make check，因此可以使用运行ctest。以 “ceph_test” 开头的目标不能，应该手动运行。发生故障时，请在 build&#x2F;Testing&#x2F;Temporary 中查找日志。</p><p><strong>开发编译测试过程</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 编写保存源代码</span><br><span class="line">2. make -j20 unittest_crush               #模块编译</span><br><span class="line">3. ctest -j20 -V -R unittest_crush         #模块测试</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_7.png"></p><h2 id="通过librados客户端调试CRUSH算法"><a href="#通过librados客户端调试CRUSH算法" class="headerlink" title="通过librados客户端调试CRUSH算法"></a>通过librados客户端调试CRUSH算法</h2><p><strong>编写客户端代码</strong><br>调用librados 库写入数据<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_8.png"></p><p><strong>运行librados代码</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install librados2-devel  libradospp   libradosstriper-devel -y  #安装相关开发包（C/C++开发包）</span><br><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib                         #编译客户端程序 rados_write.c</span><br></pre></td></tr></table></figure><p>这里解释一下gcc 几个参数，首先需要理解的是c程序在编译时依赖的库和运行时依赖库是分开指定的，也就是说，编译的时候使用的库，不一定就是运行时使用的库</p><ul><li>g : 允许gdb调试</li><li>lrados : -l 指定依赖库的名字为rados</li><li>L : 指定编译时依赖库的的路径， 如果不指定将在系统目录下寻找</li><li>o : 编译的二进制文件名</li><li>Wl : 指定编译时参数</li><li>rpath : 指定运行时依赖库的路径， 如果不指定将在系统目录下寻找</li></ul><p><strong>运行客户端程序</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./rados_write</span><br><span class="line">bin/rados ls -p default.rgw.meta                 #在集群中确认一下是否写入数据</span><br></pre></td></tr></table></figure><p>运行rados_write程序<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_9.png"><br>确认写入数据<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_10.png"></p><p>ceph的开发者模式是测试ceph功能和调试代码非常方便的途径，因为集群默认开启了debug模式，所有的日志都会详细的输出，并且为了调试的方便，在正式环境中的多线程多队列，在这都会简化。</p><h2 id="使用GDB调试分析Object至OSD映射"><a href="#使用GDB调试分析Object至OSD映射" class="headerlink" title="使用GDB调试分析Object至OSD映射"></a>使用GDB调试分析Object至OSD映射</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gdb                   #安装gdb</span><br><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib   #编译客户端程序 rados_write.c</span><br><span class="line">gdb ./rados_write                    #使用gdb 调试 rados_write 程序</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动程序后，需要设置断点，这里选择的是 crush_do_rule 函数，因为这个函数是 object–&gt;到PG 流程的终点</span></span><br><span class="line">b crush_do_rule                      #在crush_do_rule 函数设置断点</span><br><span class="line">bt                                   #查看当前的函数堆栈</span><br></pre></td></tr></table></figure><p>gdb调试raodos_wirte程序<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_11.png"><br>设置调试断点<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_12.png"><br>查看当前函数栈<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_13.png"></p><p>得到的函数流程如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#0   crush_do_rule at /home/watson/ceph/src/crush/mapper.c:904</span><br><span class="line">#1   do_rule at /home/watson/ceph/src/crush/CrushWrapper.h:1570</span><br><span class="line">#2   OSDMap::_pg_to_raw_osds at /home/watson/ceph/src/osd/OSDMap.cc:2340</span><br><span class="line">#3   OSDMap::_pg_to_up_acting_osds at /home/watson/ceph/src/osd/OSDMap.cc:2586</span><br><span class="line">#4   pg_to_up_acting_osds  at /home/watson/ceph/src/osd/OSDMap.h:1209</span><br><span class="line">#5   Objecter::_calc_target at /home/watson/ceph/src/osdc/Objecter.cc:2846</span><br><span class="line">#6   Objecter::_op_submit  at /home/watson/ceph/src/osdc/Objecter.cc:2367</span><br><span class="line">#7   Objecter::_op_submit_with_budget at /home/watson/ceph/src/osdc/Objecter.cc:2284</span><br><span class="line">#8   Objecter::op_submit at /home/watson/ceph/src/osdc/Objecter.cc:2251</span><br><span class="line">#9   librados::IoCtxImpl::operate  at /home/watson/ceph/src/librados/IoCtxImpl.cc:690</span><br><span class="line">#10  librados::IoCtxImpl::write at /home/watson/ceph/src/librados/IoCtxImpl.cc:623</span><br><span class="line">#11  rados_write at /home/watson/ceph/src/librados/librados_c.cc:1133</span><br><span class="line">#12  main at rados_write.c:73</span><br></pre></td></tr></table></figure><p>不关心librados是如何封装请求，只关心object到pg的计算过程，所以这里决定从 Objecter::_calc_target 函数开始debug 整个过程，重新开始，然后再次设置断点。重新开始，计算 object的hash值 ps</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b Objecter::_calc_target        #断点</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_14.png"></p><p>卡住在断点处，现在我们打开tui模式跟踪代码， <code>crtl + x + a</code> 可以切换到tui界面<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_15.png"><br>这里按 n 逐行debug代码， 这里我想显示打印 pg_pool_t *p 和 op_target_t *t 的信息<br>其中 pg_pool_t 是pool的结构体，包含pool相关的所有信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p *pi                   #查看pi的数据结构</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_17.png"><br>而 op_target_t 则是整个写入操作封装的结构信息，包含对象的名字，写入pool的id<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_18.png"><br>继续 n 单步调试，这里我们会进去 osdmap-&gt;object_locator_to_pg 函数。然后一步一步调试……<br>object到PG的函数流程图<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_19.jpg"><br>PG映射到OSD函数流程图<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_20.jpg"><br>crush_choose_firstn选择的过程<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_21.png"></p><h2 id="使用VScode远程调试Ceph"><a href="#使用VScode远程调试Ceph" class="headerlink" title="使用VScode远程调试Ceph"></a>使用VScode远程调试Ceph</h2><p>以ceph osd部分为例，为您演示通过第三方社区提供的vscode 编辑软件，对ceph osd进行进行图形化单步调试以及配置操作。vscode是微软公司一个开源的编译器具备轻量的特点，通过插件安装方式提供了丰富的调试功能。通常 Linux环境的c&#x2F;c++软件开发使用GDB进行命令行调试，命令行操方式极其不方便。使用vscode 的图形化界面可替代gdb 命令行 ，整个开发调试过程更加便捷。Ceph源码路径在&#x2F;home&#x2F;watson&#x2F;ceph目录下，其编译运行文件在&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;build&#x2F;bin当中。启动调试前需要停止本地的osd运行服务。<br><strong>下载安装windows的vscode和ssh</strong><br>在以下地址下载vscode:  <a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a><br>安装openssh (一般情况不用自己手动安装)如果需要远程开发，Windows机器也需要支持openssh，如果本机没有，会报错。可以到微软官网上下载ssh。<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_22.png"><br>在vscode安装Remote Development和Remote-SSH<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_23.png"><br>在安装完成之后，点击左侧的Remote-SSH选项卡，再将鼠标移向CONNECTIONS栏，点击出现的configure：<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_25.png"><br>填写linux服务器的ssh端口和用户名（如果是默认的22端口可不用填写）<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_26.png"><br>按下ctrl + s 保存 然后连接（&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;）<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_27.png"><br>输入密码，总共有多次输入密码的流程留意窗口变化<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_28.png"><br>打开远程服务器的文件夹<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_29.png"><br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_30.png"></p><p><strong>远程连接遇到的问题以及技巧</strong></p><p>因为ceph工程文件数量众多会出现无法在这个大型工作区中监视文件更改。请按照说明链接来解决此问题的问题。原因：工作区很大并且文件很多，导致VS Code文件观察程序的句柄达到上限。<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_31.png"><br>解决方法：编辑linux服务器中的 &#x2F;etc&#x2F;sysctl.conf；将以下一行添加到文件末尾，可以将限制增加到最大值<br>    <code>fs.inotify.max_user_watches=524288</code></p><p>保存之后终端窗口 输入sysctl -p可解决。<br>远程调试<br>首先前提Linux服务器已经安装了GDB，否则会提示出错。在ceph工程目录下添加launch.json文件。在最左上栏运行(R) -&gt; 添加配置 ，注意一定要在ceph当前工程目录。修改配置launch.json中的program、args选项。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">launch.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ceph-debug&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/build/bin/unittest_crush&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;-d&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--cluster&quot;</span><span class="punctuation">,</span> <span class="string">&quot;ceph&quot;</span><span class="punctuation">,</span><span class="string">&quot;--id&quot;</span><span class="punctuation">,</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--setuser&quot;</span><span class="punctuation">,</span> <span class="string">&quot;root&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--setgroup&quot;</span><span class="punctuation">,</span> <span class="string">&quot;root&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;stopAtEntry&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;environment&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;externalConsole&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Enable pretty-printing for gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>按照下图点击就可以开始调试之路<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_31.png"><br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_32.png"></p><h2 id="报错记录"><a href="#报错记录" class="headerlink" title="报错记录"></a>报错记录</h2><p>报错1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RPC failed; result=35, HTTP code = 0 fatal: The remote end hung up unexpectedly无法克隆 &#x27;https://github.com/xxxx/xxxxxxxx.git&#x27; 到子模组路径 &#x27;xxxxxxxxx&#x27;</span><br><span class="line">解决：</span><br><span class="line">    通过设置Git的http缓存大小，解决了这个问题，在当前工程目录下运行如下命令：</span><br><span class="line">        git config --global http.postBuffer 20M     (如果20M不行就50M)</span><br></pre></td></tr></table></figure><p>报错2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">编译出现了一个问题，卡在5%Built target rocksdb_ext这里 </span><br><span class="line">原因：国外网络太慢，下载boost_1_72_0.tar.bz2太慢了，换网络或者在先用本地下载再传到服务器上（ceph/build/boost/src目录下）</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_34.png"></p><p>报错3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">No Package found for python-scipy</span><br><span class="line">vim ceph.spec.in</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_35.png"></p><p>报错4</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;Error: Package: golang-github-prometheus-2.26.1-2.el7.x86_64 (epel) Requires: /usr/bin/systemd-sysusers&quot;, 去掉该需求</span><br><span class="line">vim ~/ceph-14.2.16/ceph.spec.in</span><br><span class="line"># 内容</span><br><span class="line">#BuildRequires:   golang-github-prometheus</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;对于一个ceph开发人员来说编译源码以及打rpm是其必备技能。无论是fix bug还是向社区提交pull request都离不开编译源码。&lt;/p&gt;
&lt;h2 id=&quot;编译环境&quot;&gt;&lt;a href=&quot;#编译环境&quot; class=&quot;headerlink&quot; title=&quot;编译环境&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_librados_api使用</title>
    <link href="https://watsonlu6.github.io/Ceph_librados_api%E4%BD%BF%E7%94%A8/"/>
    <id>https://watsonlu6.github.io/Ceph_librados_api%E4%BD%BF%E7%94%A8/</id>
    <published>2021-06-18T06:28:31.000Z</published>
    <updated>2024-07-27T14:37:33.694Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Librados-API概述"><a href="#Librados-API概述" class="headerlink" title="Librados API概述"></a>Librados API概述</h1><p>Ceph存储集群提供基本的存储服务，Ceph以独特的方式将对象、块和文件存储集成到一个存储系统中。基于RADOS，可以不限于RESTful或POSIX接口，使用librados API能够创建自定义的Ceph存储集群接口（除了块存储、对象存储和文件系统存储外）。<br>librados API能够与Ceph存储集群中的两种类型的守护进程进行交互：</p><ul><li>Ceph Mon守护进程，维护集群映射的主副本</li><li>Ceph OSD守护进程，它将数据作为对象存储在存储节点上<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_1.png"><br>要使用 API，您需要一个正在运行的 Ceph 存储集群。（本教程教程使用ceph编译的vstart启动的开发编程环境）<br>编译模拟启动环境<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">make vstart  #模拟启动</span><br><span class="line">MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore  #模拟集群所有的指令都在 build/bin 目录</span><br><span class="line">bin/ceph -s  #查看 ceph 集群状态</span><br><span class="line">../src/stop.sh #停止模拟集群</span><br></pre></td></tr></table></figure></li></ul><h3 id="第-1-步：获取librados"><a href="#第-1-步：获取librados" class="headerlink" title="第 1 步：获取librados"></a>第 1 步：获取librados</h3><p>Ceph客户端应用必须绑定librados才能连接Ceph存储集群。在写使用librados的ceph客户端应用前，要安装librados及其依赖包。librados API本身是用C++实现，也有C、Python、Java和PHP的API。（本教程仅限于librados C&#x2F;C++API）<br>获取C&#x2F;C++的librados</p><ul><li>要在 Debian&#x2F;Ubuntu 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令：<br>  <code>sudo apt-get install librados-dev</code></li><li>要在 RHEL&#x2F;CentOS 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令：<br>  <code>sudo yum install librados2-devel</code></li><li>安装librados 后，可以在&#x2F;usr&#x2F;include&#x2F;rados 下找到 C&#x2F;C++所需的头文件<br>  <code>ls /usr/include/rados</code></li></ul><h2 id="第-2-步：配置集群句柄"><a href="#第-2-步：配置集群句柄" class="headerlink" title="第 2 步：配置集群句柄"></a>第 2 步：配置集群句柄</h2><p>一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用libradosAPI连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它会创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_2.png"><br>Ceph存储集群手柄封装客户端配置，包括：</p><ul><li>基于用户ID的rados_create() 或者基于用户名的rados_create2()(首选) </li><li>cephx认证密钥</li><li>Mon ID和IP地址</li><li>日志记录级别</li><li>调试级别</li></ul><p>因此，Ceph客户端应用程序使用Ceph群集的步骤：</p><ol><li>创建一个集群句柄，客户端应用将使用该句柄连接到存储集群中；</li><li>使用该手柄进行连接。要连接到集群的客户端应用必须提供Mon地址，用户名和认证密钥（默认启用cephx）。<br>提示：与不同的 Ceph 存储集群或与具有不同用户的同一个集群通信需要不同的集群句柄。RADOS 提供了多种设置所需值的方法。对于Mon和加密密钥设置，处理它们的一种简单方法是确保 Ceph 配置文件包含密钥环文件的密钥环路径和至少一个Mon地址（例如mon host）。例如:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">mon host = 192.168.1.1</span><br><span class="line">keyring = /etc/ceph/ceph.client.admin.keyring</span><br></pre></td></tr></table></figure></li><li>创建句柄后，读取 Ceph 配置文件来配置句柄。可以将参数传递给客户端应用程序并使用解析命令行参数的函数（例如rados_conf_parse_argv()）或解析 Ceph 环境变量（例如rados_conf_parse_env()）来解析它们。</li><li>连接后，客户端应用程序可以调用仅使用集群句柄影响整个集群的函数。例如，一旦有了集群句柄，就可以：<br> • 获取集群统计信息<br> • 使用池操作（存在、创建、列出、删除）<br> • 获取和设置配置</li></ol><p>Ceph 的强大功能之一是能够绑定到不同的池。每个池可能有不同数量的归置组、对象副本和复制策略。例如，可以将池设置为使用 SSD 存储常用对象的“热”池或使用纠删码的“冷”池。各种语言的librados 绑定的主要区别在于 C 与C++、Java 和 Python 的面向对象绑定之间。面向对象的绑定使用对象来表示集群句柄、IO 上下文、迭代器、异常等。</p><p><strong>C调用librados 示例</strong><br>对于 C，使用管理员用户创建一个简单的集群句柄，配置它并连接到集群如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">rados_t</span> cluster;</span><br><span class="line">        <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">        <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">        <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">        <span class="type">uint64_t</span> flags;</span><br><span class="line">        <span class="type">int</span> err;</span><br><span class="line">        err = rados_create2(&amp;cluster,cluster_name,user_name,flags);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: Couldn&#x27;t create the cluster handle!%s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Create a cluster handle!!!\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_conf_read_file(cluster,conf_flie);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot read config file: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Read the config flie\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_conf_parse_argv(cluster,argc,argv);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot parse command line arguments: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Read the command line arguments\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_connect(cluster);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot connect to cluster: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Connected to the cluster\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用-lrados编译客户端应用代码并链接到librados，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc ceph-client.c -lrados -o ceph-client</span><br></pre></td></tr></table></figure><p>ceph源码开发vstart环境下的编译，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib</span><br></pre></td></tr></table></figure><p><strong>C++调用librados示例</strong><br>Ceph项目在ceph&#x2F;examples&#x2F;librados目录中提供了一个 C++ 示例。对于 C++，使用管理员用户的简单集群句柄需要初始化librados::Rados集群句柄对象</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    *通过librados::Rados句柄处理整个RADOS系统层面以及pool层面的管理。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    librados::Rados cluster;    <span class="comment">//定义一个操控集群的句柄对象</span></span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;     <span class="comment">//集群名字</span></span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;   <span class="comment">//集群用户名</span></span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;   <span class="comment">//集群配置文件</span></span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    ret = cluster.<span class="built_in">init2</span>(user_name,cluster_name,flags);      <span class="comment">//初始化句柄对象</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t initialize the cluster handle! error: &quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Create a cluster handle.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">conf_read_file</span>(conf_flie);     <span class="comment">//读配置文件获取Mon的信息</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read the ceph configuration file! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Read the ceph configuration file.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">conf_parse_argv</span>(argc,argv);   <span class="comment">//解析命令行输入的参数</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t parsed command line options!error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Parsed command line options.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">connect</span>();   <span class="comment">//连接集群</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t connect to cluster! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Connected to the cluster.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    cluster.<span class="built_in">pool_create</span>(<span class="string">&quot;testpool&quot;</span>); <span class="comment">//创建存储池</span></span><br><span class="line">    std::list&lt;std::string&gt; poolList; </span><br><span class="line">    cluster.<span class="built_in">pool_list</span>(poolList);   <span class="comment">//获取存储池列表</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> iter : poolList)&#123;</span><br><span class="line">        std::cout&lt;&lt;iter&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译源码，然后，使用-lrados链接librados，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ -g -c ceph-client.cc -o ceph-client.o </span><br><span class="line">g++ -g ceph-client.o -lrados -o ceph-client</span><br></pre></td></tr></table></figure><p>ceph源码开发vstart环境下的编译，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -g librados_rados.cpp -lrados -L/home/watson/ceph/build/lib -o librados_rados -Wl,-rpath,/home/watson/ceph/build/lib</span><br></pre></td></tr></table></figure><h2 id="第-3-步：创建-I-O-上下文"><a href="#第-3-步：创建-I-O-上下文" class="headerlink" title="第 3 步：创建 I&#x2F;O 上下文"></a>第 3 步：创建 I&#x2F;O 上下文</h2><p>一旦客户端应用程序拥有集群句柄并连接到 Ceph 存储集群，就可以创建 I&#x2F;O 上下文并开始读取和写入数据。I&#x2F;O 上下文将连接绑定到特定池。用户必须具有适当的CAPS权限才能访问指定的池。例如，具有读取权限但没有写入权限的用户将只能读取数据。I&#x2F;O 上下文功能包括：</p><ul><li>写入&#x2F;读取数据和扩展属性</li><li>列出并迭代对象和扩展属性</li><li>快照池、列表快照等<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_3.png"><br>RADOS 使客户端应用程序能够进行同步和异步交互。一旦应用程序具有 I&#x2F;O 上下文，读&#x2F;写操作只需要知道对象&#x2F;xattr 名称。librados中封装的 CRUSH 算法使用Cluster map来选择合适的 OSD。OSD 守护进程自动处理副本。librados库将对象映射到归置组。以下示例使用默认数据池。但是，也可以使用 API 列出池、确保它们存在或创建和删除池。对于写操作，示例说明了如何使用同步模式。对于读取操作，示例说明了如何使用异步模式。<code>(提示：使用此 API 删除池时要小心。如果删除池，则该池和池中的所有数据都将丢失。)</code><br><strong>C创建Ceph IO上下文示例</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">rados_t</span> cluster;      <span class="comment">//集群句柄</span></span><br><span class="line">    <span class="type">rados_ioctx_t</span> io;     <span class="comment">//io上下文</span></span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">    <span class="type">char</span> poolname[] = <span class="string">&quot;testpool&quot;</span>;</span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    <span class="type">int</span> err;</span><br><span class="line">    <span class="comment">/*  为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！  */</span></span><br><span class="line">    err = rados_create2(&amp;cluster,cluster_name,user_name,flags);</span><br><span class="line">    err = rados_conf_read_file(cluster,conf_flie);</span><br><span class="line">    err = rados_conf_parse_argv(cluster,argc,argv);</span><br><span class="line">    err = rados_connect(cluster);</span><br><span class="line">    <span class="keyword">if</span>(err &lt; <span class="number">0</span>)                     <span class="comment">//检查是否连接到集群上</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: Cannot connect to cluster: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Connected to the cluster......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//err = rados_pool_delete(cluster,poolname);</span></span><br><span class="line">    <span class="type">int</span> poolID = rados_pool_lookup(cluster,poolname);  <span class="comment">//通过poolname获取pool的ID，若池不存在返回-ENOENT</span></span><br><span class="line">    <span class="keyword">if</span>(poolID == -ENOENT)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;this pool does not exist,and create the pool...... \n&quot;</span>);</span><br><span class="line">        rados_pool_create(cluster,poolname);</span><br><span class="line">    &#125;</span><br><span class="line">    err = rados_ioctx_create(cluster,poolname,&amp;io);    <span class="comment">//初始化io上下文</span></span><br><span class="line">    <span class="type">char</span> obj_name[] = <span class="string">&quot;obj&quot;</span>;</span><br><span class="line">    <span class="type">char</span> obj_content[] = <span class="string">&quot;Hello librados&quot;</span>;</span><br><span class="line">    err = rados_write(io,obj_name,obj_content,<span class="built_in">strlen</span>(obj_content),<span class="number">0</span>);    <span class="comment">//往集群写入对象</span></span><br><span class="line">    <span class="keyword">if</span>(err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;rados_write success......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> xattr[] = <span class="string">&quot;en_US&quot;</span>;</span><br><span class="line">    err = rados_setxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>,xattr,<span class="number">5</span>);     <span class="comment">//给对象设置属性</span></span><br><span class="line">    <span class="keyword">if</span>(err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Set object xattr success......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">rados_completion_t</span> comp;</span><br><span class="line">    err = rados_aio_create_completion(<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,&amp;comp);      <span class="comment">//异步读</span></span><br><span class="line">    <span class="type">char</span> read_ret[<span class="number">1024</span>];</span><br><span class="line">    err = rados_aio_read(io,obj_name,comp,read_ret,<span class="keyword">sizeof</span>(read_ret),<span class="number">0</span>);</span><br><span class="line">    rados_aio_wait_for_complete(comp);</span><br><span class="line">    <span class="keyword">if</span>( err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\&#x27;s content is %s\n&quot;</span>,obj_name,read_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;read_aio_read: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    rados_aio_release(comp);</span><br><span class="line">    err = rados_read(io,obj_name,read_ret,<span class="keyword">sizeof</span>(read_ret),<span class="number">0</span>);        <span class="comment">//同步读</span></span><br><span class="line">    <span class="keyword">if</span>( err &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\&#x27;s content is %s\n&quot;</span>,obj_name,read_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;read_read: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> xattr_ret[<span class="number">100</span>];</span><br><span class="line">    err = rados_getxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>,xattr_ret,<span class="number">6</span>);     <span class="comment">//获取对象属性</span></span><br><span class="line">    <span class="keyword">if</span>( err &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Read %s\&#x27;s xattr \&quot;lang\&quot; is %s\n&quot;</span>,obj_name,xattr_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;rados_getxattr: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    err = rados_rmxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>);     <span class="comment">//删除对象属性</span></span><br><span class="line">    err = rados_remove(io,obj_name);     <span class="comment">//删除对象</span></span><br><span class="line">    rados_ioctx_destroy(io);   <span class="comment">//释放io上下文</span></span><br><span class="line">    rados_shutdown(cluster);    <span class="comment">//关闭集群句柄</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><strong>C++创建Ceph IO上下文示例</strong><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    librados::Rados cluster;</span><br><span class="line">    librados::IoCtx io_ctx;</span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">    <span class="type">char</span> poolname[] = <span class="string">&quot;testpool&quot;</span>;</span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    <span class="type">int</span> ret;</span><br><span class="line">    <span class="comment">/*  为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！  */</span></span><br><span class="line">    ret = cluster.<span class="built_in">init2</span>(user_name,cluster_name,flags);</span><br><span class="line">    ret = cluster.<span class="built_in">conf_read_file</span>(conf_flie);</span><br><span class="line">    ret = cluster.<span class="built_in">conf_parse_argv</span>(argc,argv);</span><br><span class="line">    ret = cluster.<span class="built_in">connect</span>();       </span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )           <span class="comment">//测试集群连接情况</span></span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t connect to cluster! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Connected to the cluster.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> poolID = cluster.<span class="built_in">pool_lookup</span>(poolname);     <span class="comment">//通过pool名检测是否存在pool</span></span><br><span class="line">    <span class="keyword">if</span>(poolID == -ENOENT)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;this pool does not exist,and create the pool...... \n&quot;</span>);</span><br><span class="line">        cluster.<span class="built_in">pool_create</span>(poolname);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;pool &quot;</span>&lt;&lt;poolID&lt;&lt;<span class="string">&quot;  is using......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">ioctx_create</span>(poolname,io_ctx);    <span class="comment">//初始化io_ctx</span></span><br><span class="line">    <span class="type">char</span> obj_name[] = <span class="string">&quot;obj&quot;</span>;</span><br><span class="line">    librados::bufferlist bl;</span><br><span class="line">    bl.<span class="built_in">append</span>(<span class="string">&quot;Hello Librados!&quot;</span>);</span><br><span class="line">    ret = io_ctx.<span class="built_in">write_full</span>(obj_name,bl);         <span class="comment">//往集群写入数据</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t write object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Write success......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist lang_bl;</span><br><span class="line">    lang_bl.<span class="built_in">append</span>(<span class="string">&quot;en_US&quot;</span>);</span><br><span class="line">    ret = io_ctx.<span class="built_in">setxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>,lang_bl);          <span class="comment">//给对象设置属性</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t write object xattr! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Set xattr success......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist read_bl;                 <span class="comment">//异步读</span></span><br><span class="line">    <span class="type">int</span> read_len = <span class="number">1024</span>;</span><br><span class="line">    librados::AioCompletion *read_completion = librados::Rados::<span class="built_in">aio_create_completion</span>();</span><br><span class="line">    ret = io_ctx.<span class="built_in">aio_read</span>(obj_name,read_completion,&amp;read_bl,read_len,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    read_completion-&gt;<span class="built_in">wait_for_complete</span>();    <span class="comment">//等待异步完成</span></span><br><span class="line">    ret = read_completion-&gt;<span class="built_in">get_return_value</span>();       <span class="comment">//获取返回值</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;read_bl.<span class="built_in">c_str</span>()&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist lang_res;</span><br><span class="line">    ret = io_ctx.<span class="built_in">getxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>,lang_res);       <span class="comment">//获取属性</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object xattr! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;lang_res.<span class="built_in">c_str</span>()&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = io_ctx.<span class="built_in">rmxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>);     <span class="comment">//删除对象属性</span></span><br><span class="line">    ret = io_ctx.<span class="built_in">remove</span>(obj_name);           <span class="comment">//删除对象</span></span><br><span class="line">    io_ctx.<span class="built_in">close</span>();       <span class="comment">//关闭io</span></span><br><span class="line">    cluster.<span class="built_in">shutdown</span>();      <span class="comment">//关闭集群句柄</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="第-4-步：结束会话"><a href="#第-4-步：结束会话" class="headerlink" title="第 4 步：结束会话"></a>第 4 步：结束会话</h2><p>一旦客户端应用程序完成了 I&#x2F;O 上下文和集群句柄，应用程序应该关闭连接并关闭句柄。对于异步 I&#x2F;O，应用程序还应确保挂起的异步操作已完成。<br><strong>C结束会话示例</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rados_ioctx_destroy(io); </span><br><span class="line">rados_shutdown(cluster);</span><br></pre></td></tr></table></figure><p><strong>C++结束会话示例</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">io_ctx.<span class="built_in">close</span>(); </span><br><span class="line">cluster.<span class="built_in">shutdown</span>();</span><br></pre></td></tr></table></figure><p>补充：查看pool下的object对象 –all 显示所有namespace的object</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados ls -p pool --all</span><br></pre></td></tr></table></figure><h2 id="LIBRADOS常用接口"><a href="#LIBRADOS常用接口" class="headerlink" title="LIBRADOS常用接口"></a>LIBRADOS常用接口</h2><ol><li><p>集群配置：提供了获取和设置配置值的方法，读取Ceph配置文件，并解析参数。<br> Rados.conf_get(option)<br> Rados.conf_set(option, val)<br> Rados.conf_read_file(path)<br> Rados.conf_parse_argv(args)<br> Rados.version()</p></li><li><p>连接管理：连接到集群、检查集群、检索集群的统计数据，并从集群断开连接。也可以断言集群句柄处于一个特定的状态（例如，”配置”，”连接”等等）。<br> Rados.connect(timeout)<br> Rados.shutdown()<br> Rados.get_fsid()<br> Rados.get_cluster_stats()</p></li><li><p>池操作：列出可用的池，创建一个池，检查一个池是否存在，并删除一个池。<br> Rados.list_pools()<br> Rados.create_pool(pool_name, crush_rule, auid)<br> Rados.pool_exists(pool_name)<br> Rados.delete_pool(pool_name)</p></li><li><p>CLI 命令：Ceph CLI命令在内部使用以下librados Python绑定方法。<br> Rados.mon_command(cmd, inbuf, timeout, target)<br> Rados.osd_command(osdid, cmd, inbuf, timeout)<br> Rados.mgr_command(cmd, inbuf, timeout, target)<br> Rados.pg_command(pgid, cmd, inbuf, timeout)</p></li><li><p>I&#x2F;O上下文：为了将数据写入Ceph对象存储和从Ceph对象存储读取数据，必须创建一个输入&#x2F;输出上下文（ioctx）。Rados类提供了open_ioctx()和open_ioctx2()方法。其余的操作涉及调用Ioctx和其他类的方法。<br> Rados.open_ioctx(ioctx_name)<br> Ioctx.require_ioctx_open()<br> Ioctx.get_stats()<br> Ioctx.get_last_version()<br> Ioctx.close()</p></li><li><p>对象操作：同步或异步地读和写对象。一个对象有一个名称（或键）和数据。<br> Ioctx.aio_write(object_name, to_write, offset, oncomplete, onsafe)<br> Ioctx.aio_write_full(object_name, to_write, oncomplete, onsafe)<br> Ioctx.aio_append(object_name, to_append, oncomplete, onsafe)<br> Ioctx.write(key, data, offset)<br> Ioctx.write_full(key, data)<br> Ioctx.aio_flush()<br> Ioctx.set_locator_key(loc_key)<br> Ioctx.aio_read(object_name, length, offset, oncomplete)<br> Ioctx.read(key, length, offset)<br> Ioctx.stat(key)<br> Ioctx.trunc(key, size)<br> Ioctx.remove_object(key)</p></li><li><p>对象扩展属性：在一个对象上设置扩展属性(XATTRs)。<br> Ioctx.set_xattr(key, xattr_name, xattr_value)<br> Ioctx.get_xattrs(oid)<br> XattrIterator.<strong>next</strong>()<br> Ioctx.get_xattr(key, xattr_name)<br> Ioctx.rm_xattr(key, xattr_name)</p></li><li><p>对象接口：从一个池中检索一个对象的列表，并对它们进行迭代。提供的对象接口使每个对象看起来像一个文件，可以对对象进行同步操作。对于异步操作，应该使用I&#x2F;O上下文的方法。<br> Ioctx.list_objects()<br> ObjectIterator.<strong>next</strong>()<br> Object.read(length&#x3D;1024 * 1024)<br> Object.write(string_to_write)<br> Object.get_xattrs()<br> Object.get_xattr(xattr_name)<br> Object.set_xattr(xattr_name, xattr_value)<br> Object.rm_xattr(xattr_name)<br> Object.stat()<br> Object.remove()</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Librados-API概述&quot;&gt;&lt;a href=&quot;#Librados-API概述&quot; class=&quot;headerlink&quot; title=&quot;Librados API概述&quot;&gt;&lt;/a&gt;Librados API概述&lt;/h1&gt;&lt;p&gt;Ceph存储集群提供基本的存储服务，Ceph</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_librados介绍</title>
    <link href="https://watsonlu6.github.io/Ceph_librados%E4%BB%8B%E7%BB%8D/"/>
    <id>https://watsonlu6.github.io/Ceph_librados%E4%BB%8B%E7%BB%8D/</id>
    <published>2021-06-05T06:15:14.000Z</published>
    <updated>2024-07-27T14:37:27.947Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-Librados介绍"><a href="#Ceph-Librados介绍" class="headerlink" title="Ceph Librados介绍"></a>Ceph Librados介绍</h1><h2 id="Ceph-Librados-概述"><a href="#Ceph-Librados-概述" class="headerlink" title="Ceph Librados 概述"></a>Ceph Librados 概述</h2><p>一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用librados，连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它要创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。</p><p>Ceph客户端主要是实现了接口，对外提供了访问的功能。上层可以通过接口访问Ceph存储。Ceph的客户端通过一套名为librados的接口进行集群的访问，这里的访问包括对集群的整体访问和对象的访问两类接口。这套接口（API）包括C、C++和Python常见语言的实现，接口通过网络实现对Ceph集群的访问。在用户层面，可以在自己的程序中调用该接口，从而集成Ceph集群的存储功能，或者在监控程序中实现对Ceph集群状态的监控。所谓集群的整体访问包括连接集群、创建存储池、删除存储池和获取集群状态等等。所谓对象访问是之对存储池中对象的访问，包括创建删除对象、向对象写数据或者追加数据和读对象数据等接口。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_1.png"></p><h2 id="客户端基本架构概述"><a href="#客户端基本架构概述" class="headerlink" title="客户端基本架构概述"></a>客户端基本架构概述</h2><p>librados客户端基本架构如下图所示，主要包括4层，分别是API层、IO处理层、对象处理层和消息收发层。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_2.png"></p><ul><li><strong>API层</strong>是一个抽象层，为上层提供统一的接口。API层提供的原生接口包括C和C++两种语言的实现外，还有Python的实现。</li><li><strong>IO处理层</strong>用于实现IO的简单封装，其通过一个名为ObjectOperation类实现，该类主要包括的是读写操作的数据信息。之后在IO处理层在IoCtxImpl::operate函数中将ObjectOperation转换为Objecter::Op类的对象，并将该对象提交到对象处理层进行进一步的处理。</li><li><strong>对象处理层</strong>包括了Ceph对象处理所需要的信息，包括通信管道、OSDMap和MonMap等内容。因此，在这里，根据对象的信息可以计算出对象存储的具体位置，最终找到客户端与OSD的连接信息（Session）。</li><li><strong>消息收发层</strong>的接口会被对象处理层调用，此时消息会传递到本层，并且通过本层的线程池发送到具体的OSD。这里需要注意的是，消息收发层与服务端的消息收发公用Messager的代码。</li></ul><h2 id="核心流程图"><a href="#核心流程图" class="headerlink" title="核心流程图"></a>核心流程图</h2><p>先根据配置文件调用librados创建Rados，接下来为这个Rados创建一个RadosClient，RadosClient包含3个主要模块(finisher、Messenger、Objecter)。再根据pool创建对应的ioctx，在ioctx中能够找到RadosClient。再调用OSDC生成对应的OSD请求，与OSD进行通信响应请求。这从大体上叙述了librados与osdc在整个Ceph中的作用。</p><p>具体细节可以按照该流程读对应源代码理解。在这个流程中需要注意的是_op_submit函数会调用_calc_target和_get_session两个函数，两个函数的作用分别是获取目的OSD和对应的Session（连接），这个是后面发送数据的基础。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_3.png"></p><h2 id="Librados与OSDC的关系"><a href="#Librados与OSDC的关系" class="headerlink" title="Librados与OSDC的关系"></a>Librados与OSDC的关系</h2><p>Librados与OSDC位于ceph客户端中比较底层的位置。</p><ul><li>Librados模块是RADOS对象存储系统访问的接口，它提供了pool的创建、删除、对象的创建、删除、读写等基本操作接口。类RadosClient是librados模块的核心管理类，处理整个RADOS系统层面以及pool层面的管理。类ioctxlmpl实现单个pool层的对象读写等操作。</li><li>OSDC模块实现了请求的封装和通过网络模块发送请求的逻辑，其核心类Object完成对象的地址计算、消息的发送和处理超时等工作。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_4.png"><br>librados模块包含两个部分，分别是RadosClient 模块和IoctxImpl。RadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。</li></ul><h2 id="Librados模块"><a href="#Librados模块" class="headerlink" title="Librados模块"></a>Librados模块</h2><h4 id="类RadosClient"><a href="#类RadosClient" class="headerlink" title="类RadosClient"></a>类RadosClient</h4><p>RadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">librados</span>::RadosClient : <span class="keyword">public</span> Dispatcher    <span class="comment">//继承Dispatcher(消息分发类)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//unique_ptr智能指针</span></span><br><span class="line">    std::unique_ptr&lt;CephContext,std::function&lt;<span class="type">void</span>(CephContext*)&gt; &gt; cct_deleter;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> Dispatcher::cct;</span><br><span class="line">    <span class="type">const</span> ConfigProxy&amp; conf;  <span class="comment">//配置文件</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">enum</span> &#123;</span><br><span class="line">    DISCONNECTED,</span><br><span class="line">    CONNECTING,</span><br><span class="line">    CONNECTED,</span><br><span class="line">    &#125; state;   <span class="comment">//Monitor的网络连接状态</span></span><br><span class="line">    MonClient monclient;    <span class="comment">//Monitor客户端</span></span><br><span class="line">    MgrClient mgrclient;    <span class="comment">//MGR客户端</span></span><br><span class="line">    Messenger *messenger;    <span class="comment">//网络消息接口</span></span><br><span class="line">    <span class="type">uint64_t</span> instance_id;     <span class="comment">//rados客户端实例的ID</span></span><br><span class="line">    <span class="comment">//相关消息分发 Dispatcher类的函数重写</span></span><br><span class="line">    <span class="type">bool</span> _dispatch(Message *m);</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_dispatch</span><span class="params">(Message *m)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_get_authorizer</span><span class="params">(<span class="type">int</span> dest_type, AuthAuthorizer **authorizer)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">ms_handle_connect</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_handle_reset</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">ms_handle_remote_reset</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_handle_refused</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    Objecter *objecter;   <span class="comment">//OSDC模块中用于发送封装好的OP消息</span></span><br><span class="line">    Mutex lock;</span><br><span class="line">    Cond cond;</span><br><span class="line">    SafeTimer timer;    <span class="comment">//定时器</span></span><br><span class="line">    <span class="type">int</span> refcnt;     <span class="comment">//引用计算</span></span><br><span class="line">    <span class="type">version_t</span> log_last_version;</span><br><span class="line">    <span class="type">rados_log_callback_t</span> log_cb;</span><br><span class="line">    <span class="type">rados_log_callback2_t</span> log_cb2;</span><br><span class="line">    <span class="type">void</span> *log_cb_arg;</span><br><span class="line">    string log_watch;</span><br><span class="line">    <span class="type">bool</span> service_daemon = <span class="literal">false</span>;</span><br><span class="line">    string daemon_name, service_name;</span><br><span class="line">    map&lt;string,string&gt; daemon_metadata;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">wait_for_osdmap</span><span class="params">()</span></span>;</span><br><span class="line">    Finisher finisher;      <span class="comment">//用于执行回调函数的finisher类</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">RadosClient</span><span class="params">(CephContext *cct_)</span></span>;    </span><br><span class="line">    ~<span class="built_in">RadosClient</span>() <span class="keyword">override</span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">ping_monitor</span><span class="params">(string mon_id, string *result)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">connect</span><span class="params">()</span></span>;   <span class="comment">//RadosClient的初始化函数、  连接</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">shutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">watch_flush</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">async_watch_flush</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">uint64_t</span> <span class="title">get_instance_id</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_min_compatible_osd</span><span class="params">(<span class="type">int8_t</span>* require_osd_release)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_min_compatible_client</span><span class="params">(<span class="type">int8_t</span>* min_compat_client,<span class="type">int8_t</span>* require_min_compat_client)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">wait_for_latest_osdmap</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">//创建一个pool相关的上下文信息IoCtxImpl对象（根据pool名字或Id创建ioctx）</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">create_ioctx</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, IoCtxImpl **io)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">create_ioctx</span><span class="params">(<span class="type">int64_t</span>, IoCtxImpl **io)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_fsid</span><span class="params">(std::string *s)</span></span>;</span><br><span class="line">    <span class="comment">//用于查找pool</span></span><br><span class="line">    <span class="function"><span class="type">int64_t</span> <span class="title">lookup_pool</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">pool_requires_alignment</span><span class="params">(<span class="type">int64_t</span> pool_id)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_requires_alignment2</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">bool</span> *<span class="keyword">requires</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">uint64_t</span> <span class="title">pool_required_alignment</span><span class="params">(<span class="type">int64_t</span> pool_id)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_required_alignment2</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">uint64_t</span> *alignment)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_get_name</span><span class="params">(<span class="type">uint64_t</span> pool_id, std::string *name, <span class="type">bool</span> wait_latest_map = <span class="literal">false</span>)</span></span>;</span><br><span class="line">    <span class="comment">//用于列出所有的pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_list</span><span class="params">(std::list&lt;std::pair&lt;<span class="type">int64_t</span>, string&gt; &gt;&amp; ls)</span></span>;</span><br><span class="line">    <span class="comment">//用于获取pool的统计信息</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_pool_stats</span><span class="params">(std::list&lt;string&gt;&amp; ls, map&lt;string,::<span class="type">pool_stat_t</span>&gt; *result,<span class="type">bool</span> *per_pool)</span></span>;</span><br><span class="line">    <span class="comment">//用于获取系统的统计信息</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_fs_stats</span><span class="params">(ceph_statfs&amp; result)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">get_pool_is_selfmanaged_snaps_mode</span><span class="params">(<span class="type">const</span> std::string&amp; pool)</span></span>;</span><br><span class="line">    <span class="comment">//pool的同步创建</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_create</span><span class="params">(string&amp; name, <span class="type">int16_t</span> crush_rule=<span class="number">-1</span>)</span></span>;</span><br><span class="line">    <span class="comment">//pool的异步创建</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_create_async</span><span class="params">(string&amp; name, PoolAsyncCompletionImpl *c,<span class="type">int16_t</span> crush_rule=<span class="number">-1</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_get_base_tier</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">int64_t</span>* base_tier)</span></span>;</span><br><span class="line">    <span class="comment">//同步删除pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_delete</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">    <span class="comment">//异步删除pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_delete_async</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, PoolAsyncCompletionImpl *c)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">blacklist_add</span><span class="params">(<span class="type">const</span> string&amp; client_address, <span class="type">uint32_t</span> expire_seconds)</span></span>;</span><br><span class="line">    <span class="comment">//处理Mon相关命令,调用monclient.start_mon_command 把命令发送给Mon处理</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">mon_command_async</span><span class="params">(………)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(<span class="type">int</span> rank,<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(string name,<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mgr_command</span><span class="params">(<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl, bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="comment">//处理OSD相关命令</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">osd_command</span><span class="params">(<span class="type">int</span> osd, vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist&amp; inbl,bufferlist *poutbl, string *prs)</span></span>;</span><br><span class="line">    <span class="comment">//处理PG相关命令</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pg_command</span><span class="params">(<span class="type">pg_t</span> pgid, vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist&amp; inbl,bufferlist *poutbl, string *prs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">handle_log</span><span class="params">(MLog *m)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">monitor_log</span><span class="params">(<span class="type">const</span> string&amp; level, <span class="type">rados_log_callback_t</span> cb,<span class="type">rados_log_callback2_t</span> cb2, <span class="type">void</span> *arg)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">put</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">blacklist_self</span><span class="params">(<span class="type">bool</span> set)</span></span>;</span><br><span class="line">    <span class="function">std::string <span class="title">get_addrs</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">service_daemon_register</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; service,  <span class="comment">///&lt; service name (e.g., &#x27;rgw&#x27;)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; name,     <span class="comment">///&lt; daemon name (e.g., &#x27;gwfoo&#x27;)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::map&lt;std::string,std::string&gt;&amp; metadata)</span></span>; <span class="comment">///&lt; static metadata about daemon</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">service_daemon_update_status</span><span class="params">(std::map&lt;std::string,std::string&gt;&amp;&amp; status)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">mon_feature_t</span> <span class="title">get_required_monitor_features</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_pgs</span><span class="params">(<span class="type">int64_t</span> pool_id, std::vector&lt;std::string&gt;* pgs)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="类IoctxImpl"><a href="#类IoctxImpl" class="headerlink" title="类IoctxImpl"></a>类IoctxImpl</h4><p>类IoctxImpl是对于其中的某一个pool进行管理，如对 对象的读写等操作的控制。<br>该类是pool的上下文信息，一个pool对应一个IoctxImpl对象。librados中所有关于io操作的API都设计在librados::IoCtx中，接口的真正实现在ioCtxImpl中，它的处理过程如下：</p><ol><li>把请求封装成ObjectOperation类(osdc类中)</li><li>把相关的pool信息添加到里面，封装成Object::Op对象</li><li>调用响应的函数object-&gt;op_submit发送给相应的OSD</li><li>操作完成后，调用相应的回调函数。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">librados</span>::IoCtxImpl &#123;</span><br><span class="line">  std::atomic&lt;<span class="type">uint64_t</span>&gt; ref_cnt = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">  RadosClient *client;</span><br><span class="line">  <span class="type">int64_t</span> poolid;</span><br><span class="line">  <span class="type">snapid_t</span> snap_seq;</span><br><span class="line">  ::SnapContext snapc;</span><br><span class="line">  <span class="type">uint64_t</span> assert_ver;</span><br><span class="line">  <span class="type">version_t</span> last_objver;</span><br><span class="line">  <span class="type">uint32_t</span> notify_timeout;</span><br><span class="line">  <span class="type">object_locator_t</span> oloc;</span><br><span class="line"></span><br><span class="line">  Mutex aio_write_list_lock;</span><br><span class="line">  <span class="type">ceph_tid_t</span> aio_write_seq;</span><br><span class="line">  Cond aio_write_cond;</span><br><span class="line">  xlist&lt;AioCompletionImpl*&gt; aio_write_list;</span><br><span class="line">  map&lt;<span class="type">ceph_tid_t</span>, std::list&lt;AioCompletionImpl*&gt; &gt; aio_write_waiters;</span><br><span class="line"></span><br><span class="line">  Objecter *objecter;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">IoCtxImpl</span>();</span><br><span class="line">  <span class="built_in">IoCtxImpl</span>(RadosClient *c, Objecter *objecter,<span class="type">int64_t</span> poolid, <span class="type">snapid_t</span> s);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">dup</span><span class="params">(<span class="type">const</span> IoCtxImpl&amp; rhs)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_snap_read</span><span class="params">(<span class="type">snapid_t</span> s)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">set_snap_write_context</span><span class="params">(<span class="type">snapid_t</span> seq, vector&lt;<span class="type">snapid_t</span>&gt;&amp; snaps)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">put</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">queue_aio_write</span><span class="params">(<span class="keyword">struct</span> AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">complete_aio_write</span><span class="params">(<span class="keyword">struct</span> AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">flush_aio_writes_async</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">flush_aio_writes</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">get_id</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">string <span class="title">get_cached_pool_name</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_object_hash_position</span><span class="params">(<span class="type">const</span> std::string&amp; oid, <span class="type">uint32_t</span> *hash_position)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_object_pg_hash_position</span><span class="params">(<span class="type">const</span> std::string&amp; oid, <span class="type">uint32_t</span> *pg_hash_position)</span></span>;</span><br><span class="line">  ::<span class="function">ObjectOperation *<span class="title">prepare_assert_ops</span><span class="params">(::ObjectOperation *op)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// snaps</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_list</span><span class="params">(vector&lt;<span class="type">uint64_t</span>&gt; *snaps)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_lookup</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, <span class="type">uint64_t</span> *snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_get_name</span><span class="params">(<span class="type">uint64_t</span> snapid, std::string *s)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_get_stamp</span><span class="params">(<span class="type">uint64_t</span> snapid, <span class="type">time_t</span> *t)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_create</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* snapname)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_create</span><span class="params">(<span class="type">uint64_t</span> *snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">aio_selfmanaged_snap_create</span><span class="params">(<span class="type">uint64_t</span> *snapid, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_remove</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* snapname)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">rollback</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *snapName)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_remove</span><span class="params">(<span class="type">uint64_t</span> snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">aio_selfmanaged_snap_remove</span><span class="params">(<span class="type">uint64_t</span> snapid, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_rollback_object</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid,::SnapContext&amp; snapc, <span class="type">uint64_t</span> snapid)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// io</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">nlist</span><span class="params">(Objecter::NListContext *context, <span class="type">int</span> max_entries)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">nlist_seek</span><span class="params">(Objecter::NListContext *context, <span class="type">uint32_t</span> pos)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">nlist_seek</span><span class="params">(Objecter::NListContext *context, <span class="type">const</span> rados_object_list_cursor&amp; cursor)</span></span>;</span><br><span class="line">  <span class="function">rados_object_list_cursor <span class="title">nlist_get_cursor</span><span class="params">(Objecter::NListContext *context)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">object_list_slice</span><span class="params">(……)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">create</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">bool</span> exclusive)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">write</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">append</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">write_full</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">writesame</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl,<span class="type">size_t</span> write_len, <span class="type">uint64_t</span> offset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">mapext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> off, <span class="type">size_t</span> len,std::map&lt;<span class="type">uint64_t</span>,<span class="type">uint64_t</span>&gt;&amp; m)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">sparse_read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, std::map&lt;<span class="type">uint64_t</span>,<span class="type">uint64_t</span>&gt;&amp; m,bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">checksum</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">int</span> flags)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">stat</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> *psize, <span class="type">time_t</span> *pmtime)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">stat2</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> *psize, <span class="keyword">struct</span> timespec *pts)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">trunc</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> size)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cmpext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> off, bufferlist&amp; cmp_bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">tmap_update</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; cmdbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">exec</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *cls, <span class="type">const</span> <span class="type">char</span> *method, bufferlist&amp; inbl, bufferlist&amp; outbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">getxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">setxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">getxattrs</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, map&lt;string, bufferlist&gt;&amp; attrset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">rmxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">operate</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, ::ObjectOperation *o, ceph::real_time *pmtime, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">operate_read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, ::ObjectOperation *o, bufferlist *pbl, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_operate</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_operate_read</span><span class="params">(…………)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_stat_Ack</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_stat2_Ack</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_Complete</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_read</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_read</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_sparse_read</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cmpext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> off,bufferlist&amp; cmp_bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cmpext</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_write</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_append</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl, <span class="type">size_t</span> len)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_write_full</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_writesame</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl, <span class="type">size_t</span> write_len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_exec</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_exec</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_stat</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> *psize, <span class="type">time_t</span> *pmtime)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_stat2</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> *psize, <span class="keyword">struct</span> timespec *pts)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_getxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,<span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_setxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_getxattrs</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,map&lt;string, bufferlist&gt;&amp; attrset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_rmxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cancel</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">hit_set_list</span><span class="params">(<span class="type">uint32_t</span> hash, AioCompletionImpl *c,std::list&lt; std::pair&lt;<span class="type">time_t</span>, <span class="type">time_t</span>&gt; &gt; *pls)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">hit_set_get</span><span class="params">(<span class="type">uint32_t</span> hash, AioCompletionImpl *c, <span class="type">time_t</span> stamp,bufferlist *pbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_objects</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_snapsets</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_sync_op_version</span><span class="params">(<span class="type">version_t</span> ver)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_watch</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_watch</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch_check</span><span class="params">(<span class="type">uint64_t</span> cookie)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">unwatch</span><span class="params">(<span class="type">uint64_t</span> cookie)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_unwatch</span><span class="params">(<span class="type">uint64_t</span> cookie, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">notify</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">notify_ack</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> notify_id, <span class="type">uint64_t</span> cookie,bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_notify</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">set_alloc_hint</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">version_t</span> <span class="title">last_version</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_assert_version</span><span class="params">(<span class="type">uint64_t</span> ver)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_notify_timeout</span><span class="params">(<span class="type">uint32_t</span> timeout)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cache_pin</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cache_unpin</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_enable</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, <span class="type">bool</span> force)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">application_enable_async</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, <span class="type">bool</span> force,PoolAsyncCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_list</span><span class="params">(std::set&lt;std::string&gt; *app_names)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_get</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key,std::string* value)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_set</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key,<span class="type">const</span> std::string&amp; value)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_remove</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_list</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, std::map&lt;std::string, std::string&gt; *values)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ol><h4 id="librados主要接口"><a href="#librados主要接口" class="headerlink" title="librados主要接口"></a>librados主要接口</h4><ol><li>集群句柄创建<br>librados::Rados对象是用来操纵ceph集群的句柄，使用init来创建RadosClient，之后读取指定的ceph配置文件，获取monitor的ip和端口号。RadosClient里面有与monitor通信的MonClient和用于与OSD通信的Messenger。</li><li>集群连接<br>初始化集群句柄之后，就可以使用这个句柄来连接集群了<br>RadosClient::connect完成了连接操作：<br> a. 调用monclient.build_inital_monmap，从配置文件种检查是否有初始化的monitor的地址信息<br> b. 创建网络通信模块messenger，并设置相关的Policy信息<br> c. 创建Objecter对象并初始化<br> d. 调用monclient.init()函数初始化monclient<br> e. Timer定时器初始化，Finisher对象初始化</li><li>IO上下文环境初始化<br>使用句柄创建好存储池后，还需要创建与存储池相关的IO上下文句柄<br>rados.ioctx_create(pool_name, io_ctx)</li><li>对象读写<br>创建对象并写入数据：io_ctx.create_full(object_name,bl)<br>读取对象中的数据到bufferlist中，对象读取有同步读取和异步读取两种接口：io_ctx.read和io_ctx.aio_read<br> a. 同步读取：io_ctx.read(object_name,read_bl,read_len,0)<br> b. 异步读取：需要指定完成读取数据后的回调，用于检查读取是否完成<br> librados::AioCompletion *read_completion &#x3D; librados::Rados::aio_create_completion();<br> io_ctx.aio_read(object_name,read_completion,&amp;read_buff,read_len,0)<br> read_completion-&gt;wait_for_complete()<br> 同时还要获取返回值，得到读取对象的字节数</li><li>IO上下文关闭<br>io_ctx.close()</li><li>集群句柄关闭<br>rados.shutdown()<br>上述功能通过Rados和IoCtx两个类实现，两个类的主要函数如下图所示（这里仅是示例，实际接口数量要多很多，具体参考源代码）。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_5.png"></li></ol><h2 id="Ceph官方的示例代码"><a href="#Ceph官方的示例代码" class="headerlink" title="Ceph官方的示例代码"></a>Ceph官方的示例代码</h2><p>为了了解如何使用这些API，这里给出一些代码片段。具体完整的代码大家可以参考Ceph官方的示例代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">librados::IoCtx io_ctx;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *pool_name = <span class="string">&quot;test&quot;</span>;</span><br><span class="line">cluster.<span class="built_in">ioctx_create</span>(pool_name, io_ctx);      <span class="comment">/*  创建进行IO处理的上下文，其实就是用于访问Ceph的对象 */</span></span><br><span class="line"><span class="comment">/* 同步写对象 */</span></span><br><span class="line">librados::bufferlist bl;</span><br><span class="line">bl.<span class="built_in">append</span>(<span class="string">&quot;Hello World!&quot;</span>);  <span class="comment">/* 对象的内容 */</span></span><br><span class="line">ret = io_ctx.<span class="built_in">write_full</span>(<span class="string">&quot;itworld123&quot;</span>, bl);    <span class="comment">/*写入对象itworld123*/</span></span><br><span class="line"><span class="comment">/* 向对象添加属性，这里的属性与文件系统中文件的扩展属性类似。   */</span></span><br><span class="line">librados::bufferlist attr_bl;</span><br><span class="line">attr_bl.<span class="built_in">append</span>(<span class="string">&quot;en_US&quot;</span>);</span><br><span class="line">io_ctx.<span class="built_in">setxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>, attr_bl);</span><br><span class="line"><span class="comment">/* 异步读取对象内容 */</span></span><br><span class="line">librados::bufferlist read_buf;</span><br><span class="line"><span class="type">int</span> read_len = <span class="number">1024</span>;</span><br><span class="line">librados::AioCompletion *read_completion = librados::Rados::<span class="built_in">aio_create_completion</span>();   <span class="comment">/* 创建一个异步完成类对象 */</span></span><br><span class="line">io_ctx.<span class="built_in">aio_read</span>(<span class="string">&quot;itworld123&quot;</span>, read_completion, &amp;read_buf, read_len, <span class="number">0</span>);    <span class="comment">/* 发送读请求 */</span></span><br><span class="line">read_completion-&gt;<span class="built_in">wait_for_complete</span>(); <span class="comment">/* 等待请求完成 */</span></span><br><span class="line">read_completion-&gt;<span class="built_in">get_return_value</span>();  </span><br><span class="line">librados::bufferlist attr_res;</span><br><span class="line">io_ctx.<span class="built_in">getxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>, attr_res);  <span class="comment">/* 读取对象属性 */</span></span><br><span class="line">io_ctx.<span class="built_in">rmxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>);      <span class="comment">/* 删除对象的属性 */</span></span><br><span class="line">io_ctx.<span class="built_in">remove</span>(<span class="string">&quot;itworld123&quot;</span>);     <span class="comment">/* 删除对象 */</span>  </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-Librados介绍&quot;&gt;&lt;a href=&quot;#Ceph-Librados介绍&quot; class=&quot;headerlink&quot; title=&quot;Ceph Librados介绍&quot;&gt;&lt;/a&gt;Ceph Librados介绍&lt;/h1&gt;&lt;h2 id=&quot;Ceph-Librados</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph数据读写过程</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/</id>
    <published>2021-05-19T09:06:37.000Z</published>
    <updated>2024-07-27T14:31:10.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph数据映射过程"><a href="#Ceph数据映射过程" class="headerlink" title="Ceph数据映射过程"></a>Ceph数据映射过程</h2><p>在一个大规模分布式存储系统中，需要解决两个核心问题：“我应该把数据写到哪里？”和“我之前把数据存储在了哪里？”。这就引出了数据寻址的问题。Ceph 的寻址流程可以如下描述。<br> <img src="/images/Ceph%E5%AF%BB%E5%9D%80.png"></p><ul><li><strong>File</strong>：此处的File就是用户需要存储或访问的文件。对于一个基于Ceph开发的对象存储应用而言，这个File也就对应于应用中的“对象” ，也就是用户直接操作的“对象”</li><li><strong>Object：</strong> 在 RADOS（Reliable Autonomic Distributed Object Store）中，”对象” 是指系统中存储的基本单位。与 File 的不同之处在于，Object 的最大尺寸受到 RADOS 的限制，通常为 2MB 或 4MB。这一限制是为了优化底层存储的管理和组织。因此，当上层应用向 RADOS 存储一个较大的 File 时，需要将其拆分成多个统一大小的 Object（最后一个 Object 的大小可能不同）进行存储。</li><li><strong>PG（Placement Group）：</strong> 顾名思义，PG 用于组织对象的存储并映射其位置。具体来说，一个 PG 负责管理多个对象，而每个对象只能映射到一个 PG 中，即 PG 和对象之间是“一对多”的映射关系。同时，一个 PG 会被映射到多个 OSD（Object Storage Device）上，通常 n 至少为 2，而在生产环境中，n 通常至少为 3。每个 OSD 上会承载大量的 PG，可能达到数百个。PG 的数量设置直接影响数据的分布均匀性，因此在实际配置中需要谨慎考虑。</li><li><strong>OSD（Object Storage Device）：</strong> OSD 是 Ceph 中用于存储数据的对象存储设备。OSD 的数量对系统的数据分布均匀性有直接影响，因此不宜过少。为了充分发挥 Ceph 系统的优势，通常需要配置至少数百个 OSD。</li></ul><ol><li><p><strong>File → Object映射</strong><br> 这个映射过程的目的是将用户操作的 File 转换为 RADOS 能够处理的 Object。这个过程相对简单，本质上就是按照 Object 的最大尺寸对 File 进行切分，类似于磁盘阵列中的条带化（striping）过程。这种切分有两个主要好处：</p><ul><li>将大小不定的 File 转换为具有一致最大尺寸的 Object，使得 RADOS 能够更高效地管理这些数据。</li><li>将对单一 File 的串行处理转变为对多个 Object 的并行处理，从而提高处理效率。</li></ul><p> 每一个切分后的 Object 将获得一个唯一的 Object ID (oid)，其生成方式非常简单，是一种线性映射。具体来说，<code>ino</code> 表示待操作 File 的元数据，可以简单理解为该 File 的唯一 ID；<code>ono</code> 则是由该 File 切分产生的某个 Object 的序号。而 <code>oid</code> 就是将这个序号简单地附加在该 File 的 ID 之后得到的。举个例子，如果一个 ID 为 <code>filename</code> 的 File 被切分成了 3 个 Object，那么其 Object 的序号依次为 0、1 和 2，最终得到的 oid 就依次为 <code>filename0</code>、<code>filename1</code> 和 <code>filename2</code>。</p><p> 这里有一个隐含的问题，即 <code>ino</code> 的唯一性必须得到保证，否则后续的映射将无法正确进行。</p></li><li><p><strong>Object → PG 映射</strong><br> 当一个 File 被映射为一个或多个 Object 后，需要将每个 Object 独立地映射到一个 PG 中。这个过程相对简单，具体计算过程如下：</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hash(oid) &amp; mask -&gt; pgid</span><br></pre></td></tr></table></figure><p> 这个计算过程分为两步：</p><ol><li>使用 Ceph 系统指定的静态哈希算法计算 oid 的哈希值，将 oid 转换为一个近似均匀分布的伪随机值。</li><li>将这个伪随机值与 mask 进行按位与操作，得到最终的 PG 序号 (pgid)。</li></ol><p> 根据 RADOS 的设计，PG 的总数为 m（m 应该为 2 的整数幂），则 mask 的值为 m - 1。哈希值计算和按位与操作的结果就是从所有 m 个 PG 中近似均匀地随机选择一个。这种机制保证了在大量 Object 和大量 PG 存在的情况下，Object 和 PG 之间的映射近似均匀。由于 Object 是由 File 切分而来，大部分 Object 的尺寸相同，因此这一映射最终保证了各个 PG 中存储的 Object 的总数据量的近似均匀性。</p><p> 这里强调“大量”是因为，只有在 Object 和 PG 数量较多时，这种伪随机关系的近似均匀性才有效，Ceph 的数据存储均匀性才能得到保障。为了确保这一点，一方面，Object 的最大尺寸应该被合理配置，以使得相同数量的 File 能被切分成更多的 Object；另一方面，Ceph 建议 PG 的总数应为 OSD 总数的数百倍，以确保有足够数量的 PG 供映射使用。</p></li><li><p><strong>PG → OSD 映射</strong><br> 第三次映射是将作为对象逻辑组织单元的 PG 映射到实际存储单元 OSD 上。RADOS 使用了一种称为 CRUSH（Controlled Replication Under Scalable Hashing）的算法，将 <code>pgid</code> 代入其中，然后得到一组包含 n 个 OSD。这 n 个 OSD 共同负责存储和维护一个 PG 中的所有对象。通常，n 的值根据实际应用中的可靠性需求而定，在生产环境下通常为 3。具体到每个 OSD，由其上运行的 OSD Daemon 负责执行映射到本地的对象在本地文件系统中的存储、访问、元数据维护等操作。</p><p> 与对象到 PG 的映射中采用的哈希算法不同，CRUSH 算法的结果并非绝对不变，而会受到其他因素的影响，主要有两个：</p><ol><li><p><strong>当前系统状态</strong>：即集群运行图。当系统中的 OSD 状态或数量发生变化时，集群运行图可能会改变，这将影响 PG 与 OSD 之间的映射关系。</p></li><li><p><strong>存储策略配置</strong>：这与数据的安全性相关。系统管理员可以通过策略配置指定承载同一个 PG 的 3 个 OSD 分别位于数据中心的不同服务器或机架上，从而提高存储的可靠性。</p></li></ol><p> 因此，只有在系统状态和存储策略都不发生变化时，PG 和 OSD 之间的映射关系才是固定的。在实际使用中，策略配置通常一经设定就不会改变。而系统状态的变化可能是由于设备损坏或存储集群规模的扩大。好在 Ceph 提供了对这些变化的自动化支持，因此，即便 PG 与 OSD 之间的映射关系发生变化，也不会对应用产生影响。实际上，Ceph 利用 CRUSH 算法的动态特性，可以根据需要将一个 PG 动态迁移到不同的 OSD 组合上，从而自动实现高可靠性和数据分布再平衡等特性。</p><p> 选择 CRUSH 算法而非其他哈希算法的原因有两点：</p><ol><li><strong>可配置性</strong>：CRUSH 算法具有可配置特性，可以根据管理员的配置参数决定 OSD 的物理位置映射策略。</li><li><strong>稳定性</strong>：CRUSH 算法具有特殊的“稳定性”，即当系统中加入新的 OSD 导致系统规模增大时，大部分 PG 与 OSD 之间的映射关系不会改变，只有少部分 PG 的映射关系会发生变化并引发数据迁移。这种特性使得系统在扩展时能够保持相对稳定，避免了普通哈希算法可能带来的大规模数据迁移问题。</li></ol></li></ol><p>至此为止，Ceph通过3次映射，完成了从File到Object、Object到PG、PG再到OSD的整个映射过程。从整个过程可以看到，这里没有任何的全局性查表操作需求。至于唯一的全局性数据结构：集群运行图。它的维护和操作都是轻量级的，不会对系统的可扩展性、性能等因素造成影响。</p><p><strong>接下来的一个问题是:为什么需要引人PG并在Object与OSD之间增加一层映射呢？</strong><br>可以想象一下，如果没有 PG 这一层的映射，会是什么情况？在这种情况下，需要采用某种算法将 Object 直接映射到一组 OSD 上。如果这种算法是某种固定映射的哈希算法，这就意味着一个 Object 将被固定映射在一组 OSD 上。当其中一个或多个 OSD 损坏时，Object 无法自动迁移到其他 OSD 上（因为映射函数不允许），而当系统为了扩容新增 OSD 时，Object 也无法被再平衡到新的 OSD 上（同样因为映射函数不允许）。这些限制违背了 Ceph 系统高可靠性和高自动化的设计初衷。</p><p>即便使用一个动态算法（如 CRUSH 算法）来完成这一映射，似乎可以避免静态映射带来的问题。但这样会导致各个 OSD 处理的本地元数据量大幅增加，计算复杂度和维护工作量也会大幅上升。</p><p>例如，在 Ceph 的现有机制中，一个 OSD 通常需要与其他承载同一个 PG 的 OSD 交换信息，以确定各自是否工作正常或是否需要进行维护。由于每个 OSD 承载约数百个 PG，而每个 PG 通常有 3 个 OSD，因此，在一定时间内，一个 OSD 大约需要进行数百次至数千次的信息交换。</p><p>然而，如果没有 PG 存在，一个 OSD 需要与其他承载同一个 Object 的 OSD 交换信息。由于每个 OSD 可能承载高达数百万个 Object，在同样时间内，一个 OSD 大约需要进行数百万次甚至数千万次的信息交换。这种状态维护成本显然过高。</p><p>综上所述，引入 PG 有至少两方面的好处：一方面，实现了 Object 和 OSD 之间的动态映射，为 Ceph 的可靠性和自动化等特性的实现提供了可能；另一方面，有效简化了数据的存储组织，大大降低了系统的维护和管理成本。</p><h2 id="Ceph数据读写过程"><a href="#Ceph数据读写过程" class="headerlink" title="Ceph数据读写过程"></a>Ceph数据读写过程</h2><p>Ceph的读&#x2F;写操作采用<strong>Primary-Replica</strong>模型，客户端只向Object所对应OSD set的Primary OSD发起读&#x2F;写请求，这保证了数据的强一致性。当Primary OSD收到Object的写请求时，它负责把数据发送给其他副本，只有这个数据被保存在所有的OSD上时，Primary OSD才应答Object的写请求，这保证了副本的一致性。</p><p><strong>写入数据</strong><br>这里以Object写入为例，假定一个PG被映射到3个OSD上。Object写入流程如图所示。<br> <img src="/images/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B.jpg"></p><p>当某个客户端需要向Ceph集群写入一个File时，首先需要在本地完成前面所述的<a href="https://blog.csdn.net/lhc121386/article/details/113428189">寻址流程</a>，将File变为一个Object，然后找出存储该Object的一组共3个OSD，这3个OSD具有各自不同的序号，序号最靠前的那个OSD就是这一组中的Primary OSD，而后两个则依次Secondary OSD和Tertiary OSD。<br>找出3个OSD后，客户端将直接和Primary OSD进行通信，发起写入操作(<strong>步骤1</strong>)。 Primary OSD收到请求后，分别向Secondary OSD和Tertiary OSD发起写人操作(<strong>步骤2</strong>和<strong>步骤3</strong>)。当Secondary OSD和Tertiary OSD各自完成写入操作后，将分别向Primary OSD发送确认信息(<strong>步骤4</strong>和<strong>步骤5</strong>)。当Primary OSD确认其他两个OSD的写入完成后，则自己也完成数据写入，并向客户端确认Object写入操作完成(<strong>步骤6</strong>)。<br>之所以采用这样的写入流程，本质上是为了保证写入过程中的可靠性，尽可能避免出现数据丢失的情况。同时，由于客户端只需要向Primary OSD发送数据，因此在互联网使用场景下的外网带宽和整体访问延迟又得到了一定程度的优化。<br>当然，这种可靠性机制必然导致较长的延迟，特别是，如果等到所有的OSD都将数据写入磁盘后再向客户端发送确认信号，则整体延迟可能难以忍受。因此， <strong>Ceph可以分两次向客户端进行确认。当各个OSD都将数据写入内存缓冲区后，就先向客户端发送一次确认，此时客户端即可以向下执行。待各个OSD都将数据写入磁盘后，会向客户端发送一个最终确认信号，此时客户端可以根据需要删除本地数据。</strong><br>分析上述流程可以看出，在正常情况下，客户端可以独立完成OSD寻址操作，而不必依赖于其他系统模块。因此，大量的客户端可以同时和大量的OSD进行并行操作。同时，如果一个File被切分成多个Object，这多个Object也可被并行发送至多个OSD上。<br>从OSD的角度来看，由于同一个OSD在不同的PG中的角色不同，因此，其工作压力也可以被尽可能均匀地分担，从而避免单个OSD变成性能瓶颈。</p><p><strong>读取数据</strong><br>如果需要读取数据，客户端只需完成同样的<a href="https://blog.csdn.net/lhc121386/article/details/113428189">寻址过程</a>，并直接和Primary OSD联系。<strong>在目前的Ceph设计中，被读取的数据默认由Primary OSD提供</strong>，但也可以设置允许从其他OSD中获取，以分散读取压力从而提高性能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph数据映射过程&quot;&gt;&lt;a href=&quot;#Ceph数据映射过程&quot; class=&quot;headerlink&quot; title=&quot;Ceph数据映射过程&quot;&gt;&lt;/a&gt;Ceph数据映射过程&lt;/h2&gt;&lt;p&gt;在一个大规模分布式存储系统中，需要解决两个核心问题：“我应该把数据写到哪里？</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph体系架构</title>
    <link href="https://watsonlu6.github.io/Ceph%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    <id>https://watsonlu6.github.io/Ceph%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/</id>
    <published>2021-05-07T02:19:42.000Z</published>
    <updated>2024-07-27T14:30:54.244Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Ceph 官方定义</strong><br>Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.(Ceph 是一种为优秀的性能、可靠性和可扩展性而设计的统一的、分布式的存储系统。)</p><p><strong>Ceph 设计思路</strong></p><ul><li><strong>充分发挥存储设备自身的计算能力。</strong> 采用具有计算能力的设备作为存储系统的存储节点。</li><li><strong>去除所有的中心点。</strong> 解决单点故障点和当系统规模扩大时出现的规模和性能瓶颈问题。</li></ul><p> <strong>Ceph的设计哲学</strong></p><ul><li>每个组件必须可扩展  </li><li>不存在单点故障</li><li>解决方案必须是基于软件的</li><li>可摆脱专属硬件的束缚即可运行在常规硬件上 </li><li>推崇自我管理</li></ul><p><strong>Ceph体系结构</strong><br>首先作为一个存储系统，Ceph在物理上必然包含一个存储集群，以及这个存储集群的应用或客户端。Ceph客户端又需要一定的协议与Ceph存储集群进行交互，Ceph的逻辑层次演化如图所示。<br><img src="/images/Ceph%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.jpg"><br><strong>OSD</strong>：主要功能包括存储数据，处理数据的复制、恢复、回补、平衡数据分布，并将一些相关数据提供给Ceph Monitor。一个Ceph的存储集群，至少需要两个Ceph OSD来实现active+clean健康状态和有效的保存数据的双副本。一旦应用程序向ceph集群发出写操作，数据就以对象的形式存储在OSD中，OSD是Ceph集群中存储实际用户数据的唯一组件。通常，一个OSD守护进程绑定到集群中的一个物理磁盘。因此，通常来说，Ceph集群中物理磁盘的总数与在每个物理磁盘上存储用户数据的OSD守护进程的总数相同。</p><p><strong>MON</strong>：Ceph的监控器，主要功能是维护整个集群健康状态，提供一致性的决策。</p><p><strong>MDS</strong>：主要保存的是Ceph文件系统的元数据。（Ceph的块存储和对象存储都不需要Ceph MDS）</p><p><strong>RADOS</strong>：Ceph基于可靠的、自动化的、分布式的对象存储(<strong>R</strong>eliabl,<strong>A</strong>utonomous,<strong>D</strong>istributed <strong>O</strong>bject <strong>S</strong>torage, <strong>RADOS</strong> )提供了一个可无限扩展的存储集群，RADOS是Ceph最为关键的技术，它是一个支持海量存储对象的分布式对象存储系统。RADOS层本身就是一个完整的对象存储系统，事实上，所有存储在Ceph系统中的用户数据最终都是由这一层来存储。RADOS层确保数据始终保持一致，他执行数据复制、故障检测和恢复，以及跨集群节点的数据迁移和再平衡。 RADOS集群主要由两种节点组成：<em><strong>为数众多的OSD</strong></em>，负责完成数据存储和维护；<em><strong>若干个Monitor</strong></em>，负责完成系统状态检测和维护。OSD和Monion之间互相传递节点的状态信息，共同得出系统的总体运行状态，并保存在一个全局数据结构中，即所谓的集群运行图(Cluster Map )里。集群运行图与RADOS提供的特定算法相配合，便实现了Ceph的许多优秀特性。</p><p><strong>Librados</strong>：Librados库实际上是对RADOS进行抽象和封装，并向上层提供API，支持PHP、Ruby、Java、Python、C和C++编程语言。它为Ceph存储集群（RADOS）提供了本机接口，并为其他服务提供基础，如RBD、RGW和CephFS，这些服务构建在Librados之上，Librados还支持从应用程序直接访问RADOS，没有HTTP开销。</p><p><strong>RBD</strong>：RBD提供了一个标准的块设备接口，常用于在虚拟化的场景下为虚拟机创建存储卷，Red Hat已经将RBD驱动集成在QEMU&#x2F;KVM中，以提高虚拟机的访问性能。</p><p><strong>RADOS GW</strong>：Ceph对象网关RADOS GW提供对象存储服务，是一个构建在Librados库之上的对象存储接口，为应用访问Ceph集群提供了一个与Amazon S3和OpenStack Swift兼容的RESTful风格的 网关。</p><p><strong>Ceph FS</strong>：Ceph文件系统提供了一个符合posix标准的文件系统，它使用Ceph存储集群在文件系统上存储用户数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Ceph 官方定义&lt;/strong&gt;&lt;br&gt;Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalabili</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>ansible搭建Ceph集群</title>
    <link href="https://watsonlu6.github.io/Ceph%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://watsonlu6.github.io/Ceph%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2021-05-05T14:08:55.000Z</published>
    <updated>2024-07-29T14:45:54.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>共计20台服务器，单台前置热插拔硬盘位10T * 10（业务盘）+2T * 2（系统盘）或10T * 10（业务盘）+4T * 2（系统盘），其中两块系统盘配置为RAID 1，安装CentOS 7系统，分布如下图。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B21.png"></p><p>Ceph01 - Ceph20依次对应IP地址：172.25.7.201 - 172.25.7.220<br>其中，Ceph01、Ceph02、Ceph03、Ceph11、Ceph12为Monitor节点，其余为OSD节点。业务盘不配置RAID，每块业务盘作为一个OSD，资源池数据使用单副本。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B22.png"></p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h4 id="hosts配置-（所有节点执行）"><a href="#hosts配置-（所有节点执行）" class="headerlink" title="hosts配置 （所有节点执行）"></a>hosts配置 （所有节点执行）</h4><p>hostnamectl –static set-hostname 节点对应主机名<br>echo -e “127.0.0.1\tlocalhost localhost.localdomain localhost4 localhost4.localdomain4<br>::1\tlocalhost localhost.localdomain localhost6 localhost6.localdomain6<br>172.25.7.201\tceph-node1-mon1<br>172.25.7.202\tceph-node2-mon2<br>172.25.7.203\tceph-node3-mon3<br>172.25.7.204\tceph-node4<br>172.25.7.205\tceph-node5<br>172.25.7.206\tceph-node6<br>172.25.7.207\tceph-node7<br>172.25.7.208\tceph-node8<br>172.25.7.209\tceph-node9<br>172.25.7.210\tceph-node10<br>172.25.7.211\tceph-node11-mon4<br>172.25.7.212\tceph-node12-mon5<br>172.25.7.213\tceph-node13<br>172.25.7.214\tceph-node14<br>172.25.7.215\tceph-node15<br>172.25.7.216\tceph-node16<br>172.25.7.217\tceph-node17<br>172.25.7.218\tceph-node18<br>172.25.7.219\tceph-node19<br>172.25.7.220\tceph-node20” &gt; &#x2F;etc&#x2F;hosts</p><h4 id="配置SSH免密登陆（在ceph-ansible节点上执行）"><a href="#配置SSH免密登陆（在ceph-ansible节点上执行）" class="headerlink" title="配置SSH免密登陆（在ceph-ansible节点上执行）"></a>配置SSH免密登陆（在ceph-ansible节点上执行）</h4><p>ssh-keygen -t rsa<br>ssh-copy-id root@ceph-node1-mon1<br>ssh-copy-id root@ceph-node2-mon2<br>ssh-copy-id root@ceph-node3-mon3<br>ssh-copy-id root@ceph-node4<br>ssh-copy-id root@ceph-node5<br>ssh-copy-id root@ceph-node6<br>ssh-copy-id root@ceph-node7<br>ssh-copy-id root@ceph-node8<br>ssh-copy-id root@ceph-node9<br>ssh-copy-id root@ceph-node10<br>ssh-copy-id root@ceph-node11-mon4<br>ssh-copy-id root@ceph-node12-mon5<br>ssh-copy-id root@ceph-node13<br>ssh-copy-id root@ceph-node14<br>ssh-copy-id root@ceph-node15<br>ssh-copy-id root@ceph-node16<br>ssh-copy-id root@ceph-node17<br>ssh-copy-id root@ceph-node18<br>ssh-copy-id root@ceph-node19<br>ssh-copy-id root@ceph-node20<br>验证各节点ssh是否能免密登陆</p><h4 id="关闭SELINUX和防火墙（所有节点执行）"><a href="#关闭SELINUX和防火墙（所有节点执行）" class="headerlink" title="关闭SELINUX和防火墙（所有节点执行）"></a>关闭SELINUX和防火墙（所有节点执行）</h4><p>sed -i “s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;g” &#x2F;etc&#x2F;selinux&#x2F;config<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld<br>reboot</p><h4 id="配置时间同步"><a href="#配置时间同步" class="headerlink" title="配置时间同步"></a>配置时间同步</h4><p><strong>所有节点执行</strong><br>yum -y install ntp ntpdate<br>cd &#x2F;etc &amp;&amp; mv ntp.conf ntp.conf.bak</p><p><strong>在ceph-ansible节点执行</strong><br>编辑ntpd配置文件<br>vi &#x2F;etc&#x2F;ntp.conf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line">restrict 172.25.7.0 mask 255.255.255.0</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 8</span><br></pre></td></tr></table></figure><p>启动ntpd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start ntpd</span><br><span class="line">systemctl enable ntpd</span><br></pre></td></tr></table></figure><p><strong>其余节点执行</strong><br>编辑ntp服务<br>vi &#x2F;etc&#x2F;ntp.conf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server 172.25.7.201</span><br></pre></td></tr></table></figure><p>启动ntp，同步时间</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ceph-node1-mon1</span><br><span class="line">hwclock -w</span><br><span class="line"></span><br><span class="line">crontab -e</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">键入</span></span><br><span class="line">*/10 * * * * /usr/sbin/ntpdate 172.25.7.201</span><br></pre></td></tr></table></figure><h4 id="配置Ceph源-所有节点"><a href="#配置Ceph源-所有节点" class="headerlink" title="配置Ceph源(所有节点)"></a>配置Ceph源(所有节点)</h4><p>编辑ceph源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/yum.repos.d/ceph.repo</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">键入</span></span><br><span class="line">[Ceph]</span><br><span class="line">name=Ceph packages for $basearch</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[Ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph source packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>更新ceph源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install epel-release</span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br></pre></td></tr></table></figure><h2 id="Ceph-ansible配置（仅在ceph-ansible节点安装）"><a href="#Ceph-ansible配置（仅在ceph-ansible节点安装）" class="headerlink" title="Ceph-ansible配置（仅在ceph-ansible节点安装）"></a>Ceph-ansible配置（仅在ceph-ansible节点安装）</h2><h4 id="安装ansible"><a href="#安装ansible" class="headerlink" title="安装ansible"></a>安装ansible</h4><p>安装ansible，并修改&#x2F;etc&#x2F;ansible&#x2F;hosts<br><code>yum -y install ansible</code><br>注意对应的版本号<br>参考官网文档：<a href="https://docs.ceph.com/projects/ceph-ansible/en/latest/">https://docs.ceph.com/projects/ceph-ansible/en/latest/</a><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B23.png"></p><p>检测是否成功安装ansible<br><code>ansible --version</code><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B24.png"></p><p>修改&#x2F;etc&#x2F;ansible&#x2F;hosts</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/ansible/hosts</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加以下内容</span></span><br><span class="line">[mons]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[mgrs]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[osds]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node4</span><br><span class="line">ceph-node5</span><br><span class="line">ceph-node6</span><br><span class="line">ceph-node7</span><br><span class="line">ceph-node8</span><br><span class="line">ceph-node9</span><br><span class="line">ceph-node10</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line">ceph-node13</span><br><span class="line">ceph-node14</span><br><span class="line">ceph-node15</span><br><span class="line">ceph-node16</span><br><span class="line">ceph-node17</span><br><span class="line">ceph-node18</span><br><span class="line">ceph-node19</span><br><span class="line">ceph-node20</span><br><span class="line"></span><br><span class="line">[grafana-server]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br></pre></td></tr></table></figure><p>测试ansible是否能正常运行：<code>ansible all -m ping</code><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B25.png"></p><h4 id="安装ceph-absible"><a href="#安装ceph-absible" class="headerlink" title="安装ceph-absible"></a>安装ceph-absible</h4><p>确保环境上安装了git，可通过一下方式安装<br>    <code>yum -y install git</code></p><p>配置“http.sslVerify”参数为“false”，跳过系统证书。<br>    <code>git config --global http.sslVerify false</code></p><p>下载Ceph-ansible，注意ceph N版的版本号是stable-4.0<br>    <code>git clone -b stable-4.0 https://github.com/ceph/ceph-ansible.git --recursive</code></p><p>安装 Ceph-ansible 依赖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y python-pip           #安装python-pip</span><br><span class="line">pip install --upgrade pip           # 将pip更新到最新版本</span><br><span class="line">cd /root/ceph-ansible/              #进入ceph-ansible目录</span><br><span class="line">pip install -r requirements.txt     #检查并安装需要的软件版本</span><br></pre></td></tr></table></figure><p>在ceph-ansible目录内新建hosts文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">vi /root/ceph-ansible/hosts</span><br><span class="line"></span><br><span class="line">[mons]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[mgrs]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[osds]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node4</span><br><span class="line">ceph-node5</span><br><span class="line">ceph-node6</span><br><span class="line">ceph-node7</span><br><span class="line">ceph-node8</span><br><span class="line">ceph-node9</span><br><span class="line">ceph-node10</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line">ceph-node13</span><br><span class="line">ceph-node14</span><br><span class="line">ceph-node15</span><br><span class="line">ceph-node16</span><br><span class="line">ceph-node17</span><br><span class="line">ceph-node18</span><br><span class="line">ceph-node19</span><br><span class="line">ceph-node20</span><br><span class="line"></span><br><span class="line">[grafana-server]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br></pre></td></tr></table></figure><p>使用Ceph-ansible提供的ansible变量用来设置ceph集群的配置。<br>所有选项及默认配置放在group_vars目录下，每种ceph进程对应相关的配置文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp mons.yml.sample mons.yml</span><br><span class="line">cp mgrs.yml.sample mgrs.yml</span><br><span class="line">cp mdss.yml.sample mdss.yml</span><br><span class="line">cp rgws.yml.sample rgws.yml</span><br><span class="line">cp osds.yml.sample osds.yml</span><br><span class="line">cp clients.yml.sample clients.yml</span><br><span class="line">cp all.yml.sample all.yml</span><br></pre></td></tr></table></figure><p>修改group_vars&#x2F;all.yml文件（注意网络接口）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">vi group_vars/all.yml</span><br><span class="line"></span><br><span class="line">ceph_origin: repository</span><br><span class="line">ceph_repository: community</span><br><span class="line">ceph_mirror: http://download.ceph.com</span><br><span class="line">ceph_stable_release: nautilus</span><br><span class="line">ceph_stable_repo: &quot;&#123;&#123; ceph_mirror &#125;&#125;/rpm-&#123;&#123; ceph_stable_release &#125;&#125;&quot;</span><br><span class="line">ceph_stable_redhat_distro: el7</span><br><span class="line">journal_size: 5120</span><br><span class="line">monitor_interface: p1p1</span><br><span class="line">public_network: &quot;172.25.7.0/24&quot;</span><br><span class="line">cluster_network: &quot;172.25.7.0/24&quot;</span><br><span class="line">mon_host: 172.25.7.201, 172.25.7.202, 172.25.7.203, 172.25.7.211, 172.25.7.212</span><br><span class="line">osd_objectstore: bluestore</span><br><span class="line"></span><br><span class="line">dashboard_enabled: True</span><br><span class="line">dashboard_protocol: http</span><br><span class="line">dashboard_port: 8443</span><br><span class="line">dashboard_admin_user: admin</span><br><span class="line">dashboard_admin_password: admin</span><br><span class="line">grafana_admin_user: admin</span><br><span class="line">grafana_admin_password: admin</span><br><span class="line">grafana_uid: 472</span><br><span class="line">grafana_datasource: Dashboard</span><br><span class="line">grafana_dashboard_version: nautilus</span><br><span class="line">grafana_port: 3000</span><br><span class="line">grafana_allow_embedding: True</span><br><span class="line">grafana_crt: &#x27;&#x27;</span><br><span class="line">grafana_key: &#x27;&#x27;</span><br><span class="line">grafana_container_image: &quot;grafana/grafana:5.2.4&quot;</span><br><span class="line">grafana_container_cpu_period: 100000</span><br><span class="line">grafana_container_cpu_cores: 2</span><br><span class="line">grafana_container_memory: 4</span><br><span class="line">grafana_dashboards_path: &quot;/etc/grafana/dashboards/ceph-dashboard&quot;</span><br><span class="line">grafana_dashboard_files:</span><br><span class="line">  - ceph-cluster.json</span><br><span class="line">  - cephfs-overview.json</span><br><span class="line">  - host-details.json</span><br><span class="line">  - hosts-overview.json</span><br><span class="line">  - osd-device-details.json</span><br><span class="line">  - osds-overview.json</span><br><span class="line">  - pool-detail.json</span><br><span class="line">  - pool-overview.json</span><br><span class="line">  - radosgw-detail.json</span><br><span class="line">  - radosgw-overview.json</span><br><span class="line">  - rbd-overview.json</span><br><span class="line">grafana_plugins:</span><br><span class="line">  - vonage-status-panel</span><br><span class="line">  - grafana-piechart-panel</span><br><span class="line">prometheus_container_image: &quot;prom/prometheus:v2.7.2&quot;</span><br><span class="line">prometheus_container_cpu_period: 100000</span><br><span class="line">prometheus_container_cpu_cores: 2</span><br><span class="line">prometheus_container_memory: 4</span><br><span class="line">prometheus_data_dir: /var/lib/prometheus</span><br><span class="line">prometheus_conf_dir: /etc/prometheus</span><br><span class="line">prometheus_user_id: &#x27;65534&#x27;  </span><br><span class="line">prometheus_port: 9092</span><br><span class="line"></span><br><span class="line">ceph_conf_overrides:</span><br><span class="line"> global:</span><br><span class="line">osd_pool_default_pg_num: 64</span><br><span class="line">  osd_pool_default_pgp_num: 64</span><br><span class="line">  osd_pool_default_size: 2</span><br><span class="line"> mon:</span><br><span class="line">  mon_allow_pool_create: true</span><br></pre></td></tr></table></figure><p>修改group_vars&#x2F;osds.yml文件<br>在osds.yml添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vi group_vars/osds.yml</span><br><span class="line"></span><br><span class="line">devices:</span><br><span class="line">  - /dev/sda</span><br><span class="line">  - /dev/sdb</span><br><span class="line">  - /dev/sdc</span><br><span class="line">  - /dev/sdd</span><br><span class="line">  - /dev/sde</span><br><span class="line">  - /dev/sdf</span><br><span class="line">  - /dev/sdg</span><br><span class="line">  - /dev/sdh</span><br><span class="line">  - /dev/sdi</span><br><span class="line">  - /dev/sdj</span><br></pre></td></tr></table></figure><p>修改site.yml文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp site.yml.sample site.yml</span><br><span class="line">vi site.yml</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B26.png"></p><h2 id="Ceph-集群部署"><a href="#Ceph-集群部署" class="headerlink" title="Ceph 集群部署"></a>Ceph 集群部署</h2><p>执行命令：ansible-playbook -i hosts site.yml<br>执行结束，在执行页面会有相关的提示，如图所示，所有节点显示failed&#x3D;0，则处于部署过程中。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B27.png"></p><p>如果是过程出错，先清空集群，在进行部署</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp infrastructure-playbooks/purge-cluster.yml purge-cluster.yml # 必须copy到项目根目录下</span><br><span class="line">ansible-playbook -i hosts purge-cluster.yml</span><br></pre></td></tr></table></figure><h2 id="Rados性能测试工具"><a href="#Rados性能测试工具" class="headerlink" title="Rados性能测试工具"></a>Rados性能测试工具</h2><p>创建pool<br>    <code>ceph osd pool create testbench 100 100</code><br>清除缓存<br>    <code>echo 3 &gt; /proc/sys/vm/drop_caches</code></p><p>4M写入测试<br>    <code>rados bench -p testbench 180 write -t 32 --no-cleanup</code></p><p>4k写入测试<br>    <code>rados bench -p testbench 180 write -t 32 -b 4096 --no-cleanup</code></p><p>4K顺序读<br>    <code>rados bench -p testbench 180 seq -t 32 --no-cleanup</code></p><p>4K随机读<br>    <code>rados bench -p testbench 180 rand -t 32  --no-cleanup</code></p><p>清除数据<br>    <code>rados -p testbench cleanup</code></p><p>参数说明<br>格式：rados bench -p <pool-name> <seconds> <mode> -b <block size> -t –no-cleanup</p><ul><li>pool-name：测试存储池名称</li><li>seconds：测试时间，单位秒</li><li>mode：操作模式，write：写，seq：顺序读；rand：随机读</li><li>-b：block size，块大小，默认为 4M,单位字节，只有在写的时候有效。</li><li>-t：读&#x2F;写并行数，默认为 16</li><li>–no-cleanup 表示测试完成后不删除测试用数据。<br>注意：在测试之前要执行一次命令加–no-cleanup产生数据</li></ul><h2 id="部署过程的问题"><a href="#部署过程的问题" class="headerlink" title="部署过程的问题"></a>部署过程的问题</h2><ol><li>   执行完ansible-playbook -i hosts site.yml 命令后，前面无报错但某些节点不正常<br>解决方法：属于正常现象，再执行ansible-playbook -i hosts site.yml命令可显示正常状态。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;p&gt;共计20台服务器，单台前置热插拔硬盘位10T * 10（业务盘）+2T * 2（系统盘）或10T * 10（业务盘）+4T </summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>块存储_文件系统存储_对象存储的区别</title>
    <link href="https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2021-04-23T08:29:15.000Z</published>
    <updated>2024-07-27T14:30:41.200Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB.png"></p><h2 id="定义角度"><a href="#定义角度" class="headerlink" title="定义角度"></a>定义角度</h2><ul><li><strong>块存储</strong><br>指以扇区为基础，一个或者连续的扇区组成一个块，也叫物理块。它是在文件系统与块设备(例如：磁盘驱动器)之间。利用多个物理硬盘的并发能力。关注的是写入偏移位置。 </li><li><strong>文件系统存储</strong><br>文件系统存储也称为文件级存储或基于文件的存储，数据会以单条信息的形式存储在文件夹中。当需要访问该数据时，计算机需要知道相应的查找路径，存储在文件中的数据会根据数量有限的元数据来进行整理和检索，这些元数据会告诉计算机文件所在的确切位置。它就像是数据文件的库卡目录。</li><li><strong>对象存储</strong><br>对象存储，也称为基于对象的存储，是一种扁平结构，其中的文件被拆分成多个部分并散布在多个硬件间。在对象存储中，数据会被分解为称为“对象”的离散单元，并保存在单个存储库中，而不是作为文件夹中的文件或服务器上的块来保存。</li></ul><h2 id="使用角度"><a href="#使用角度" class="headerlink" title="使用角度"></a>使用角度</h2><ul><li><strong>块存储</strong><br>生活中常见的块存储设备（也叫“块设备”）比如，插在你本地电脑上的U盘、硬盘，你电脑连接的iSCSI等。<br>从使用上来说，块级的存储如果是第一次使用，那么必须需要进行一次格式化的操作，创建出一个文件系统，然后才可以使用。例如新买的U盘、硬盘、或者新发现的iSCSI设备等，首次使用的时候都需要进行一次格式化操作，创建出一个文件系统，然后才可以将你的文件拷贝到U盘、硬盘、或者新发现的iSCSI设备中。</li><li><strong>文件系统存储</strong><br>文件系统存储是最常见的一种文件内系统，我们日常对操作系使用中，基本上能够直接接触到的都就是这种，能够直接访问的C、D、E盘，电脑里的一个目录，网上邻居的空间都是文件级的存储。块级的存储设备经过格式化以及挂载（win 会自动挂载）之后，你就将一个块级的存储变成了文件级的存储。</li><li><strong>对象存储</strong><br>对象存储一般来说并不是给我们人直接去使用的，从使用者角度来说，它更适合用用于给程序使用。平时最常见的一般就是百度网盘，其后端对接的就是对象存储。还有就网页上的图片、视频，其本身也是存储在对象存储的文件系统中的。如果要直接使用对象级的存储，你会发现对象级的存储本身是非常的简单的（但是对人来说不方便），它只有简单的几种命令如上传、下载、删除，并且你只需要知道某个文件的编号（如：”d5t35e6tdud725dgs6u2hdsh27dh27d7”  这不是名字）就可以直接对它进行上传、下载、删除等操作，不需要像文件级那样，直到文件的具体的路径（如:D:\photo\1.jpg），并且他也只有这几种操作，如果你想编辑文件，那只能将文件下载下来编辑好之后在进行上传（这也是它对人来说不方便的原因之一）</li></ul><h2 id="技术角度"><a href="#技术角度" class="headerlink" title="技术角度"></a>技术角度</h2><p>块级、文件级、对象级技术上的区别，首先要明白两个概念<br>第一，无论是那个级别的存储系统，其数据都是会存储在物理的存储设备上的，这些存储设备现在常见的基本上就两种机械硬盘、固态硬盘。<br>第二，任何数据都是由两部”数据“分组成的，一部分是”数据本身”(下文中“数据”指”数据本身“)，另一部分就是这些“数据”的”元数据“。所谓的”元数据”就是用来描述”数据”的”数据”。包括数据所在的位置，文件的长度（大小），文件的访问权限、文件的时间戳（创建时间、修改时间….），元数据本身也是数据。</p><ul><li><strong>块存储</strong><br>对于块级来说，如果要通过块设备来访问一段数据的话，你自己需要知道这些数据具体是存在于那个存储设备上的位置上，例如如果你要从块设备上读取一张照片，你就要高速存储设备：我要从第2块硬盘中的从A位置开始到B位置的数据，硬盘的驱动就会将这个数据给你。读取照片的过程中照片的具体位置就是元数据，也就是说块级的存储中要求程序自己保存元数据。</li><li><strong>文件系统存储</strong><br>如果需要自己保存元数据的话就太麻烦了，上文也说了，元数据本身也是数据，实际上元数据也是存储在硬盘上的，那么如何访问元数据这个数据呢其实，文件级的元数据是存储在固定位置的，存储的位置和方式是大家事先约定好的，这个约定就叫做文件系统，例如EXT4、FAT32、XFS、NTFS等。借助于这些约定，我们就不用自己去维护一个表去记录每一份数据的具体存储位置了。我们只需要直到我们存储的文件的路径和名字就好了，例如我们想要 D:\1.jpg 这个文件，那么你只需要告诉文件系统 D:\1.jpg 这个位置就可以了，去硬盘的哪里找D:\1.jpg 数据的真身，就是文件系统的工作了</li><li><strong>对象存储</strong><br>对象级存储，文件级的元数据实际上是和数据放在一起的，就像一本书每本书都有一个目录，这个目录描述的是这本书上内容的索引，目录就是书内容的“元数据”，而对象存储，会有一本书只放目录（元数据），其他更多的书只有内容，并且内容都是被拆分好的一段一段的，就是说你会看每本书上面的内容完全是混在在一起的，这一页的前两行是书A的某句话，后面就跟的是书D的某句话，如果只放目录（元数据）那本书，你根本不知道这里写的是啥。对象及存储将一切的文件都视作对象，并且将对象按照固定的”形式”组合或拆分的存储在存储设备中，并且将数据的元数据部分完全的独立出来，进行单独的管理。</li></ul><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><ul><li>从<strong>距离（io路径）</strong> 上来说（相对于传统的存储），块存储的使用者距离最底层实际存储数据的存储设备是最近的，对象级是最远的。</li><li>从<strong>使用</strong>上来说，块存储需要使用者自己直到数据的真是位置，需要自己管理记录这些数据，所以使用上是最复杂的，而对象存储的接口最简单，基本上只有上传、下载、删除，并且不需要自己保存元数据，也不需要直到文件的索引路径，所以使用上是最简单的。但是从方便角度来讲还是文件存储最方便。</li><li>从<strong>性能</strong>上来说，综合的来讲（在特定的应用场合）性能最好的是块存储，它主要用在数据库、对延时要求非常高的场景中，对象存储多用于互联网，因为扩展性好，容量可以做的非常的大。对于人类来说，如果不借助特定的客户端、APP，使用文件存储是最友好最简单的。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li><strong>块存储：</strong> 要求高性能的应用，如数据库需要高IO，用块存储比较合适。</li><li><strong>文件系统存储：</strong> 需局域网共享的应用，如文件共享，视频处理，动画渲染&#x2F;高性能计算。</li><li><strong>对象存储：</strong> 互联网领域的存储，如点播&#x2F;视频监控的视频存储、图片存储、网盘存储、静态网页存储等，以及异地备份存储&#x2F;归档等。</li></ul><p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB_1.png"></p><h2 id="为什么块级的存储性能最好"><a href="#为什么块级的存储性能最好" class="headerlink" title="为什么块级的存储性能最好"></a>为什么块级的存储性能最好</h2><p>&emsp;&emsp;首先要明确一点，要明确，每次在发生数据读取访问的时候，实际上对应系统的底层是发生了多次IO的（主要是要对元数据进行访问），例如，你要打开文件1.txt ，操作系统回去进行文件是否存在的查询，以及读写权限的查询等操作，这些操作实际上都是对于元数据的访问。<br>&emsp;&emsp;然后，相对于其它的存储方式，块存储的元数据是有操作系统自己管理的，也就是说整个文件系统（元数据）是存在在操做系统的内存中的，这样操作系统在进行元数据管理的时候可以直和自己的内存打交道。而文件系统存储和对象存储，它的文件系统是存在于另一台服务器上的，这样在进行元数据访问时就需要从网络进行访问，这样要比从内存访问慢得多。<br>&emsp;&emsp;总结来讲，就是块级存储的元数据在系统本机中，在进行元数据访问（每次读写文件实际都会在操作系统底层发生），会更快，因为其它的级别的存储元数据都要通过网络访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
