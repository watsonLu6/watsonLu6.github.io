{"meta":{"title":"watson'blogs","subtitle":"","description":"","author":"John Doe","url":"https://watsonlu6.github.io","root":"/"},"pages":[],"posts":[{"title":"Cpeh Mon常见故障处理","slug":"Ceph-OSD常见故障处理","date":"2024-09-08T06:53:31.000Z","updated":"2024-09-08T07:24:11.454Z","comments":true,"path":"Ceph-OSD常见故障处理/","permalink":"https://watsonlu6.github.io/Ceph-OSD%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/","excerpt":"","text":"监视器故障排查即使集群出现与监视器相关的问题，集群也不一定会面临宕机的风险。即使集群丢失了多个监视器，只要还有足够的监视器存活并能够形成法定人数（quorum），集群就能继续运行。如果集群遇到了监视器相关的问题，可以参考以下的故障排查信息。 初步故障排查Ceph 监视器故障排查的第一步是确保监视器正在运行，并且它们能够与网络进行通信。按照本节的步骤操作，以排除监视器故障的最简单原因。 确保监视器正在运行确保监视器守护进程（ceph-mon）正在运行。可能是由于升级后监视器没有重新启动。检查这个简单的疏忽可以节省大量的故障排查时间。同时，也要确保管理守护进程（ceph-mgr）正在运行。记住，典型的集群配置中，每个监视器（ceph-mon）都有一个相应的管理器（ceph-mgr）。注意： 在 v1.12.5 之前的版本中，Rook 不会运行超过两个管理器。 确保可以访问监视器节点在某些罕见情况下，iptables 规则可能会阻止访问监视器节点或 TCP 端口。这些规则可能是以前压力测试或规则开发时遗留下来的。要检查是否存在这样的规则，可以通过 SSH 登录每个监视器节点，并使用 telnet、nc 或类似工具尝试连接到其他监视器节点的 tcp&#x2F;3300 和 tcp&#x2F;6789 端口。 确保“ceph status”命令能够运行并从集群接收回复如果 ceph status 命令从集群接收到回复，说明集群正在运行。监视器只有在形成法定人数时才会响应状态请求。确认是否有一个或多个管理器（mgr）守护进程正在运行。在没有任何问题的集群中，ceph status 将报告所有管理器守护进程都在运行。如果 ceph status 命令未能从集群接收到回复，那么很可能是由于没有足够的监视器来形成法定人数。如果运行 ceph -s 命令时未指定进一步的选项，它会连接到任意选择的一个监视器。然而，在某些情况下，添加 -m 标志来连接特定的监视器（或按顺序连接几个特定的监视器）可能更有帮助，例如：ceph status -m mymon1。 如果以上解决方案未能解决问题，可能需要逐一检查每个监视器。即使没有形成法定人数，仍然可以单独联系每个监视器，并使用 ceph tell mon.ID mon_status 命令请求其状态（此处 ID 是监视器的标识符）。对集群中的每个监视器运行 ceph tell mon.ID mon_status 命令。关于此命令的输出。还有另一种联系各个监视器的方法：通过 SSH 登录每个监视器节点并查询守护进程的管理套接字。 使用监视器的管理套接字监视器的管理套接字允许通过 Unix 套接字文件直接与特定的守护进程交互。此套接字文件位于监视器的运行目录中。管理套接字的默认目录是 /var/run/ceph/ceph-mon.ID.asok。可以覆盖管理套接字的默认位置。如果默认位置被覆盖，那么管理套接字会出现在其他位置。这种情况通常发生在集群的守护进程部署在容器中时。要查找管理套接字的目录，请检查ceph.conf 文件以获取备用路径，或运行以下命令： 1ceph-conf --name mon.ID --show-config-value admin_socket 管理套接字只有在监视器守护进程运行时可用。每次监视器正常关闭时，管理套接字都会被移除。如果监视器未运行但管理套接字仍存在，可能是由于监视器未正确关闭。如果监视器未运行，将无法使用管理套接字，并且 ceph 命令很可能返回错误 111：连接被拒绝。 要访问管理套接字，请运行以下形式的 ceph tell 命令： 1ceph tell mon.&lt;id&gt; mon_status 此命令通过管理套接字将帮助命令传递给指定的运行中的监视器守护进程 &lt;id&gt;。如果知道管理套接字文件的完整路径，可以更直接地运行以下命令： 1ceph --admin-daemon &lt;full_path_to_asok_file&gt; &lt;command&gt; 运行 ceph help 显示通过管理套接字可用的所有受支持的命令。特别参考 config get、config show、mon stat 和 quorum_status。 理解 mon_status监视器的状态（由 ceph tell mon.X mon_status 命令报告）可以通过管理套接字获得。ceph tell mon.X mon_status 命令输出关于监视器的大量信息（包括在 quorum_status 命令输出中找到的信息）。 注意命令 ceph tell mon.X mon_status 不应被字面输入。运行命令时，mon.X 的 X 部分应替换为 Ceph 集群中的特定值。 为了理解此命令的输出，考虑以下例子，看到 ceph tell mon.c mon_status 的输出： 123456789101112131415161718192021222324&#123; &quot;name&quot;: &quot;c&quot;, &quot;rank&quot;: 2, &quot;state&quot;: &quot;peon&quot;, &quot;election_epoch&quot;: 38, &quot;quorum&quot;: [ 1, 2], &quot;outside_quorum&quot;: [], &quot;extra_probe_peers&quot;: [], &quot;sync_provider&quot;: [], &quot;monmap&quot;: &#123; &quot;epoch&quot;: 3, &quot;fsid&quot;: &quot;5c4e9d53-e2e1-478a-8061-f543f8be4cf8&quot;, &quot;modified&quot;: &quot;2013-10-30 04:12:01.945629&quot;, &quot;created&quot;: &quot;2013-10-29 14:14:41.914786&quot;, &quot;mons&quot;: [ &#123; &quot;rank&quot;: 0, &quot;name&quot;: &quot;a&quot;, &quot;addr&quot;: &quot;127.0.0.1:6789/0&quot;&#125;, &#123; &quot;rank&quot;: 1, &quot;name&quot;: &quot;b&quot;, &quot;addr&quot;: &quot;127.0.0.1:6790/0&quot;&#125;, &#123; &quot;rank&quot;: 2, &quot;name&quot;: &quot;c&quot;, &quot;addr&quot;: &quot;127.0.0.1:6795/0&quot;&#125;]&#125;&#125; 该输出报告 monmap 中有三个监视器（a, b, 和 c），法定人数由两个监视器组成，而 c 是 peon。 哪个监视器不在法定人数中？答案是 a（即 mon.a）。mon.a 不在法定人数中。 我们如何知道在此示例中 mon.a 不在法定人数中？我们知道 mon.a 不在法定人数中，因为它的 rank 是 0，而 rank 为 0 的监视器根据定义不在法定人数中。如果我们检查法定人数集，可以看到集合中明显有两个监视器：1 和 2。但这些不是监视器名称，而是当前 monmap 中确立的监视器 rank。法定人数集不包括 rank 为 0 的监视器，根据 monmap，该监视器是 mon.a。 监视器的 rank 是如何确定的？每当监视器被添加或从集群中移除时，监视器的 rank 会被计算（或重新计算）。rank 的计算遵循一个简单的规则：IP:PORT 组合越大，rank 越低。在此情况下，因为 127.0.0.1:6789（mon.a）在数值上小于其他两个 IP:PORT 组合（即 “监视器 b”的 127.0.0.1:6790 和 “监视器 c”的 127.0.0.1:6795），mon.a 拥有最高的 rank，即 rank 0。 最常见的监视器问题集群有法定人数但至少有一个监视器关闭当集群有法定人数但至少有一个监视器关闭时，ceph health detail 会返回类似以下的消息： 123$ ceph health detail[snip]mon.a (rank 0) addr 127.0.0.1:6789/0 is down (out of quorum) 如何排查 Ceph 集群有法定人数但至少有一个监视器关闭的问题？确保 mon.a 正在运行。确保可以从其他监视器节点连接到 mon.a 的节点。也检查 TCP 端口。检查所有节点上的 iptables 和 nf_conntrack，并确保未丢弃&#x2F;拒绝连接。 如果这些初步故障排查无法解决问题，那么需要进一步调查。 首先，通过管理套接字检查有问题的监视器的 mon_status，如“使用监视器的管理套接字”和“理解 mon_status”中所述。如果监视器不在法定人数中，则其状态将是以下之一：probing（探测）、electing（选举中）或 synchronizing（同步中）。如果监视器的状态是 leader（领导者）或 peon（跟随者），则监视器认为自己在法定人数中，但集群的其余部分认为它不在法定人数中。排查过程中，可能处于 probing、electing 或 synchronizing 状态的监视器已进入法定人数。再次检查 ceph status 以确定排查过程中监视器是否已进入法定人数。如果监视器仍未进入法定人数，则继续参考本文件中的相关调查。 监视器状态为 probing 是什么意思？如果 ceph health detail 显示监视器的状态为 probing，则该监视器仍在寻找其他监视器。每个监视器启动时都会在这个状态停留一段时间。当监视器连接到 monmap 中指定的其他监视器时，它就不再处于 probing 状态。监视器处于 probing 状态的时间取决于其所在集群的参数。例如，当监视器是单监视器集群的一部分时（在生产环境中绝对不要这样做），监视器几乎是瞬间通过 probing 状态。在多监视器集群中，监视器保持在 probing 状态，直到找到足够的监视器形成法定人数——这意味着如果集群中的三个监视器中有两个关闭，则剩下的一个监视器将无限期地保持在 probing 状态，直到您启动其他监视器之一。 如果已建立法定人数，则只要守护进程能够被访问，监视器守护进程应能够快速找到其他监视器。如果监视器卡在 probing 状态，并且您已经完成了上面描述的监视器之间通信的故障排查，那么可能是有问题的监视器尝试以错误地址连接其他监视器。mon_status 会输出监视器已知的 monmap：确定 monmap 中指定的其他监视器的位置是否与网络中监视器的位置匹配。如果不匹配，请参阅“恢复监视器的损坏 monmap”。如果 monmap 中指定的监视器位置与网络中的监视器位置匹配，则持久的 probing 状态可能与监视器节点之间严重的时钟偏差有关。 监视器的状态为“electing”时意味着什么？如果 ceph health detail 显示某个监视器的状态为“electing”，这表明该监视器正在进行选举。选举通常会很快完成，但有时监视器可能会陷入所谓的选举风暴。如果选举状态持续存在，可以将有问题的监视器置于停机状态以进行调查。这只有在集群中有足够的存活监视器以形成仲裁的情况下才可行。 监视器的状态为“synchronizing”时意味着什么？如果 ceph health detail 显示某个监视器的状态为“synchronizing”，这意味着该监视器正在与集群的其他部分同步，以便加入仲裁。监视器与仲裁的其余部分同步所需的时间取决于集群监视器存储的大小、集群的规模以及集群的状态。通常较大且已降级的集群会使监视器在“synchronizing”状态停留的时间比较小且新建的集群更长。如果监视器的状态在“synchronizing”和“electing”之间来回切换，这表明可能存在问题：集群状态可能正在快速推进（即生成新映射），而同步过程无法跟上新映射的生成速度。这个问题在 Cuttlefish 版本之前更为常见，因为同步过程在较新的版本中已经被重构和增强，以避免这种情况。如果您在较新的版本中遇到此问题，请在 Ceph 错误追踪系统中报告问题。准备并提供日志以支持您报告的任何错误。有关日志准备的信息，请参阅《日志准备》。 监视器的状态为“leader”或“peon”时意味着什么？在 Ceph 正常运行期间，当集群处于 HEALTH_OK 状态时，Ceph 集群中的一个监视器处于“leader”状态，其余的监视器处于“peon”状态。可以通过查看命令 ceph tell &lt;mon_name&gt; mon_status 返回的 state 键的值来确定给定监视器的状态。如果 ceph health detail 显示监视器处于“leader”状态或“peon”状态，很可能存在时钟偏移。请遵循《时钟偏移》中的说明。如果您已经按照这些说明进行操作，但 ceph health detail 仍然显示监视器处于“leader”状态或“peon”状态，请在 Ceph 错误追踪系统中报告问题。如果您提出问题，请提供日志以支持它。有关日志准备的信息，请参阅《日志准备》。 修复监视器的损坏“monmap”可以使用类似 ceph tell mon.c mon_status 的命令来检索 monmap。下面是一个 monmap 的示例： 1234567epoch 3fsid 5c4e9d53-e2e1-478a-8061-f543f8be4cf8last_changed 2013-10-30 04:12:01.945629created 2013-10-29 14:14:41.9147860: 127.0.0.1:6789/0 mon.a1: 127.0.0.1:6790/0 mon.b2: 127.0.0.1:6795/0 mon.c 这个 monmap 是正常的，但您可能的 monmap 可能不正常。在某个节点上的 monmap 可能会因为节点长时间宕机，而期间集群的监视器发生了变化，从而变得过时。 更新监视器过时的 monmap 有两种方法： 报废并重新部署监视器仅在确保不会丢失所报废监视器中保留的信息时使用此方法。确保有其他状态良好的监视器，以便新监视器能够与存活的监视器同步。请记住，如果没有其他监视器内容的副本，销毁监视器可能会导致数据丢失。 将 monmap 注入监视器可以通过从集群中存活的监视器中检索最新的 monmap 并将其注入到损坏或缺失 monmap 的监视器中来修复它。实施此解决方案请执行以下步骤： 按以下方式之一检索 monmap： 如果存在监视器仲裁：从仲裁中检索 monmap： 1ceph mon getmap -o /tmp/monmap 如果没有监视器仲裁： 直接从已停止的监视器中检索 monmap： 1ceph-mon -i ID-FOO --extract-monmap /tmp/monmap 在此示例中，已停止监视器的 ID 是 ID-FOO。 停止将注入 monmap 的监视器： 1service ceph -a stop mon.&#123;mon-id&#125; 将 monmap 注入已停止的监视器： 1ceph-mon -i ID --inject-monmap /tmp/monmap 启动监视器。 警告将 monmap 注入监视器可能会引起严重问题。注入 monmap 会覆盖监视器上存储的最新 monmap。请小心操作！ 时钟偏移Paxos 共识算法需要紧密的时间同步，这意味着仲裁中的监视器之间的时钟偏移会对监视器的操作产生严重影响，导致一些令人困惑的行为。为避免这种问题，应在监视器节点上运行时钟同步工具，例如 Chrony 或传统的 ntpd 工具。配置每个监视器节点时确保启用了 iburst 选项，并确保每个监视器有多个对等节点，包括以下内容： 其他监视器 内部 NTP 服务器 多个外部公共池服务器 注意iburst 选项在初始同步时会发送八个数据包，而不是通常的一个。此外，建议将集群中的所有节点与内部和外部服务器同步，甚至与监视器同步。请在物理机上运行 NTP 服务器，因为虚拟机的虚拟化时钟不适合稳定的时间保持。 时钟偏移问题及解答容忍的最大时钟偏移是多少？默认情况下，监视器允许时钟最大漂移 0.05 秒（50 毫秒）。 我可以增加最大容忍的时钟偏移吗？可以，但我们强烈建议不要这样做。最大容忍的时钟偏移可通过 mon-clock-drift-allowed 选项进行配置，但更改此选项几乎肯定是一个糟糕的决定。设定的时钟偏移上限是因为时钟不同步的监视器不可靠。当前的默认值已证明其在监视器遇到严重问题之前提醒用户方面的有效性。更改此值可能会对监视器的稳定性和整体集群健康状况造成不可预见的影响。 我如何知道是否存在时钟偏移？当存在时钟偏移时，监视器会通过集群状态 HEALTH_WARN 发出警告。执行 ceph health detail 和 ceph status 命令时，输出类似如下内容： 1mon.c addr 10.10.0.1:6789/0 clock skew 0.08235s &gt; max 0.05s (latency 0.0045s) 在此示例中，监视器 mon.c 被标记为存在时钟偏移。在 Luminous 及更高版本中，可以通过运行 ceph time-sync-status 命令来检查时钟偏移。注意，主监视器通常具有数值最低的 IP 地址。它始终显示 0：其他监视器报告的偏移是相对于主监视器的，而不是任何外部参考源。 如果存在时钟偏移，我该怎么办？同步时钟。使用 NTP 客户端可能会有所帮助。但是，如果已经在使用 NTP 客户端并且仍然遇到时钟偏移问题，请确定使用的 NTP 服务器是否位于网络之外，还是托管在网络中。托管自己的 NTP 服务器往往可以缓解时钟偏移问题。 客户端无法连接或挂载如果客户端无法连接到集群或挂载，请检查您的 iptables。一些操作系统安装程序会向 iptables 添加一个 REJECT 规则。iptables 规则会拒绝所有尝试连接到主机的客户端（除了 ssh）。如果您的监视器主机的 iptables 具有 REJECT 规则，则从单独节点连接的客户端会失败，并引发超时错误。检查 iptables 规则，看看是否有任何拒绝尝试连接到 Ceph 守护进程的客户端。例如： 1REJECT all -- anywhere anywhere reject-with icmp-host-prohibited 可能还需要在 Ceph 主机上的 iptables 添加规则，以确保客户端能够访问与 Ceph 监视器（默认：端口 6789）和 Ceph OSD（默认：6800 到 7568）关联的 TCP 端口。例如： 1iptables -A INPUT -m multiport -p tcp -s &#123;ip-address&#125;/&#123;netmask&#125; --dports 6789,6800:7568 -j ACCEPT 监视器存储故障存储损坏的症状Ceph 监视器在键值存储中维护集群地图。如果键值存储损坏导致监视器失败，则监视器日志可能包含以下错误消息之一： 1Corruption: error in middle of record 或者： 1Corruption: 1 missing files; e.g.: /var/lib/ceph/mon/mon.foo/store.db/1234567.ldb 使用健康的监视器恢复如果集群中有幸存的监视器，损坏的监视器可以用新的监视器替换。新监视器启动后，它会与健康的对等体同步。新监视器完全同步后，将能够为客户端提供服务。 使用 OSDs 进行恢复即使所有监视器同时失效，也可以使用存储在 OSDs 中的信息恢复监视器存储。建议在 Ceph 集群中部署至少三个（最好是五个）监视器。在这种部署中，完全的监视器故障是不太可能的。然而，如果数据中心在磁盘设置或文件系统设置配置不当的情况下发生意外断电，可能会导致底层文件系统故障，这可能会导致所有监视器故障。在这种情况下，OSDs 中的数据可用于恢复监视器。以下是可以在这种情况下使用的脚本来恢复监视器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546ms=/root/mon-storemkdir $ms# collect the cluster map from stopped OSDsfor host in $hosts; do rsync -avz $ms/. user@$host:$ms.remote rm -rf $ms ssh user@$host &lt;&lt;EOF for osd in /var/lib/ceph/osd/ceph-*; do ceph-objectstore-tool --data-path \\$osd --no-mon-config --op update-mon-db --mon-store-path $ms.remote doneEOF rsync -avz user@$host:$ms.remote/. $msdone# rebuild the monitor store from the collected map, if the cluster does not# use cephx authentication, we can skip the following steps to update the# keyring with the caps, and there is no need to pass the &quot;--keyring&quot; option.# i.e. just use &quot;ceph-monstore-tool $ms rebuild&quot; insteadceph-authtool /path/to/admin.keyring -n mon. \\ --cap mon &#x27;allow *&#x27;ceph-authtool /path/to/admin.keyring -n client.admin \\ --cap mon &#x27;allow *&#x27; --cap osd &#x27;allow *&#x27; --cap mds &#x27;allow *&#x27;# add one or more ceph-mgr&#x27;s key to the keyring. in this case, an encoded key# for mgr.x is added, you can find the encoded key in# /etc/ceph/$&#123;cluster&#125;.$&#123;mgr_name&#125;.keyring on the machine where ceph-mgr is# deployedceph-authtool /path/to/admin.keyring --add-key &#x27;AQDN8kBe9PLWARAAZwxXMr+n85SBYbSlLcZnMA==&#x27; -n mgr.x \\ --cap mon &#x27;allow profile mgr&#x27; --cap osd &#x27;allow *&#x27; --cap mds &#x27;allow *&#x27;# If your monitors&#x27; ids are not sorted by ip address, please specify them in order.# For example. if mon &#x27;a&#x27; is 10.0.0.3, mon &#x27;b&#x27; is 10.0.0.2, and mon &#x27;c&#x27; is 10.0.0.4,# please passing &quot;--mon-ids b a c&quot;.# In addition, if your monitors&#x27; ids are not single characters like &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, please# specify them in the command line by passing them as arguments of the &quot;--mon-ids&quot;# option. if you are not sure, please check your ceph.conf to see if there is any# sections named like &#x27;[mon.foo]&#x27;. don&#x27;t pass the &quot;--mon-ids&quot; option, if you are# using DNS SRV for looking up monitors.ceph-monstore-tool $ms rebuild -- --keyring /path/to/admin.keyring --mon-ids alpha beta gamma# make a backup of the corrupted store.db just in case! repeat for# all monitors.mv /var/lib/ceph/mon/mon.foo/store.db /var/lib/ceph/mon/mon.foo/store.db.corrupted# move rebuild store.db into place. repeat for all monitors.mv $ms/store.db /var/lib/ceph/mon/mon.foo/store.dbchown -R ceph:ceph /var/lib/ceph/mon/mon.foo/store.db 该脚本执行以下步骤： 从每个 OSD 主机收集地图。 重建存储。 用适当的权限填充 keyring 文件中的实体。 用恢复的副本替换 mon.foo 上的损坏存储。 已知限制上述恢复工具无法恢复以下信息： 某些添加的 keyring：所有使用 ceph auth add 命令添加的 OSD keyring 都会从 OSD 的副本中恢复，并且使用 ceph-monstore-tool 导入 client.admin keyring。但是，MDS keyring 和其他所有 keyring 都会在恢复的监视器存储中缺失，可能需要手动重新添加。 创建池：如果任何 RADOS 池正在创建过程中，则该状态会丢失。恢复工具假设所有池都已创建。如果恢复后部分创建的池中有 PG 卡在未知状态，可以运行 ceph osd force-create-pg 命令强制创建空 PG。只有当你确定池是空的时才采取此操作。 MDS 映射：MDS 映射会丢失。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Cpeh OSD常见故障处理","slug":"Ceph-PG常见故障处理","date":"2024-09-08T06:53:31.000Z","updated":"2024-09-08T09:18:04.959Z","comments":true,"path":"Ceph-PG常见故障处理/","permalink":"https://watsonlu6.github.io/Ceph-PG%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/","excerpt":"","text":"PG故障排除PG 永远无法变干净如果在创建集群后，任何 PG 保持在 active 状态、active+remapped 状态或 active+degraded 状态，并且永远无法达到 active+clean 状态，那么可能是配置出现了问题。在这种情况下，可能需要查看 Pool、PG 和 CRUSH 配置参考的设置，并进行适当调整。一般来说，运行集群时应使用多个 OSD，并且池的大小应大于两个对象副本。 单节点集群 Ceph 不再提供单节点操作的文档。按定义，分布式计算系统不应在单节点上运行。在包含 Ceph 守护进程的单节点上安装客户端内核模块可能会由于 Linux 内核本身的问题而导致死锁（除非使用虚拟机作为客户端）。尽管有上述限制，您仍可以在单节点配置中实验 Ceph。 要在单节点上创建集群，必须在创建监视器和 OSD 之前，将 Ceph 配置文件中的 osd_crush_chooseleaf_type 设置从默认的 1（表示主机或节点）更改为 0（表示 OSD）。这告诉 Ceph 允许在同一主机上放置另一个 OSD。如果您尝试设置单节点集群，并且 osd_crush_chooseleaf_type 大于 0，Ceph 将尝试将一个 OSD 的 PG 与另一个 OSD 的 PG 放置在另一个节点、机箱、机架、行或数据中心中，具体取决于设置。 提示 不要将内核客户端直接安装在与 Ceph 存储集群相同的节点上。这样可能会产生内核冲突。然而，您可以在单节点上通过虚拟机 (VMs) 安装内核客户端。 如果您使用单个磁盘创建 OSD，则必须先手动创建数据目录。 OSDs 少于副本 如果两个 OSD 处于 up 和 in 状态，但 PG 并未处于 active + clean 状态，可能是 osd_pool_default_size 设置大于 2。 解决这种情况有几种方法。如果您想以 active + degraded 状态运行集群并保持两个副本，您可以将 osd_pool_default_min_size 设置为 2，这样可以在 active + degraded 状态下写入对象。您也可以将 osd_pool_default_size 设置为 2，这样只会有两个存储副本（原始副本和一个副本）。在这种情况下，集群应达到 active + clean 状态。 注意 您可以在集群运行时进行更改。如果您在 Ceph 配置文件中进行更改，可能需要重新启动集群。 POOL SIZE &#x3D; 1 如果将 osd_pool_default_size 设置为 1，则对象只有一个副本。OSDs 依赖其他 OSDs 来告诉它们应该拥有哪些对象。如果一个 OSD 有一个对象副本而没有第二个副本，那么就没有第二个 OSD 来告诉第一个 OSD 它应该拥有这个副本。对于映射到第一个 OSD 的每个 PG（请参见 ceph pg dump），您可以通过运行以下命令来强制第一个 OSD 注意它需要的 PG： 1ceph osd force-create-pg &lt;pgid&gt; CRUSH MAP 错误 如果集群中的任何 PG 不干净，则可能是 CRUSH 映射中存在错误。 PG卡住PG 进入“degraded”或“peering”状态在组件故障后是正常的。这些状态通常反映了故障恢复过程中的预期进展。然而，若一个 PG 长时间停留在这些状态中，可能是更大问题的迹象。因此，Ceph 监视器会在 PG “卡住”在非最佳状态时发出警告。具体检查的状态包括： inactive - PG 长时间未处于活跃状态（即无法处理读写请求）。 unclean - PG 长时间未处于干净状态（即无法完全从先前的故障中恢复）。 stale - PG 状态未被 ceph-osd 更新。这表明存储该 PG 的所有节点可能都已宕机。通过运行以下命令来列出卡住的PG： 123ceph pg dump_stuck staleceph pg dump_stuck inactiveceph pg dump_stuck unclean 卡住的 stale PG 通常表明关键的 ceph-osd 守护进程未运行。 卡住的 inactive PG 通常表明存在 peering 问题（见 PG Down - Peering Failure）。 卡住的 unclean PG 通常表明某些因素阻止了恢复完成，可能是未找到的对象（见 Unfound Objects）。 PG 下线 - 对等连接失败在某些情况下，ceph-osd peering 过程可能会遇到问题，导致 PG 无法变为活跃和可用。在这种情况下，运行 ceph health detail 命令会报告类似以下内容： 1234567ceph health detailHEALTH_ERR 7 pgs degraded; 12 pgs down; 12 pgs peering; 1 pgs recovering; 6 pgs stuck unclean; 114/3300 degraded (3.455%); 1/3 in osds are down...pg 0.5 is down+peeringpg 1.4 is down+peering...osd.1 is down since epoch 69, last address 192.168.106.220:6801/8651 查询集群以确定为什么 PG 被标记为 down，可以运行如下命令： 123456789101112131415161718192021222324ceph pg 0.5 query&#123; &quot;state&quot;: &quot;down+peering&quot;, ... &quot;recovery_state&quot;: [ &#123; &quot;name&quot;: &quot;Started\\/Primary\\/Peering\\/GetInfo&quot;, &quot;enter_time&quot;: &quot;2012-03-06 14:40:16.169679&quot;, &quot;requested_info_from&quot;: []&#125;, &#123; &quot;name&quot;: &quot;Started\\/Primary\\/Peering&quot;, &quot;enter_time&quot;: &quot;2012-03-06 14:40:16.169659&quot;, &quot;probing_osds&quot;: [ 0, 1], &quot;blocked&quot;: &quot;peering is blocked due to down osds&quot;, &quot;down_osds_we_would_probe&quot;: [ 1], &quot;peering_blocked_by&quot;: [ &#123; &quot;osd&quot;: 1, &quot;current_lost_at&quot;: 0, &quot;comment&quot;: &quot;starting or marking this osd lost may let us proceed&quot;&#125;]&#125;, &#123; &quot;name&quot;: &quot;Started&quot;, &quot;enter_time&quot;: &quot;2012-03-06 14:40:16.169513&quot;&#125; ]&#125; recovery_state 部分告诉我们 peering 被阻止是由于 ceph-osd 守护进程宕机，具体是 osd.1。在这种情况下，我们可以启动该 ceph-osd，恢复将继续进行。或者，如果 osd.1 发生灾难性故障（例如磁盘故障），可以告知集群该 OSD 已丢失，并指示集群尽可能应对。 重要告知集群一个 OSD 已丢失是危险的，因为集群不能保证其他副本的数据是一致和最新的。要报告 OSD 丢失并指示 Ceph 继续尝试恢复，可以运行如下命令： 1ceph osd lost 1 恢复将继续进行。 未找到的对象在某些故障组合下，Ceph 可能会报告未找到的对象，例如： 123ceph health detailHEALTH_WARN 1 pgs degraded; 78/3778 unfound (2.065%)pg 2.4 is active+degraded, 78 unfound 这意味着存储集群知道一些对象（或现有对象的新副本）存在，但没有找到它们的副本。以下是这种情况可能发生的示例：一个 PG 的数据在两个 OSD 上，我们称它们为“1”和“2”： OSD 1 发生故障。 OSD 2 单独处理一些写操作。 OSD 1 重新上线。 OSD 1 和 OSD 2 重新进行 peering，OSD 1 上缺失的对象被排队等待恢复。 在新的对象被复制之前，OSD 2 发生故障。此时，OSD 1 知道这些对象存在，但没有活跃的 ceph-osd 拥有这些对象的副本。在这种情况下，对这些对象的 IO 请求将被阻塞，集群希望故障节点尽快恢复。这被认为比直接返回 IO 错误给用户更可取。 注意上述情况是将 size=2 设置在复制池和 m=1 设置在纠删码池时可能导致数据丢失的原因之一。 通过运行以下命令来识别哪些对象未找到： 1234567891011121314151617181920212223242526272829303132333435ceph pg 2.4 list_unfound [starting offset, in json]&#123; &quot;num_missing&quot;: 1, &quot;num_unfound&quot;: 1, &quot;objects&quot;: [ &#123; &quot;oid&quot;: &#123; &quot;oid&quot;: &quot;object&quot;, &quot;key&quot;: &quot;&quot;, &quot;snapid&quot;: -2, &quot;hash&quot;: 2249616407, &quot;max&quot;: 0, &quot;pool&quot;: 2, &quot;namespace&quot;: &quot;&quot; &#125;, &quot;need&quot;: &quot;43&#x27;251&quot;, &quot;have&quot;: &quot;0&#x27;0&quot;, &quot;flags&quot;: &quot;none&quot;, &quot;clean_regions&quot;: &quot;clean_offsets: [], clean_omap: 0, new_object: 1&quot;, &quot;locations&quot;: [ &quot;0(3)&quot;, &quot;4(2)&quot; ] &#125; ], &quot;state&quot;: &quot;NotRecovering&quot;, &quot;available_might_have_unfound&quot;: true, &quot;might_have_unfound&quot;: [ &#123; &quot;osd&quot;: &quot;2(4)&quot;, &quot;status&quot;: &quot;osd is down&quot; &#125; ], &quot;more&quot;: false&#125; 如果单次结果中列出的对象过多，more 字段将为 true，你可以查询更多信息。（最终命令行工具将会隐藏这一点，但现在还没有。）接下来，你可以识别哪些 OSD 已被探测或可能包含数据。在列表的末尾（在 more: false 之前），might_have_unfound 是在 available_might_have_unfound 为 true 时提供的。这相当于 ceph pg #.# query 的输出。它可以避免直接使用 query。提供的 might_have_unfound 信息与 query 的输出方式相同，仅不同的是，状态为“已探测”的 OSD 会被忽略。查询的使用： 1234567ceph pg 2.4 query&quot;recovery_state&quot;: [ &#123; &quot;name&quot;: &quot;Started\\/Primary\\/Active&quot;, &quot;enter_time&quot;: &quot;2012-03-06 15:15:46.713212&quot;, &quot;might_have_unfound&quot;: [ &#123; &quot;osd&quot;: 1, &quot;status&quot;: &quot;osd is down&quot;&#125;]&#125; 在这种情况下，集群知道 osd.1 可能有数据，但它已宕机。以下是可能的状态范围： 已探测 正在查询 OSD 已宕机 尚未查询 有时集群需要一些时间来查询可能的位置。可能还有其他未列出的对象可能存在的位置。例如：如果一个 OSD 停止并从集群中移除，然后集群完全恢复，然后通过随后的故障集群最终出现未找到的对象，集群将忽略已移除的 OSD。（然而，这种情况不太可能发生。） 如果所有可能的位置都已被查询，且对象仍然丢失，你可能需要放弃这些丢失的对象。这仅在发生了不寻常的故障组合，导致集群在写入之前了解了写入操作的情况时才可能发生。要将“未找到”的对象标记为“丢失”，运行以下命令： 1ceph pg 2.5 mark_unfound_lost revert|delete 这里的最后一个参数（revert|delete）指定了集群应如何处理丢失的对象。 delete 选项将使集群完全忘记这些对象。 revert 选项（对于纠删码池不可用）将回滚到对象的先前版本，或（如果它是新对象）完全忘记该对象。使用 revert 时请小心，因为它可能会混淆期望对象存在的应用程序。 无家 PG如果所有具有特定 PG 副本的 OSD 都发生故障，那么包含这些 PG 的对象存储子集将变得不可用，监视器将无法接收到这些 PG 的状态更新。监视器会将主 OSD 已故障的任何 PG 标记为 stale。例如： 12ceph healthHEALTH_WARN 24 pgs stale; 3/300 in osds are down 通过运行以下命令来识别哪些 PG 是 stale 的，以及最后一个存储这些 stale PG 的 OSD 是哪些： 12345678ceph health detailHEALTH_WARN 24 pgs stale; 3/300 in osds are down...pg 2.5 is stuck stale+active+remapped, last acting [2,0]...osd.10 is down since epoch 23, last address 192.168.106.220:6800/11080osd.11 is down since epoch 13, last address 192.168.106.220:6803/11539osd.12 is down since epoch 24, last address 192.168.106.220:6806/11861 此输出表明 PG 2.5（pg 2.5）最后由 osd.0 和 osd.2 管理。重启这些 OSD 以允许集群恢复该 PG。 只有少数 OSD 接收数据如果集群中的只有少数节点在接收数据，请检查池中的 PG 数量，如 PG 文档中所述。由于 PG 会在涉及将集群中的 PG 数量除以集群中 OSD 数量的操作中映射到 OSD，因此在这种操作中，少量的 PG（余数）有时不会在集群中分布。在这种情况下，创建一个 PG 数量是 OSD 数量倍数的池。有关详细信息，请参见 PG。有关如何更改用于确定每个池分配多少 PG 的默认值的说明，请参见 Pool、PG 和 CRUSH 配置参考。 无法写入数据如果集群正常运行，但一些 OSD 已经关闭且无法写入数据，请确保在池中运行了最小数量的 OSD。如果池中没有运行最小数量的 OSD，Ceph 不会允许你向其写入数据，因为无法保证 Ceph 可以复制你的数据。有关详细信息，请参见 Pool、PG 和 CRUSH 配置参考中的 osd_pool_default_min_size。 PG 状态不一致如果命令 ceph health detail 返回 active + clean + inconsistent 状态，这可能表示在清理过程中发生了错误。通过运行以下命令来识别不一致的 PG： 1234$ ceph health detailHEALTH_ERR 1 pgs inconsistent; 2 scrub errorspg 0.6 is active+clean+inconsistent, acting [0,1,2]2 scrub errors 或者，如果你希望以编程方式检查输出，可以运行以下命令： 12$ rados list-inconsistent-pg rbd[&quot;0.6&quot;] 在最坏的情况下，我们可能会在多个对象中发现不同的不一致。如果 PG 0.6 中名为 foo 的对象被截断，rados list-inconsistent-pg rbd 的输出可能类似于： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950rados list-inconsistent-obj 0.6 --format=json-pretty&#123; &quot;epoch&quot;: 14, &quot;inconsistents&quot;: [ &#123; &quot;object&quot;: &#123; &quot;name&quot;: &quot;foo&quot;, &quot;nspace&quot;: &quot;&quot;, &quot;locator&quot;: &quot;&quot;, &quot;snap&quot;: &quot;head&quot;, &quot;version&quot;: 1 &#125;, &quot;errors&quot;: [ &quot;data_digest_mismatch&quot;, &quot;size_mismatch&quot; ], &quot;union_shard_errors&quot;: [ &quot;data_digest_mismatch_info&quot;, &quot;size_mismatch_info&quot; ], &quot;selected_object_info&quot;: &quot;0:602f83fe:::foo:head(16&#x27;1 client.4110.0:1 dirty|data_digest|omap_digest s 968 uv 1 dd e978e67f od ffffffff alloc_hint [0 0 0])&quot;, &quot;shards&quot;: [ &#123; &quot;osd&quot;: 0, &quot;errors&quot;: [], &quot;size&quot;: 968, &quot;omap_digest&quot;: &quot;0xffffffff&quot;, &quot;data_digest&quot;: &quot;0xe978e67f&quot; &#125;, &#123; &quot;osd&quot;: 1, &quot;errors&quot;: [], &quot;size&quot;: 968, &quot;omap_digest&quot;: &quot;0xffffffff&quot;, &quot;data_digest&quot;: &quot;0xe978e67f&quot; &#125;, &#123; &quot;osd&quot;: 2, &quot;errors&quot;: [ &quot;data_digest_mismatch_info&quot;, &quot;size_mismatch_info&quot; ], &quot;size&quot;: 0, &quot;omap_digest&quot;: &quot;0xffffffff&quot;, &quot;data_digest&quot;: &quot;0xffffffff&quot; &#125; ] &#125; ]&#125; 在这种情况下，输出表示以下内容： 唯一的不一致对象名为 foo，其头部存在不一致。 不一致分为两类： errors：这些错误表示分片之间的不一致，没有指示哪些分片有问题。检查 shards 数组中的错误，以确定问题所在。 data_digest_mismatch：从 OSD.2 读取的副本摘要与从 OSD.0 和 OSD.1 读取的副本摘要不同。 size_mismatch：从 OSD.2 读取的副本大小为 0，但 OSD.0 和 OSD.1 报告的大小为 968。 union_shard_errors：分片数组中所有特定分片错误的联合。这些错误包括 read_error 和其他类似错误。以 oi 结尾的错误表示与 selected_object_info 进行比较。检查 shards 数组以确定哪些分片存在哪些错误。 data_digest_mismatch_info：对象信息中存储的摘要不是 0xffffffff，这是从 OSD.2 读取的分片计算出的。 size_mismatch_info：对象信息中存储的大小与从 OSD.2 读取的大小不同，后者为 0。 警告：如果 read_error 列在分片的错误属性中，可能是由于物理存储错误导致的不一致。在这种情况下，请检查该 OSD 使用的存储。 在尝试修复驱动器之前，请检查 dmesg 和 smartctl 的输出。 要修复不一致的 PG，运行如下命令： 1ceph pg repair &#123;placement-group-ID&#125; 例如： 1ceph pg repair 1.4 注意：PG ID 形式为 N.xxxxx，其中 N 是包含 PG 的池的编号。命令 ceph osd listpools 和 ceph osd dump | grep pool 返回池编号的列表。 如果由于时钟偏差而定期收到 active + clean + inconsistent 状态，请考虑配置监视主机上的 NTP 守护进程以充当对等体。有关更多信息，请参见《网络时间协议和 Ceph 时钟设置》。 关于 PG 修复的更多信息Ceph 存储并更新集群中存储对象的校验和。当在 PG 上执行清理时，主 OSD 尝试从其副本中选择一个权威副本。只有一个可能的情况是一致的。执行深度清理后，Ceph 计算从磁盘读取的每个对象的校验和，并将其与先前记录的校验和进行比较。如果当前校验和与先前记录的校验和不匹配，则该不匹配被视为不一致。在复制池的情况下，任何副本的校验和与权威副本的校验和之间的任何不匹配都意味着存在不一致。发现这些不一致会导致 PG 状态被设置为不一致。 pg repair 命令尝试修复各种类型的不一致。当 pg repair 发现不一致的 PG 时，它尝试用权威副本的摘要覆盖不一致副本的摘要。当 pg repair 在复制池中发现不一致副本时，它将不一致副本标记为丢失。在复制池的情况下，恢复超出了 pg repair 的范围。 对于编码和 BlueStore 池，Ceph 会自动执行修复，如果 osd_scrub_auto_repair（默认值为 false）设置为 true 并且发现的错误不超过 osd_scrub_auto_repair_num_errors（默认值为 5）。 pg repair 命令不会解决所有问题。Ceph 不会自动修复发现有不一致的 PG。 RADOS 对象或 omap 的校验和并不总是可用。校验和是逐步计算的。如果一个复制对象非顺序更新，涉及的写入操作会更改对象并使其校验和无效。在重新计算校验和时不会读取整个对象。即使校验和不可用，pg repair 命令也能够进行修复，如 Filestore 中的情况。使用复制 Filestore 池的用户可能会更倾向于手动修复，而不是使用 ceph pg repair。 该材料适用于 Filestore，但不适用于 BlueStore，后者具有自己的内部校验和。匹配记录的校验和和计算的校验和不能证明任何特定副本实际上是权威的。如果没有校验和可用，pg repair 倾向于主数据，但这可能不是未损坏的副本。因此，在发现不一致时需要人工干预。这种干预有时涉及使用 ceph-objectstore-tool。 编码池 PG 不是 active+clean如果 CRUSH 无法找到足够的 OSD 映射到 PG，它将显示为 2147483647，这是 ITEM_NONE 或未找到 OSD。例如： 1[2,1,6,0,5,8,2147483647,7,4] OSD 数量不足 如果 Ceph 集群只有八个 OSD，而一个编码池需要九个 OSD，则集群会显示“OSD 不足”。在这种情况下，你可以创建 另一个需要更少 OSD 的编码池，运行如下命令： 12ceph osd erasure-code-profile set myprofile k=5 m=3ceph osd pool create erasurepool erasure myprofile 或者添加新的 OSD，PG 将自动使用它们。 CRUSH 约束无法满足如果集群中有足够的 OSD，可能是 CRUSH 规则施加了无法满足的约束。如果两个主机上有十个 OSD，而 CRUSH 规则要求同一主机上的两个 OSD 不得在同一 PG 中使用，则映射可能失败，因为只会找到两个 OSD。通过显示（“转储”）规则来检查约束，如下所示： 12345678910111213141516ceph osd crush rule ls[ &quot;replicated_rule&quot;, &quot;erasurepool&quot;]$ ceph osd crush rule dump erasurepool&#123; &quot;rule_id&quot;: 1, &quot;rule_name&quot;: &quot;erasurepool&quot;, &quot;type&quot;: 3, &quot;steps&quot;: [ &#123; &quot;op&quot;: &quot;take&quot;, &quot;item&quot;: -1, &quot;item_name&quot;: &quot;default&quot;&#125;, &#123; &quot;op&quot;: &quot;chooseleaf_indep&quot;, &quot;num&quot;: 0, &quot;type&quot;: &quot;host&quot;&#125;, &#123; &quot;op&quot;: &quot;emit&quot;&#125;]&#125; 通过运行以下命令解决此问题： 12ceph osd erasure-code-profile set myprofile crush-failure-domain=osdceph osd pool create erasurepool erasure myprofile CRUSH 过早放弃如果 Ceph 集群只有足够的 OSD 来映射 PG（例如，总共九个 OSD 的集群和每个 PG 需要九个 OSD 的编码池），则可能 CRUSH 在找到映射之前就放弃了。可以通过以下方式解决此问题： 降低编码池的要求，以使用更少的 OSD（这需要创建另一个池，因为编码配置文件不能动态修改）。 向集群中添加更多 OSD（这不需要修改编码池，因为它会自动变干净）。 使用手动创建的 CRUSH 规则，尝试更多次找到合适的映射。可以通过设置 set_choose_tries 为大于默认值的值来修改现有的 CRUSH 规则。 首先，通过在从集群中提取 crushmap 后使用 crushtool 验证问题。这可以确保你的实验不会修改 Ceph 集群，只在本地文件上操作： 123456789101112131415161718192021ceph osd crush rule dump erasurepool&#123; &quot;rule_id&quot;: 1, &quot;rule_name&quot;: &quot;erasurepool&quot;, &quot;type&quot;: 3, &quot;steps&quot;: [ &#123; &quot;op&quot;: &quot;take&quot;, &quot;item&quot;: -1, &quot;item_name&quot;: &quot;default&quot;&#125;, &#123; &quot;op&quot;: &quot;chooseleaf_indep&quot;, &quot;num&quot;: 0, &quot;type&quot;: &quot;host&quot;&#125;, &#123; &quot;op&quot;: &quot;emit&quot;&#125;]&#125;$ ceph osd getcrushmap &gt; crush.mapgot crush map from osdmap epoch 13$ crushtool -i crush.map --test --show-bad-mappings \\ --rule 1 \\ --num-rep 9 \\ --min-x 1 --max-x $((1024 * 1024))bad mapping rule 8 x 43 num_rep 9 result [3,2,7,1,2147483647,8,5,6,0]bad mapping rule 8 x 79 num_rep 9 result [6,0,2,1,4,7,2147483647,5,8]bad mapping rule 8 x 173 num_rep 9 result [0,4,6,8,2,1,3,7,2147483647] 在这里，--num-rep 是编码规则需要的 OSD 数量，--rule 是 ceph osd crush rule dump 显示的 rule_id 值。此测试将尝试映射一百万个值（在此示例中，范围定义为 [–min-x,–max-x]），并且必须显示至少一个错误映射。如果此测试没有输出任何内容，则表示所有映射都成功，你可以确定集群中的问题不是由于坏映射造成的。 更改 set_choose_tries 的值将 CRUSH 映射解压以编辑 CRUSH 规则，运行以下命令： 1crushtool --decompile crush.map &gt; crush.txt 在规则中添加以下行： 1step set_choose_tries 100 crush.txt 文件的相关部分将类似于： 123456789rule erasurepool &#123; id 1 type erasure step set_chooseleaf_tries 5 step set_choose_tries 100 step take default step chooseleaf indep 0 type host step emit&#125; 重新编译并重新测试 CRUSH 规则： 1crushtool --compile crush.txt -o better-crush.map 当所有映射成功时，通过使用 crushtool 命令的 --show-choose-tries 选项显示找到所有映射所需的尝试次数的直方图，如下所示： 12345crushtool -i better-crush.map --test --show-bad-mappings \\ --show-choose-tries \\ --rule 1 \\ --num-rep 9 \\ --min-x 1 --max-x $((1024 * 1024)) …11: 4212: 4413: 5414: 4515: 3516: 3417: 3018: 2519: 1920: 2221: 2022: 1723: 1324: 1625: 1326: 1127: 1128: 1329: 1130: 1031: 632: 533: 1034: 335: 736: 537: 238: 539: 540: 241: 542: 443: 144: 245: 246: 347: 148: 0…102: 0103: 1104: 0… 这个输出表示映射 42 个 PG 需要 11 次尝试，映射 44 个 PG 需要 12 次尝试等。最大尝试次数是防止坏映射的 set_choose_tries 的最小值（例如，上述输出中的 103，因为没有超过 103 次尝试的 PG 被映射）。 由 Ceph Foundation 提供 Ceph 文档是一个由非盈利组织 Ceph Foundation 资助和托管的社区资源。如果你想支持这一点和我们的其他工作，请考虑立即加入。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Cpeh OSD常见故障处理","slug":"Ceph-Mon常见故障处理","date":"2024-09-08T06:53:31.000Z","updated":"2024-09-08T07:47:55.858Z","comments":true,"path":"Ceph-Mon常见故障处理/","permalink":"https://watsonlu6.github.io/Ceph-Mon%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/","excerpt":"","text":"OSD故障排除在故障排除集群的 OSD 之前，请先检查监视器和网络。首先，确定监视器是否有法定人数。运行 ceph health 命令或 ceph -s 命令，如果 Ceph 显示 HEALTH_OK，则表示有监视器法定人数。如果监视器没有法定人数或监视器状态出现错误，请在继续之前处理监视器问题。接下来，检查网络以确保其正常运行。网络对 OSD 的操作和性能有显著影响。检查主机端是否有丢包，并检查交换机端是否有 CRC 错误。 获取 OSD 数据在故障排除 OSD 时，收集关于 OSD 的不同信息非常有用。一些信息来自于对 OSD 的监控（例如，运行 ceph osd tree 命令）。额外的信息涉及到集群的拓扑结构，以下部分将讨论这些内容。 Ceph 日志 Ceph 的日志文件存储在 /var/log/ceph 下。除非路径已被更改（或者您在存储日志位置不同的容器化环境中），否则可以通过以下命令列出日志文件： 1ls /var/log/ceph 如果日志详情不够，请调整日志级别。要确保 Ceph 在高日志量下表现良好，请参阅“日志记录和调试”。 管理员套接字使用管理员套接字工具来检索运行时信息。首先，列出 Ceph 守护进程的套接字，通过以下命令： 1ls /var/run/ceph 接下来，运行如下命令（将 &#123;daemon-name&#125; 替换为特定守护进程的名称，例如 osd.0）： 1ceph daemon &#123;daemon-name&#125; help 或者，指定 &#123;socket-file&#125;（“套接字文件”是 /var/run/ceph 中的特定文件）运行命令： 1ceph daemon &#123;socket-file&#125; help 管理员套接字可以完成许多任务，包括： 列出 Ceph 配置运行时 转储历史操作 转储操作优先级队列状态 转储正在进行的操作 转储性能计数器 显示空闲空间可能会出现文件系统问题。要显示文件系统的空闲空间，请运行以下命令： 1df -h 要查看此命令支持的语法和选项，请运行 df --help。 I&#x2F;O 统计iostat 工具可用于识别 I&#x2F;O 相关的问题。运行以下命令： 1iostat -x 诊断信息要从内核中检索诊断信息，请运行 dmesg 命令，并使用 less、more、grep 或 tail 进行指定输出。例如： 1dmesg | grep scsi 停止而不重新平衡有时可能需要对集群的子集进行维护或解决影响故障域（例如机架）的问题。然而，当停止 OSD 进行维护时，可能希望防止 CRUSH 自动重新平衡集群。为避免这种重新平衡行为，可以通过运行以下命令将集群设置为 noout 状态： 1ceph osd set noout 警告这更多是一个思考练习，用于让读者理解故障域和 CRUSH 行为，而不是建议在 Luminous 版本后的环境中运行 ceph osd set noout。当 OSD 返回到正常状态时，重新平衡将恢复，ceph osd set noout 命令引入的更改将被撤销。 然而，在 Luminous 及后续版本中，更安全的做法是只标记受影响的 OSD。要添加或删除特定 OSD 的 noout 标志，可以运行如下命令： 12ceph osd add-noout osd.0ceph osd rm-noout osd.0 也可以标记整个 CRUSH 组。例如，如果计划停用 prod-ceph-data1701 以增加 RAM，可以运行以下命令： 1ceph osd set-group noout prod-ceph-data1701 设置标志后，停止 OSD 和需要维护的故障域内的其他 Ceph 服务： 1systemctl stop ceph\\*.service ceph\\*.target 注意当 OSD 被停止时，该 OSD 内的任何放置组将被标记为降级。维护完成后，需重新启动 OSD 和其他停止的守护进程。然而，如果主机在维护过程中重启，则不需要重新启动，系统会自动恢复。要重新启动 OSD 或其他守护进程，使用如下命令： 1sudo systemctl start ceph.target 最后，根据需要取消 noout 标志，可以运行如下命令： 12ceph osd unset nooutceph osd unset-group noout prod-ceph-data1701 许多现代 Linux 发行版使用 systemd 进行服务管理。然而，对于某些操作系统（尤其是旧版本），可能需要发出等效的服务或启动&#x2F;停止命令。 OSD 未运行在正常情况下，重新启动 ceph-osd 守护进程将允许它重新加入集群并恢复。 OSD 无法启动如果集群已启动，但某个 OSD 无法启动，请检查以下内容： 配置文件：如果您在新的安装中无法启动 OSD，请检查配置文件以确保其符合标准（例如，确保使用的是 host 而不是 hostname 等）。 检查路径：确保配置中指定的路径与实际存在的数据和元数据路径对应（例如，日志、WAL 和 DB 的路径）。将 OSD 数据与元数据分开，以查看配置文件和实际挂载是否存在错误。如果有，这些错误可能解释了为何 OSD 无法启动。要将元数据存储在单独的块设备上，可以对驱动器进行分区或使用 LVM，并为每个 OSD 分配一个分区。 检查最大线程数：如果集群中有一个节点的 OSD 数量特别高，可能会达到默认的最大线程数（通常是 32,000）。这在恢复过程中尤其可能发生。将最大线程数增加到允许的最大线程数（4194303）可能有助于解决问题。要将线程数增加到最大值，请运行以下命令： 1sysctl -w kernel.pid_max=4194303 如果增加线程数解决了问题，您必须通过在 /etc/sysctl.d 文件夹下的文件或在主 /etc/sysctl.conf 文件中包含 kernel.pid_max 设置来使更改永久生效。例如： 1kernel.pid_max = 4194303 **检查 nf_conntrack**：这个连接跟踪和连接限制系统对许多生产 Ceph 集群造成问题。问题往往缓慢而微妙地出现。随着集群拓扑和客户端工作负载的增长，神秘和间歇性的连接失败和性能问题会越来越多，尤其是在一天中的某些时候。为开始评估问题，请检查 syslog 历史中的 “table full” 事件。解决这种问题的一种方法是：首先，使用 sysctl 实用程序将 nf_conntrack_max 设置为更高的值。接下来，将 nf_conntrack_buckets 的值提高到 nf_conntrack_buckets × 8 = nf_conntrack_max；这可能需要在 sysctl 之外运行命令（例如，echo 131072 &gt; /sys/module/nf_conntrack/parameters/hashsize）。另一种解决方法是将相关内核模块列入黑名单，从而完全禁用处理。这种方法强大但脆弱。模块及其列出顺序可能因内核版本而异。即使被列入黑名单，iptables 和 docker 有时仍会激活连接跟踪，因此我们建议对调优参数采用“设置并忘记”的策略。在现代系统中，这种方法不会消耗显著资源。 内核版本：确定正在使用的内核版本和发行版。默认情况下，Ceph 使用的第三方工具可能存在缺陷或与某些发行版或内核版本冲突（例如，Google 的 gperftools 和 TCMalloc）。检查操作系统建议和每个 Ceph 版本的发行说明，以确保您已解决与内核相关的任何问题。 段错误：如果出现段错误，请提高日志级别并重新启动有问题的守护进程。如果段错误重复发生，请在 Ceph bug 跟踪器（https://tracker.ceph.com/projects/ceph）和 dev 及 ceph-users 邮件列表归档（https://ceph.io/resources）中搜索是否有其他人遇到并报告了这些问题。如果这确实是一个新的和独特的故障，请在 dev 邮件列表中发布，并提供以下信息：正在运行的具体 Ceph 版本、ceph.conf（秘密已用 XXX 替换）、监视器状态输出和日志文件摘录。 OSD 失败当 OSD 失败时，表示 ceph-osd 进程无响应或已死亡，相应的 OSD 已被标记为下线。存活的 ceph-osd 守护进程将向监视器报告该 OSD 似乎已经下线，并且 ceph health 命令的输出中将显示新的状态，如下例所示： 12ceph healthHEALTH_WARN 1/3 in osds are down 当有一个或多个 OSD 被标记为下线时，会引发此健康警报。要查看哪些 OSD 已下线，请为命令添加详细信息，如下所示： 123ceph health detailHEALTH_WARN 1/3 in osds are downosd.0 is down since epoch 23, last address 192.168.106.220:6800/11080 或者，运行以下命令： 1ceph osd tree down 如果由于驱动器故障或其他故障导致某个 ceph-osd 守护进程无法工作或重新启动，则其日志文件（位于 /var/log/ceph 下）中应存在错误消息。如果 ceph-osd 守护进程因心跳故障或自杀超时错误而停止，则底层驱动器或文件系统可能无响应。检查 dmesg 输出和 syslog 输出中的驱动器错误或内核错误。可能需要指定某些标志（例如，dmesg -T 以查看人类可读的时间戳）以避免将旧错误误认为新错误。 如果整个主机的 OSD 都下线，请检查是否存在网络错误或主机的硬件问题。如果 OSD 问题是软件错误（例如，断言失败或其他意外错误）的结果，请在 bug 跟踪器、dev 邮件列表归档和 ceph-users 邮件列表归档中搜索是否有问题报告。如果没有明确的修复或现有 bug，请向 ceph-devel 邮件列表报告问题。 没有可用驱动器空间如果 OSD 已满，Ceph 会通过确保不会将新数据写入 OSD 来防止数据丢失。在正常运行的集群中，当集群的 OSD 和池接近某些“满”比率时，会引发健康检查。mon_osd_full_ratio 阈值默认为 0.95（即 95% 的容量）：这是防止客户端写入数据的点。mon_osd_backfillfull_ratio 阈值默认为 0.90（即 90% 的容量）：这是防止开始回填的点。mon_osd_nearfull_ratio 阈值默认为 0.85（即 85% 的容量）：这是引发 OSD_NEARFULL 健康检查的点。集群中的 OSD 在 Ceph 分配的数据量上会有所不同。要通过显示每个 OSD 的数据使用情况来检查“满”状态，请运行以下命令： 1ceph osd df 要通过显示集群的总体数据使用情况和池之间的数据分布来检查“满”状态，请运行以下命令： 1ceph df 在检查 ceph df 命令的输出时，请特别注意最满的 OSD，而不是原始空间使用的百分比。如果单个 OSD 变满，所有对该 OSD 池的写入可能会失败。当 ceph df 报告池的可用空间时，它会考虑相对于池中最满 OSD 的比率设置。为了平衡数据分布，可以采取两种方法：（1）使用 reweight-by-utilization 命令逐步将数据从过满的 OSD 移动到不足满的 OSD，或者（2）在 Luminous 的后续版本及以后的版本中，利用 ceph-mgr balancer 模块自动执行相同任务。要调整“满”比率，请运行如下命令： 123ceph osd set-nearfull-ratio &lt;float[0.0-1.0]&gt;ceph osd set-full-ratio &lt;float[0.0-1.0]&gt;ceph osd set-backfillfull-ratio &lt;float[0.0-1.0]&gt; 有时，集群问题的原因是 OSD 失败。这可能发生在测试过程中，或者因为集群较小、非常满或不平衡。当 OSD 或节点占据集群数据的过高比例时，组件故障或自然增长可能导致接近满和满的比率被超过。在测试 Ceph 对 OSD 故障的恢复能力时，建议保留足够的空闲磁盘空间，并考虑暂时降低 OSD 的满比率、回填满比率和接近满比率。OSD 的“满”状态在 ceph health 命令的输出中可见，如下例所示： 12ceph healthHEALTH_WARN 1 nearfull osd(s) 有关详细信息，请使用详细命令，如下所示： 1234567ceph health detailHEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)osd.3 is full at 97%osd.4 is backfill full at 91%osd.2 is near full at 87% 为解决满集群问题，建议通过添加 OSD 来增加容量。添加新 OSD 允许集群将数据重新分配到新提供的存储空间。查找浪费空间的 rados bench 孤儿对象。 如果旧版 Filestore OSD 由于已满而无法启动，可以通过删除满 OSD 上的一小部分放置组目录来回收空间。 重要 如果您选择在满 OSD 上删除放置组目录，请勿在其他满 OSD 上删除相同的放置组目录。否则，您将丢失数据。您必须在至少一个 OSD 上保留数据的至少一个副本。删除放置组目录是一种罕见且极端的干预，不应轻易进行。 OSD 运行缓慢&#x2F;无响应OSD 有时会运行缓慢或无响应。在排查这个常见问题时，建议在调查 OSD 性能问题之前排除其他可能性。例如，确保网络正常工作，确认 OSD 正在运行，并检查 OSD 是否限制了恢复流量。提示在 Luminous 版本之前，某些 up 和 in 状态的 OSD 有时不可用或运行缓慢，因为恢复中的 OSD 消耗了系统资源。更新版本通过防止这种现象提供了更好的恢复处理。 网络问题 作为分布式存储系统，Ceph 依赖网络进行 OSD 对等和复制、故障恢复以及周期性心跳。网络问题可能导致 OSD 延迟和抖动的 OSD。更多信息请参见“抖动 OSD”。要确保 Ceph 进程和 Ceph 相关进程连接正常并在监听，请运行以下命令： 123netstat -a | grep cephnetstat -l | grep cephsudo netstat -p | grep ceph 要检查网络统计信息，请运行以下命令： 1netstat -s 驱动器配置 SAS 或 SATA 存储驱动器应仅容纳一个 OSD，但 NVMe 驱动器可以轻松容纳两个或更多。然而，如果其他进程共享驱动器，读写吞吐量可能会受到瓶颈。此类进程包括：日志&#x2F;元数据、操作系统、Ceph 监视器、syslog 日志、其他 OSD 和非 Ceph 进程。 由于 Ceph 在日志记录后确认写入，快速 SSD 是加速响应时间的一个有吸引力的选项——特别是在使用 XFS 或 ext4 文件系统作为传统 FileStore OSD 时。相比之下，Btrfs 文件系统可以同时进行写入和日志记录。（然而，不推荐在生产环境中使用 Btrfs。） 注意 对驱动器进行分区不会改变其总吞吐量或顺序读&#x2F;写限制。通过在单独的分区中运行日志，吞吐量可能会有所改善，但更好的做法是将日志运行在单独的物理驱动器中。 警告 Reef 不支持 FileStore。Reef 之后的版本不再支持 FileStore。提到 FileStore 的信息仅适用于 Quincy 版本及 Quincy 之前的版本。 坏扇区&#x2F;碎片化磁盘 检查驱动器是否存在坏块、碎片化和其他可能导致性能显著下降的错误。检查驱动器错误的有用工具包括 dmesg、syslog 日志和 smartctl（在 smartmontools 包中）。 注意 smartmontools 7.0 及更高版本提供 NVMe 状态直通和 JSON 输出。 共存的监视器&#x2F;OSD 尽管监视器是相对轻量的进程，但当监视器与 OSD 运行在同一主机上时，可能会出现性能问题。监视器发出许多 fsync() 调用，这可能干扰其他工作负载。当监视器与 OSD 共存在同一存储驱动器上时，性能问题尤其严重。此外，如果监视器运行的是较旧的内核（3.0 之前）或没有 syncfs(2) 系统调用的内核，那么同一主机上运行的多个 OSD 可能会进行太多提交，从而影响彼此的性能。这种问题有时会导致所谓的“突发写入”。 共存进程 在与 OSD 运行在同一硬件上时，处理写入数据到 Ceph 的进程（例如基于云的解决方案和虚拟机）可能会导致显著的 OSD 延迟。因此，一般不推荐将这些进程与 OSD 共存在同一硬件上。推荐的做法是优化某些主机用于 Ceph，其他主机用于其他进程。这种将 Ceph 操作与其他应用程序分开的做法可能有助于提高性能，并简化故障排除和维护。在同一硬件上运行共存进程有时被称为“融合”。使用 Ceph 时，仅在具备专业知识和经过考虑后再进行融合。 日志级别 高日志级别可能导致性能问题。操作人员有时会提高日志级别以跟踪问题，然后忘记在之后降低它们。在这种情况下，OSD 可能会消耗宝贵的系统资源，将不必要的详细日志写入磁盘。任何希望使用高日志级别的人都应考虑将驱动器挂载到日志的默认路径（例如，&#x2F;var&#x2F;log&#x2F;ceph&#x2F;$cluster-$name.log）。 恢复限制 根据您的配置，Ceph 可能会减少恢复速率以保持客户端或 OSD 性能，或者可能会增加恢复速率到影响客户端或 OSD 性能的程度。检查客户端或 OSD 是否正在恢复。 内核版本 检查您运行的内核版本。较旧的内核可能缺少改进 Ceph 性能的更新。 内核 SyncFS 问题 如果您遇到 SyncFS 的内核问题，请尝试每个主机运行一个 OSD 以查看性能是否提高。旧的内核可能没有足够新的 glibc 版本来支持 syncfs(2)。 文件系统问题 在 Luminous 版本之后，我们建议使用 BlueStore 后端部署集群。当运行 Luminous 版本之前的版本时，或者如果您有特别的理由使用旧的 Filestore 后端，我们建议使用 XFS。 我们不推荐使用 Btrfs 或 ext4。Btrfs 文件系统有许多吸引人的特性，但可能会导致性能问题和虚假的 ENOSPC 错误。由于 xattr 限制破坏了对长对象名称的支持，我们不推荐在 Filestore OSD 中使用 ext4。 内存不足 我们建议每个 OSD 守护进程至少配备 4GB 内存，并建议将其增加到 6GB 或 8GB。在正常操作期间，您可能会注意到 ceph-osd 进程只使用了其中的一小部分。您可能会被诱使将多余的内存用于共存应用程序，或减少每个节点的内存容量。然而，当 OSD 正在恢复时，其内存使用会急剧增加。如果在恢复过程中没有足够的内存，OSD 性能会显著下降，守护进程可能会崩溃或被 Linux OOM Killer 杀死。 请求阻塞或请求缓慢 当 ceph-osd 守护进程对请求响应缓慢时，集群日志会收到报告操作处理时间过长的消息。警告阈值默认为 30 秒，可以通过 osd_op_complaint_time 设置进行配置。 旧版 Ceph 报告旧请求： 1osd.0 192.168.106.220:6800/18813 312 : [WRN] old request osd_op(client.5099.0:790 fatty_26485_object789 [write 0~4096] 2.5e54f643) v4 received at 2012-03-06 15:42:56.054801 currently waiting for sub ops 新版 Ceph 报告慢请求： 12&#123;date&#125; &#123;osd.num&#125; [WRN] 1 slow requests, 1 included below; oldest blocked for &gt; 30.005692 secs&#123;date&#125; &#123;osd.num&#125; [WRN] slow request 30.005692 seconds old, received at &#123;date-time&#125;: osd_op(client.4240.0:8 benchmark_data_ceph-1_39426_object7 [write 0~4194304] 0.69848840) v4 currently waiting for subops from [610] 可能的原因包括： 驱动器故障（检查 dmesg 输出） 内核文件系统中的错误（检查 dmesg 输出） 集群过载（检查系统负载、iostat 等） ceph-osd 守护进程中的错误 可能的解决方案： 从 Ceph 主机中移除虚拟机 升级内核 升级 Ceph 重启 OSD 更换故障或有问题的组件 调试缓慢请求 如果您运行 ceph daemon osd.&lt;id&gt; dump_historic_ops 或 ceph daemon osd.&lt;id&gt; dump_ops_in_flight，您将看到一组操作和每个操作经历的事件列表。这些事件简要描述如下。 来自 Messenger 层的事件： header_read: Messenger 开始从网络读取消息的时间。 throttled: Messenger 尝试获取内存节流空间以将消息读入内存的时间。 all_read: Messenger 完成从网络读取消息的时间。 dispatched: Messenger 将消息交给 OSD 的时间。 initiated: 这与 header_read 相同。存在这两个事件是历史上的异常。 来自 OSD 处理操作的事件: - queued_for_pg: 操作已被放入队列等待 PG 处理。 - reached_pg: PG 开始执行操作。 - waiting for *: 操作在等待其他工作完成后才能继续（例如，新 OSDMap；对象目标的检查；PG 的对等完成；这些都在消息中指定）。 - started: 操作已被接受为 OSD 应执行的任务，并且正在执行中。 - waiting for subops from: 操作已被发送到副本 OSD。 来自 Filestore 的事件： - commit_queued_for_journal_write: 操作已交给 FileStore。 - write_thread_in_journal_buffer: 操作在日志的缓冲区中，等待持久化（作为下一次磁盘写入）。 - journaled_completion_queued: 操作已被写入日志，回调已排队等待调用。 来自 OSD 在数据已交给底层存储后的事件： - op_commit: 操作已由主 OSD 提交（即，写入日志）。 - op_applied: 操作已写入主 OSD 的后台文件系统（即，在内存中应用但未刷新到磁盘）。 - sub_op_applied: 副本的 op_applied。 - sub_op_committed: 副本的 op_commit（仅对 EC 池）。 - sub_op_commit_rec/sub_op_apply_rec from &lt;X&gt;: 主 OSD 在听到上述消息后进行标记，但针对特定副本（即 ）。 - commit_sent: 我们向客户端（或主 OSD，针对子操作）发送了回复。 虽然一些事件可能看起来冗余，但它们跨越了内部代码中的重要边界（例如，跨锁将数据传递到新线程中）。 OSD抖动“抖动”是指 OSD 被快速重复标记为上线然后下线的现象。本节解释如何识别抖动以及如何减轻它。 当 OSD 进行对等和检查心跳时，它们使用集群（后端）网络。如果您的 OSD 节点有两个网络端口，将一个端口专用于公共网络，另一个端口专用于私有网络，可以避免网络维护和网络故障对集群或客户端造成的重大影响。在这种情况下，可以考虑将两个链接仅用于公共网络：使用绑定（LACP）或等成本路由（例如 FRR），可以获得更高的吞吐量容差、容错能力和减少 OSD 抖动。 当私有网络（甚至单个主机链接）故障或降级时，而公共网络正常运行，OSD 可能无法很好地处理这种情况。在这种情况下，OSD 使用公共网络向监视器报告彼此故障，同时将自己标记为上线。然后，监视器再次通过公共网络发送更新的集群地图，将受影响的 OSD 标记为下线。这些 OSD 向监视器回复“我还没死！”，然后循环重复。我们称这种情况为“抖动”，它可能很难隔离和修复。没有私有网络时，这种恼人的动态被避免了：OSD 通常要么上线要么下线，没有抖动。 如果某些原因导致 OSD “抖动”（被反复标记为下线然后再上线），您可以通过暂时冻结其状态来强制监视器停止抖动： 12ceph osd set noup # 防止 OSD 被标记为上线ceph osd set nodown # 防止 OSD 被标记为下线 这些标志记录在 osdmap 中： 12ceph osd dump | grep flagsflags no-up,no-down 您可以使用以下命令清除这些标志： 12ceph osd unset noupceph osd unset nodown 还有两个其他标志 noin 和 noout，它们分别防止启动的 OSD 被标记为分配数据（in）或保护 OSD 被标记为最终移除（out），无论 mon_osd_down_out_interval 的当前值如何。 注意 noup、noout 和 nodown 是临时性的，因为清除标志后，它们阻止的操作应该很快能够恢复。但是 noin 标志防止 OSD 在启动时被标记为在线，任何在标志设置期间启动的守护进程将保持这种状态。 注意 通过仔细调整 mon_osd_down_out_subtree_limit、mon_osd_reporter_subtree_level 和 mon_osd_min_down_reporters 可以在一定程度上缓解抖动的原因和效果。最佳设置的推导取决于集群大小、拓扑结构和使用的 Ceph 版本。这些因素的交互很微妙，超出了本文档的范围。 由 Ceph 基金会提供 Ceph 文档是由非营利组织 Ceph 基金会资助和托管的社区资源。如果您想支持我们以及其他努力，请考虑立即加入。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph Cache Tier源码实现","slug":"Ceph-Cache-Tier源码实现","date":"2022-09-28T12:45:54.000Z","updated":"2024-09-01T13:34:00.917Z","comments":true,"path":"Ceph-Cache-Tier源码实现/","permalink":"https://watsonlu6.github.io/Ceph-Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Cache Tier架构Ceph存储集群如果采用廉价的PC和传统的机械硬盘进行搭建，磁盘的访问速度受到了一定的限制，无法达到理想的IOPS性能水平。为了优化系统的IO性能，可以考虑添加快速的存储设备作为缓存，以减少数据的访问延时。其中，Cache Tier分层存储机制是一种常见的解决方案，在Ceph服务端缓存中被广泛使用，可以有效提升后端存储层的I&#x2F;O性能。Cache Tier需要创建一个由高速且昂贵的存储设备（如SSD）组成的存储池作为缓存层，以及一个相对廉价的设备组成的后端存储池作为经济存储层。缓存层使用多副本模式，存储层可以使用多副本或纠删码模式。Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。 Ceph Cache tier处理流程使用命令add-cache 可以将一个cachepool作为base pool的tier。这时会设置pool的信息，在pool里面记录了cache pool和base pool的关系。客户端在获取pool信息的时候可知，目标base pool存在一个tier，叫做cache pool，那么操作base pool的请求都会发送给cache pool。请求达到cache pool中时，作为tier的pool会有一些特别的处理maybe_cache_handle，具体的流程如下图： 判断操作的object是否在cache pool中命中，如果命中，则直接在cache pool中处理，和在普通pool的请求一样处理。后续会有agent线程将缓存脏数据刷写到base pool中。 没有命中缓存的情况下，才会去判断缓存模式。如果命中缓存，不管是什么模式都会在cache pool中处理。下面的处理都是未命中缓存的情况。 判断是否是writeback模式，读操作，如果可以proxy_read，那就直接do_proxy_read读取数据即可，不可以proxy_read 就使用do_cache_redirect，告诉客户端去base pool中读取。写操作，如果当前是evict_full模式，说明现在缓存中已经达到了阈值，需要等待缓存淘汰一些object，在完成写操作，目前放在等待队列中等待，如果不是evict_full模式，则需要从base pool中promote对应的object到cache pool中，promote结束后继续处理本次的写操作。 判断是否是forward模式。在forward模式下，不再在cachepool中处理请求，会告诉客户端将请求全部发送到base pool中。 判断是不是readonly模式。写操作会告诉客户端直接想base pool写即可，如果是读操作，则会从base pool中promote该object。 判断是不是readforward模式。该模式读操作全部都告诉客户端直接去base pool中读取即可，写操作按着writeback模式处理。 判断是不是readproxy模式。该模式读操作都采用cachepool的proxy read方法，写操作按着writeback模式处理。 针对其中涉及到的几个封装好的方法的操作： do_cache_redirect， do_proxy_read， do_proxy_write，promote_object do_cache_redirect ：客户端请求cache pool，cache pool告诉客户端你应该去base pool中请求，客户端收到应答后，再次发送请求到base pool中请求数据，由base pool告诉客户端请求完成。 do_proxy_read：客户端发送读请求到cache pool，但是未命中，则cache pool自己会发送请求到base pool中，获取数据后，由cache pool将数据发送给客户端，完成读请求。但是值得注意的是，虽然cache pool读取到了该object，但不会保存在cache pool中，下次请求仍然需要调用函数promote_objectbasePool读取该对象请求，然后写入cachePool中。 do_proxy_write：直接写数据到basePool中，同样，cachePool中并没有该数据对象，还需要后续调用promote_object函数把数据对象从basePool中读到cachePool中。 promote_object：当客户端发送请求到cache pool中，但是cache pool未命中，cache pool会选择将该object从base pool中提升到cache pool中，然后在cache pool进行读写操作，操作完成后告知客户端请求完成，在cache pool会缓存该object，下次直接在cache中处理，和proxy_read存在的区别。构造PromoteCallback回调函数，然后调用函数start_copyk拷贝函数。 无论是 Proxy Read 还是 Promote Object 操作最终都是调用了 objecter 的 read 方法来从base storage层读取对象数据 Cache Tier数据结构由于 Tier cache 在 Ceph 中的存在形式是存储池，pg_pool_t保存了存储池的相关属性。(src&#x2F;osd&#x2F;osd_type.h&#x2F;struct pg_pool_t) 123456789101112131415161718set&lt;uint64_t&gt; tiers; //如果当前pool是一个basePool，tiers就记录改basepool的cachePool层，一个base pool可以设置多个cachePoolint64_t tier_of; //如果当前pool是一个cachePool，那么tier_of记录了该cachePool的basePoolint64_t read_tier; //设置basePool的读缓存层，根据Ceph不同的Cache Tier模式来设置int64_t write_tier; //设置basePool的写缓存层，根据Ceph不同的Cache Tier模式来设置cache_mode_t cache_mode; //设置Cache Tier模式uint64_t target_max_bytes; //设置了cachePool的最大字节数uint64_t target_max_objects; //设置了cachePool的最大对象数量uint32_t cache_target_dirty_ratio_micro; // 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据uint32_t cache_target_dirty_high_ratio_micro; // 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据uint32_t cache_target_full_ratio_micro; // 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰uint32_t cache_min_flush_age; // 对象在 cache 中被刷入到 storage 层的最小时间uint32_t cache_min_evict_age; // 对象在 cache 中被淘汰的最小时间HitSet::Params hit_set_params; // HitSet 相关参数uint32_t hit_set_period; // 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的缓存统计信息uint32_t hit_set_count; // 记录系统保存最近的多少个 hit_set 记录bool use_gmt_hitset; // hitset archive 对象的命名规则 uint32_t hit_set_grade_decay_rate; //当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数uint32_t hit_set_search_last_n; //为温度累积，最多N次hit_sets 读写IOAdd Cache在 ceph&#x2F;src&#x2F;mon&#x2F;OSDMonitor.cc 中实现了 add-cache 命令，从命令行中获取对应的参数并绑定 Tier 关系 选择 Cache PoolCache Tier的应用主要体现在计算OSD的过程中，通过判断basepool的参数，来决定是否要更新targetpool：读操作时，如果有read_tier，则更新为read_tier pool；写操作时，如果有write_tier，则更新为write_tier pool。read_tier和write_tier与pool是否开启Cache Tier有关。 在 ceph&#x2F;src&#x2F;osdc&#x2F;Objecter.cc&#x2F;Objecter::_calc_target中指定目标存储池为 Cache Pool，设置之后由后续的代码在该 Pool 中执行 Crush 算法。 123456789101112131415161718//首先根据base_oloc.pool获取pool信息，获取pg_pool_t对象 const pg_pool_t *pi = osdmap-&gt;get_pg_pool(t-&gt;base_oloc.pool);// apply tiering 根据读写操作，分别设置需要操作的 tiert-&gt;target_oid = t-&gt;base_oid; #base_oid //读取的对象 #target_oid; //最终读取的目标对象t-&gt;target_oloc = t-&gt;base_oloc; #base_oloc //对象的pool信息 #//target_oloc //最终目标对象的pool信息if ((t-&gt;flags &amp; CEPH_OSD_FLAG_IGNORE_OVERLAY) == 0) &#123;//检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值。if (is_read &amp;&amp; pi-&gt;has_read_tier()) t-&gt;target_oloc.pool = pi-&gt;read_tier; //如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值。if (is_write &amp;&amp; pi-&gt;has_write_tier()) t-&gt;target_oloc.pool = pi-&gt;write_tier;pi = osdmap-&gt;get_pg_pool(t-&gt;target_oloc.pool);if (!pi) &#123; t-&gt;osd = -1; return RECALC_OP_TARGET_POOL_DNE;&#125;&#125; osd 先接收到客户端发送来的请求，然后OSD::dequeue_op()调用 PrimaryLogPG:: do_request()——&gt;PrimaryLogPG::do_op()中处理，这都是正常的一个 pool 处理请求的流程，在 do_op 中来看看不同于其他普通 pool 的处理。如果开启了Cache Tier，将会在do_op中执行以下操作： 首先判断hit_set中是否包含待操作的对象（hit_set-&gt;contains(obc-&gt;obs.oi.soid)），如果不包含，则把对象添加到hit_set中。添加对象后，如果hit_set满了，或者hit_set超时，则调用hit_set_persist()。 执行agent_choose_mode()，设置agent相关参数，如flush_mode、num_objects、num_bytes等。 执行maybe_handle_cache()。这里处理cache执行逻辑。 如果maybe_handle_cache()中调用maybe_handle_cache_detail()，如果成功处理了op请求，则直接return，否则会继续执行后续操作（说明不需要从datapool读取数据或者转发请求到datapool，可以直接在此osd命中查询的对象），由本OSD执行读取操作。 HitSet在 write back&#x2F;read forward&#x2F;read proxy 模式下需要 HitSet 来记录缓存命中。 HitSet 用于跟踪和统计对象的访问行为，记录对象是否存在缓存中。定义了一个缓存查找到抽象接口，目前提供了三种实现方式：ExplicitHashHitSet，ExplicitObjectHitSet，BloomHitSet ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h 定义了抽象接口，同时该头文件中包含了具体的 HitSet 实现 ExplicitHashHitSet ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitHashHitSet 基于对象的 32 位 HASH 值的 set 来记录对象的命中，每个对象占用 4 bytes 内存空间 优点：空间占用相对较少，但需要根据 HASH 进行全局的扫描遍历比较 ExplicitObjectHitSet ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitObjectHitSet 使用一个基于 ceph&#x2F;src&#x2F;common&#x2F;hobject 的 set 来记录对象的命中，占用的内存取决于对象的关键信息的大小 使用内存中缓存数据结构来进行判断带来的优点就是实现相对简单直观，但占用的内存空间相对较大 BloomHitSet ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class BloomHitSet 采用了压缩的 Bloom Filter 的方式来记录对象是否在缓存中，进一步减少了内存占用空间 Cache Tier的初始化 src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::hit_set_setup()用来创建并初始化HisSet对象 src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_setup()完成agent相关的初始化工作 Cache Pool 请求处理Cache 的相关请求处理可以通过do_op()进行梳理，主要包含了 agent_choose_mode()和 maybe_handle_cache() 两个主要方法。(src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;do_op(OpRequestRef &amp;)) agent_choose_mode(bool restart, OpRequestRef op) src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;agent_choose_mode 该函数主要计算一个 PG 的 flush_mode 和 evic_mode 的参数值。 返回值如果为 True，表明该请求 Op 被重新加入请求队列（由于 EvictMode 为 Full），其他情况返回 false。 maybe_handle_cache(…) src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;maybe_handle_cache()调用maybe_handle_cache_detail(） 处理有关cache的读写请求 Cache flush &amp; evictcachePool空间不够时，需要选择一些脏数据对象会刷到数据层，即flush操作；将一些clean对象从缓存层剔除，以释放更多的缓存空间，即evict操作。这两种操作都是在后台线程完成的。flush操作和evict操作算法的好坏决定了Cache Tier的缓存命中率。evict是针对cachepool中已经过期或过冷的数据，只需要把它从cachepool中删除即可，evict操作通常会影响缓存命中率。flush是把脏数据刷新到storagePool，flush操作通常不会直接影响缓存命中率。flush操作是将缓存中的数据写回到持久存储介质中，从而保证数据的一致性，但并不会直接影响缓存的访问，脏数据是只保存在cachePool中，经过修改后，还未写入storagePool的数据。 数据结构src&#x2F;osd&#x2F;osd.h&#x2F;OSDServices ：定义了 AgentThread 后台线程，用于完成 flush 和 evict 操作：一是把脏对象从cachePool层适时地会刷到basePool层；二是从cachePool层剔除掉一些不经常访问的clean对象。 1234567891011121314Mutex agent_lock; // agent 线程锁，保护下面所有数据结构Cond agent_cond; // 线程相应的条件变量map&lt;uint64_t, set&lt;PGRef&gt; &gt; agent_queue; // agent线程的工作队列，保存了OSD中所有归属于cachePool的淘汰或者回刷所需的 PG 集合，根据PG集合的优先级，保存在不同的map中set&lt;PGRef&gt;::iterator agent_queue_pos; //当前在扫描的PG集合的一个位置bool agent_valid_iterator; //只有agent_valid_iterator为true时，agent_queue_pos指针才有效，否则从集合的起始处开始扫描int agent_ops; // 所有正在进行的回刷和淘汰操作int flush_mode_high_count; //一旦FLUSH_MODE_HIGH有了一个pg，就可以高速刷新对象set&lt;hobject_t&gt; agent_oids; // 所有正在进行的 agent 操作（回刷或者淘汰）的对象bool agent_active; // agent 是否有效struct AgentThread : public Thread&#123;&#125; agent_thread; // agent 线程，专门用来处理cache tier数据迁移的线程，线程名叫：osd_srv_agent。其作用就是循环遍历agent_queue中的所有pg，并对他们执行agent_work()操作。osd_srv_agent线程是一个OSD上所有PG公用的，为了保证效率，设置了严格的限流参数：osd_pool_default_cache_max_evict_check_size限制依次遍历对象的总数，达到后立刻切换退出循环在osd_srv_agent中切换PG；osd_agent_max_ops设置了一个循环中最多能够处理几次flush或者evict操作。bool agent_stop_flag; // agent 停止的标志 SafeTimer agent_timer; //agent相关定时器：当扫描一个 PG 对象时，该对象既没有剔除操作，也没有回刷操作，就停止 PG 的扫描，把该 PG 加入到定时器中，5S 后继续 src&#x2F;osd&#x2F;TierAgentState.h：TierAgentState用来保存PG相关的agent信息。 123456789hobject_t position; //PG内扫描的对象位置int started; //PG里所有对象扫描完成后，所发起的所有的agent操作数目。如果没有agent操作，就需要延迟一段时间hobject_t start; //本次扫描起始位置bool delaying; //是否延迟pow2_hist_t temp_hist; //历史统计信息int hist_age;map&lt;time_t,HitSetRef&gt; hit_set_map; //Hitset的历史记录list&lt;hobject_t&gt; recent_clean; //最近处于clean的对象unsigned evict_effort; //应该驱逐的对象的大致比例（假设它们均匀分布） flush&#x2F;evict 执行入口src&#x2F;osd&#x2F;osd.cc&#x2F;OSDService::agent_entry：agent_entry 是 agent_thread 的入口函数，它在后台调用pg-&gt;agent_work()，agent_queue的改变是在PrimaryLogPG::agent_choose_mode函数中改变的 src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_work：遍历PG中所有对象，去寻找已经过期的、失效的需要flush或者evict的对象并对它们执行相应操作。 扫描本PG的对象，从 agent_state-&gt;position 开始扫描，结果保存在 ls 中 12vector&lt;hobject_t&gt; ls;int r = pgbackend-&gt;objects_list_partial(agent_state-&gt;position, ls_min, ls_max, &amp;ls, &amp;next); 对扫描的 ls 对象做相应的检查，执行 evict 操作和 flush 操作 1234567for (vector&lt;hobject_t&gt;::iterator p = ls.begin();p != ls.end(); ++p) if (agent_state-&gt;evict_mode != TierAgentState::EVICT_MODE_IDLE &amp;&amp; agent_maybe_evict(obc, false)) ++started;else if (agent_state-&gt;flush_mode!=TierAgentState::FLUSH_MODE_IDLE&amp;&amp;agent_flush_quota&gt;0&amp;&amp;agent_maybe_flush(obc)) &#123; ++started; --agent_flush_quota; &#125; 真正执行操作的方法 evict：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_evict flush：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_flush start_flush：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_flush 该函数完成实际的 flush 操作 start_manifest_flush：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_manifest_flush 真正刷回数据之前的数据准备 do_manifest_flush：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::do_manifest_flush 真正刷回数据的过程 flush 操作最终是以 Op 请求的方式传递到底层存储层的，也就意味着需要再执行一次 Ceph 存储池写数据的相关逻辑。Ceph的Cache Tier功能目前在对象访问频率和热点统计上的实现都比较简单，可以通过基于自学习的Cache算法提升缓存命中率。 agent_state在每个函数中都起到决定性地位：在agent_work中，agent_state-&gt;evict_mode和agent_state-&gt;flush_mode的值决定要不要进行evict和flush判断。在agent_maybe_evict和agent_maybe_flush中agent_state-&gt;evict_mode的值决定要不要直接执行evict或者flush。而agent_state值的计算过程是在agent_choose_mode函数中。agent_choose_mode函数计算一个PG的flush和evict行为的相关参数。该函数主要完成以下任务： 统计当前PG中dirty object数量和当前PG中所有的object数量；（dirty object指的是脏数据对象) 统计当前PG中dirty object占用的字节数和当前PG中所有object占用的总的字节数； 分别从object数量角度和object占用的字节数角度计算dirty占比和full占比； 计算当前flush mode和evict mode； 更新agent_state-&gt;flush_mode和agent_state-&gt;evict_mode； 根据当前flush mode和evict mode决定是要将当前PG加入到待处理的PG队列中； 从agent_choose_mode最后可以看到，如果缓存池需要flush或者evict，需要将待处理的PG加入到agent_queue队列中，这一动作是最终通过调用_enqueue函数实现，该函数主要完成以下任务： src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_enqueue 判断是否需要调整agent线程要处理哪个pg set； 将待处理的pg加入到pg set中； 唤醒agent线程，执行flush或者evict任务； 从agent_choose_mode最后可以看到，如果缓存池需不需要flush或者evict，但是如果之前agent线程有处理过该PG，需要将待处理的PG从agent_queue队列中移除掉，这一动作最终通过调用_dequeue函数实现，该函数主要完成以下任务： src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_dequeue 根据old_priority从agent_queue队列中获取到相应的pg set； 在pg set中查找要移除的PG；如果找到了，从pg set中删除，并调整下一个要处理的PG； 如果删除之后的pg set没有任何一个PG，需要从agent_queue队列中移除，并调整下一个要处理的pg set； agent_choose_mode流程图agent_entry流程图","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph Cache Tier使用介绍","slug":"Ceph-Cache-Tier使用介绍","date":"2022-08-25T08:45:47.000Z","updated":"2024-09-01T13:33:52.799Z","comments":true,"path":"Ceph-Cache-Tier使用介绍/","permalink":"https://watsonlu6.github.io/Ceph-Cache-Tier%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1、Ceph Cache Tier介绍缓存层(Ceph Cache Tier)为 Ceph 客户端提供了存储在后备存储层中的一部分数据的更好 I&#x2F;O 性能。缓存分层涉及创建一个相对较快&#x2F;昂贵的存储设备池（例如固态硬盘），配置为缓存层，以及一个后备池，该池由纠删码或相对较慢&#x2F;更便宜的设备组成，配置为经济的存储层。Ceph 对象处理器决定对象的存放位置，而缓存代理负责决定何时将对象从缓存中刷新到后备存储层。因此，缓存层和后备存储层对 Ceph 客户端完全透明。缓存分层代理会自动处理缓存层和后备存储层之间的数据迁移。不过，管理员可以通过设置缓存模式来配置这种迁移方式。 写回模式 (writeback mode)： 如果基础层和缓存层被配置为写回模式，Ceph 客户端每次将数据写入时会从基础层接收到 ACK 确认。然后，缓存分层代理会判断是否设置了 osd_tier_default_cache_min_write_recency_for_promote。如果已经设置，并且在指定时间间隔内数据被写入的次数超过设定值，那么数据将被提升到缓存层。当 Ceph 客户端需要访问存储在基础层的数据时，缓存分层代理会从基础层读取数据并返回给客户端。当数据从基础层读取时，缓存分层代理会查阅 osd_tier_default_cache_min_read_recency_for_promote 的值，并决定是否将数据从基础层提升到缓存层。当数据从基础层提升到缓存层后，Ceph 客户端可以通过缓存层对其进行 I&#x2F;O 操作。这种模式非常适合处理可变数据（例如，照片&#x2F;视频编辑，事务性数据）。 读代理模式 (readproxy mode)： 该模式将使用缓存层中已存在的对象，但如果缓存中不存在该对象，请求将被代理到基础层。这在从写回模式过渡到禁用缓存的过程中非常有用，因为它允许在缓存被清空的同时，工作负载能够正常运行，而不向缓存添加任何新对象。 只读模式 (readonly)： 该模式在读操作时将对象提升到缓存层；写操作则会被直接转发到基础层。该模式适用于无需存储系统强制保持一致性的只读工作负载。（警告：当对象在基础层中被更新时，Ceph 不会尝试将这些更新同步到缓存中的相应对象。由于该模式被认为是实验性的，因此启用时必须传递 --yes-i-really-mean-it 选项。） 无缓存模式 (none)： 该模式用于完全禁用缓存。 2、使用Ceph Cache Tier要设置缓存分层，您必须拥有两个池。一个将作为后备存储，另一个将作为缓存。在后续示例中，我们将缓存池称为 hot-storage，后备池称为 cold-storage。 2.1、设置后备存储池设置后备存储池通常涉及以下两种场景之一： 标准存储： 在这种情况下，池在 Ceph 存储集群中存储对象的多个副本。 纠删码： 在这种情况下，池使用纠删码来更高效地存储数据，代价是会有一些性能上的折扣。 在标准存储场景中，可以设置一个 CRUSH 规则来确定故障域（例如，osd、主机、机箱、机架、行等）。当规则中的所有存储驱动器尺寸、速度（包括 RPM 和吞吐量）和类型一致时，Ceph OSD 守护进程的性能最佳。关于创建规则的详细信息，请参阅 CRUSH Maps。一旦创建了规则，就可以创建后备存储池。 2.2、设置缓存池设置缓存池的过程与标准存储场景相同，但有以下不同：缓存层的驱动器通常是高性能驱动器，位于各自的服务器中，并拥有自己的 CRUSH 规则。设置此类规则时，应考虑拥有高性能驱动器的主机，同时排除没有这些驱动器的主机。 2.3、创建缓存层设置缓存层需要将一个后备存储池与一个缓存池关联起来： 1ceph osd tier add &#123;storagepool&#125; &#123;cachepool&#125; 要设置缓存模式，请执行以下命令： 1ceph osd tier cache-mode &#123;cachepool&#125; &#123;cache-mode&#125; 缓存层会覆盖后备存储层，因此还需要执行一个额外的步骤：必须将所有客户端流量从存储池直接引导到缓存池。为此，请执行以下命令： 1ceph osd tier set-overlay &#123;storagepool&#125; &#123;cachepool&#125; 2.4、配置缓存层缓存层有多种配置选项。您可以使用以下方式设置缓存层配置选项： 1ceph osd pool set &#123;cachepool&#125; &#123;key&#125; &#123;value&#125; 目标大小和类型Ceph 的生产缓存层使用布隆过滤器作为 hit_set_type： 1ceph osd pool set &#123;cachepool&#125; hit_set_type bloom hit_set_count 和 hit_set_period 定义了要存储的 HitSets 数量以及每个 HitSet 应覆盖的时间长度： 123ceph osd pool set &#123;cachepool&#125; hit_set_count 12ceph osd pool set &#123;cachepool&#125; hit_set_period 14400ceph osd pool set &#123;cachepool&#125; target_max_bytes 1000000000000 注意 较大的 hit_set_count 会消耗更多的 RAM，影响 ceph-osd 进程的内存使用。 通过对访问时间的分类，Ceph 可以判断 Ceph 客户端是否在一定时间内访问了一个对象至少一次或多次（即“年龄” vs “热度”）。 读写缓存设置min_read_recency_for_promote 定义了在处理读操作时检查对象存在性的 HitSets 数量。检查结果用于决定是否异步提升对象。其值应在 0 到 hit_set_count 之间。如果设置为 0，对象将始终被提升；如果设置为 1，则仅检查当前 HitSet，如果对象在当前 HitSet 中，将被提升，否则不提升。对于其他值，将检查对应数量的历史 HitSets，如果对象出现在最近的min_read_recency_for_promote 个 HitSets 中，将会被提升。min_write_recency_for_promote定义了写操作可以设置类似的参数。 12ceph osd pool set &#123;cachepool&#125; min_read_recency_for_promote 2ceph osd pool set &#123;cachepool&#125; min_write_recency_for_promote 2 注意 周期越长、min_read_recency_for_promote 和 min_write_recency_for_promote 值越高，ceph-osd 守护进程消耗的 RAM 就越多。特别是在代理活动冲刷或驱逐缓存对象时，所有 hit_set_count 个 HitSets 都会加载到 RAM 中。 缓存大小设置缓存分层代理执行两个主要功能： 冲刷： 代理识别已修改（或脏）对象并将其转发到存储池以供长期存储。 驱逐： 代理识别未修改（或干净）的对象，并从中驱逐最少最近使用的对象。 绝对大小设置缓存分层代理可以基于字节总数或对象总数来冲刷或驱逐对象。要指定最大字节数，请执行以下命令： 1ceph osd pool set &#123;cachepool&#125; target_max_bytes &#123;bytes&#125; 例如，要在 1 TB 时进行冲刷或驱逐，请执行： 1ceph osd pool set hot-storage target_max_bytes 1099511627776 要指定最大对象数量，请执行以下命令： 1ceph osd pool set &#123;cachepool&#125; target_max_objects &#123;objects&#125; 例如，要在 100 万个对象时进行冲刷或驱逐，请执行： 1ceph osd pool set hot-storage target_max_objects 1000000 注意 Ceph 无法自动确定缓存池的大小，因此这里需要对绝对大小进行配置，否则冲刷&#x2F;驱逐将无法正常工作。如果同时指定了两个限制，当任一阈值触发时，缓存分层代理将开始冲刷或驱逐。 仅当达到 target_max_bytes 或 target_max_objects 时，所有客户端请求才会被阻塞。 相对大小设置缓存分层代理可以相对于缓存池的大小（由绝对大小设置中的 target_max_bytes &#x2F; target_max_objects 指定）来冲刷或驱逐对象。当缓存池包含一定比例的已修改（或脏）对象时，缓存分层代理将冲刷它们到存储池。要设置 cache_target_dirty_ratio，执行以下命令： 1ceph osd pool set &#123;cachepool&#125; cache_target_dirty_ratio &#123;0.0~1.0&#125; 例如，将值设置为 0.4 当已修改（脏）对象达到缓存池容量的 40% 时开始冲刷： 1ceph osd pool set hot-storage cache_target_dirty_ratio 0.4 当已修改（脏）对象达到一定比例时，以更高速度冲刷这些对象。设置 cache_target_dirty_high_ratio： 1ceph osd pool set &#123;cachepool&#125; cache_target_dirty_high_ratio &#123;0.0~1.0&#125; 例如，将值设置为 0.6 当已修改（脏）对象达到缓存池容量的 60% 时开始积极地冲刷脏对象。显然，最好将值设置在 dirty_ratio 和 full_ratio 之间： 1ceph osd pool set hot-storage cache_target_dirty_high_ratio 0.6 当缓存池达到一定容量比例时，缓存分层代理将驱逐对象以保持空闲容量。设置 cache_target_full_ratio，执行以下命令： 1ceph osd pool set &#123;cachepool&#125; cache_target_full_ratio &#123;0.0~1.0&#125; 例如，将值设置为 0.8，当未修改（干净）对象达到缓存池容量的 80% 时开始冲刷： 1ceph osd pool set hot-storage cache_target_full_ratio 0.8 缓存年龄可以指定对象在缓存分层代理将最近修改（或脏）对象冲刷到后备存储池之前的最小年龄： 1ceph osd pool set &#123;cachepool&#125; cache_min_flush_age &#123;seconds&#125; 例如，在 10 分钟后冲刷修改（或脏）对象，请执行： 1ceph osd pool set hot-storage cache_min_flush_age 600 可以指定对象在从缓存层驱逐之前的最小年龄： 1ceph osd pool &#123;cache-tier&#125; cache_min_evict_age &#123;seconds&#125; 例如，在 30 分钟后驱逐对象，请执行： 1ceph osd pool set hot-storage cache_min_evict_age 1800 移除缓存层移除缓存层的步骤取决于缓存是回写类型还是只读类型。移除只读缓存由于只读缓存没有已修改的数据，您可以在不丢失缓存中对象的任何最新更改的情况下禁用并移除它。将缓存模式更改为 none 以禁用它： 1ceph osd tier cache-mode &#123;cachepool&#125; none 从后备池中移除缓存池： 1ceph osd tier remove &#123;storagepool&#125; &#123;cachepool&#125; 移除回写缓存由于回写缓存可能包含已修改的数据，因此在禁用并移除它之前，必须采取措施确保不会丢失缓存中对象的任何最新更改。将缓存模式更改为 proxy，以便新对象和已修改对象将被冲刷到后备存储池： 1ceph osd tier cache-mode &#123;cachepool&#125; proxy 确保缓存池已经被冲刷。此过程可能需要几分钟： 1rados -p &#123;cachepool&#125; ls 如果缓存池中仍有对象，可以手动冲刷它们。例如： 1rados -p &#123;cachepool&#125; cache-flush-evict-all 移除覆盖，以便客户端不会将流量引导到缓存中： 1ceph osd tier remove-overlay &#123;storagetier&#125; 最后，从后备存储池中移除缓存层池： 1ceph osd tier remove &#123;storagepool&#125; &#123;cachepool&#125; 3、注意事项缓存分层会降低大多数工作负载的性能。在使用此功能之前，应格外谨慎。 依赖于工作负载： 缓存是否能够提升性能高度依赖于工作负载。由于将对象移入或移出缓存会产生一定的成本，缓存分层只有在数据集的访问模式存在较大偏斜时才有效，例如大多数请求集中访问少量对象。缓存池的大小应足够大，以捕获工作负载的工作集，从而避免缓存抖动。 难以基准测试： 大多数用户用来衡量性能的基准测试在启用缓存分层时会显示出较差的性能，部分原因是这些测试很少将请求集中在少量对象上，缓存“预热”需要较长时间，而且预热的成本可能很高。 通常更慢： 对于不适合缓存分层的工作负载，其性能通常会比没有启用缓存分层的普通 RADOS 池更慢。 librados 对象枚举： librados 级别的对象枚举 API 在存在缓存时并不保证一致性。如果你的应用程序直接使用 librados 并依赖对象枚举，那么缓存分层可能不会如预期工作。（对于 RGW、RBD 或 CephFS，这不是问题。） 复杂性： 启用缓存分层意味着 RADOS 集群内将使用大量额外的机制和增加的复杂性。这增加了你可能会遇到其他用户尚未遇到的系统错误的概率，并使你的部署面临更高的风险。 3.1、已知表现良好的工作负载 RGW 时间偏斜： 如果 RGW 工作负载的情况是几乎所有读操作都针对最近写入的对象，那么一个简单的缓存分层配置可以很好地工作，该配置在可配置的时间后将最近写入的对象从缓存层降级到基础层。 3.2、已知表现不佳的工作负载以下配置已知与缓存分层配合表现不佳。 RBD 与复制缓存和纠删码基础： 这是一个常见的请求，但通常表现不好。即使是相对倾斜的工作负载，仍然会将一些小的写入发送到冷对象上，而由于纠删码池尚不支持小的写操作，因此必须将整个对象（通常为 4 MB）迁移到缓存中，以满足一个小的（通常为 4 KB）写入请求。只有少数用户成功部署了这种配置，而且对他们而言，这仅在数据极为冷（备份）并且完全不敏感于性能的情况下有效。 RBD 与复制缓存和基础层： 使用复制基础层的 RBD 比使用纠删码基础层的表现稍好，但仍然高度依赖于工作负载中的偏斜程度，并且非常难以验证。用户需要对其工作负载有很好的理解，并需要仔细调整缓存分层参数。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"缓存基础与Ceph分层存储","slug":"缓存基础与Ceph分层存储","date":"2022-08-10T11:59:00.000Z","updated":"2024-09-01T13:34:14.905Z","comments":true,"path":"缓存基础与Ceph分层存储/","permalink":"https://watsonlu6.github.io/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/","excerpt":"","text":"缓存基础 缓存命中率：表示从缓存中获取数据的成功率，即缓存命中的次数与总访问次数的比值。缓存命中率越高，表示缓存系统的效率越高，能够更快地响应用户的请求。 缓存失效率：表示从缓存中获取数据失败的次数与总访问次数的比值。缓存失效率越高，表示缓存系统的效率越低，需要从持久存储介质中读取数据的次数也越多，可能会导致系统的响应速度变慢。 缓存容量：指缓存系统能够存储数据的最大容量。缓存容量的大小会影响缓存系统的性能和可靠性，如果缓存容量不足，可能会导致缓存系统频繁地进行evict操作，从而影响系统的响应速度和可用性。 缓存算法：指缓存系统用于决定哪些数据被缓存，哪些数据被删除的算法。常见的缓存算法包括LRU（最近最少使用）、LFU（最不经常使用）、FIFO（先进先出）等。 脏数据（Dirty Data）：指缓存中已经被修改但尚未被写回到持久存储介质（如磁盘）中的数据。这些数据需要及时写回到持久存储介质中以保证数据的一致性。常见的处理策略包括写回（write-back）和写直达（write-through）策略。 干净数据（Clean Data）：指缓存中未被修改或已经被写回到持久存储介质中的数据。干净数据在缓存系统中可以快速读取，减少写入操作，优先选择删除干净数据可以避免写回操作带来的额外开销。 evict操作：从缓存中移除某些数据，以释放缓存空间供其他数据使用。常用的策略包括LRU（Least Recently Used）等，根据最近最少使用的数据进行移除。 flush操作：将缓存中的数据立即写回到持久性存储介质（例如硬盘），以确保缓存中的数据与存储介质中的数据保持一致。 数据一致性和性能考虑 脏数据的处理：存在脏数据可能导致数据一致性问题和性能问题，因此需要及时处理脏数据。选择适当的写回策略可以平衡数据一致性和系统性能。 干净数据的优先删除：在缓存系统中，干净数据的存在可以提高系统性能，因为它们可以快速读取而不需要进行额外的写入操作。当需要从缓存中删除对象时，通常优先选择删除干净数据。 flush操作的选择：通常在以下情况下使用flush操作： 数据一致性要求高的场景，如数据库应用 性能要求不高或系统关闭时需要保证数据的持久性 evict操作的选择：通常在以下情况下使用evict操作： 缓存空间不足，需要释放空间 数据访问模式固定或数据访问频率低 基于缓存替换算法（如LRU、LFU、FIFO等） 缓存替换算法 LRU（Least Recently Used）：根据最近的访问时间来决定删除哪些数据。 LFU（Least Frequently Used）：基于数据的访问频率选择删除数据。 FIFO（First In First Out）：按照数据进入缓存的时间顺序移除数据。 Random（随机）：随机选择数据进行删除，简单但效果不如其他算法。 性能优化 优化evict操作：通过使用动态策略（基于数据使用情况）和静态策略（基于数据属性），可以提升缓存性能。了解系统的负载和压力情况也有助于优化evict操作。 缓存命中率影响：evict操作可能导致缓存命中率下降，因为被删除的数据可能被访问到。flush操作通常不会直接影响缓存命中率，但需要高效的实现以避免影响系统性能。 这些基本要素和策略可以帮助优化缓存系统的性能和可靠性，根据具体的应用需求进行适当的调整和选择。 Ceph分层存储Cache Tier分层存储是存储领域中的一个重要分支，其思想基石是存储的金字塔模型——描述了快速设备通常容量小而性能高，慢速设备通常容量大而性能低。对于数据访问而言，通常在一段时间内，真实数据的访问是具有时间局部性和空间局部性的。时间局部性是指被访问的数据在短时间内可能再次被访问，空间局部性是指与被访问数据临近的数据有更大的概率被访问。故基于时间局部性理论产生了通常所说的缓存，如：cpu缓存、内存等；而基于空间局部性原理，产生了数据预取，如：指令预取（prefetch）、数据预读（read ahead）等。 目前Ceph的OSD主要可以基于SSD或者HDD的裸盘进行构建，机械盘通常比固态盘容量大、价格比固态盘低、但读写比固态盘慢，如何用机械盘和固态盘来提供一个高可靠、高性能、高性价比的分布式存储是需要解决的重要问题。如果全部基于SSD进行构建，其性能一定会最优，但是SSD价格昂贵，出于成本考虑，不可能全部采用SSD进行构建，那么SSD与HDD混合硬件架构就显得很有必要。 Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。 Ceph Cache Tier提供了快速存储池与慢速存储池间的分层缓存特性。通常来说，对于块存储用户而言，数据访问会有明显的时间局部性与空间局部性，故可以通过分层存储思想，改善资源配置及效率。Ceph提供了Cache Tier的解决方案，能够融合两种存储，通过合理配比提供容量与性能介于SSD与HDD之间的虚拟存储资源池。对于对象存储而言，目前主要对外提供基于S3与Swift restful api的访问接口。RGW对象存储可以通过对数据池进行Cache Tier，从而提高其访问效率。 在Ceph中，分层存储系统通过缓存和存储池的方式实现，热资源池可以将数据存储至那些管理SSD磁盘的OSD上，而冷资源池可以将数据存储至那些管理HDD磁盘的OSD上。若客户命中被访问的数据落在热资源池中，可以直接被访问，此时IO速度最快，接近SSD磁盘的性能。 若客户被访问的数据不落在热资源池中，出现缓存丢失的情况，需要转向去HDD盘上读取数据，而HDD盘处理请求访问速度为毫秒级别，故网络延时与请求处理延时可以近似忽略，认为其访问速度接近HDD磁盘的性能。这时候的处理分为两种：代理读写和数据拉取。当读写请求出现缓存丢失时，代理读写向后端请求冷数据，但缓存池不对数据进行缓存，直接将请求内容返回给客户端。 读写请求出现缓存丢失时，缓存池向后端请求冷数据，在向后端请求冷数据后，会将数据读入缓存池，继续处理客户端请求并返回请求内容。此外，短时间内被多次访问的数据会被认为是热数据而拉取到热池中，这将消耗HDD磁盘的读带宽与SSD磁盘的写入带宽。 另一方面，在热池中的数据，需要定期回写入冷池，此时，回写数据将暂用SSD与HDD磁盘的部分带宽，这个过程叫数据回写。 还未回写入冷资源池的数据，在热资源池中再次被修改，这种情况越多，缓存效率越高，即相当于热资源池带宽充分利用，帮助冷资源池挡掉了大量的写入带宽。可以简单的认为，有1%的数据是需要脏回刷的（即回刷后的1%数据为clean状态，所以后续的命中会是非脏命中），如果所有数据都不脏回刷，且都访问命中的话，那么脏命中率为100%。 根据上述原理，不难发现，Ceph Cache Tier的性能取决于访问命中率。访问命中率越高时，存储系统越接近SSD磁盘的性能；反之，访问命中率越低时，越接近HDD磁盘的性能。另一方面，在Ceph中，缓存粒度以对象方式进行拉取与回写，故在实际情况下，如果缓存丢失过多，将会有大量的数据会被拉取，从而占用SSD磁盘的带宽，使得其访问带宽比SATA磁盘更差。然而，在实际生产使用过程中，数据总使用量总是逐步增加的，与此同时，热数据的量也将逐步的增加。那么，在整个使用周期中，随着数据量的增加，就必然会经历以下过程：首先刚刚开始使用时，数据量还很少。此时，所有数据全部能够被缓存，数据命中率为100%，效果很好。随着总数据量与热数据量不断的增加，缓存池已经无法容纳所有数据，只能容纳较多的热数据，此时缓存命中率会随之逐步的下降。随着数据的进一步增加，缓存命中率低于某个临界值了，此时保持同样大小的缓存池已经无法给使用带来足够好的收益。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"存储系统缓存/分层相关论文","slug":"存储系统缓存相关论文","date":"2022-02-10T07:31:33.000Z","updated":"2024-08-04T07:59:18.239Z","comments":true,"path":"存储系统缓存相关论文/","permalink":"https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/","excerpt":"","text":"TDC: Pool-level object cache replacement algorithm based on temperature density 在原生Ceph系统的基础上，提出缓存池的基于热度密度缓存替换算法，计算每个对象消耗空间的热度密度，并以最低的热度密度驱逐对象。通过驱逐对命中率贡献不大的对象，提高缓存池的命中率以及分层存储性能。 在 Ceph 中，Cache Tier通过缓存机制和存储池方式的实现，其将热数据存储SSD池，冷数据存储HDD池。若客户访问的数据直接命中落在SSD池中，可以直接被访问，此时IO速度最快 ，接近SSD磁盘的性能。但如果被访问的数据不在SSD池中，需要转向去HDD池上读取数据，而HDD盘处理请求访问速度为毫秒级别，则认为其访问速度接近HDD磁盘的性能。 目前 Cache Tier 采用的是基于频率估计的类 LRU缓存替换算法，并未充分利用数据对象所携带的元数据信息，这种频率估计概率存在误差，缓存命中率性能有限，且很难达到理论极限。因此实际使用时缓存命中率较低，导致较长的 IO 路径，使得Cache Tier性能表现较差。为进一步提升缓存命中率，考虑 Cache Tier 数据对象可以携带更多信息的特点，提出基于热度密度的缓存替换算法(TDC)。对象的热度计算基于访问频率，而热度密度计算基于热度和缓存对象占用时空的比例。通过引入热度密度计算，可以更准确地评估对象对命中率贡献，从而更有效地驱逐对命中率贡献不大的对象。 在用户文件上传到Ceph集群时，Ceph通过调用file_to_extents()函数将文件分割成若干个对象。面对数目庞大的对象，为了计算每个对象的访问热度值，采用Multiple Bloomfilter记录存储池每个对象访问的频率，通过这种方式有效地捕获更细粒度的最近性和频率。 将数据对象在缓存池中花费的时间和占用缓存空间视为缓存成本，这样，将缓存池中的对象对缓存命中率的贡献转化成一种成本效益分析。热度密度就是一种综合考虑对象大小、访问频率和访问时间等因素的指标，可以用来评估每个对象对缓存命中率的贡献，并根据热度密度来进行缓存替换。整个图形的热度密度可以表示为所有命中对象的贡献之和除以所有对象的占用缓存资源之和。通过比较已缓存对象的热度密度，并按一定比例删除热度密度较低的对象。 A Survey on Tiering and Caching in High-Performance Storage Systems 论文讨论了针对高性能存储系统的缓存和分层解决方案研究。在第2节中，简要介绍了存储设备及其技术。在第3节中，讨论关于缓存解决方案及缓存算法的研究。在第4节中，讨论关于存储分层解决方案的研究。缓存和分层已被长期用于隐藏存储层次结构中慢速设备的长延迟。 基于响应时间，计算机存储系统被设计为有组织的多级层次结构，旨在提高整体性能和存储管理。不同类型的存储介质根据其性能、容量和控制技术指定为级别。通常，层次结构中级别越低，其带宽越小，存储容量越大。层次结构中有四个主要级别：处理器寄存器和缓存（SRAM、触发器或锁存缓冲区）、主存储器（DRAM）、辅助存储（SSD、HDD）、第三级存储（可移动存储设备）。图1概述了当前可用的和新兴的存储技术。表1比较了不同的计算机存储技术。 硬盘驱动器由固定在主轴周围的刚性快速旋转磁盘和使用致动器臂重新定位的磁头组成。数字数据以磁材料薄膜磁化转变的形式存储在每个磁盘上。HDD的机电方面和存储数据的串行化使得HDD比所提到的非易失性存储器技术慢几个数量级。然而，它的低价格和极高的密度使它成为二级和三级存储级别的理想选择。根据表1，HDD的容量可以比DRAM大1000倍，而操作延迟大约慢106倍。 IDC报告[58]预测到2020年，云将只触及数字世界的24%，13%将存储在云中，63%可能根本无法触及[58]。需要保护的数据的速度超过40%，甚至比数字世界本身还要快。因此，大部分数据通常存储在更便宜、更可靠和更大的设备中，而未经处理的部分数据则保存在快速存储介质中。因此，无疑需要具有缓存&#x2F;分层机制的混合存储系统 为了减轻慢设备的长延迟，可以在混合存储系统中使用缓存机制。缓存子系统有两个主要原则：1）在将原始数据保持在层次结构的中等级别时，缓存中存在一个处理不足的数据副本；以及2）缓存层中数据的生命周期短，并且它是临时的。 分层ARC（H-ARC）[12]缓存是一种基于NVM的缓存，它优化了ARC算法，以考虑最近、频率、脏和干净四种状态，并首先将缓存拆分为脏&#x2F;干净页缓存，然后将每个部分拆分为最近&#x2F;频率页缓存。基于与ARC类似的机制，它在每个级别上按层次调整每个部分的大小。因此，H-ARC在缓存中保持较高频率的脏页的时间更长。 如今，多层存储系统中使用了许多具有不同特性和容量的存储介质。缓存和分层之间的主要区别在于，在缓存系统中，数据的副本保存在缓存中，而在分层系统中，原始数据通过升级和降级两种操作在多个层之间迁移。数据根据应用程序需求和可用层的特性进行分类，通常分为热层和冷层。热数据驻留在性能层，冷数据留在容量层。考虑到随机性、传输速度等多种因素，可能有两个以上的层。 eMRC: Efficient Miss Ratio Approximation for Multi-Tier Caching 研究高效的多层缓冲命中率分析技术 未命中率曲线（MRC）是捕获工作负载特性和调整系统行为的有用工具。MRC表示缓存大小和相应的缓存未命中率之间的关系。假设随着时间的推移，工作负载相对稳定，从观察到的IO跟踪得出的MRC对于单层缓存有效工作[13]。 许多存储缓存分配方法使用未命中率曲线（MRC）来提高缓存效率。然而，他们只关注单层缓存架构，并需要整个MRC作为缓存管理的输入，而现代数据中心采用分层缓存架构以最大限度地提高资源利用率。由于每个缓存层的逐出策略和容量不同，为多层缓存生成MRC（我们称之为未命中率函数）要困难得多。我们引入eMRC，一种多维未命中率近似技术，以实现多层缓存的高效MRC生成。论文使用了一种新颖的多维性能悬崖去除方法和凸包近似技术，以使用少量采样点有效地生成没有悬崖的多维MRC。 多层缓存需要一种有效的、低开销的缓存管理方案，因为多层的任意缓存配置可能会因其副作用而对租户不利[27]。为具有不同服务级别目标（SLO）的租户配置缓存需要对缓存的每一层进行高效、准确的缓存性能分析。 扩展：已经有很多关于MRC(miss ratio curves)的理论，来对上层缓存进行建模，得出程序分配缓存大小和性能的关系模型：MissRatio&#x3D;F(capacity)。基本分为两种方法：1、通过数据重新访问距离(reuse distance)，来建立MRC模型。2、通过数据重新访问时间(reuse time)，来建立MRC模型。 PHOEBE: Reuse-Aware Online Caching with Reinforcement Learning for Emerging Storage Models NVMe和SSD是新兴存储技术的公认代表，具有数据持久性、高访问速度、低功耗和字节寻址能力。高性能采用这些技术的一个关键问题是如何正确定义智能缓存层，以便能够很好地弥补新兴技术和主存储器之间的性能差距。快速的主机端内存和慢速的后端存储驱动器之间的延迟差异很大，存储I&#x2F;O仍然是性能瓶颈，这导致了难以置信的长I&#x2F;O等待时间和大量CPU闲置浪费。为了缓解这种延迟差异，缓存层被广泛用于驻留在主存储器和后端存储驱动器之间。缓存系统的性能通常受到三个因素的影响：数据分配策略、数据热识别的准确性和数据驱逐策略。数据分配策略基本上控制数据流，并确定各种数据的接纳，例如只读、只读或两者兼而有之；数据热识别的高精度可以防止不必要数据对缓存的污染，通过局部保护提高缓存性能；数据驱逐策略决定在缓存已满时驱逐哪个数据块，从而间接增加了缓存的有效容量。这三个因素关注三个不同的方面，具有高度相关性。值得一提的是，传统的缓存策略，如LRU和LFU，并不是一个符合所有这些因素的通用解决方案（Li等人2019；Li和Gu 2020；Liu等人2020）。 PHOEBE是一种基于强化学习的在线缓存的可重用优化方案，适用于广泛的新兴存储模型。通过与缓存环境和数据流的持续交互，PHOEBE能够从单个跟踪中提取关键的时间数据依赖性和相对位置信息，随着时间的推移变得越来越智能。实验结果表明，PHOEBE能够将LRU和最先进的基于在线学习的缓存策略Belady最优策略之间的缓存未命中率差距分别缩小70.3%和52.6%。 PHOEBE预测了一个新定义的指标，即停留优先级，以表示每个数据块的相对重要性，而不是显式预测重用距离，重用距离可能是无界值，从而增加了高精度预测的难度和复杂性。当驱逐事件发生时，缓存根据其停留优先级值替换数据块（驱逐具有最低停留优先级的数据块），旨在最大化缓存命中率。停留优先级值具有时间滞后特性，在过时时间戳处的高优先级值不能在最新时间戳处保持同样高，因此它们通常与相应的时间戳组合以得出最终驱逐决定。PHOEBE关注9个特征来提取同时考虑全局和局部模式的重用信息。前六个特征和最后一个是全局特征；第7和第8特征是从当前数据块之前的滑动窗口收集的局部特征。数据块地址、数据块地址增量、频率、重复使用距离、最终重复使用距离、平均重复使用距离、滑动窗口中的频率、滑动窗口中的缓存未命中数、优先级值 将在线缓存问题建模为马尔可夫决策过程 LeCaR（Vietri等人，2018）：一种基于在线学习的缓存策略，根据学习到的概率在LRU和LFU缓存算法之间切换。 相关工作：将机器学习应用于缓存优化有两个主要途径：设计智能预取策略或改进缓存替换策略。 Sprout: A functional caching approach to minimize service latency in erasure-coded storage 利用缓存优化纠删码存储的性能，没有优化缓存策略。 论文提出一种新的具有纠删码存储的缓存框架，称为功能缓存。功能缓存涉及在缓存中使用纠删码块，使得存储节点中的块和缓存组合形成的代码是最大距离可分离（MDS）纠删码。 SSD-HDD混合存储中基于顺序封装的缓存取出 论文提出了一种基于顺序打包的缓存逐出技术，该技术将垃圾收集（GC）块中的相邻冷数据页与位于其他SSD块中的相邻冷数据页数据分组。然后，打包这些数据页一起flush到较低级别的HDD存储中，以充分利用HDD的高顺序带宽。该方法可以减少写放大对SSD缓存的负面影响，并有助于提高SSD-HDD混合存储的I&#x2F;O性能。 Shi等人[13]提出了SSDUP+，该SSDUP＋采用SSD设备来缓冲随机访问的数据，并且顺序访问的数据被刷新到磁盘的低级别存储。在SSDUP+中，需要SSD缓存来缓存热读数据，尽管它们揭示了序列特征并直接刷新到HDD上。也就是说，如果SSD缓存已满，SSDUP+必须使用最近最少使用（LRU）策略来处理缓存逐出。 将热数据放在快速存储中，将冷数据放在慢速存储中并不是一个新想法，分层存储管理通常采用快速存储作为慢速存储的缓冲[5]。已经推出了许多结合HDD和SSD的混合存储解决方案，以提高读写吞吐量[11、12、14、15]。Chen等人[11]提出Hystor将低成本HDD和高速SSD相结合，以识别关键数据（例如元数据），从而将其保存在SSD中以快速响应。此外，它利用SSD作为回写缓冲区来吸收写请求，从而产生更好的写性能。HotDataTrap[20]建议仅缓冲SSD缓存中的热数据，并将冷数据直接刷新到HDD，这为热数据存储在缓存空间中提供了更多机会。类似地，Zhang等人[21]提出了一种基于机器学习的混合存储系统写策略。具体来说，它使用机器学习来识别只写数据，并将其直接刷新到HDD中，以最大限度地减少SSD的写入流量。混合存储系统的性能受到数据刷新例程或缓存逐出方案的严重影响[2，8]。 SeqPack的Hot Read&#x2F;Write Separate模块维护两个固定长度的LRU链接列表，以分别记录最近读取和写入的数据页，用于筛选热读取数据页而不是热写入。具体而言，在发生读或写访问之后，可以将数据页插入或移动到相应链接列表的开头。然后，两个LRU链接列表都维护最近访问的读写页，这样我们可以筛选热读数据页，但不筛选热写数据页，它们可以始终缓存在SSD缓存中，同时其他数据页被视为顺序打包的候选页。sequential packer模块依赖于所提出的顺序打包模型，通过将GC块中的弹出页面与其他SSD块中的冷数据页面打包，将许多随机写入分组为大型顺序写入。GC Selector模块以较小的成本释放SSD空间，引入了一种基于成本的选择方法来定位GC目标块， 性能指标：I&#x2F;O响应时间、缓存命中率、长尾延迟。 Improving in-memory file system reading performance by fine-grained user-space cache mechanisms（大数据场景的缓存优化） 随着服务器的内存容量越来越大，分布式内存文件系统已被广泛使用，该系统使应用程序能够快速与数据交互。然而，现有的分布式内存文件系统在小数据读取中仍然面临数据访问性能低的问题（非混合存储），这严重降低了它们在许多重要的大数据场景中的可用性。论文分析了影响内存文件读取性能的因素，并提出了一种两层用户空间缓存管理机制：在第一层，我们缓存数据包引用以减少频繁的页面故障中断（包级缓存）；在第二层，我们缓存和管理小文件数据单元，以避免冗余的进程间通信（对象级缓存）。设计了一个基于子模块函数优化理论的细粒度缓存模型，以有效地管理客户端具有部分重叠片段的可变长度缓存单元，更准确地识别热碎片，避免不必要的RPC通信。。重点是设计可变长度缓存块的管理机制和替换策略。 [15]提出了一种缓存模型，该模型使用不同的LRU队列来管理不同大小的文件。因此，它可以减少小文件被部分锁定的频率。为了使应用程序能够从客户端节点读取和写入数据，而不会失去全局文件系统命名空间的优势。传统的缓存替换策略包括FIFO、LRU[17]、LFU[18]、ARC[19]、FBR[20]和2Q[21]。根据[19]的结果，ARC通过复杂的自调整机制改进了基本的LRU策略，在各种工作负载上优于上述算法。然而，对大数据工作负载的实验表明，即使使用非常大的缓存空间，传统的缓存方法仍然遭受相对较低的命中率[22]。为了进一步提高I&#x2F;O性能，研究人员提出了大量方法，这些方法通过专门的指标来替代缓存候选[23–26]。 许多智能技术应用于广泛领域[33-35]。受此启发，一些研究人员采用了先进的数学方法或机器学习模型来描述和分析缓存问题。例如，[24，36]考虑马尔可夫决策过程背景下的缓存替换问题，[37，38]提出了基于强化学习和长短期记忆神经网络的更复杂场景下的智能缓存替换框架。特别是，在这些算法中，基于概率模型的EVA[24]通过充分利用所有缓存单元的命中、逐出和年龄分布，实现了最佳性能。 数据压缩是另一种常用于优化缓存空间利用率的策略。通常，压缩用于优化存储级别的访问性能。事实上，压缩也可以用于优化缓存性能[45–48]。压缩可以扩大有效的缓存容量，因此，通过保存更多对象可以减少缓存未命中。然而，由于压缩&#x2F;解压缩过程，压缩方案引入了额外的访问延迟。更糟糕的是，由于压缩比不可预测，这可能会导致性能下降。 数据包级缓存机制：在分布式文件系统中，要读取的数据被拆分为数据包，以便在多次小规模读取时容错和提高性能。当读取文件时，客户端调用mmap()将数据包映射到进程的虚拟地址空间，并调用munmap()读取后立即释放映射区域。在某种情况下，每个计算任务都将调用mmap()和munmap()，导致多页错误中断。为了提高读取性能，论文设计了一种包级缓存机制：在读取后不会立即释放它们，而是设法存储读取数据包的引用以供后续使用。数据包级缓存机制维护缓存队列。如果数据包的引用被减少到0，则该数据包的参考被放入队列。当队列大小超过阈值, 包将由munmap()根据缓存迁移策略调用。（带有优先级计数和缓存队列的数据包级缓存机制） 对象级缓存机制：哈希表：在第一级，整个文件被分成几个桶；每个文件片段根据其起始地址和结束地址被放入特定的存储桶中。红黑树：当单个存储桶中的单元数量超过限制时，缓存模型会根据当前存储桶中所有元素的地址将其放入红黑树中。当存储桶中的单元数小于限制时，原始红黑树将被删除。双重链接列表：文件片段自然按其起始地址和结束地址排序。每个缓存单元包含指向最近单元的前指针和后指针。 为了获得对象级缓存模型中缓存管理问题的近似解，论文实现了[53]提出的两种Greedy和ISK算法 Improving NAND Flash Based Disk Caches 论文介绍了Flash在当今的服务器平台中用作磁盘缓存的研究。提出了两项改进。第一种方法通过将基于Flash的磁盘缓存拆分为单独的读写区域来提高性能和可靠性。第二种通过采用可编程闪存控制器来提高可靠性。它可以根据应用的需求改变错误码强度（可纠正位的数量）和存储单元可以存储的位的数量（单元密度）。Flash的可管理性和可靠性是一个具有挑战性的问题，需要解决这些问题才能将Flash完全集成到数据中心。提出了一种用于NAND闪存的硬件辅助软件管理磁盘缓存。 为了减轻磨损，对基于闪存的磁盘缓存的闪存擦除执行磨损级别管理。对于读缓存和写缓存，首先使用LRU策略选择要逐出的块，该策略针对磁盘缓存容量未命中（对于读缓存）或容量写入（对于写缓存，需要首先擦除块的异地写入）。然而，如果该块的磨损超过最新块的磨损预定阈值，则驱逐与最小磨损相对应的块（最新块）以平衡磨损水平。从整个闪存块集合中选择最新的块。在驱逐最新的块之前，它的内容被迁移到旧块。 Optimizing the SSD Burst Buffer by Traffic Detection（细粒度缓存替换策略） HPC存储系统仍然使用硬盘驱动器（HDD）作为其主要存储设备。固态驱动器（SSD）被广泛部署为HDD的缓冲区。还提出了突发缓冲器来管理突发写入请求的SSD缓冲。虽然突发缓冲区在许多情况下可以提高I&#x2F;O性能，但它具有一些限制，例如需要大的SSD容量以及计算阶段和数据flush阶段之间的和谐重叠。提出了一种称为SSDUP+的方案。SSDUP+旨在通过解决上述限制来改善突发缓冲区。首先，为了减少对SSD容量的需求，只选择一部分数据写入SSD，而其余数据则直接写入HDD，而不牺牲I&#x2F;O性能。开发了一种新的方法来检测和量化写入流量中的数据随机性。此外，提出了一种自适应算法来动态地对随机写入进行分类。通过这样做，需要更少的SSD容量来实现与其他突发缓冲方案类似的性能。然后，为了克服计算阶段和flush阶段完美重叠的困难，提出了SSD缓冲区的流水线机制，在流水线机制中，SSD缓冲区被分成两半。当一半接收写入数据时，另一半完全占用将数据从SSD刷新到HDD。其中数据缓冲和刷新在流水线中执行。为了提高I&#x2F;O吞吐量，采用了流量感知刷新策略来减少HDD中的I&#x2F;O干扰。最后，为了进一步提高SSD中缓冲随机写入的性能，SSDUP+通过使用日志结构存储数据，将SSD中的随机写入转换为顺序写入。此外，SSDUP+使用AVL树结构来存储数据的序列信息。SSDUP+以减少满足突发性大规模I&#x2F;O访问性能所需的SSD容量，从另一个角度来看，在相同的SSD容量下提高I&#x2F;O性能。 硬盘驱动器（HDD）仍然被用作HPC存储系统中的主要永久存储设备，部分原因是其成本低，可以在访问大型连续数据块时提供高带宽。然而，HDD有一个主要缺点：当随机访问数据时，由于磁盘头的缓慢机械移动，它们的性能很差。固态驱动器（SSD）等新的存储设备由于其接近零的寻道延迟和优异的性能（特别是对于随机访问）而被广泛部署在HPC环境中。然而，SSD比HDD昂贵得多。因此，在大规模生产HPC系统中使用SSD作为唯一的存储设备并不是一个经济高效的解决方案，更不用说SSD的技术限制，例如磨损和寿命有限的问题。解决HDD随机数据访问问题的一个流行解决方案是使用SSD缓冲HDD和计算节点之间的数据流。另一方面，对HDD的突发随机写入可能会显著降低HPC存储系统上运行的数据密集型应用程序的性能。为了解决上述问题，引入了突发缓冲器，它使用SSD缓冲器作为计算节点和基于HDD的存储服务器之间的中间层，以吸收突发写入请求。 Exploration and Exploitation for Buffer-Controlled HDD-Writes for SSD-HDD Hybrid Storage Server（细粒度缓存替换策略） 结合固态驱动器（SSD）和硬盘驱动器（HDD）的混合存储服务器为应用程序提供了成本效益和μ级响应能力。会导致HDD通常利用不足，而SSD使用过度，特别是在密集写入下。这会导致SSD的快速磨损和高尾部延迟。HDD的一系列顺序和连续写入呈现出周期性、阶梯状的写入延迟模式，即低（35μs）、中（55μs）和高延迟（12毫秒），这是由HDD控制器内的缓冲写入导致的。可以利用HDD的潜在μs级IO延迟，以吸收过多的SSD写入，而不会降低性能。论文建立了一个描述阶梯行为的HDD写入模型，并设计了一个配置过程来初始化和动态重新校准模型参数。然后，提出了一种缓冲区控制写入方法（BCW），以主动控制缓冲区写入，从而用应用程序数据调度低延迟和中延迟时段，并用填充数据填充高延迟时段。利用BCW，设计了一个混合IO调度器（MIOS），以自适应地将传入数据引导到SSD和HDD。进一步设计了多HDD调度以最小化HDD写入延迟 Cache Replacement Policy Based on Expected Hit Count 现有处理器采用最近最少使用（LRU）策略的变体来确定替换的缓存块。不幸的是，LRU提供的服务与Belady的MIN之间存在很大差距，这是最佳的更换策略。Belady的MIN要求选择具有最长重用距离的缓存块，因此，由于需要了解未来，这是不可行的。在论文研究中，发现缓存块的预期命中数与其重用距离的倒数之间存在很强的相关性。论文提出了用于替换缓存中的缓存块的预期命中计数（EHC）策略，在现有低成本替换策略的基础上，采用基于命中计数的缓存块选择程序，以显著提高最后一级缓存中缓存块选择的质量，而无需相应的区域开销。 现代处理器经常需要从最后一级缓存中移出一段数据，以便为新数据留出空间。替换策略决定了在所有可能的候选项中，在新数据到达时应该从缓存中删除哪个候选项。 使用第二届缓存替换锦标赛（CRC2）发布的模拟框架评估预期命中计数（EHC）策略。 Hystor: Making the best use of solid state drives in high performance storage systems（分层存储） 由于SSD相对较高的价格和较低的容量，需要解决的一个主要系统研究问题是如何以成本和性能有效的方式使SSD在高性能存储系统中发挥最有效的作用。论文设计和实现Hystor高性能混合存储系统，Hystor将SSD和HDD作为一个单块设备进行管理，Hystor可以有效地识别（1）可能导致长延迟或（2）语义关键的块（例如文件系统元数据），并将其存储在SSD中以供将来访问，从而实现显著的性能改进。为了进一步利用最先进SSD中极高的写入性能，Hystor还充当回写缓冲区，以加快写入请求。 将高容量SSD视为存储的一部分，而不是缓存位置。相应地，与基于缓存的传统策略不同，基于缓存的策略在每次数据访问时频繁更新缓存内容，论文只定期和异步地重新组织设备之间的块布局，以实现长期优化。Hystor通过三个主要组件实现其数据管理的优化目标。首先，通过实时监控I&#x2F;O流量，Hystor自动学习工作负载访问模式并识别性能关键块。只有能够带来最大性能优势的块才能从HDD重新映射到高速SSD。第二，通过有效利用现有接口中可用的高级信息，Hystor识别语义关键块（例如文件系统元数据），并及时为它们提供高优先级，使其留在SSD中，这进一步提高了系统性能。第三，传入的写入被缓冲到低延迟SSD中，以提高写入密集型工作负载的性能。 Back to the Future: Leveraging Belady’s Algorithm for Improved Cache Replacement 缓存是减少数据访问的长延迟的重要机制，其有效性受到其替换策略的显著影响。论文解释了缓存替换算法如何通过将其应用于过去的缓存访问来学习Belady的算法，以告知未来的缓存替换决策。并提出了基于Belady的缓存替换算法，将Belady方法的变体应用于过去的内存访问历史。如果过去的行为是未来行为的良好预测，论文提出的策略将接近Belady算法的行为。新缓存替换策略由两部分组成。第一个使用OPTgen算法重构了Belady对过去缓存访问的最佳解决方案。第二个是一个预测器，它可以学习OPT对过去PC的行为，以告知同一PC对未来负载的驱逐决定。 在缺乏明确反馈的情况下，现有的替换策略基于启发式方法，如最近最少使用（LRU）和最近最多使用（MRU），这两种方法都适用于不同的工作负载。然而，即使使用越来越聪明的技术来优化和组合这些策略，这些基于启发式的解决方案也仅限于特定类别的访问模式，无法在更复杂的场景中表现良好。 将缓存替换视为一个二进制分类问题，其目标是确定传入的行是缓存友好的还是缓存厌恶的：缓存友好的行以高优先级插入，而缓存厌恶的行被标记为未来冲突的驱逐候选行。为了确定传入线路应如何分类，Hawkeye重构了Belady对过去访问的最优解决方案，以了解单个加载指令的行为。 Performance Evaluation of Traditional Caching Policies on A Large System with Petabytes of Data 大多数现有的缓存性能研究都评估填充相对较小缓存的、相当小的文件。很少有报告讨论了传统缓存替换策略在超大系统上的性能。论文在PB级存储系统中，全面评估了几种缓存策略的性能，包括先进先出（FIFO）、最近最少使用（LRU）和最不频繁使用（LFU）。研究表明当应用于大型数据集和小型数据集时，传统缓存策略能够提高性能。 在整个评估过程中，FIFO缓存替换策略经常导致比LRU或LFU显著更低的命中率，尽管有一小部分数据点的FIFO命中率较高。LRU缓存替换策略在所有测试的替换策略中获得了最高的比率，但与LFU策略相比，LRU导致平均命中率的标准偏差更高。当排除攻击性用户时，LFU缓存替换策略的平均命中率最高，而当LRU包含攻击性用户后，该策略的命中率仅超过0.29%。 将可用缓存的大小增加一倍，最多可以提高12%的命中率。论文建议额外的需求可以通过简单地扩展缓存大小来降低性能增益的价值。论文认为，对专用缓存策略进行更彻底的检查能够专注于大规模缓存大小的优化。通过将所使用的缓存大小增加一倍，命中率发生了相对较小的变化，这表明，在使用更有效的缓存策略的同时，缩小总体缓存大小将节省大量空间，并减少用作缓存所需的活动磁盘数。 预取是另一种有可能显著提高缓存性能的技术[24]，[25]，[26]，[27]，[28]。事实上，预取比简单地用流行文档加载缓存更有效[33]。有效的预取策略可以帮助缓存将命中率提高50%[32]。智能地预加载数据可以在不增加成本的情况下实现性能提高，因为使用预取的缓存可以与不使用预取缓存的两倍缓存一样有效[30]。已经证明，使用有效的预取方案可以显著减少不同缓存替换策略的命中率之间的差异，增强了格式良好的预取算法的重要性[33]。 Improving Cache Management Policies Using Dynamic Reuse Distances 论文提出了一种新的PDP缓存管理策略，一种使用动态重用距离来进一步改进缓存替换策略，该策略防止替换缓存线，直到对其缓存集进行一定数量的访问，称为保护距离（PD）。该策略保护缓存线足够长，可以重复使用，但不能超过该长度，以避免缓存污染。这可以与旁路机制相结合，该机制也依赖于动态重用分析，以绕过预期重用较少的管线。如果没有未保护的行，则忽略未命中提取。提出了一种基于动态重用历史的命中率模型，并动态计算了使命中率最大的PD。PD会定期重新计算，以跟踪程序的内存访问行为和阶段。 Optimum Caching versus LRU and LFU: Comparison and Combined Limited Look-Ahead Strategies 将基于最近最少使用（LRU）和最不频繁使用（LFU）替换原则的web缓存策略与根据Belady算法的最佳缓存进行比较。研究了一种结合LRU、LFU或其他非预测方法的有限前瞻最优策略的组合方法。、通过模拟，根据请求跟踪和独立参考模型（IRM）的前瞻性程度来评估命中率增益，并对观察到的行为进行分析确认。 将常用缓存策略的命中率和更新工作量与最佳缓存作为性能上限进行比较。缓存策略性能评估的三种基本方法是通过跟踪模拟、根据综合模型模拟运行生成的请求模式和分析。 对一种组合缓存方法的评估表明，优化缓存不仅可以提供缓存命中率上限，而且可以部分用于视频流的缓存和服务于巨大请求工作负载的缓存。对缓存和请求特定参数对有限前瞻方案适用性的影响进行更详细的分析，以供将来研究。 A Distributed Block Storage Optimization Mechanism Based on Ceph 为了应对企业在提高块存储服务的资源利用率和读&#x2F;写速率方面面临的挑战，Ceph提供了缓存分层，以提高异构存储环境中的群集性能。然而，由于缓存污染，缓存分层中最近最少使用的（LRU）算法会驱逐更多有价值的数据，这会导致某些请求的延迟更高；同时，当在存储节点上分配数据时，可扩展哈希下的受控复制（CRUSH）算法只考虑存储节点容量，这使得Ceph无法动态平衡节点的I&#x2F;O负载。为了解决这些问题，提出了一种基于预测模型的存储选择策略，以提高缓存池中对象访问的命中率，提高集群的整体I&#x2F;O性能；此外，还提出了缓存池I&#x2F;O负载平衡策略。与原生机制相比，所提出的块存储优化机制可以实现更高的I&#x2F;O吞吐量和更均衡的I&#x2F;O负载。 当数据在缓存层被逐出时，缓存分层中的LRU算法仅基于最近的访问记录逐出数据，这可能会由于偶尔的冷数据访问而导致逐出更有价值的热数据[3]。基于Ceph的缓存分层机制，论文提出了一种基于预测模型的存储选择策略，该策略根据对象访问频率确定对象请求是访问SSD OSD池还是访问后端HDD OSD池。该策略可以减少冷数据处理所造成的不必要开销，从而提高集群的总体I&#x2F;O性能。 为了有效利用缓存分层中有限的缓存池资源，冷数据应该存储在后端存储池中，而热数据应该存储到缓存池中。因此，在海量数据存储的背景下，区分数据的热量（即访问频率）并采用不同的处理策略可以充分利用Cache Tiering中的存储资源，并减少冷数据处理（例如冷数据从后端存储池进入缓存池，LRU驱逐冷数据）所造成的不必要开销。提出了一种基于预测模型的存储选择策略。该策略适应海量数据存储的特点，分析存储对象的长期访问记录。同时，根据某一时间段内的对象热度，判断是选择访问SSD缓存池还是后端HDD存储池，以减少冷数据处理带来的不必要开销，最终提高集群性能。 Maximizing Cache Performance Under Uncertainty（提出EVA）2017 HPCA 指出Belady理论假设了对未来的完全了解，但这在实践中是不可用的，其明显在信息不完善的情况下是次优的。并建议：对于实际的缓存替换，应该根据其经济增加值（即其预期命中率与平均值的差异）来替代。缓存替换中的两个主要权衡：命中概率和缓存空间，并描述了EVA如何在一个直观的度量中协调它们。通过借鉴马尔可夫决策过程（MDP）理论，证明了EVA最大化了缓存命中率。 最常见的缓存替换策略是使用最近性和频率启发式。大多数缓存替换策略采用某种形式的最近性，有利于最近被引用的候选人：例如，LRU仅使用最近性，而RRIP[17，39]预测较老的候选人需要更长的时间才能被引用。类似地，一些不假设最近的政策仍然基于候选人最后被引用的时间：PDP[14]保护候选人直到某个年龄；IRGD[35]使用年龄的启发式函数。另一种常见的缓存替换策略解释动态行为的方式是通过频率，倾向于先前重用的候选：例如，LFU单独使用频率，ARC[26]和SRRIP[17]等“抗扫描”策略倾向于至少重用一次的候选。 EVA缓存替换策略：本质上是一种成本效益分析，即候选数据的命中概率是否值得其所消耗的缓存空间。EVA将每个候选数据选视为一项投资，试图留住利润最高的候选候选（以命中率衡量）。首先，EVA奖励每个候选数据预期的未来命中率。然后，由于缓存空间是一种稀缺资源，EVA需要考虑每个候选将消耗多少空间。EVA通过对每个候选数据在缓存中花费的时间“收费”来实现这一点。具体而言，EVA以单行的平均命中率（即缓存的命中率除以其大小）对候选项收费，因为这是消耗缓存空间的长期机会成本。EVA &#x3D; Expected hits - (Cache hit rate&#x2F; Cache size) * Expected time EVA策略的实现主要包括以下几个步骤： 计算每个缓存行的经济增值（EVA）：EVA是一个衡量缓存行价值的指标，它考虑了缓存行的命中概率和占用缓存空间的时间成本。具体地，EVA等于缓存行的期望命中次数减去缓存的命中率乘以缓存行在缓存中的时间。 选择EVA最小的缓存行进行替换：当需要替换缓存行时，EVA策略会选择EVA最小的缓存行进行替换。这是因为EVA最小的缓存行对缓存的贡献最小，替换它可以最大化缓存的命中率。 更新缓存行的EVA值：当缓存行被访问时，EVA策略会更新它的EVA值。具体地，EVA策略会根据缓存行的命中情况和占用缓存空间的时间，重新计算缓存行的EVA值。 调整缓存大小：EVA策略还可以根据缓存的命中率和缓存行的EVA值，动态调整缓存的大小。具体地，当缓存的命中率较低时，EVA策略会增加缓存的大小；当缓存的命中率较高时，EVA策略会减小缓存的大小。 EVA策略的实现比较简单，只需要对每个缓存行维护一个EVA值，并选择EVA最小的缓存行进行替换即可。 LHD: Improving Cache Hit Rate by Maximizing Hit Density 2018 NSDI 云应用程序的性能严重依赖于数据中心键值缓存的命中率。键值缓存通常使用最近最少使用（LRU）作为其逐出策略，但在实际工作负载下，LRU的命中率远不是最佳的。论文提出最小命中密度（LHD）缓存替换算法，这是一种针对键值缓存的新驱逐策略。LHD预测每个对象每消耗空间的预期命中率（命中密度），过滤对缓存命中率贡献不大的对象。与先前的驱逐策略不同，LHD不依赖启发式，而是使用条件概率严格地模拟对象的行为，以实时调整其行为。 缓存命中率的小幅增加会对应用程序性能产生巨大影响。例如，将命中率从98%提高到99%，只需1%，就可以将对数据库的请求数量减半。使用上面使用的延迟数，这将平均服务时间从210µs减少到110µs（接近2倍），并且对于云应用程序来说，重要的是，将长延迟请求的尾部减半[21]。为了提高缓存命中率，云提供商通常会扩展服务器数量，从而增加缓存总容量[37]。从长远来看，添加缓存容量是不可行的，因为命中率随着缓存容量的增加呈对数增长[3，13，20]。需要大量内存才能显著影响命中率。在一定的缓存空间条件下，可以采用高效的缓存替换策略来提高缓存命中率。 流行的内存缓存使用最近最少使用（LRU）或LRU的变体作为其逐出策略。然而，LRU远不是缓存工作负载的最佳选择，因为：当工作负载具有可变的对象大小时，LRU的性能会受到影响，以及常见的访问模式暴露了LRU中的病态，导致命中率低。LRU的这些缺点已经得到了充分的记录，先前的工作已经提出了许多针对LRU的驱逐政策[4，14，16，25，35，38，40]。然而，这些策略并没有被广泛采用，因为它们通常需要大量的参数调整，这使得它们的性能不可靠，并且全局同步状态会影响它们的请求吞吐量。 论文提出命中密度的概念，用它衡量对象对缓存命中率的贡献程度。根据每个对象的信息（其年龄或大小）推断出每个对象的命中密度，然后以最小的命中密度（LHD）驱逐该对象。最小命中密度（LHD）是一种基于命中密度的缓存替换策略。LHD在线监控对象，并使用条件概率预测其可能的行为。LHD利用了许多不同的对象特性（例如，年龄、频率、应用程序id和大小），并且很容易支持其他对象。动态排名使LHD能够随时间调整其替换策略，以适应不同的应用程序工作负载，而无需任何手动调整。例如，在某个工作负载上，LHD可能最初接近LRU，然后切换到最近使用的（MRU）、最不频繁使用的（LFU）或其组合。LHD动态预测每个对象每消耗空间的预期命中率或命中密度，并以最低的命中率驱逐对象。通过过滤掉对缓存命中率贡献不大的对象，LHD逐渐提高了平均命中率。 根据Memcachier[36]提供的为期一周的商业memcached跟踪和Microsoft Research提供的存储跟踪对LHD进行了评估[48]。LHD显著提高了先前策略的命中率，例如，与LRU相比，将未命中率减少了一半，与最近的策略相比，减少了四分之一，并且还避免了诸如影响先前策略的性能悬崖等问题。图1显示了实现与LHD相同命中率所需的缓存大小，Memcachier上为256 MB，Microsoft跟踪上为64 GB。LHD需要的空间比以前的驱逐策略少得多，从而节省了现代数据中心数千台服务器的成本。 先前的缓存替换策略以许多不同的方式改进了LRU。几乎所有的政策都通过额外的机制来改善其最坏的病理状况。例如，ARC[35]使用两个LRU列表来区分新进入的对象，并限制来自不常访问对象的污染。类似地，AdaptSize[9]在LRU列表前面添加了一个概率过滤器，以限制大型物体的污染。最近的一些策略将访问划分为多个LRU列表，以消除性能悬崖[6，18，51]或在不同大小的对象之间分配空间[10，17，18，37，41，43，49]。所有这些策略都使用LRU列表作为核心机制，因此保留了最近性作为内置假设。此外，他们增加的机制可以引入新的假设和病理。例如，ARC通过将频繁访问的对象与新允许的对象放在一个单独的LRU列表中，并倾向于驱逐新允许的物体，从而假设频繁访问的物体更有价值。这通常是LRU的改进，但可能表现为病态。 EVA，一种最近针对处理器缓存的驱逐策略[7，8]，引入了使用条件概率来平衡命中与消耗的资源的想法。LHD和EVA之间有几个显著的差异，使LHD能够在关键价值工作负载上表现出色。首先，LHD和EVA使用不同的排名功能。EVA根据对象的命中率（而不是命中密度）对其进行排名。 LHD算法的实现过程如下： 首先，需要为每个对象计算其期望的命中率。这可以通过以下公式计算： Hit density &#x3D; Hit probability * Object size &#x2F; Expected time in cache 其中，Hit probability是对象在其生命周期内被访问的概率，Object size是对象的大小，Expected time in cache是对象在缓存中的期望时间。在LHD算法中，Expected time in cache是通过对象的访问模式和缓存的大小等因素来计算的。具体地，可以使用以下公式计算对象的Expected time in cache： Expected time in cache &#x3D; (Cache size &#x2F; Object size) * (1 &#x2F; Hit probability) 其中，Cache size是缓存的大小，Object size是对象的大小，Hit probability是对象在其生命周期内被访问的概率。这个公式的意思是，如果缓存中有足够的空间来存储对象，那么对象在缓存中的期望时间就是对象被访问的平均间隔时间的倒数。这个期望时间可以用来计算对象的期望命中率，从而帮助LHD算法更好地预测对象的命中率。 然后，需要为每个对象维护一个命中率分布。这可以通过记录对象的命中和驱逐时间来实现。当对象被命中时，将其命中时间添加到命中率分布中。当对象被驱逐时，将其驱逐时间添加到驱逐率分布中。 当需要驱逐一个对象时，LHD算法会选择命中率分布最小的对象进行驱逐。这可以通过计算每个对象的命中率分布的加权平均值来实现。具体地，对于每个对象，将其命中率分布的每个时间点乘以其命中率，然后将所有时间点的乘积相加，得到该对象的加权平均命中率。然后，选择加权平均命中率最小的对象进行驱逐。 在实现过程中，还可以使用其他技术来优化LHD算法的性能。例如，可以使用分类来改进预测，以便更好地考虑对象的特征。还可以使用并发技术来提高算法的吞吐量。 总之，LHD算法的实现过程包括计算对象的期望命中率，维护命中率分布，选择命中率分布最小的对象进行驱逐等步骤。通过这些步骤，LHD算法可以更好地预测对象的命中率，从而提高缓存","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}]},{"title":"Ceph PG介绍","slug":"ceph-PG介绍","date":"2021-11-10T10:22:25.000Z","updated":"2024-09-01T13:29:00.495Z","comments":true,"path":"ceph-PG介绍/","permalink":"https://watsonlu6.github.io/ceph-PG%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"Ceph并不是直接通过CRUSH算法将数据对象一一映射到OSD中的，这样做将非常复杂与低效。而且，Ceph用户并不需要了解实际的CRUSH算法是怎么运行的，只需要关心数据保存在哪里即可。Ceph通过存储池Pool和放置组Placement Groups (PGs)来实现CRUSH算法进行数据寻址。PG聚合了池中的对象。按对象跟踪 RADOS 对象的位置和元数据在计算上是昂贵的。对于具有数百万个 RADOS 对象的系统，按对象跟踪位置是不切实际的。Ceph 客户端计算一个 RADOS 对象应位于哪个 PG。作为计算的一部分，客户端会对对象 ID 进行哈希处理，并执行涉及池中 PG 数量和池 ID 的操作。 属于 PG 的 RADOS 对象的内容存储在一组 OSD 中。例如，在一个大小为 2 的复制池中，每个 PG 将在两个 OSD 上存储对象，如下所示：如果 OSD #2 发生故障，另一个 OSD 将被分配到 Placement Group #1，然后用 OSD #1 中所有对象的副本填充。如果池大小从 2 更改为 3，将分配一个额外的 OSD 到 PG，并接收 PG 中所有对象的副本。分配给 PG 的 OSD 并不是专门属于该 PG 的；相反，OSD 也与来自同一池或其他池的其他 PG 共享。在我们的例子中，OSD #2 由 Placement Group #1 和 Placement Group #2 共享。如果 OSD #2 发生故障，那么 Placement Group #2 必须恢复对象副本（利用 OSD #3）。 PG是 Ceph 中的逻辑池的子集。PG 执行将对象（作为一组）放置到 OSDs 中的功能。Ceph 以 PG 为单位管理数据, 这比管理单个 RADOS 对象更具扩展性。在集群中拥有较多的 PG的集群，相比具有较少 PG 的相同集群，数据分布更均衡。每个 Ceph 的内部 RADOS 对象都会映射到特定的 PG，而每个 PG 又只属于一个 Ceph 池。 当 PG 数量增加时，会发生几个后果。新的 PG 被分配到 OSD。CRUSH 函数的结果发生变化，这意味着一些来自已经存在的 PG 的对象被复制到新的 PG 中，并从旧的 PG 中删除。 在理想条件下，对象会在PG之间均匀分布。由于CRUSH计算每个对象的PG，但不知道每个与PG关联的OSD中存储了多少数据，因此PG和OSD的数量比例可能对数据分布产生显著影响。 例如，假设在一个有三个副本的池中，只有一个PG分配给十个OSD。在这种情况下，由于CRUSH没有其他选择，只会使用三个OSD。然而，如果有更多PG可用，RADOS对象更有可能在OSD之间均匀分布。CRUSH会尽力使OSD在所有现有PG之间均匀分布。 只要PG的数量比OSD多一个或两个数量级，分布通常会比较均匀。例如：3个OSD对应256个PG，10个OSD对应512个PG，或者10个OSD对应1024个PG。 但是，不均匀的数据分布可能由于PG与OSD比例之外的因素而出现。例如，由于CRUSH不考虑RADOS对象的大小，一些非常大的RADOS对象的存在可能会造成不平衡。例如，假设有一百万个4 KB的RADOS对象，总计4 GB，均匀分布在10个OSD的1024个PG中。这些RADOS对象将会在每个OSD上消耗4 GB &#x2F; 10 &#x3D; 400 MB。如果再往池中添加一个400 MB的RADOS对象，则在该RADOS对象所在的PG的三个OSD上，每个OSD将被填充到400 MB + 400 MB &#x3D; 800 MB，而其他七个OSD仍然只有400 MB。 每个PG对OSD和MON增加了内存、网络和CPU的需求。这些需求必须始终得到满足，并在恢复期间增加。实际上，PG的主要作用之一是通过将对象聚集在一起分担这些开销。因此，减少PG的数量可以节省大量资源。 自动缩放PGPG是 Ceph 用于分配数据的内部实现细节。自动缩放提供了一种管理 PG，特别是管理不同池中 PG 数量的方法。当启用 pg-autoscaling 时，集群可以根据预期的集群和池使用情况，对每个池的 PG 数量（pgp_num）进行建议或自动调整。每个池都有一个 pg_autoscale_mode 属性，可以设置为以下值： off：禁用该池的自动缩放。管理员需要为每个池选择合适的 pgp_num。有关更多信息，请参见选择 PG 数量。 on：启用对给定池的 PG 数量的自动调整。 warn：当 PG 数量需要调整时发出健康检查警告。 要设置现有池的自动缩放模式，请运行以下命令： 1ceph osd pool set &lt;pool-name&gt; pg_autoscale_mode &lt;mode&gt; 对于在集群初始设置后创建的池，也有一个 pg_autoscale_mode 设置。要更改此设置，请运行以下命令： 1ceph config set global osd_pool_default_pg_autoscale_mode &lt;mode&gt; 可以使用 noautoscale 标志来禁用或启用所有池的自动缩放。默认情况下，该标志设置为 off，但可以通过以下命令将其设置为 on： 1ceph osd pool set noautoscale 要将 noautoscale 标志设置为 off，请运行： 1ceph osd pool unset noautoscale 要获取标志的值，请运行： 1ceph osd pool get noautoscale 查看 PG 缩放状态要查看每个池、其相对利用率以及对 PG 数量的任何推荐更改，请运行以下命令： 1ceph osd pool autoscale-status 输出将类似于： 1234POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE BULKa 12900M 3.0 82431M 0.4695 8 128 warn Truec 0 3.0 82431M 0.0000 0.2000 0.9884 1.0 1 64 warn Trueb 0 953.6M 3.0 82431M 0.0347 8 warn False POOL：池的名称。 SIZE：池中存储的数据量。 TARGET SIZE（如果存在）：预计池中存储的数据量，由管理员指定。系统使用两个值中的较大者进行计算。 RATE：池的倍数，决定了消耗多少原始存储容量。例如，一个三副本池的比例为 3.0，一个 k&#x3D;4 m&#x3D;2 的纠删编码池的比例为 1.5。 RAW CAPACITY：负责存储池数据（以及可能的其他池数据）的特定 OSD 上的总原始存储容量。 RATIO：池使用的存储量与总原始存储容量的比率。换句话说，RATIO 定义为 (SIZE * RATE) &#x2F; RAW CAPACITY。 TARGET RATIO（如果存在）：池的预期存储（即管理员指定的池预计消耗的存储量）与设置了目标比例的所有其他池的预期存储之比。如果同时指定了 target_size_bytes 和 target_size_ratio，则 target_size_ratio 优先。 EFFECTIVE RATIO：对目标比例进行两次调整后的结果： 减去预期被使用的目标容量。 在设置了目标比例的池之间对目标比例进行归一化，以便它们集体瞄准集群容量。例如，四个目标比例为 1.0 的池将具有 0.25 的有效比例。 BIAS：用作倍数，根据之前有关特定池应有多少 PG 的信息手动调整池的 PG 数量。 PG_NUM：池当前的 PG 数量，或如果正在进行 pg_num 更改，则为池正在努力达到的 PG 数量。 NEW PG_NUM（如果存在）：系统建议的池的 pg_num 值。它始终是 2 的幂，并且仅在推荐值与当前值的差异大于默认的 3 倍时出现。 AUTOSCALE：池的 pg_autoscale_mode，设置为 on、off 或 warn。 BULK：确定池是否是批量池。它的值为 True 或 False。批量池预计会很大，应该最初具有大量 PG，以避免性能问题。另一方面，非批量池预计会很小（例如，一个 .mgr 池或元数据池）。 注意如果 ceph osd pool autoscale-status 命令没有返回任何输出，可能至少有一个池跨越了多个 CRUSH 根。这种“跨越池”问题可能发生在以下场景中：当新部署自动在默认 CRUSH 根上创建 .mgr 池时，后续池的创建规则将它们约束到特定的阴影 CRUSH 树。例如，如果您创建一个限制为 deviceclass = ssd 的 RBD 元数据池和一个限制为 deviceclass = hdd 的 RBD 数据池，您将遇到此问题。要解决此问题，将跨越池约束到仅一个设备类。在上述场景中，可能会有一个 replicated-ssd CRUSH 规则生效，可以通过运行以下命令将 .mgr 池约束到 ssd 设备： 1ceph osd pool set .mgr crush_rule replicated-ssd 此干预将导致少量的回填，但通常这些流量很快就会完成。 自动扩缩容在最简单的自动扩缩容方法中，集群允许根据使用情况自动调整 pgp_num。Ceph 会考虑整个系统的总可用存储和目标 PG 数量，考虑每个池中存储的数据量，并相应地分配 PG。系统采取保守的方法，仅在当前 PG 数量（pg_num）与推荐数量的差异超过 3 倍时，才对池进行更改。每个 OSD 的目标 PG 数量由 mon_target_pg_per_osd 参数确定（默认值：100），可以通过以下命令调整： 1ceph config set global mon_target_pg_per_osd 100 自动缩放器会分析池并在每个子树基础上进行调整。由于每个池可能映射到不同的 CRUSH 规则，每条规则可能将数据分配到不同的设备，Ceph 将独立考虑层次结构中每个子树的利用率。例如，映射到 ssd OSD 的池和映射到 hdd OSD 的池将根据这两种不同设备类型的数量来确定各自的最佳 PG 数量。如果一个池使用了两个或更多 CRUSH 根（例如，同时包含 ssd 和 hdd 设备的阴影树），自动缩放器会在管理器日志中发出警告。警告中会列出池的名称和重叠的根集。自动缩放器不会对具有重叠根的池进行扩缩容，因为这种情况可能会导致扩缩容过程出现问题。我们建议将每个池约束到仅一个根（即一个 OSD 类别），以消除警告并确保扩缩容过程成功。 管理标记为批量的池如果一个池被标记为批量池，则自动缩放器会为池分配完整的 PG 数量，然后仅在池的使用比例不均时才缩减 PG 数量。然而，如果一个池未被标记为批量池，则自动缩放器会以最小 PG 数量启动池，仅在池中使用量增加时才创建额外的 PG。要创建一个标记为批量池的池，请运行以下命令： 1ceph osd pool create &lt;pool-name&gt; --bulk 要设置或取消设置现有池的批量标志，请运行以下命令： 1ceph osd pool set &lt;pool-name&gt; bulk &lt;true/false/1/0&gt; 要获取现有池的批量标志，请运行以下命令： 1ceph osd pool get &lt;pool-name&gt; bulk 指定预期池大小当集群或池首次创建时，它只消耗了集群总容量的一小部分，并且系统认为它只需要少量 PG。然而，在某些情况下，集群管理员知道哪些池在长期内可能会消耗大部分系统容量。当 Ceph 提供了这些信息时，可以从一开始就使用更合适的 PG 数量，从而避免后续更改 pg_num 和相关的数据迁移开销。 池的目标大小可以通过两种方式指定：一种是与池的绝对大小（以字节为单位）相关，另一种是作为与所有其他设置了 target_size_ratio 的池的权重关系。 例如，要告诉系统 mypool 预计将消耗 100 TB 的容量，请运行以下命令： 1ceph osd pool set mypool target_size_bytes 100T 或者，要告诉系统 mypool 预计将消耗相对于设置了 target_size_ratio 的其他池的 1.0 比例，请运行以下命令： 1ceph osd pool set mypool target_size_ratio 1.0 如果 mypool 是集群中唯一的池，则预计它将使用集群总容量的 100%。然而，如果集群中包含一个目标比例设置为 1.0 的第二个池，则两个池都预计将使用集群总容量的 50%。 ceph osd pool create 命令具有两个命令行选项，可以在创建池时设置目标大小：--target-size-bytes &lt;bytes&gt; 和 --target-size-ratio &lt;ratio&gt;。 注意，如果指定的目标大小值不合理（例如，大于集群总容量），则会引发健康检查（POOL_TARGET_SIZE_BYTES_OVERCOMMITTED）。 如果为池同时指定了 target_size_ratio 和 target_size_bytes，则会忽略后者，前者将用于系统计算，并会引发健康检查（POOL_HAS_TARGET_SIZE_BYTES_AND_RATIO）。 指定池的 PG 范围 可以指定池的 PG 最小值和最大值。 设置 PG 的最小值和最大值 如果设置了最小值，则 Ceph 不会自行将 PG 数量减少（也不会建议减少）到低于配置值的水平。设置最小值是为了在 I&#x2F;O 期间即使池大部分为空时，也能为客户端提供一定程度的并行性。 如果设置了最大值，则 Ceph 不会自行将 PG 数量增加（也不会建议增加）到高于配置值的水平。 要设置池的 PG 最小值，请运行以下命令： 1ceph osd pool set &lt;pool-name&gt; pg_num_min &lt;num&gt; 要设置池的 PG 最大值，请运行以下命令： 1ceph osd pool set &lt;pool-name&gt; pg_num_max &lt;num&gt; 此外，ceph osd pool create 命令具有两个命令行选项，可用于在创建池时指定池的最小或最大 PG 数量：--pg-num-min &lt;num&gt; 和 --pg-num-max &lt;num&gt;。 预选择PG_NUM在创建池时，可以通过以下命令预选择 pg_num 参数的值： 1ceph osd pool create &#123;pool-name&#125; [pg_num] 如果在命令中选择不指定 pg_num，集群会使用 PG 自动缩放器根据池中存储的数据量自动配置该参数（见上文的自动扩缩容部分）。无论是否在创建时指定 pg_num，都不会影响集群之后是否会自动调整该参数。PG 自动缩放的启用或禁用可以通过以下命令设置： 1ceph osd pool set &#123;pool-name&#125; pg_autoscale_mode (on|off|warn) 没有平衡器时，建议的目标是在每个 OSD 上大约 100 个 PG 副本。使用平衡器时，初始目标是每个 OSD 上大约 50 个 PG 副本。自动缩放器尝试满足以下条件： 每个 OSD 上的 PG 数量应与池中的数据量成正比。 每个池应有 50-100 个 PG，考虑到每个 PG 副本在 OSD 之间的复制开销或纠删编码扩展。 指定 PG_NUM 的相关因素在某种程度上，数据高可用和在 OSD 之间均匀分配的标准倾向于更高的 PG 数量。另一方面，节省 CPU 资源和最小化内存使用的标准则倾向于较低的 PG 数量。数据高可用当一个 OSD 发生故障时，数据丢失的风险增加，直到恢复到配置的复制水平。为了说明这一点，假设以下场景导致一个 PG 的永久数据丢失： OSD 发生故障，所有其包含的对象副本丢失。对于 PG 中的每个对象，其副本数量从三降到两。 Ceph 开始为这个 PG 选择一个新的 OSD，以重新创建每个对象的第三个副本。 在新的 OSD 完全填充第三个副本之前，另一个 OSD 在同一 PG 内发生故障。某些对象将只有一个剩余副本。 Ceph 选择另一个 OSD 并继续复制对象，以恢复所需的副本数量。 在恢复完成之前，PG 内的第三个 OSD 发生故障。如果这个 OSD 恰好包含对象的唯一剩余副本，则对象将永久丢失。 在一个包含 10 个 OSD 的集群中，具有 512 个 PG 和三副本池的情况下，CRUSH 会将每个 PG 分配给三个 OSD。因此，当第一个 OSD 发生故障时，将同时为所有 150 个 PG 开始恢复。被恢复的 150 个 PG 可能会均匀分布在 9 个剩余的 OSD 上。每个剩余的 OSD 因此可能会将对象副本发送到所有其他 OSD，并且还可能接收一些新对象，因为它已成为新的 PG 的一部分。 恢复完成所需的时间取决于 Ceph 集群的架构。比较两种设置：（1）每个 OSD 由一台机器上的 1 TB SSD 托管，所有 OSD 连接到 10 Gb&#x2F;s 交换机，单个 OSD 的恢复在一定时间内完成。（2）每台机器上有两个 OSD，使用 HDD，没有 SSD WAL+DB 和 1 Gb&#x2F;s 交换机。在第二种设置中，恢复将慢至少一个数量级。 在这样的集群中，PG 数量对数据高可用几乎没有影响。无论每个 OSD 有 128 个 PG 还是 8192 个 PG，恢复不会更快或更慢。然而，增加 OSD 的数量可以提高恢复速度。假设我们的 Ceph 集群从 10 个 OSD 扩展到 20 个 OSD。每个 OSD 现在只参与大约 75 个 PG，而不是大约 150 个 PG。所有 19 个剩余的 OSD 仍然需要复制相同数量的对象以进行恢复。但现在有 20 个 OSD 必须复制仅 50 GB 的每个对象，而不是 10 个 OSD 复制 100 GB 的每个对象。如果网络以前是瓶颈，则恢复现在的速度加倍。 类似地，假设我们的集群增长到 40 个 OSD。每个 OSD 仅托管大约 38 个 PG。如果 OSD 发生故障，恢复将比以前更快，除非被其他瓶颈阻碍。然而，假设我们的集群增长到 200 个 OSD。每个 OSD 将只托管大约 7 个 PG。如果 OSD 发生故障，恢复将在最多 7 个 OSD 上进行，这意味着恢复时间将比 40 个 OSD 时长。因此，应该增加 PG 数量。 无论恢复时间多么短，在恢复过程中始终有额外 OSD 失败的可能性。考虑上面的 10 个 OSD 的集群：如果任何 OSD 失败，则大约 150 除以 9 的 PG 将只有一个剩余副本。如果剩余的 8 个 OSD 中的任何一个失败，则大约 17 除以 8 的 PG 可能会丢失其剩余的对象。这是为什么设置 size=2 是有风险的一个原因。 当集群中的 OSD 数量增加到 20 时，损失3个OSD 会显著减少损坏的 PG 数量。第二个 OSD 的损失仅导致大约 17 除以 8 个 PG 损坏，而第三个 OSD 的损失仅导致如果它是包含剩余副本的 4 个 OSD 之一，则才会丢失数据。这意味着——假设恢复期间失去一个 OSD 的概率是 0.0001%——在 10 个 OSD 的集群中丢失三个 OSD 的概率为 X，而在 20 个 OSD 的集群中为 Y。总之，OSD 数量越多，恢复速度越快，因级联故障而永久丢失 PG 的风险越低。就数据高可用而言，在少于 50 个 OSD 的集群中，512 或 4096 个 PG 的数量差异几乎没有影响。 注意最近添加到集群中的 OSD 可能需要较长时间来填充分配给它的 PG。但是，这一过程的缓慢不会导致对象退化或对数据耐用性产生影响，因为 Ceph 会在从旧 PG 中移除数据之前，将数据填充到新的 PG 中。 选择PG的数量如果OSD数量超过50个，我们建议每个OSD大约设置50-100个PG，以平衡资源使用、数据耐久性和数据分布。如果OSD数量少于50个，请参阅预选择部分的指导。对于单个池，使用以下公式获取基线值：[\\text{Total PGs} &#x3D; \\text{OSD数量} \\times \\text{池大小}] 其中池大小是复制池的副本数量或编码池的K+M总和。要检索这个总和，请运行命令 ceph osd erasure-code-profile get。 接下来，检查结果的基线值是否与您设计Ceph集群的方式一致，以最大化数据耐久性和对象分布，并最小化资源使用。 这个值应四舍五入到最接近的2的幂。 每个池的 pg_num 应该是2的幂。其他值可能会导致数据在OSD之间分布不均。最好只在可行且期望的情况下增加 pg_num 到下一个最高的2的幂。注意，这个2的幂规则是针对每个池的；对所有池的 pg_num 的总和对齐到2的幂既不是必要的，也不容易。 例如，如果您有一个200个OSD的集群和一个副本大小为3的单个池，估算PG的数量如下：[\\text{Total PGs} &#x3D; 200 \\times 3 &#x3D; 600] 四舍五入到最接近的2的幂：8192。 当使用多个数据池存储对象时，确保平衡每个池的PG数量和每个OSD的PG数量，以便得到一个合理的PG总数。找到一个为每个OSD提供合理低方差的数字，而不会对系统资源造成过大压力或使配对过程过慢是很重要的。 例如，假设您有一个包含10个池的集群，每个池有512个PG，分布在10个OSD上。这意味着总共有5120个PG分布在10个OSD上，每个OSD上有512个PG。这种集群不会使用过多的资源。然而，在一个包含1000个池的集群中，每个池有512个PG，OSD将处理大约50000个PG。这种集群将需要显著更多的资源和更多的配对时间。 设置PG的数量设置池中初始PG数量必须在创建池时进行。然而，即使在池创建之后，如果未使用 pg_autoscaler 管理 pg_num 值，您仍然可以通过运行以下命令更改PG数量： 1ceph osd pool set &#123;pool-name&#125; pg_num &#123;pg_num&#125; 如果您增加PG数量，集群将不会重新平衡，直到您增加用于放置的PG数量（pgp_num）。pgp_num 参数指定了CRUSH算法在放置时要考虑的PG数量。增加 pg_num 会拆分集群中的PG，但数据不会迁移到新的PG，直到 pgp_num 被增加。pgp_num 参数应与 pg_num 参数相等。要增加用于放置的PG数量，请运行以下命令：shell 1ceph osd pool set &#123;pool-name&#125; pgp_num &#123;pgp_num&#125; 如果您减少PG数量，则 pgp_num 会自动调整。在Nautilus及以后的版本中，当未使用 pg_autoscaler 时，pgp_num 会自动调整以匹配 pg_num。这个过程表现为PG的重新映射和回填，这是正常的预期行为。 获取PG数量要获取池中的PG数量，请运行以下命令： 1ceph osd pool get &#123;pool-name&#125; pg_num 获取集群的PG统计信息要查看集群中PG的详细信息，请运行以下命令： 1ceph pg dump [--format &#123;format&#125;] 有效的格式有plain（默认）和json。 获取卡住PG的统计信息要查看所有处于指定状态的卡住PG的统计信息，请运行以下命令： 1ceph pg dump_stuck inactive|unclean|stale|undersized|degraded [--format &lt;format&gt;] [-t|--threshold &lt;seconds&gt;] Inactive PGs 不能处理读写操作，因为它们在等待足够的OSD来获得最新的数据。 Undersized PGs 包含未被复制到所需次数的对象。在正常情况下，可以假设这些PG正在恢复。 Stale PGs 处于未知状态 — 托管它们的OSD在一定时间内（由 mon_osd_report_timeout 决定）没有向监视集群报告。 有效的格式有plain（默认）和json。阈值定义PG卡住的最少秒数，超过该时间PG会被包括在返回的统计信息中（默认：300秒）。 获取PG映射要获取特定PG的映射，请运行以下命令： 1ceph pg map &#123;pg-id&#125; Ceph会返回PG映射、PG和OSD状态。输出类似于以下内容： 1osdmap e13 pg 1.6c (1.6c) -&gt; up [1,0] acting [1,0] 获取PG的统计信息要查看特定PG的统计信息，请运行以下命令： 1ceph pg &#123;pg-id&#125; query 对PG进行清理要对PG进行清理，请运行以下命令： 1ceph pg scrub &#123;pg-id&#125; Ceph检查主OSD和副本OSD，生成PG中所有对象的目录，并将对象进行对比，以确保没有对象丢失或不匹配，并且其内容是一致的。如果副本全部匹配，则进行最终的语义扫描，以确保所有与快照相关的对象元数据一致。错误会记录在日志中。 要对特定池中的所有PG进行清理，请运行以下命令： 1ceph osd pool scrub &#123;pool-name&#125; 优先恢复&#x2F;回填PG如果遇到多个PG需要恢复或回填的情况，但某些PG中的数据比其他PG中的数据更重要（例如，有些PG包含正在运行的机器使用的镜像数据，而其他PG用于非活动机器，包含的数据不太相关），您可能希望优先恢复或回填特别重要的数据所在的PG，以便尽快恢复集群的性能和数据的可用性。要将特定PG标记为恢复优先，请运行以下命令： 1ceph pg force-recovery &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...] 要将特定PG标记为回填优先，请运行以下命令： 1ceph pg force-backfill &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...] 这些命令指示Ceph在处理 其他PG之前，优先对指定的PG进行恢复或回填。优先级不会中断当前的回填或恢复，但会将指定的PG置于队列顶部，以便下一个被处理。如果您改变主意或意识到优先级设置错误，请运行以下命令之一： 12ceph pg cancel-force-recovery &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...]ceph pg cancel-force-backfill &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...] 这些命令会从指定PG中移除强制标记，使PG按常规顺序处理。与添加强制标记的情况一样，这只会影响那些仍在排队的PG，而不会影响当前正在恢复的PG。 强制标记会在PG的恢复或回填完成后自动清除。 同样，要指示Ceph优先处理指定池中的所有PG（即，首先对这些PG进行恢复或回填），请运行以下命令之一： 12ceph osd pool force-recovery &#123;pool-name&#125;ceph osd pool force-backfill &#123;pool-name&#125; 这些命令也可以被取消。要恢复到默认顺序，请运行以下命令之一： 12ceph osd pool cancel-force-recovery &#123;pool-name&#125;ceph osd pool cancel-force-backfill &#123;pool-name&#125; 警告这些命令可能会打破Ceph内部优先级计算的顺序，因此使用时请小心！如果您有多个池当前共享相同的底层OSD，并且某些池中的数据比其他池中的数据更重要，则建议运行以下命令来为所有池安排自定义恢复&#x2F;回填优先级： 1ceph osd pool set &#123;pool-name&#125; recovery_priority &#123;value&#125; 例如，如果您有二十个池，您可以将最重要的池的优先级设为20，次重要的池设为19，以此类推。另一种选择是仅为适当的池子子集设置恢复&#x2F;回填优先级。在这种情况下，可能会将三个重要的池都分配为优先级1，而所有其他池将没有分配恢复&#x2F;回填优先级。另一种可能性是选择三个重要的池，并将它们的恢复&#x2F;回填优先级分别设置为3、2和1。 重要使用 ceph osd pool set &#123;pool-name&#125; recovery_priority &#123;value&#125; 设置恢复&#x2F;回填优先级时，数值越大优先级越高。例如，优先级为30的池比优先级为15的池具有更高的优先级。 恢复丢失的RADOS对象如果集群丢失了一个或多个RADOS对象，并且您决定放弃对丢失数据的搜索，您必须将未找到的对象标记为丢失。 如果已经查询了所有可能的位置，并且所有OSD都正常，但某些RADOS对象仍然丢失，您可能不得不放弃这些对象。当罕见和异常的故障组合允许集群了解到在写入操作恢复之前执行的写入时，可能会出现这种情况。 标记RADOS对象丢失的命令只有一个支持的选项：revert。revert选项将回滚到RADOS对象的先前版本（如果它足够旧以拥有先前版本），或者完全忽略它（如果它太新而没有先前版本）。要标记“未找到”的对象为丢失，请运行以下命令： 1ceph pg &#123;pg-id&#125; mark_unfound_lost revert|delete 平衡模块平衡模块可以优化放置组（PG）在OSD之间的分配，以实现平衡分布。平衡器可以自动操作，也可以在监督下操作。 状态要检查平衡器的当前状态，请运行以下命令： 1ceph balancer status 自动平衡当平衡器处于 upmap 模式时，自动平衡功能默认启用。要禁用平衡器，请运行以下命令： 1ceph balancer off 平衡器模式可以从 upmap 模式更改为 crush-compat 模式。crush-compat 模式与较旧的客户端向后兼容。在 crush-compat 模式下，平衡器会自动对数据分布进行小的调整，以确保 OSD 被均等利用。 限制如果集群处于降级状态（即，OSD 已失败且系统尚未自愈），则平衡器不会对 PG 分布进行任何调整。 当集群处于健康状态时，平衡器将逐步移动一小部分不平衡的 PG，以改善分布。这个比例不会超过默认的 5% 阈值。要调整这个 target_max_misplaced_ratio 阈值设置，请运行以下命令： 1ceph config set mgr target_max_misplaced_ratio .07 # 7% 平衡器在运行之间会休眠。要设置此休眠间隔的秒数，请运行以下命令： 1ceph config set mgr mgr/balancer/sleep_interval 60 要设置自动平衡开始的时间（HHMM 格式），请运行以下命令： 1ceph config set mgr mgr/balancer/begin_time 0000 要设置自动平衡结束的时间（HHMM 格式），请运行以下命令： 1ceph config set mgr mgr/balancer/end_time 2359 自动平衡可以限制在特定的星期几。要将其限制为特定的星期几或之后的时间（如 crontab 中，0 是星期天，1 是星期一，以此类推），请运行以下命令： 1ceph config set mgr mgr/balancer/begin_weekday 0 要限制自动平衡为特定的星期几或之前的时间（同样，0 是星期天，1 是星期一，以此类推），请运行以下命令： 1ceph config set mgr mgr/balancer/end_weekday 6 自动平衡可以限制在特定的池。默认情况下，这个设置的值是空字符串，这样所有池都会自动平衡。要将自动平衡限制到特定的池，请获取它们的数字池 ID（通过运行 ceph osd pool ls detail 命令），然后运行以下命令： 1ceph config set mgr mgr/balancer/pool_ids 1,2,3 模式支持两种平衡器模式： crush-compat：此模式使用兼容权重集功能（在 Luminous 中引入）来管理 CRUSH 层次结构中设备的备用权重集。当平衡器在此模式下运行时，正常权重应保持为设备的大小，以反映计划存储在设备上的数据量。然后，平衡器将优化权重集值，通过小的增量进行调整，以实现尽可能接近目标分布的分布。（由于 PG 放置是伪随机过程，因此会受到自然变异的影响；优化权重有助于对抗这种自然变异。） 请注意，此模式与较旧的客户端完全向后兼容：当 OSD Map 和 CRUSH 图与较旧的客户端共享时，Ceph 将优化后的权重呈现为“真实”权重。 此模式的主要限制是，平衡器无法处理具有不同放置规则的多个 CRUSH 层次结构，如果层次结构的子树共享任何 OSD。（这种 OSD 共享是不典型的，并且由于管理共享 OSD 上的空间利用的困难，通常不推荐。） upmap：在 Luminous 及更高版本中，OSDMap 可以存储对单个 OSD 的显式映射，作为正常 CRUSH 放置计算的例外。这些 upmap 条目提供了对 PG 映射的细粒度控制。此平衡器模式优化单个 PG 的放置，以实现平衡分布。在大多数情况下，结果分布几乎是完美的：即，每个 OSD 上的 PG 数量相等（±1 PG，因为总数可能无法均匀分割）。 要使用 upmap，所有客户端必须是 Luminous 或更高版本。 默认模式是 upmap。可以通过运行以下命令将模式更改为 crush-compat： 1ceph balancer mode crush-compat 监控优化监督使用平衡器可以分为三个不同的阶段： 制定计划 评估数据分布的质量，无论是当前的 PG 分布还是执行计划后将产生的 PG 分布 执行计划 要评估当前分布，请运行以下命令： 1ceph balancer eval 要评估单个池的分布，请运行以下命令： 1ceph balancer eval &lt;pool-name&gt; 要详细查看评估，请运行以下命令： 1ceph balancer eval-verbose ... 要指示平衡器生成一个计划（使用当前配置的模式），为计划起个名字（任何有用的标识字符串），并运行以下命令： 1ceph balancer optimize &lt;plan-name&gt; 要查看计划的内容，请运行以下命令： 1ceph balancer show &lt;plan-name&gt; 要显示所有计划，请运行以下命令： 1ceph balancer ls 要丢弃旧的计划，请运行以下命令： 1ceph balancer rm &lt;plan-name&gt; 要查看当前记录的计划，请检查以下状态命令的输出： 1ceph balancer status 要评估执行特定计划后将产生的分布，请运行以下命令： 1ceph balancer eval &lt;plan-name&gt; 如果计划预计会改善分布（即计划的评分低于当前集群状态的评分），可以通过运行以下命令执行该计划： 1ceph balancer execute &lt;plan-name&gt;","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"存储性能测试工具","slug":"存储性能测试","date":"2021-10-11T05:26:35.000Z","updated":"2024-08-03T06:56:02.287Z","comments":true,"path":"存储性能测试/","permalink":"https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","excerpt":"","text":"FIO简介FIO是Linux下开源的一款IOPS测试工具，主要用来对磁盘进行压力测试和性能验证。它可以产生许多线程或进程来执行用户特定类型的I&#x2F;O操作，通过编写作业文件或者直接命令去执行测试动作，相当于是一个 多线程的io生成工具，用于生成多种IO模式来测试硬盘设备的性能（大多情况用于测试裸盘性能）。硬盘I&#x2F;O测试主要有以下类型： 随机读 随机写 顺序读 顺序写 混合读写 （可根据需求设置70%读，30%写或100%读等等） FIO的安装与使用github地址：github.com&#x2F;axboe&#x2F;fio下载安装方式： 123456789# 方式1yum -i install fio# 方式2yum -y install libaio-devel #安装libaio引擎，不然执行fio会报“fio: engine libaio not loadable”，必须要在fio安装前安装，不然还要重新编译安装一遍fiowget https://github.com/axboe/fio/archive/refs/tags/fio-3.10.zipcd /root/fio-fio-3.10./configuremke &amp;&amp; make install 常用参数介绍 filename&#x3D;&#x2F;dev&#x2F;sdb 要测试盘的名称，支持文件系统或者裸设备，&#x2F;dev&#x2F;sda2或&#x2F;dev&#x2F;sdb direct&#x3D;1 测试过程绕过机器自带的buffer，使测试结果更真实（Linux在读写时，数据会先写到缓存，再在后台写到硬盘，读的时候也是优先从缓存中读，这样访问速度会加快，但是一旦掉电，缓存中数据就会清空，所有一种模式为DirectIO，可以跳过缓存，直接读写硬盘） ioengine&#x3D;libaio 定义使用什么io引擎去下发io请求 sync：同步IO引擎，使用Linux系统调用实现IO操作，可以测试磁盘性能的上限。 mmap：使用内存映射技术实现IO操作，可以测试文件系统的缓存和文件的预读能力。 libaio：异步IO引擎，使用Linux系统调用libaio实现IO操作，可以测试磁盘的随机读写性能。 posixaio：类似于libaio的异步IO引擎，但使用POSIX AIO接口实现IO操作。 pvsync：使用Linux系统调用实现IO操作，但对写操作进行缓存，并且只在需要时进行刷新，可以提高IO性能。 rbd：用于测试Ceph集群中rados block device (RBD)的性能，支持异步IO和同步IO操作。 iodepth&#x3D;16 队列的深度为16，在异步模式下，CPU不能一直无限的发命令到硬盘设备。比如SSD执行读写如果发生了卡顿，那有可能系统会一直不停的发命令，几千个，甚至几万个，这样一方面SSD扛不住，另一方面这么多命令会很占内存，系统也要挂掉了。这样，就带来一个参数叫做队列深度。 bs&#x3D;4k 单次io的块文件大小为4k numjobs&#x3D;10 并发工作线程数 size&#x3D;5G 每个线程读写的数据量是5GB runtime&#x3D;60 测试时间为60秒，可以设置2m为两分钟。如果不配置此项，会将设置的size大小全部写入或者读取完为止 rw&#x3D;randread 测试随机读的I&#x2F;O rw&#x3D;randwrite 测试随机写的I&#x2F;O rw&#x3D;randrw 测试随机混合写和读的I&#x2F;O rw&#x3D;read 测试顺序读的I&#x2F;O rw&#x3D;write 测试顺序写的I&#x2F;O rw&#x3D;rw 测试顺序混合写和读的I&#x2F;O thread 使用pthread_create创建线程，另一种是fork创建进程。进程的开销比线程要大，一般都采用thread测试 rwmixwrite&#x3D;30 在混合读写的模式下，写占30%（即rwmixread读为70%，单独配置这样的一个参数即可） group_reporting 关于显示结果的，汇总每个进程的信息 name&#x3D;”TDSQL_4KB_read_test” 定义测试任务名称扩展 lockmem&#x3D;1g 只使用1g内存进行测试 zero_buffers 用全0初始化缓冲区，默认是用随机数据填充缓冲区 random_distribution&#x3D;random #默认情况下，fio 会在询问时使用完全均匀的随机分布，有需要的话可以自定义访问区域，zipf、pareto、normal、zoned nrfiles&#x3D;8 每个进程生成文件的数量 测试场景示例100%随机读，5G大小，4k块文件： 1fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randread -group_reporting -name=&quot;TDSQL_4KB_randread_test&quot; 100%顺序读，5G大小，4k块文件： 1fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=read -group_reporting -name=&quot;TDSQL_4KB_write_test&quot; 70%随机读，30%随机写，5G大小，4k块文件： 1fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=&quot;TDSQL_4KB_randread70-write_test&quot; 70%顺序读，30%随机写，5G大小，4k块文件： 1fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=rw -rwmixread=70 -group_reporting -name=&quot;TDSQL_4KB_read70-write_test&quot; 输出报告1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@localhost test]# fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=&quot;local_randrw_test&quot;# 结果local_randrw_test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16...fio-3.10Starting 10 threadsJobs: 10 (f=10): [m(10)][100.0%][r=19.4MiB/s,w=8456KiB/s][r=4969,w=2114 IOPS][eta 00m:00s]local_randrw_test: (groupid=0, jobs=10): err= 0: pid=11189: Mon Oct 25 11:01:46 2021 read: IOPS=5230, BW=20.4MiB/s (21.4MB/s)(1226MiB/60031msec) slat (usec): min=2, max=342637, avg=1266.82, stdev=7241.29 clat (usec): min=4, max=459544, avg=20056.81, stdev=24888.90 lat (usec): min=134, max=459586, avg=21329.16, stdev=25378.16 clat percentiles (usec): | 1.00th=[ 1467], 5.00th=[ 1844], 10.00th=[ 2147], 20.00th=[ 2606], | 30.00th=[ 3032], 40.00th=[ 3556], 50.00th=[ 4359], 60.00th=[ 6063], | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507], | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[152044], | 99.99th=[219153] bw ( KiB/s): min= 795, max= 4494, per=9.91%, avg=2072.23, stdev=744.04, samples=1195 iops : min= 198, max= 1123, avg=517.74, stdev=186.00, samples=1195 write: IOPS=2243, BW=8972KiB/s (9188kB/s)(526MiB/60031msec) slat (usec): min=2, max=311932, avg=1272.76, stdev=7272.09 clat (usec): min=6, max=458031, avg=20206.30, stdev=24897.71 lat (usec): min=974, max=459755, avg=21484.12, stdev=25400.41 clat percentiles (usec): | 1.00th=[ 1500], 5.00th=[ 1860], 10.00th=[ 2147], 20.00th=[ 2606], | 30.00th=[ 3064], 40.00th=[ 3621], 50.00th=[ 4424], 60.00th=[ 6194], | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507], | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[149947], | 99.99th=[200279] bw ( KiB/s): min= 357, max= 1944, per=9.90%, avg=888.57, stdev=325.49, samples=1195 iops : min= 89, max= 486, avg=221.80, stdev=81.37, samples=1195 lat (usec) : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.02%, 500=0.01% lat (usec) : 750=0.01%, 1000=0.01% lat (msec) : 2=7.45%, 4=38.36%, 10=18.10%, 20=1.09%, 50=22.31% lat (msec) : 100=11.42%, 250=1.24%, 500=0.01% cpu : usr=0.26%, sys=19.41%, ctx=12026, majf=0, minf=18 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=100.0%, 32=0.0%, &gt;=64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, &gt;=64=0.0% issued rwts: total=313975,134655,0,0 short=0,0,0,0 dropped=0,0,0,0 latency : target=0, window=0, percentile=100.00%, depth=16Run status group 0 (all jobs): READ: bw=20.4MiB/s (21.4MB/s), 20.4MiB/s-20.4MiB/s (21.4MB/s-21.4MB/s), io=1226MiB (1286MB), run=60031-60031msec WRITE: bw=8972KiB/s (9188kB/s), 8972KiB/s-8972KiB/s (9188kB/s-9188kB/s), io=526MiB (552MB), run=60031-60031msecDisk stats (read/write): sdb: ios=314008/134653, merge=0/0, ticks=189470/89778, in_queue=279286, util=99.75% 输出报告分析下面是每个执行的数据方向的I&#x2F;O统计数据信息的代表值含义 read&#x2F;write： 读&#x2F;写的IO操作（还有一个trim没用过） salt： 提交延迟，这是提交I&#x2F;O所花费的时间（min:最小值，max:最大值，avg:平均值，stdev:标准偏差） chat： 完成延迟，表示从提交到完成I&#x2F;O部分的时间 lat： 相应时间，表示从fio创建I&#x2F;O单元到完成I&#x2F;O操作的时间 bw： 带宽统计 iops： IOPS统计 lat(nsec&#x2F;usec&#x2F;msec)： I&#x2F;O完成延迟的分布。这是从I&#x2F;O离开fio到它完成的时间。与上面单独的读&#x2F;写&#x2F;修剪部分不同，这里和其余部分的数据适用于报告组的所有I&#x2F; o。10&#x3D;0.01%意味着0.01%的I&#x2F;O在250us以下完成。250&#x3D;0.02%意味着0.02%的I&#x2F;O需要10到250us才能完成。 cpu： cpu使用率 IO depths： I&#x2F;O深度在作业生命周期中的分布 IO submit： 在一个提交调用中提交了多少个I&#x2F;O。每一个分录表示该数额及其以下，直到上一分录为止——例如，4&#x3D;100%意味着我们每次提交0到4个I&#x2F;O调用 IO complete： 和上边的submit一样，不过这个是完成了多少个 IO issued rwt： 发出的read&#x2F;write&#x2F;trim请求的数量，以及其中有多少请求被缩短或删除 IO latency： 满足指定延迟目标所需的I&#x2F;O深度 bw： 总带宽以及最小和最大带宽 io： 该组中所有线程执行的累计I&#x2F;O run： 这组线程中最小和最长的运行时。 ios： 所有组的I&#x2F; o个数 merge： I&#x2F;O调度器执行的总合并数 ticks： 使磁盘繁忙的滴答数（仅供参考，原文是Number of ticks we kept the disk busy） in_queue： 在磁盘队列中花费的总时间 util： 磁盘利用率。值为100%意味着我们保留了磁盘，如果一直很忙，那么50%的时间磁盘就会闲置一半的时间 FIO通过配置文件运行除了命令行直接执行命令外，也可以通过写配置到xxx.fio文件中，每次只用修改配置即可，使用更方便些，执行方式为fio xxx.fio 12345678910111213141516171819202122232425262728293031323334353637[root@localhost jobs]# cat test.fio[global]filename=/dev/sdbioengine=libaiodirect=1threadgroup_reporting[randread-4k-128M]rw=randreadbs=4ksize=128Mnumjobs=5[randwrite-4k-128M]rw=randwritebs=4ksize=128Mnumjobs=5[write-4k-128M]rw=writebs=4ksize=128Mnumjobs=5#执行fio命令测试[root@localhost jobs]# fio test.fiorandread-4k-128M: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1...randwrite-4k-128M: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1...write-4k-128M: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1...fio-3.10Starting 15 threadsJobs: 6 (f=6): [_(3),r(1),_(1),w(5),E(1),_(4)][92.1%][r=10.8MiB/s,w=29.2MiB/s][r=2777,w=7483 IOPS][eta 00m:05s] 性能关注的重点 顺序读写和随机读写：顺序读写指对大块数据进行读写操作，随机读写则是对随机位置的小块数据进行读写操作。顺序读写通常比随机读写更快，因为它可以利用SSD的顺序读写优势。然而，随机读写需要处理更多的数据以找到所需数据，因此其IOPS和带宽通常低于顺序读写。 SSD与HDD性能比较： HDD：顺硬盘驱动器 (HDD) 的顺序读写和随机读写性能是不同的。顺序读写操作是指读写大块连续的数据，这是硬盘驱动器的强项。因为磁头可以直接读写连续的数据块，因此顺序读写速度快。随机读写操作是指读写随机位置的小块数据，这是硬盘驱动器的弱点。因为磁头需要频繁移动以读写不同的数据块，因此随机读写速度较慢。因此，硬盘驱动器的顺序读写速度通常比随机读写速度快。在评估硬盘驱动器性能时，需要考虑两种读写方式的结果。 SSD：SSD 具有很高的随机读写性能，但顺序读写性能仍然不如随机读写性能。因为 SSD 需要管理大量的块，因此对大块连续的数据的读写可能不如对随机位置的小块数据的读写快。但需要注意的是，SSD 的顺序读写性能仍然高于硬盘驱动器 (HDD)。因此，即使是 SSD 的顺序读写性能不如随机读写性能，它仍然具有很高的性能。 测试配置建议 numjobs和iodepth设置： numjobs过大可能导致任务等待时间过长，建议设置为1、2、4、8。 iodepth可以设置大一些，建议为64、128，以增加IO任务队列。 利用率观察：通过iostat -x -m 5 /dev/sdb查看磁盘的utilize是否达到百分百。如果未达到，可继续增加numjobs直到utilize达到百分百。 关闭写缓存： 关闭写缓存可以提高数据持久性测试的准确性。 使用hdparm -W /dev/device查看当前状态，hdparm -W 0 /dev/device关闭写缓存。 其他建议 获取设备信息：使用smartctl -a /dev/device获取设备型号、连接版本和速度。 numjobs大小:FIO的多线程调度其实还是一个进程，numjobs过大的话会导致任务等待时间过长，任务一直在排队。numjobs不能开太大，建议是1、2、4、8；iodepth任务可以开大点，建议是64、128，因为队列任务相当于IO任务，进行压测时，numjobs从1、2、4、8往上调，同时使用iostat -x -m 5 /dev/sdb查看磁盘的utilize是否达到百分百；如果当前numjobs的utilize还不是百分百，表示不是压测，numjobs再往上加，直到utilize达到百分百为止。 多个fio进程测一个SSD和一个fio进程多线程测一个SSD的区别 多个fio进程测一个SSD和一个fio进程多线程测一个SSD的主要区别在于并发性和资源利用率。多个fio进程可以并发地访问SSD并生成更多的负载，这可以更好地测试SSD的并行读写能力和响应时间，但同时也会占用更多的CPU和内存资源。此外，由于多个fio进程之间的I&#x2F;O请求存在竞争关系，可能会影响测试结果的准确性和一致性。 相比之下，一个fio进程多线程测一个SSD可以更好地利用系统资源并模拟真实的应用程序I&#x2F;O模式。在这种情况下，每个线程可以并发地访问SSD并生成负载，同时避免了多个fio进程之间的竞争关系。这可以更好地测试SSD的性能和稳定性，并提供更准确的测试结果。 总的来说，两种方法都有其优缺点和适用场景。需要根据实际情况选择适当的测试方法来评估SSD的性能和可靠性。 磁盘性能摸底时需要关闭写缓存？ 在使用fio进行性能测试时，是否需要关闭写缓存取决于具体的测试需求和测试方案。如果测试场景需要模拟真实应用程序中的写操作，并希望测试结果反映出SSD的真实性能水平，那么建议关闭写缓存，以便更准确地衡量SSD的写性能和数据持久性。然而，在某些情况下，为了测试SSD的I&#x2F;O性能而不是数据持久性，或者为了测试SSD的读性能，可能需要保持写缓存打开。因此，是否需要关闭写缓存取决于具体的测试需求和测试方案，需要根据实际情况进行决定。 关闭写缓存会使得磁盘的性能更具可预测性，因为每次写入都会立即被持久化到磁盘上，可以更准确地测试磁盘的写入性能和数据持久性。然而，关闭写缓存会使得写入操作变慢，因为每个写入操作都必须等待磁盘确认数据已经被永久写入。 不关闭写缓存会使得磁盘的写入性能更高，因为数据可以先被缓存起来，减少了写入操作对磁盘的访问次数，从而提高了写入性能。然而，数据可能会在缓存中存储一段时间，而不是立即写入磁盘，这可能会导致数据丢失或不一致。 通过合理配置fio参数，可以有效测试存储系统的性能。需要根据实际需求选择适当的测试方法和参数设置，确保测试结果的准确性和代表性。在测试过程中，需特别注意顺序读写和随机读写性能的差异，以及SSD和HDD在不同读写模式下的表现。 Ceph Rados性能测试工具Ceph 提供了 rados bench 和 rados load-gen 两个命令，用于测试和评估集群的性能。以下是这两个命令的用法和选项。 rados bench 命令rados bench 命令用于对 Ceph 集群进行基准测试，以评估集群的读写性能。 语法1rados bench &#123;seconds&#125; &#123;operation&#125; [options] 参数说明 &#123;seconds&#125;：测试运行的持续时间，单位为秒。 &#123;operation&#125;：指定测试的操作类型，包括 write、seq（顺序读）、rand（随机读）。 常用选项 -p &#123;pool&#125; 或 --pool &#123;pool&#125;：指定使用的存储池名称。 -b &#123;block_size&#125; 或 --block-size &#123;block_size&#125;：指定块大小，默认值为 4MB。 -t &#123;threads&#125; 或 --threads &#123;threads&#125;：指定使用的线程数，默认值为 16。 -n &#123;num_objects&#125; 或 --num-objects &#123;num_objects&#125;：指定创建的对象数量。 -c 或 --no-cleanup：在测试结束后保留测试数据。 -D 或 --verify：启用数据验证。 示例写入测试1rados bench 60 write --pool testpool 顺序读测试1rados bench 60 seq --pool testpool 随机读测试1rados bench 60 rand --pool testpool 使用自定义块大小和线程数1rados bench 60 write --pool testpool --block-size 8192 --threads 32 rados load-gen 命令rados load-gen 命令用于生成负载，以测试和评估 Ceph 集群在不同负载下的性能。 语法1rados load-gen [options] 常用选项 -b &#123;bytes&#125; 或 --block-size &#123;bytes&#125;：指定块大小，默认值为 4096 字节。 -t &#123;threads&#125; 或 --threads &#123;threads&#125;：指定使用的线程数，默认值为 16。 -o &#123;objects&#125; 或 --objects &#123;objects&#125;：指定创建的对象数量，默认值为 100。 -p &#123;pool&#125; 或 --pool &#123;pool&#125;：指定使用的存储池名称，默认值为 rbd。 -c &#123;clients&#125; 或 --clients &#123;clients&#125;：指定客户端数量，默认值为 1。 -d &#123;seconds&#125; 或 --duration &#123;seconds&#125;：指定测试运行的持续时间，单位为秒。 --num-objects：指定对象的总数 --min-object-size：指定最小object尺寸 --max-object-size：指定最大object尺寸 --min-op-len：指定操作的最小 io 长度 --max-op-len：指定操作的最大 io 长度 --max-ops：指定最大操作数 --max-backlog：指定最大压测规模 --read-percent：指定读取操作的百分比 --target-throughput：指定目标吞吐量（以字节为单位） --run-length：指定总时间（以秒为单位） 示例使用默认参数测试1rados load-gen 指定块大小和对象数量测试1rados load-gen --block-size 8192 --objects 500 在指定存储池中测试1rados load-gen --pool mypool 使用多个线程和客户端测试1rados load-gen --threads 32 --clients 4 指定时间的测试1rados load-gen --duration 60 指定object大小范围的测试1rados -p hdd_pool load-gen --num-objects 200 --min-object-size 4K --max-object-size 4M --max-ops 20 --read-percent 0 --min-op-len 4K --max-op-len 1M --target-throughput 20G --run-length 20 --num-threads 64","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}]},{"title":"rbd相关运维命令","slug":"rbd相关运维命令","date":"2021-09-22T16:31:00.000Z","updated":"2024-08-04T08:03:25.937Z","comments":true,"path":"rbd相关运维命令/","permalink":"https://watsonlu6.github.io/rbd%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/","excerpt":"","text":"创建 rbd 镜像12rbd create &#123;pool-name&#125;/&#123;image-name&#125; [--size &#123;size&#125;] [--image-format &#123;format&#125;] [--features &#123;feature-list&#125;] 参数说明 {pool-name}&#x2F;{image-name}：指定存储池名称和镜像名称。 –size {size}：设置镜像的大小。 –image-format {format}：指定镜像的格式。有效的格式包括 1（兼容旧版格式）和 2（支持更多特性）。 –features {feature-list}：启用镜像特性，特性名称之间用逗号分隔。例如，layering,exclusive-lock。 查看 rbd 镜像列表1rbd ls &#123;pool-name&#125; 获取 rbd 镜像信息1rbd info &#123;pool-name&#125;/&#123;image-name&#125; 删除 rbd 镜像1rbd rm &#123;pool-name&#125;/&#123;image-name&#125; 映射 rbd 镜像到本地设备1rbd map &#123;pool-name&#125;/&#123;image-name&#125; 取消映射 rbd 镜像1rbd unmap /dev/rbd/&#123;pool-name&#125;/&#123;image-name&#125; 扩展 rbd 镜像大小1rbd resize &#123;pool-name&#125;/&#123;image-name&#125; --size &#123;new-size-in-MB&#125; 从ceph导出 RBD 镜像用于将镜像的数据导出到一个本地文件中。 1rbd export &#123;pool-name&#125;/&#123;image-name&#125; &#123;output-file&#125; 向ceph导入 RBD 镜像用于将本地文件导入到ceph rbd中。 1rbd import &#123;input-file&#125; &#123;pool-name&#125;/&#123;image-name&#125; 启用rbd特性1rbd feature enable &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125; rbd镜像特性 layering：支持图层（Layering） exclusive-lock：独占锁（Exclusive Locking） object-map：对象映射（Object Map） 禁用rbd特性1rbd feature disable &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125; 启用和禁用所有特性12rbd feature enable &#123;pool-name&#125;/&#123;image-name&#125; --allrbd feature disable &#123;pool-name&#125;/&#123;image-name&#125; --all RBD 复制命令用于复制 RBD 镜像到同一存储池中的新镜像，或复制到不同存储池中。 1rbd cp &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125; 启RBD 深度复制命令用于执行深度复制，包括镜像的所有快照和元数据。这个命令是 RADOS 镜像的完整复制工具。 1rbd deep-copy &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125; RBD 差异命令用于查看两个 RBD 镜像之间的差异，包括哪些块已更改、已删除或已新增。它可以帮助识别镜像之间的更改。 1rbd diff &#123;pool-name&#125;/&#123;image-name&#125; [--snap &#123;snapshot-name&#125;] [--diff &#123;other-image&#125;] RBD 磁盘使用命令用于显示 RBD 镜像的磁盘使用情况，包括镜像占用的总磁盘空间和其他相关信息。 1rbd du &#123;pool-name&#125;/&#123;image-name&#125; RBD 状态命令用于显示 RBD 镜像的状态信息，包括镜像的健康状态和其他相关信息。 1rbd status &#123;pool-name&#125;/&#123;image-name&#125; RBD 观察命令用于观察镜像的实时更改，这个命令允许用户跟踪镜像的变化，包括数据的写入、删除和其他操作。 1rbd watch &#123;pool-name&#125;/&#123;image-name&#125; RBD 稀疏化命令用于将 RBD 镜像的已分配但未使用的空间标记为稀疏。通过稀疏化，可以释放磁盘上未使用的空间，从而优化存储资源。注意事项 影响：稀疏化操作会扫描镜像并更新其内部元数据，可能会占用一定的 I&#x2F;O 带宽和计算资源。 稀疏化条件：只有在镜像的写入操作完成后，才建议执行稀疏化，以避免在镜像空间仍在使用时进行操作。1rbd sparsify &#123;pool-name&#125;/&#123;image-name&#125; 创建 rbd 快照1rbd snap create &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125; 保护 rbd 快照1rbd snap protect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125; 取消保护 rbd 快照1rbd snap unprotect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125; 列出 rbd 快照1rbd snap ls &#123;pool-name&#125;/&#123;image-name&#125; 回滚到 rbd 快照1rbd snap rollback &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125; 删除 rbd 快照1rbd snap rm &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125; rbd trashrbd trash 功能允许管理员在删除 rbd 镜像时先将其移动到 trash，而不是立即永久删除。这为误删除的镜像提供了恢复的机会。以下是 rbd trash 的详细说明和常用操作指南。rbd trash 功能的主要特点包括： 安全性：防止意外删除镜像。 可恢复性：在一定时间内可以恢复已删除的镜像。 定期清理：可以设置镜像在 trash 中的过期时间，自动清理过期的镜像。 查看 rbd trash 中的镜像1rbd trash ls &#123;pool-name&#125; 将 rbd 镜像移动到 trash1rbd trash mv &#123;pool-name&#125;/&#123;image-name&#125; 恢复 trash 中的 rbd 镜像1rbd trash restore &#123;pool-name&#125;/&#123;image-id or image-name&#125; 永久删除 trash 中的 rbd 镜像1rbd trash rm &#123;pool-name&#125;/&#123;image-id or image-name&#125; 查看 trash 中镜像的详细信息1rbd trash info &#123;pool-name&#125;/&#123;image-id or image-name&#125; 设置 trash 镜像的过期时间1rbd trash mv &#123;pool-name&#125;/&#123;image-name&#125; --expire &#123;time-spec&#125; 其中，&#123;time-spec&#125; 可以是以下格式之一： 1d：1天 1h：1小时 1m：1分钟 查看 trash 镜像的过期时间1rbd trash list &#123;pool-name&#125; --long 清空 trash1rbd trash purge &#123;pool-name&#125; 克隆 rbd 镜像1rbd clone &#123;pool-name&#125;/&#123;parent-image&#125;@&#123;snap-name&#125; &#123;pool-name&#125;/&#123;clone-name&#125; 合并克隆的 rbd 镜像1rbd flatten &#123;pool-name&#125;/&#123;clone-name&#125; 启用镜像同步1rbd mirror image enable &#123;pool-name&#125;/&#123;image-name&#125; &#123;mode&#125; 禁用镜像同步1rbd mirror image disable &#123;pool-name&#125;/&#123;image-name&#125; 查看镜像同步状态1rbd mirror image status &#123;pool-name&#125;/&#123;image-name&#125; 查看镜像配置1rbd config image list &#123;pool-name&#125;/&#123;image-name&#125; 修改镜像配置1rbd config image set &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125; &#123;value&#125; 删除镜像配置1rbd config image rm &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125;","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph相关运维命令","slug":"Ceph常见运维命令","date":"2021-09-07T12:01:00.000Z","updated":"2024-08-02T17:38:18.260Z","comments":true,"path":"Ceph常见运维命令/","permalink":"https://watsonlu6.github.io/Ceph%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/","excerpt":"","text":"查看 Ceph 的守护进程使用以下命令查看所有 Ceph 守护进程： 1systemctl list-unit-files | grep ceph 按类型在 Ceph 节点上启动特定类型的所有守护进程1234systemctl start/restart/stop ceph-osd.targetsystemctl start/restart/stop ceph-mon.targetsystemctl start/restart/stop ceph-mds.targetsystemctl start/restart/stop ceph-radosgw.target 启动特定守护进程实例1234systemctl start/status/restart/stop ceph-osd@&#123;id&#125;systemctl start/status/restart/stop ceph-mon@&#123;hostname&#125;systemctl start/status/restart/stop ceph-mds@&#123;hostname&#125;systemctl start/restart/stop ceph-radosgw@&#123;hostname&#125; 查看 Ceph 集群状态123ceph -s# 或者ceph health detail 输出信息包括： 集群的 ID 集群健康状况 monitor map 版本和 mon 法定人数状态 OSD map 版本和 OSD 状态摘要 PG map 版本 PG 和 Pool 的数量 集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量 客户端的 IOPS 信息 观察集群中的状态1ceph -w 输出信息包含： 集群的 ID 集群健康状况 monitor map 版本和 mon 法定人数状态 OSD map 版本和 OSD 状态摘要 PG map 版本 PG 和 Pool 的数量 集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量 客户端的 IOPS 信息 检查集群的容量情况1ceph df 修改集群配置查看默认配置1ceph --show-config 修改配置Ceph 支持在运行时更改 ceph-osd、ceph-mon、ceph-mds 守护进程的配置。 使用 tell 的方式1234ceph tell &#123;daemon-type&#125;.&#123;id or *&#125; injectargs --&#123;name&#125; &#123;value&#125; [--&#123;name&#125; &#123;value&#125;]# 示例：ceph tell osd.0 injectargs --debug-osd 20 --debug-ms 1 使用 daemon 的方式设置在设置的角色所在主机上进行设置。 1234# 查看配置ceph daemon osd.1 config get mon_osd_full_ratio# 修改配置ceph daemon osd.1 config set mon_osd_full_ratio 0.97 在线调整日志级别1ceph tell osd.0 injectargs --debug-osd 0/5 修改配置文件进行调整编辑 /etc/ceph/ceph.conf 中的 [global] 字段添加配置，重启相应服务生效。 查看 mon 状态1ceph mon stat 查看 mon 的详细状态1ceph daemon mon.ceph-xx-mon00 mon_status mon 法定人数状态1ceph quorum_status -f json-pretty 查看 mon 选举状态1ceph quorum_status 查看 mon 的映射信息1ceph mon dump 查看 mon 的 admin socket12ceph-conf --name mon.ceph-xx-mon00 --show-config-value admin_socket/var/run/ceph/ceph-mon.ceph-xx-mon00.asok CRUSH Map创建 bucket1ceph osd crush add-bucket host-xx host 移动 bucket1ceph osd crush move host-xx room=default 提取 CRUSH Map1ceph osd getcrushmap -o crush 反编译 crush map1crushtool -d crush -o de_crush 编译 crush map1crushtool -c de_crush -o new_crush 测试新的 CRUSH Map1crushtool --test -i new_crush --num-rep 3 --rule 1 --show-mappings 注入 CRUSH Map1ceph osd setcrushmap -i new_crush 列出 crush_rule1ceph osd crush rule ls 查看 crush_rule1ceph osd crush rule dump &#123;rule&#125; PG 和 PGP查看 PG 状态1ceph pg stat 查看 PG 组映射信息1ceph pg dump 查看一个 PG 的 map1ceph pg map 1.2f6 查看 PG 详细信息1ceph pg 1.2f6 query 显示集群所有 PG 统计1ceph pg dump --format plain 显示非正常状态的 PG1ceph pg dump_stuck inactive|unclean|stale OSD查看 OSD 状态1ceph osd stat 检查 OSD 容量是否均衡1ceph osd df tree 查看 OSD 映射信息1ceph osd dump 查看 OSD 目录树1ceph osd tree 定位 OSD 在集群中的节点位置1ceph osd find [osd] 查看对象在哪些 OSD 上1ceph osd map test-pool object1 下线某个 OSD1ceph osd down 0 拉起某个 OSD1ceph osd up 0 将某个 OSD 逐出集群1ceph osd out 0 将某个 OSD 加入集群1ceph osd in 0 删除某个 OSD1ceph osd rm 0 查看 OSD 延迟1ceph osd perf 查看当前 OSD 的状态1ceph daemon osd.14 perf dump Pool查看 pool 信息1ceph osd lspools 查看 pool 详细信息1ceph osd pool ls detail 查看 pool 状态1ceph osd pool stats 创建 pool创建副本 pool1ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; replicated &#123;crush-ruleset-name&#125; 创建 EC pool1ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; erasure &#123;erasure-code-profile&#125; 创建 erasure-code-profile1ceph osd erasure-code-profile set ec-4-2 k=4 m=2 ruleset-failure-domain=host ruleset-root=hddRoom 列出 erasure-code-profile1ceph osd erasure-code-profile ls 查看 erasure-code-profile1ceph osd erasure-code-profile get [name] 删除 pool1234# 删除 pool 前需要执行ceph tell mon.* injectargs --mon-allow-pool-delete=true# 删除poolceph osd pool delete test_pool test_pool --yes-i-really-really-mean-it #pool的名字需要重复两次 设置 pool 的 PG 数量1ceph osd pool set test_pool pg_num 100 查看 pool 的 PG 数量1ceph osd pool get test_pool pg_num 设置 pool 的 PGP 数量1ceph osd pool set test_pool pgp_num 100 查看 pool 的 PGP 数量1ceph osd pool get test_pool pgp_num 设置 pool 池副本数1ceph osd pool set test_pool size 3 查看 pool 池副本数1ceph osd pool get test_pool size 设置存储池 crush rule1ceph osd pool set &lt;poolname&gt; crush_ruleset &lt;ruleset&gt; 查看存储池 crush rule1ceph osd pool get &lt;poolname&gt; crush_rule RADOS查看对象信息1rados -p test_pool stat test-object-1 获取对象内容1rados -p test_pool get test-object-1 test.txt 将指定文件作为对象写入到资源池1rados -p test_pool put test-object-2 test.txt 删除对象1rados -p test_pool rm test-object-1","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph线程池实现","slug":"Ceph线程池实现","date":"2021-08-27T14:26:42.000Z","updated":"2024-07-28T10:16:50.698Z","comments":true,"path":"Ceph线程池实现/","permalink":"https://watsonlu6.github.io/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"线程池和工作队列是紧密相连的，基本流程就是将任务送入到对应的工作队列中，线程池中的线程从工作队列中取出任务并进行处理。Ceph 为了支持高并发读写，源码设计中大量采用线程池来进行io的推进。Ceph的线程池实现了多种不同的工作队列。一般情况下，一个线程池对应一个类型的工作队列。在要求不高的情况下，也可以一个线程池对应多种类型的工作队列，让线程池处理不同类型的任务。 mutex的实现src&#x2F;common&#x2F;mutex.h condition variable的实现src&#x2F;common&#x2F;cond.h 线程的实现Ceph中线程的在src&#x2F;common&#x2F;Thread.h中定义线程编程接口中，一个线程在创建时调用pthread_create函数来传入entry函数，杀死线程调用pthread_kill函数，当线程被杀死之后，必须调用pthread_join函数来进行线程资源的回收，如果不调用此函数，就会出现类似zombie process。如果要想让系统自己回收线程资源，就要将线程与父线程分离即调用pthread_detach。通过接口对比，src&#x2F;common&#x2F;Thread.h中定义的class thread，实际上是Ceph自己封装了一个线程类，这个线程类其实就是对Linux线程接口的一层封装。 Ceph中所有要用的线程必须继承Thread类，通过查找发现如下一些线程： Accepter.h (src\\msg)：class Accepter : public Thread &#x2F;&#x2F;用来socket bind的线程, accepter线程入口函数里定义了poll的网络通讯结构，用来放入管道 Admin_socket.h (src\\common)：class AdminSocket : public Thread Ceph_context.cc (src\\common)：class CephContextServiceThread : public Thread DispatchQueue.h (src\\msg): class DispatchThread : public Thread &#x2F;&#x2F;用来进行消息分发的线程， 在simpleMessenger中有dispatch_queue成员变量, FileJournal.h (src\\os): class Writer : public Thread &#x2F;&#x2F;用来进行写数据到journal中的线程 FileJournal.h (src\\os): class WriteFinisher : public Thread &#x2F;&#x2F;当用aio异步模式写数据到journal完成后，此线程用来接管其他剩余操作 FileStore.h (src\\os): struct SyncThread : public Thread &#x2F;&#x2F;用来同步数据执行同步的线程，主要是将已经完成的journal的序列号写入到文件中 Finisher.h (src\\common): struct FinisherThread : public Thread &#x2F;&#x2F;公用的finisher线程，用来查看某些特定的操作是否结束，结束后进行后续处理工作 MDLog.h (src\\mds): class ReplayThread : public Thread OSD.h (src\\osd): struct T_Heartbeat : public Thread &#x2F;&#x2F;维系osd进程之间互相心跳连接的线程 OutputDataSocket.h (src\\common):class OutputDataSocket : public Thread Pipe.h (src\\msg): class Reader : public Thread &#x2F;&#x2F;用来处理所有对socket的读操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理 Pipe.h (src\\msg): class Writer : public Thread &#x2F;&#x2F;用来处理所有对socket的写操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理 Pipe.h (src\\msg): class DelayedDelivery: public Thread &#x2F;&#x2F;用来处理所有对socket的延时操作 Signal_handler.cc (src\\global)：struct SignalHandler : public Thread SimpleMessenger.h (src\\msg): class ReaperThread : public Thread &#x2F;&#x2F;用来进行消息通信的主要线程 reaper是用来在通讯完成时拆除管道，其中成员有accepter线程（用来bind，accept socket文件放入管道），还有dispatch_queue线程 Throttle.cc (src\\test\\common): class Thread_get : public Thread Timer.cc (src\\common)：class SafeTimerThread : public Thread WorkQueue.h (src\\common): struct WorkThread : public Thread 可以将这些线程分为四类线程 普通类线程： 使用此类线程类直接申明继承自Thread，重写一个entry函数，在进程启动最初时，调用了create函数创建了线程，同时使用它的人必须自己定义消息队列。上面大部分线程都是此类，比如FileJournal::write_thread就是一个FileJournal::Writer类对象，它自己定义了消息队列FileJournal::writeq SafeTimerThread类线程: 此类线程使用者可以直接申明一个SafeTimer成员变量，因为SafeTimer中已经封装了SafeTimerThread类和一个消息队列（成员是Context回调类），并完成了entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过SafeTimer::add_event_after函数将钩子埋入，等待规定时间到达后执行。 FinisherThread类线程: 此类线程使用者可以直接申明一个Finisher成员变量，因为Finsher中已经封装了FinisherThread类和一个消息队列（成员是Context回调类），并完成entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过Finisher::queue函数将钩子埋入，等待某类操作完成后执行。 ThreadPool内部线程： 这类线程由于是具体工作类线程，所以他们一般都是以线程池形式一下创建多个。ThreadPool类内部有多个线程set&lt;WorkThread*&gt;和多个消息队列vector&lt;WorkQueue_*&gt;组成。工作流程就是线程不断的轮询从队列中拿去数据进行操作。 可以看到Ceph线程的所有接口都只是对相应的Linux接口的封装。继承其的子类主要在于实现entry()函数： 线程池的实现Ceph中线程池的在src&#x2F;common&#x2F;WorkQueue.h中定义线程池和工作队列其实是密不可分的，从Ceph的代码中也可以看出来。让任务推入工作队列，而线程池中的线程负责从工作队列中取出任务进行处理。工作队列和线程池的关系，类似于狡兔和走狗的关系，正是因为有任务，所以才需要雇佣线程来完成任务，没有了狡兔，走狗也就失去了存在的意义。而线程必须要可以从工作队列中认领任务并完成，这就类似于猎狗要有追捕狡兔的功能。正因为两个数据结构拥有如此紧密的关系，因此，Ceph中他们的相关函数都位于WorkQueue.cc和WorkQueue.h中。 void ThreadPool::start()函数ThreadPool::start()用来启动线程池，其在加锁的情况下，调用函数start_threads()，start_threads()检查当前的线程数，如果小于配置的线程池线程数，就创建新的工作线程。 struct WorkThread : public Thread ThreadPool::worker()线程池的关键在于线程的主函数做的事情。首先是工作线程。线程池中会有很多的WorkThread，它的基类就是Thread。线程的主函数为pool-&gt;worker，即ThreadPool::worker函数。其entry函数其实就是调用线程池的worker函数进行具体的工作。 ThreadPool::worker函数内定义了WorkThread类线程的操作逻辑。基本流程就是轮询所有WorkQueue_，当发现某种类型WorkQueue_中有数据时拿出，然后依次调用该WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。（worker函数的主要实现其实很常规，就是遍历work_queues，从其中找出每一个消息队列实例，并调用WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。） 线程池是支持动态调整线程个数的。所谓调整，有两种可能性，一种是线程个数增加，一种线程个数减少。当添加OSD的时候，数据会重分布，恢复的速度可以调节，其中一个重要的参数为osd-max-recovery-threads，该值修改可以实时生效。 ThreadPool::join_old_threads()线程本身是一个loop，不停地处理WorkQueue中的任务，在一个loop的开头，线程个数是否超出了配置的个数，如果超出了，就需要自杀，所谓自杀即将自身推送到_old_threads中，然后跳出loop，直接返回了。线程池中的其他兄弟在busy-loop开头的join_old_threads函数会判断是否存在自杀的兄弟，如果存在的话，执行join，为兄弟收尸。 ThreadPool::start_threads()start_threads函数不仅仅可以用在初始化时启动所有工作线程，而且可以用于动态增加，它会根据配置要求的线程数_num_threads和当前线程池中线程的个数，来创建WorkThread，当然了，他会调整线程的io优先级。 ThreadPool::handle_conf_change()线程池的线程个数如果不够用，也可以动态的增加，通过配置的变化来做到： ThreadPool::pause()线程池的工作线程，绝大部分时间内，自然是busy－loop中处理工作队列上的任务，但是有一种场景是，需要让工作暂时停下来，停止工作，不要处理WorkQueue中的任务。线程池提供了一个标志为_pause,只要_pause不等于0，那么线程池中线程就在loop中就不会处理工作队列中的任务，而是空转。为了能够及时的醒来，也不是sleep，而是通过条件等待，等待执行的时间。 当下达pause指令的时候，很可能线程池中的某几个线程正在处理工作队列中的任务，这种情况下并不是立刻就能停下的，只有处理完手头的任务，在下一轮loop中检查_pause标志位才能真正地停下。那么pause指令就面临选择，要不要等工作线程WorkThread处理完手头的任务。pause函数是等，pauser_new函数并不等，pause_new函数只负责设置标志位，当其返回的时候，某几个线程可能仍然在处理工作队列中的任务。 struct WorkQueue_在ThreadPool这个类中，set&lt;WorkThread*&gt; _threads保存着线程池中的多个线程，vector&lt;WorkQueue_*&gt; work_queues保存着线程池中的待线程处理的消息队列。整个线程池的原理思想比较简单就是生成一定数目的线程，然后线程从队列中遍历获取队列实例，调用实例自带的处理函数_void_process和_void_process_finish处理。 ThreadPool中的WorkQueue_，这是一种抽象的类，只定义了一个队列应该有的一些特定的函数，这些函数几乎都是虚函数，目的是为了调用到自己三个子类BatchWorkQueue、WorkQueueVal、WorkQueue自己定义的函数。而在三个子类中对应函数_void_process、_void_process_finish中又分别调用了使用者自己继承它们而自己实现的具体操作函数如_process,_process_finish。存放在work_queues里面的WorkQueue_类： 这是一个纯虚基类，也就是说不同的线程池要实现自己的队列，继承WorkQueues_并且实现其接口。线程池已经有4个纯虚基类继承这个类： BatchWorkQueue 批量处理队列 WorkQueueVal 存值队列 WorkQueue 存指针队列 PointerWQ 存指针队列 add_work_queue()&#x2F;remove_work_queue()ThreadPool中的add_work_queue和remove_work_queue就是用来建立和移除与WorkQueue关联的函数 TPHandle超时检查，每次线程函数执行时，都会设置一个grace超时时间，当线程执行超过该时间，就认为是unhealthy的状态。当执行时间超过suicide_grace时，OSD就会产生断言而导致自杀。heartbeat_handle_d记录了相关信息，并把该结构添加到HeartbeatMap的系统链表中保存。OSD会有一个定时器，定时检查是否超时。 线程池使用步骤先创建线程池，然后创建WorkQueue的时候，将线程池作为参数传递给WorkQueue，就能建立关系。 声明线程池成员ThreadPool *_tp 声明队列类型ThreadPool::WorkQueue_*_wq 重写WorkQueue中对应函数_void_process,_void_process_finish 调用*_tp.add_work_queue(*_wq)将队列传入 基本线程池扩展在Ceph中有不少线程池会实现继承以上基类：ThreadPool op_tp: 处理client请求 struct recovery_tp: 处理recovery_tp操作 struct command_tp: 处理命令行来的操作 ShardedThreadPool: Ceph还实现了另外一种线程池ShardedThreadPool，这种线程池与上面的线程池不同之处在于这种线程池是多线程共享队列的方式。只有一个队列，多个线程同时对这个队列进行处理。 SharededWQ: shardedThreadPool类型线程池内部有个比较重要的消息队列SharededWQ，该队列将多种OP放入其中 Ceph 在实际使用中，会用到这种线程池","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph_rbd客户端实现","slug":"Ceph-rbd客户端实现","date":"2021-08-15T14:26:55.000Z","updated":"2024-07-28T09:48:58.097Z","comments":true,"path":"Ceph-rbd客户端实现/","permalink":"https://watsonlu6.github.io/Ceph-rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Ceph RBD介绍随着云计算的发展，Ceph已经成为目前最为流行的分布式存储系统，俨然存储界的Linux操作系统。Ceph集块存储、文件存储和对象存储于一身，适用场景广泛，用户众多。RBD是 Ceph 分布式存储系统中提供的块存储服务，Ceph的块存储通过一个客户端模块实现，这个客户端可以直接从数据守护进程读写数据（不需要经过一个网关）。根据客户端整合生态系统的差异，使用Ceph的块设备有两种实现方式：librbd (用户态)和krbd (内核态)。RBD：RADOS Block Devices. Ceph block devices are thin-provisioned, resizable and store data striped over multiple OSDs in a Ceph cluster. 使用Ceph的块设备有两种路径（内核态与用户态）：(rbd map就是内核使用ceph块设备，调用librbd&#x2F;librados API访问ceph块设备是用户态) 通过Kernel Module(内核态RBD)：即创建了RBD设备后，把它映射到内核中（使用rbd map命令映射到操作系统上），成为一个虚拟的块设备，这时这个块设备同其他通用块设备一样，设备文件一般为&#x2F;dev&#x2F;rbd0，后续直接使用这个块设备文件就可以了，可以把&#x2F;dev&#x2F;rbd0格式化后挂载到某目录，也可以直接作为裸设备进行使用。krbd是一个内核模块。其在内核中以一个块设备的方式加以实现。这整个Ceph客户端都是以内核模块的方式实现（没有与之相关的用户态进程或者守护进程）。krbd在内核的源码目录源文件:drivers&#x2F;block&#x2F;rbd.c、drivers&#x2F;block&#x2F;rbd_types.h、net&#x2F;ceph&#x2F;、include&#x2F;linux&#x2F;ceph https://www.likecs.com/show-203739919.html https://github.com/torvalds/linux/blob/cfb92440ee71adcc2105b0890bb01ac3cddb8507/drivers/block/rbd.c https://github.com/torvalds/linux/tree/85c7000fda0029ec16569b1eec8fd3a8d026be73/include/linux/ceph 通过librbd(用户态RBD)：即创建了RBD设备后，使用librbd&#x2F;librados库访问和管理块设备。这种方式直接调用librbd提供的接口，实现对RBD设备的访问和管理，不会在客户端产生设备文件。应用方案有：SPDK+librbd&#x2F;librados https://github.com/ceph/ceph/tree/acf835db0376b1b71152949fdfec36e68f4a8474/src/librbd https://github.com/spdk/spdk/tree/cff525d336fb2c4c087413d4c53474b9e61cbdbe/module/bdev/rbd RBD 的块设备由于元数据信息少而且访问不频繁，故 RBD 在 Ceph 集群中不需要单独的守护进程将元数据加载到内存进行元数据访问加速，所有的元数据和数据操作直接与集群中的 Monitor 服务和 OSD 服务进行交互。 RBD 模块相关IO流图 客户端写数据osd过程： 采用的是 librbd 的形式，使用 librbd 创建一个块设备，向这个块设备中写入数据 在客户端本地同过调用 librados 接口，然后经过 pool，rbd，object，pg 进行层层映射（CRUSH 算法）,在 PG 这一层中，可以知道数据保存在哪几个 OSD 上，这几个 OSD 分为主从的关系 客户端与 primary OSD 建立 SOCKET 通信，将要写入的数据传给 primary OSD，由 primary OSD 再将数据发送给其他 replica OSD 数据节点。 IO 时序图librbd提供了针对image的数据读写和管理操作两种访问接口，其中数据读写请求入io_work_queue，然后由线程池中的线程将io请求以object粒度切分并分别调用rados层的aio接口（IoCtxImpl）下发，当所有的object请求完成时，调用librbd io回调（librbd::io::AioCompletion）完成用户层的数据io。而对image的管理操作通常需要涉及单个或多个对象的多次访问以及对内部状态的多次更新，其第一次访问将从用户线程调用至rados层 aio 接口或更新状态后入 op_work_queue 队列进行异步调用，当 rados aio 层回调或 Context 完成时再根据实现逻辑调用新的 rados aio 或构造 Context 回调，如此反复，最后调用应用层的回调完成管理操作请求。 此外为了支持多客户端共享访问 image，librbd 提供了构建于 rados watch&#x2F;notify 之上的通知、远程执行以及 exclusive lock 分布式锁机制。每个 librbd 客户端在打开 image 时（以非只读方式打开）都会 watch image 的 header 对象，从远程发往本地客户端的通知消息或者内部的 watch 错误消息会通过 RadosClient 的 Finisher 线程入 op_work_queue 队列进行异步处理。 RBD读写流程对于任何RBD客户端的读写都要经过以下步骤： 集群句柄创建、读取配置 集群句柄的创建即是librados:Rados的创建，初始化，读取配置 创建：librados::Rados rados; 初始化：librados::Rados::init(const char * const id) 主要是初始化librados::RadosClient 读取配置： librados::Rados::conf_read_file(const char * const path) const librados::Rados::conf_parse_argv(int argc, const char ** argv) const 集群连接 librados::Rados::connect() IO上下文环境初始化（pool创建读写等） librados::Rados::ioctx_create(const char *name, IoCtx &amp;io) 主要是IoCtxImpl即librados::IoCtx rbd创建 librbd::RBD rbd; RBD::create2(IoCtx&amp; io_ctx, const char *name, uint64_t size,uint64_t features, int *order) rbd的读写 librbd::Image image; RBD::open(IoCtx&amp; io_ctx, Image&amp; image, const char *name) Image::write(uint64_t ofs, size_t len, bufferlist&amp; bl) Image::read(uint64_t ofs, size_t len, bufferlist&amp; bl) IO上下文环境关闭 librbd::Image::close() librados::IoCtx::close() 集群句柄关闭 librados::Rados::shutdown() RBD源码介绍librbd以及librados都是属于ceph 的客户端，其提供ceph的接口向上提供块存储服务。librados提供客户端访问Ceph集群的原生态统一接口。其它接口或者命令行工具都基于该动态库实现。在librados中实现了Crush算法和网络通信等公共功能，数据请求操作在librados计算完成后可以直接与对应的OSD交互进行数据传输。librbd 是Ceph提供的在librados上封装的块存储接口的抽象。 librados主要的类是Rados和IoCtxlibrados::Rados负责初始化集群、读取配置、连接集群 librados::IoCtx负责创建IO上下文环境 librados::bufferlist负责读写缓存 librbd最主要的两个类是：RBD和Imagelibrbd::rbd主要负责 Image 的创建、删除、重命名、克隆映像等操作，包括对存储池的元数据的管理，针对部分操作提供异步接口 librbd::image负责image的读写(read&#x2F;write)，以及快照相关的操作等等。同时提供了相关异步操作的接口。 rbd Image的创建rbd卷的创建接口： 函数输入参数： io_ctx: 针对pool的上下文环境，对pool的操作都要首先建立一个相应的上下文环境 *name：rbd卷名字 size：rbd卷大小 features: rbd卷的特性 order: rbd卷的分块大小其具体实现在internal.cc中： 继续往下调用： 根据format格式调用不同的创建接口，现在主流采用新的format2，所用调用新的接口： 12int create_v2(IoCtx&amp; io_ctx, const char *imgname, uint64_t bid, uint64_t size,int order, uint64_t features, uint64_t stripe_unit,uint64_t stripe_count, uint8_t journal_order,uint8_t journal_splay_width, const std::string &amp;journal_pool,const std::string &amp;non_primary_global_image_id,const std::string &amp;primary_mirror_uuid,bool negotiate_features) 这个接口会做如下工作：创建rbd_id.{volume_name}的object： 然后想这个object写入block_name_prefix中的id号： 然后向rbd_directory写入卷名和id的一一映射。 创建名为rbd_header.id的object，并向这个object写入size,order,features,RBD_DATA_PREFIX等信息。 如果有条带化，则会设置条带化信息： 创建名为rbd_object_map.{id}的对象： rbd Image的打开 其实就是生成一个ImageCtx实例，调用其open接口。 rbd Image的写 rbd Image的读 rbd Image的快照 rbd Image的克隆 rbd Image的删除 rbd的读写 要使用librbd, 需要先安装下面两个包。可以通过yum安装, 也可以通过下载ceph源码编译后, 通过make install进行安装。 123$ yum list | grep librbdlibrbd1.x86_64 1:0.80.7-3.el7 baselibrbd1-devel.x86_64 1:0.80.7-3.el7 base 至于如何使用librbd来编程, 请参考下面的代码, 这是使用librbd的一般流程。编译时记得加上链接参数: g++ librbdtest.cpp -lrados -lrbd。更多函数的使用请参考 librbd.hpp。 另外 这里 有一些不错的示例。 12#include &lt;rbd/librbd.hpp&gt;#include &lt;rados/librados.hpp&gt;","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph_crush算法实现","slug":"Ceph-crush算法实现","date":"2021-08-02T14:26:17.000Z","updated":"2024-07-28T09:23:25.673Z","comments":true,"path":"Ceph-crush算法实现/","permalink":"https://watsonlu6.github.io/Ceph-crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"分布式存储系统的数据分布算法要解决数据如何分布到集群中的各个节点和磁盘上，其面临： 数据分布和负载均衡、灵活应对集群伸缩、大规模集群计算速率三方面的挑战。 数据分布和负载均衡：数据分布均衡，使数据能均匀地分布在各个节点和磁盘上，使数据访问的负载在各个节点和磁盘上。 灵活应对集群伸缩：系统可以方便地增加或者删除存储设备，当增加或删除存储设备后，能自动实现数据的均衡，并且迁移的数据尽可能减少。 大规模集群算法计算速率：要求数据分布算法维护的元数据相对较小，并且计算量不能太大。 在分布式存储系统中，数据分布算法由两种基本实现方法，一种是基于集中式的元数据查询的方式，如HDFS的实现：文件的分布信息是通过访问集中元数据服务器获得；另一种是基于哈希算法计算的方式。例如一致性哈希算法(DHT)。Ceph的数据分布算法CRUSH属于后者。CRUSH(Controlled Replication Under Scalable Hashing)，是一种基于哈希的数据分布算法。与另一种基于集中式的元数据查询的存储方式(文件的分布信息需要先通过访问集中元数据服务器获得)不同。CRUSH算法以数据唯一标识符、当前存储集群的拓扑结构以及数据分布策略作为CRUSH的输入，经过计算获得数据分布位置，直接与OSD进行通信，从而避免集中式查询操作，实现去中心化和高度并发。 Ceph 作为分布式存储系统，采用多节点多副本的数据存放方式，必然要解决数据如何分布到集群中各个节点和磁盘上。Ceph使用CRUSH数据分布算法。例如一个Ceph集群三副本，就存在着如何映射3个OSD存储这3个副本的数据，Ceph写数据时，即写object时，首先需要计算出object属于哪个PG，然后根据PG id 计算出存放的OSD位置。过程分两步：PG id的计算 ；OSD位置的计算。结合rbd的代码介绍这两个过程： 数据分片rbd的写接口（src&#x2F;linrbd&#x2F;librbd.cc）接口传入的参数是起始写位置（ofs）以及写数据大小（len）和要写入的数据（bl），调用io_work_queue-&gt;write()，生成Object写入请求对象，发送到ImageRequestWQ任务队列中，等待工作线程处理。现在看看ImageRequest的数据类型 因为Image的ImageWriteRequest继承AbstractImageWriteRequest类，重点关注AbstractImageWriteRequest类 发送写请求时调用void AbstractImageWriteRequest::send_request()函数，在这个函数进行切分数据，分成大小同等（可设定，一般为4M）的object(最后一块object可能大小小于块大小)。 file_to_extents就是将数据段切分各个object，具体怎么分割就不深入看源码了。然后调用send_object_requests()将分片各个object分别构造写请求 Op请求处理此后会构造objecter的Op请求，发送出去；转到src&#x2F;librados&#x2F;IoCtxImpl.cc，深入了解Op请求的处理。类IoCtxImpl是pool相关的上下文信息，一个pool对应一个IoCtxImpl对象，可以在该pool里创建、删除对象，完成对象数据读写等各种操作，包括同步和异步的实现。类IoCtxImpl把请求封装成ObjectOperation类。然后再添加pool的地址信息，封装成Obejcter::Op对象。Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。类IoCtxImpl的write&#x2F;read等同步操作函数通过调用operate()来调用op_submit()，类IoCtxImpl的aio_write&#x2F;aio_read&#x2F;aio_operate等异步函数直接调用了op_submit(），说明op_submit(）是object读写操作的入口。调用函数objeter-&gt;op_submit发送给相应的OSD，如果是同步操作，就等待操作完成。如果是异步操作，就不用等待，直接返回，当操作完成后，调用相应的回调函数通知。 Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。 发送数据op_submit在op_submit()调用_op_submit_with_budget()处理Throttle相关流量的限制在_op_submit_with_budget()中，如果osd_timeout大于0，就是设置定时器，当操作超时，就调用定时器回调函数op_ cancel取消操作，然后通过调用_op_submit(op, sul, ptid)。 _op_submit函数完成了关键的地址寻址和发送工作，比如_calc_target()、_get_session()、_send_op()等，调用函数_calc_target()计算对象的目标OSD；调用函数_get_session()获取目标OSD的链接，如果返回值为-EAGAIN，就升级为写锁，重新获取。检查当前的状态标志，如果当前是CEPH_OSDMAP_PAUSEWR或者OSD空间满，就暂时不发送，否则调用函数_prepare_osd_op准备请求的信息，调用函数_send_op发送出去。 对象寻址_calc_target重点详细分析下_calc_target函数：首先调用函数osdmap-&gt;get_pg_pool()根据t-&gt;base_oloc.pool获取pool信息，获取pg_pool_t对象；检查pi-&gt;last_force_op_resend是否强制重发，如果强制重发，force_resend设置为true；检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值；如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值；调用函数osdmap-&gt;object_locator_to_pg()获取目标对象所在的PG；调用函数osdmap-&gt;pg_to_up_acting_osds()通过CRUSH算法，获取该PG对应的OSD列表，即pg_to_up_acting_osds()通过CRUSH算法计算OSD；判断读写操作：读操作，如果设置了CEPH_OSD_FLAG_BALANCE_READS标志，调用rand() 取余随机选择一个副本读取；读操作，如果设置了CEPH_OSD_FLAG_LOCALIZE_READS标志，尽可能从本地副本读取；写操作，target的OSD就设置为主OSD。 首先获取pool信息，判断是否有效： const pg_pool_t *pi = osdmap-&gt;get_pg_pool(t-&gt;base_oloc.pool);然后根据获取pgid，注意pgid是一个结构体pg_tpg_t 的结构如下： m_pool 是pool id， m_seed是函数根据object id算出来的哈希值，m_preferred赋值-1。接下来就是调用osdmap-&gt;pg_to_up_acting_osds()，获取该PG对应的OSD列表，即选择OSD： pg_to_up_acting_osds()函数在src\\osd\\OSDMap.cc中，函数功能是选出up osds以及 acting osds, 两个都是数组类型，大小为副本数 继续跟踪这个函数： 进入_pg_to_raw_osds： 上面函数crush-&gt;do_rule()就是真正调用crush算法计算出相应的osd列表。这里重点解释下参数pps：对象到PG的映射：任何程序通过客户端访问集群时，首先由客户端生成一个字符串形式的对象名，然后基于对象名和命名空间计算得出一个32位哈希值。针对此哈希值，对该存储池的PG总数量pg_num取模(掩码计算)，得到该对象所在的PG的id号。ps_t pps = pool.raw_pg_to_pps(pg); // placement ps 可以看出pps这是一个哈希值，这个哈希值根据pool id，函数中pg.ps()就是我们object哈希算出的m_seed： 调用CRUSH算法下面就是进入do_rule 进行CRUSH算法的处理了：src&#x2F;crush&#x2F;CrushWrapper.h调用crush_do_rule()函数 继续调用crush_do_rule()算法，执行CEUSH算法CRUSH算法：针对指定输入x(要计算PG的pg_id)，CRUSH将输出一个包含n个不同目标存储对象(例如磁盘)的集合(OSD列表)。CRUSH的计算过程使用x、cluster map、placement rule作为哈希函数输入。因此如果cluster map不发生变化(一般placement rule不会轻易变化)，那么结果就是确定的。算法输入需要3个输入参数： 输入x 即PG id的哈希值 crush_map即集群的拓扑结构，集群的层级化描述，形如”数据中心-&gt;机架-&gt;主机-&gt;磁盘”这样的层级拓扑。用树来表示，每个叶子节点都是真实的最小物理存储设备，称为devices；所有中间节点统称为bucket，每个bucket可以是一些devices的集合，也可以是低一级的buckets集合；根节点称为root，是整个集群的入口。 ruleno 即选择策略，就rule规则，这里用编号表示；它决定一个PG的对象副本如何选择(从定义的cluster map的拓扑结构中)的规则，以此完成数据映射。palcement rule可以包含多个操作，这些操作共有3种类型：take(root)、select(replicas, type)、emit(void) crush 算法输入需要3个输入参数： 输入x 即PG id的哈希值 crush_map即集群的拓扑结构 ruleno 即选择策略，就rule规则，这里用编号表示 可以通过集群输出crush_map: vim crush_map如下： 显示的结构和代码中的结构还是有着映射的关系： 其中crush_bucket:对应： crush_rule:对应于： 逐一对比分析其数据结构。这里分析下其选择OSD的过程： 12345int *a = scratch;int *b = scratch + result_max;int *c = scratch + result_max*2;w = a;o= b; a, b, c 分别指向 scratch向量的0, 1, 2的位置.w &#x3D; a; o &#x3D; b; w被用作一个先入先出队列来在CRUSH map中进行横向优先搜索(BFS traversal). o存储crush_choose_firstn选择的结果. c存储最终的OSD选择结果. crush_do_rule函数里面最重要的是函数里面的for循环，这个循环就是筛选osd的过程， for循环中： 首先从rule规则中当前执行的步骤，首次就执行第一条步骤： struct crush_rule_step *curstep = &amp;rule-&gt;steps[step]; 然后根据当前执行步骤的操作类型，选择不同的分支操作，首先一般是take操作，而且是take fault。即crush map树根节点。这个过程就是根据step 逐步选择bucket 知道知道叶子节点，即OSD。 这个过程中，crush_choose_firstn 函数, 递归的选择特定bucket或者设备,并且可以处理冲突,失败的情况. 如果当前是choose过程,通过调用crush_bucket_choose来直接选择. 如果当前是chooseleaf选择叶子节点的过程,该函数将递归直到得到叶子节点. 在for循环中的crush_choose_firstn()计算后如果结果不是OSD类型, o 交给w。以便于 w成为下次crush_choose_firstn的输入参数。在crush_choose_firstn()中，for(){}：副本选择循环判断条件rep是否等于副本数numrep，rep叠加。do{}while (retry_descent)：选择OSD冲突或故障域失效时循环，随机因子r改变。do{}while (retry_bucket)：进行bucket层级选择，当前item type不是OSD时循环，当前进行选择的bucket，即in改变。 在crush_choose_firstn()函数中有crush_bucket_choose函数，这个函数根据bucket类型选择不同的权重计算方法刷选出bucket。如果采用straw2，就会采用bucket_straw2_choose接口进行筛选。 bucket_straw2_choose()功能是通过调用伪随机算法计算伪随机数，以伪随机数最高的作为选择出的节点 generate_exponential_distribution()产生随机数的思想是：采用逆变换采样的思想，先调用crush_hash32_3()计算哈希值，然后取随机数的低16位。计算指数随机变量。作为参考，请参阅指数分布示例：https://en.wikipedia.org/wiki/Inverse_transform_sampling#Examples。 由于某种原因，略小于 0x10000 会产生更准确的分布……可能是舍入效果。 自然对数查找表映射 [0,0xffff]（对应实数 [1&#x2F;0x10000, 1] 到 [0, 0xffffffffffff]（对应实数 [-11.090355,0]）。除以 16.16 定点权重。 请注意，ln 值为负数，因此较大的权重意味着较大的（较小的负数）draw值。 CRUSH算法的一些缺陷： CRUSH算法提供了uniform、list和tree等bucket类型作为straw bucket类型的替代方案，但这些算法在添加或删除服务器时需要进行不必要的重排，这使它们不适合用于大规模存储系统。 CRUSH算法的查找函数需要进行O(log n)的二分查找，以找到与给定对象ID最接近的虚拟ID。这个计算对于系统中的每个对象都需要进行，因此在系统中有大量对象时，计算成本会很高。 CRUSH算法在重建过程中可能会出现瓶颈，因为它需要在placement groups中进行数据放置，这可能会导致数据重建速度变慢。 CRUSH算法的计算复杂度较高，需要进行大量的计算，这可能会影响系统的性能。 综上所述，CRUSH算法虽然是一种灵活的对象放置算法，但它也存在一些缺陷，需要进一步改进和优化。 由于CRUSH算法的计算复杂度较高，需要进行大量的计算，因此使用多线程来加速计算是一种可行的方法。具体来说，可以将CRUSH算法的计算任务分配给多个线程，每个线程负责计算一部分任务，然后将结果合并起来。这样可以充分利用多核处理器的计算能力，提高计算效率。但是，需要注意的是，多线程计算也会带来一些额外的开销，如线程间的同步和通信开销，因此需要进行合理的线程调度和优化，以达到最佳的性能提升效果。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph_Bufferlist的设计与使用","slug":"Ceph_Bufferlist的设计与使用","date":"2021-07-14T05:19:06.000Z","updated":"2024-07-27T14:37:12.169Z","comments":true,"path":"Ceph_Bufferlist的设计与使用/","permalink":"https://watsonlu6.github.io/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Ceph Bufferlist的设计与使用做为主要和磁盘、网络打交道的分布式存储系统，序列化是最基础的功能之一。当一个结构通过网络发送或写入磁盘时，它被编码为一串字节。可序列化结构具encode 和 decode方法，将结构体序列化后存入bufferlist和从bufferlist读出字节串反序列化出结构体。bufferlist是ceph的底层组件，用于存储二进制数据，其存储的数据可以直接写入磁盘，在代码中有很广泛的使用。 为什么要用bufferlist？ 为了免拷贝。发送数据时，传统的socket接口通常需要读取一段连续的内存。但是我们要发的数据内存不连续，所以以前的做法是申请一块大的内存，然后将不连续的内存内的数据拷贝到大内存块中，然后将大内存块地址给发送接口。但是找一块连续的大内存并不容易，系统可能会为此做各种腾挪操作，而将数据拷贝的大内存中，又是一个拷贝操作。RDMA的发送支持聚散表，不需要读取连续的内存。有bufferlist之后，我们可以通过bufferlist，将不连续的物理内存管理起来，形成一段“连续”的虚拟内存，然后将bufferlist的内存指针传递给聚散表，再把聚散表交给RDMA 发送接口即可。整个过程免去了内存拷贝操作。大大降低了CPU的消耗。 在ceph中经常需要将一个bufferlist编码(encode)到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和copy，效率较高。 补充： 传统内存访问需要通过CPU进行数据copy来移动数据，通过CPU将内存中的Buffer1移动到Buffer2中。 DMA(直接内存访问)是一种能力，允许在计算机主板上的设备直接把数据发送到内存中去，数据搬运不需要CPU的参与。 DMA模式：可以同DMA Engine之间通过硬件将数据从Buffer1移动到Buffer2，而不需要操作系统CPU的参与，大大降低了CPU Copy的开销。 RDMA是一种概念，在两个或者多个计算机进行通讯的时候使用DMA， 从一个主机的内存直接访问另一个主机的内存。RDMA是一种新的直接内存访问技术，RDMA让计算机可以直接存取其他计算机的内存，而不需要经过处理器的处理。RDMA将数据从一个系统快速移动到远程系统的内存中，而不对操作系统造成任何影响。 bufferlist的设计Bufferlist负责管理Ceph中所有的内存。整个Ceph中所有涉及到内存的操作，无论是msg分配内存接收消息，还是OSD构造各类数据结构的持久化表示（encode&#x2F;decode），再到实际磁盘操作，都将bufferlist作为基础。bufferlist对应的类为buffer::list(using bufferlist &#x3D; buffer::list;)，而buffer::list又基于buffer::ptr和buffer::raw实现，探讨buffer::list的实现，不能跳过它们。 123456789101112namespace ceph &#123; namespace buffer &#123; inline namespace v14_2_0 &#123; class ptr; class list; &#125; class hash; &#125; using bufferptr = buffer::ptr; using bufferlist = buffer::list; using bufferhash = buffer::hash;&#125; ceph::buffer是ceph非常底层的实现，负责管理ceph的内存。ceph::buffer的设计较为复杂，但本身没有任何内容，主要包含buffer::list、 buffer::ptr、 buffer::raw、 buffer::hash。这三个类都定义在src&#x2F;include&#x2F;buffer.h和src&#x2F;common&#x2F;buffer.cc中。 buffer::raw：负责维护物理内存的引用计数nref和释放操作。 buffer::ptr：指向buffer::raw的指针。 buffer::list：表示一个ptr的列表（std::list），相当于将N个ptr构成一个更大的虚拟的连续内存。 buffer::hash：一个或多个bufferlist的有效哈希。 buffer这三个类的相互关系可以用下面这个图来表示：图中蓝色的表示bufferlist，橙色表示bufferptr，绿色表示bufferraw。 在这个图中，实际占用的系统内存一共就三段，分别是raw0，raw1和raw2代表的三段内存。 raw0被ptr0，ptr1，ptr2使用 raw1被ptr3，ptr4，ptr6使用 raw2被ptr5，ptr7使用 而list0是由ptr0-5组成的，list1是由ptr6和ptr7组成的。 从这张图上我们就可以看出bufferlist的设计思路： 对于bufferlist来说，仅关心一个个ptr。bufferlist将ptr连在一起，当做是一段连续的内存使用。因此，可以通过bufferlist::iterator一个字节一个字节的迭代整个bufferlist中的所有内容，而不需要关心到底有几个ptr，更不用关心这些ptr到底和系统内存是怎么对应的；也可以通过bufferlist::write_file方法直接将bufferlist中的内容出到一个文件中；或者通过bufferlist::write_fd方法将bufferlist中的内容写入到某个fd中。 bufferraw负责管理系统内存的，bufferraw只关心一件事：维护其所管理的系统内存的引用计数，并且在引用计数减为0时——即没有ptr再使用这块内存时，释放这块内存。 bufferptr负责连接bufferlist和bufferraw。bufferptr关心的是如何使用内存。每一个bufferptr一定有一个bufferraw为其提供系统内存，然后ptr决定使用这块内存的哪一部分。bufferlist只用通过ptr才能对应到系统内存中，而bufferptr而可以独立存在，只是大部分ptr还是为bufferlist服务的，独立的ptr使用的场景并不是很多。通过引入ptr这样一个中间层次，bufferlist使用内存的方式可以非常灵活。 快速encode&#x2F;decode。在Ceph中经常需要将一个bufferlist编码（encode）到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和Copy，效率较高。 一次分配，多次使用。调用malloc之类的函数申请内存是非常重量级的操作。利用ptr这个中间层可以缓解这个问题，可以一次性申请一块较大的内存，也就是一个较大的bufferraw，然后每次需要内存的时候，构造一个bufferptr，指向这个bufferraw的不同部分。这样就不再需要向系统申请内存了。最后将这些ptr都加入到一个bufferlist中，就可以形成一个虚拟的连续内存。 减少内存分配次数和碎片。利用bufferptr这个中间层进行内存的多次使用，多个bufferptr可以引用同一段bufferraw的不同区域，这个bufferraw可以预先一次性申请较大一段连续内存，从而避免了多次申请内存以及内存碎片的产生。 buffer::rawraw的数据成员部分代码如下： 1234567891011class buffer::raw&#123;public: char *data; //数据指针 unsigned len; //数据长度 std::atomic&lt;unsigned&gt; nref&#123;0&#125;; //引用计数 int mempool; mutable ceph::spinlock crc_spinlock; //读写锁 map&lt;pair&lt;size_t, size_t&gt;, pair&lt;uint32_t, uint32_t&gt;&gt; crc_map; //crc校验信息 ......&#125;; 最基本的成员：data是指向具体数据的指针，len是数据的长度，nref是引用计数。而mempool是其对应的内存池的index，这个和data空间的分配有关，暂时不去管它。 data指向的数据有很多来源，直接通过malloc从内存分配只是最基础的一种，可能还来自mmap内存映射的空间，甚至可以通过pipe管道＋splice实现零拷贝获取空间。有些时候，分配的空间时，会提出对齐的要求，比如按页对齐等等。对于每一种数据来源，需要不同逻辑的数据分配和释放函数，所以raw对应了很多子类，分别表示不同的数据。 下列类都继承了buffer::raw，实现了对data对应内存空间的申请 类raw_malloc实现了用malloc函数分配内存空间的功能 类class buffer::raw_mmap_pages实现了通过mmap来把内存匿名映射到进程的地址空间 类class buffer::raw_posix_aligned调用了函数posix_memalign来申请内存地址对齐的内存空间。 类class buffer::raw_hack_aligned是在系统不支持内存对齐申请的情况下自己实现了内存地址的对齐 类class buffer::raw_pipe实现了pipe做为Buffer的内存空间 类class buffer::raw_char使用了C++的new操作符来申请空间 这是因为这些来源不同，要求不同，buffer::raw也就有了一些变体，举个例子，对应于malloc的raw子类为buffer::raw_malloc，构造和析构函数中实现了使用malloc进行数据分配和释放的逻辑： 123456789101112131415161718192021222324252627282930313233343536class buffer::raw_malloc : public buffer::raw&#123;public: MEMPOOL_CLASS_HELPERS(); explicit raw_malloc(unsigned l) : raw(l) &#123; if (len) &#123; data = (char *)malloc(len); if (!data) throw bad_alloc(); &#125; else &#123; data = 0; &#125; inc_total_alloc(len); inc_history_alloc(len); bdout &lt;&lt; &quot;raw_malloc &quot; &lt;&lt; this &lt;&lt; &quot; alloc &quot; &lt;&lt; (void *)data &lt;&lt; &quot; &quot; &lt;&lt; l &lt;&lt; &quot; &quot; &lt;&lt; buffer::get_total_alloc() &lt;&lt; bendl; &#125; raw_malloc(unsigned l, char *b) : raw(b, l) &#123; inc_total_alloc(len); bdout &lt;&lt; &quot;raw_malloc &quot; &lt;&lt; this &lt;&lt; &quot; alloc &quot; &lt;&lt; (void *)data &lt;&lt; &quot; &quot; &lt;&lt; l &lt;&lt; &quot; &quot; &lt;&lt; buffer::get_total_alloc() &lt;&lt; bendl; &#125; ~raw_malloc() override &#123; free(data); dec_total_alloc(len); bdout &lt;&lt; &quot;raw_malloc &quot; &lt;&lt; this &lt;&lt; &quot; free &quot; &lt;&lt; (void *)data &lt;&lt; &quot; &quot; &lt;&lt; buffer::get_total_alloc() &lt;&lt; bendl; &#125; raw *clone_empty() override &#123; return new raw_malloc(len); &#125;&#125;; 对应于malloc的raw子类为buffer::raw_mmap_pages，顾名思义，也能够猜到，这个数据的来源是通过mmap分配的匿名内存映射。因此析构的时候，毫不意外，掉用munmap解除映射，归还空间给系统： 12345678910111213141516171819class buffer::raw_mmap_pages : public buffer::raw &#123;public: explicit raw_mmap_pages(unsigned l) : raw(l) &#123; data = (char*)::mmap(NULL, len, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0); if (!data) throw bad_alloc(); inc_total_alloc(len); inc_history_alloc(len); bdout &lt;&lt; &quot;raw_mmap &quot; &lt;&lt; this &lt;&lt; &quot; alloc &quot; &lt;&lt; (void *)data &lt;&lt; &quot; &quot; &lt;&lt; l &lt;&lt; &quot; &quot; &lt;&lt; buffer::get_total_alloc() &lt;&lt; bendl; &#125; ~raw_mmap_pages() &#123; ::munmap(data, len); dec_total_alloc(len); bdout &lt;&lt; &quot;raw_mmap &quot; &lt;&lt; this &lt;&lt; &quot; free &quot; &lt;&lt; (void *)data &lt;&lt; &quot; &quot; &lt;&lt; buffer::get_total_alloc() &lt;&lt; bendl; &#125; raw* clone_empty() &#123; return new raw_mmap_pages(len); &#125;&#125;; buffer::ptrbuffer::ptr是在buffer::raw系列的基础上，这个类也别名bufferptr， 这个类是raw这个类的包装升级版本，它的_raw就是指向buffer::raw类型的变量。成员部分如下（include&#x2F;buffer.h）： 123456class CEPH_BUFFER_API ptr&#123; raw *_raw; unsigned _off, _len; ......&#125;; 类buffer::ptr就是对于buffer::raw的一部分数据段，ptr是raw里的一个任意的数据段，_off是在_raw里的偏移量，_len是在ptr的长度。raw是真正存储数据的地方，而ptr只是指向某个raw中的一段的指针。其数据成员 _raw为指向raw的指针，_off表示数据起始偏移，_len表示数据长度。这边还有提一下ptr的append函数，直观上ptr不应该提供append函数，事实上ptr的append确实很局限，只有当ptr对应的raw区域后方有空闲空间的时候，才能append成功，至于空间不够的情况，应该是交给list等高层类来处理。代码如下： 123456789unsigned buffer::ptr::append(const char *p, unsigned l)&#123; assert(_raw); assert(l &lt;= unused_tail_length()); char *c = _raw-&gt;data + _off + _len; maybe_inline_memcpy(c, p, l, 32); _len += l; return _len + _off;&#125; buffer::ptr其他常见操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364buffer::ptr&amp; buffer::ptr::operator= (const ptr&amp; p)&#123; if (p._raw) &#123; p._raw-&gt;nref.inc(); bdout &lt;&lt; &quot;ptr &quot; &lt;&lt; this &lt;&lt; &quot; get &quot; &lt;&lt; _raw &lt;&lt; bendl; &#125; buffer::raw *raw = p._raw; release(); if (raw) &#123; _raw = raw; _off = p._off; _len = p._len; &#125; else &#123; _off = _len = 0; &#125; return *this;&#125;buffer::raw *buffer::ptr::clone()&#123; return _raw-&gt;clone();&#125;void buffer::ptr::swap(ptr&amp; other)&#123; raw *r = _raw; unsigned o = _off; unsigned l = _len; _raw = other._raw; _off = other._off; _len = other._len; other._raw = r; other._off = o; other._len = l;&#125;const char&amp; buffer::ptr::operator[](unsigned n) const&#123; assert(_raw); assert(n &lt; _len); return _raw-&gt;get_data()[_off + n];&#125;char&amp; buffer::ptr::operator[](unsigned n)&#123; assert(_raw); assert(n &lt; _len); return _raw-&gt;get_data()[_off + n];&#125;int buffer::ptr::cmp(const ptr&amp; o) const&#123; int l = _len &lt; o._len ? _len : o._len; if (l) &#123; int r = memcmp(c_str(), o.c_str(), l); if (r) return r; &#125; if (_len &lt; o._len) return -1; if (_len &gt; o._len) return 1; return 0;&#125; buffer::list类buffer::list是一个使用广泛的类，它是多个buffer::ptr的列表，也就是多个内存数据段的列表。多个bufferptr形成一个list，这就是bufferlist。简单来说，list就是一个ptr组成的链表：（include&#x2F;buffer.h） 12345678910class CEPH_BUFFER_API list&#123;// my private bitsstd::list&lt;ptr&gt; _buffers; //所有的ptrunsigned _len; //所有的ptr的数据总长度unsigned _memcopy_count; //当调用函数rebuild用来内存对齐时，需要内存拷贝的数据量ptr append_buffer; // 当有小的数据就添加到这个buffer里 mutable iterator last_p; //访问list的迭代器......&#125;; buffers是一个ptr的链表，_len是整个_buffers中所有的ptr的数据的总长度，_memcopy_count用于统计memcopy的字节数，append_buffer是用于优化append操作的缓冲区，可以看出bufferlist将数据以不连续链表的方式存储。 bufferlist的迭代器迭代器中提供的seek(unsigned o)和advance(int o)等函数中的o都是指bufferlist的偏移，而不是单个ptr内的偏移。 123456789101112template &lt;bool is_const&gt;class CEPH_BUFFER_API iterator_impl : public std::iterator&lt;std::forward_iterator_tag, char&gt;&#123;protected: bl_t *bl; list_t *ls; // meh.. just here to avoid an extra pointer dereference.. unsigned off; // in bl list_iter_t p; unsigned p_off; // in *p ......&#125;; 其数据成员的含义如下： bl：指针，指向bufferlist ls：指针，指向bufferlist的成员 _buffers p: 类型是std::list::iterator，用来迭代遍历bufferlist中的bufferptr p_off：当前位置在对应的bufferptr中的偏移量 off：当前位置在整个bufferlist中的偏移量 bufferlist常用函数librados只给出bufferlist API clear() 清空bufferlist中的内容 push_front(raw* &#x2F; ptr &amp;)push_back(raw* &#x2F; ptr &amp;) 在_buffers的前面或后面增加新的ptr rebuild()rebuild(ptr &amp;nb) 将bufferlist中buffers链表中所有的ptr中的数据存到一个ptr中，并将_buffers原有数据clear，然后将新的单个ptr push到_buffers中。 带参数时使用参数传入的ptr作为目标ptr，不带参数时自己创建一个ptr。 claim(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT); 将bl的数据拿过来，替换原有的数据。调用后bl数据被清空。 claim_append(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);claim_prepend(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT); 将bl的数据拿过来，splice到_buffers的尾部&#x2F;头部。 append(…) 将数据追加到_buffers尾部，已有ptr空间不够时，会自动分配新的ptr。 splice(unsigned off, unsigned len, list *claim_by &#x3D; 0) bl.splice(10,10,&amp;bl2); 将_buffers中总偏移off处长度为len的数据，move到claim_by对应的bufferlist的尾部。注意是move不是copy。 write(int off, int len, std::ostream &amp;out) 将_buffers中总偏移量off处长度为len的数据，写入到ostream。注意是copy，不是move。 push_front(ptr&amp; pb) 添加一个ptr到list头部 push_front(raw *r)添加一个raw到list头部中，先构造一个ptr，后添加list中 is_aligned(align)判断内存是否以参数align对齐，每一个ptr都必须以align对齐 read_fd()&#x2F;write_fd()把数据写入文件描述符或者从文件描述符读取数据 read_file()&#x2F;write_file()把数据写入文件或从文件读取数据的功能 write_stream() 内存对齐：有些情况下，需要内存地址对齐，例如当以directIO方式写入数据至磁盘时，需要内存地址按照内存页面大小（page）对齐，也即buffer::list的内存地址都需按照page对齐。函数rebuild用来完成对齐的功能。其实现的方法也比较简单，检查没有对齐的ptr，申请一块新对齐的内存，把数据拷贝过去，释放内存空间就可以了。 相关链接： http://bean-li.github.io/bufferlist-in-ceph/ https://www.jianshu.com/p/01e1f4e398df","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph序列化","slug":"Ceph数据序列化","date":"2021-07-10T04:43:01.000Z","updated":"2024-07-27T14:36:56.441Z","comments":true,"path":"Ceph数据序列化/","permalink":"https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"","text":"Ceph 数据序列化Ceph 作为主要处理磁盘和网络的分布式存储系统，数据序列化是其最基本的功能之一。当一个结构通过网络发送或写入磁盘时，它会被编码为一串字节。可序列化的结构体具有 encode 和 decode 方法，用于将结构体序列化后存入 bufferlist，或从 bufferlist 读取字节串并反序列化为结构体。 在 Ceph 中，经常需要将一个 bufferlist 编码（encode）到另一个 bufferlist 中。例如，在 msg 发送消息时，msg 通常会接收到由 OSD 等逻辑层传递给它的 bufferlist，然后 msg 需要给这个 bufferlist 添加消息头和消息尾，而消息头和消息尾也是用 bufferlist 表示的。在这种情况下，msg 通常会构造一个空的 bufferlist，然后将消息头、消息尾和内容都编码到这个空的 bufferlist 中。 在 bufferlist 之间进行编码实际上只需要进行指针的复制，而不涉及系统内存的申请和复制，因此效率较高。encode 和 decode 方法的主要作用是方便 Ceph 不同模块之间的参数传输。 在Ceph代码中有很多例子，这里有一个例子。 12345678910111213141516171819class AcmeClass&#123; int member1; std::string member2; void encode(bufferlist &amp;bl) &#123; ENCODE_START(1, 1, bl); ::encode(member1, bl); ::encode(member2, bl); ENCODE_FINISH(bl); &#125; void decode(bufferlist::iterator &amp;bl) &#123; DECODE_START(1, bl); ::decode(member1, bl); ::decode(member2, bl); DECODE_FINISH(bl); &#125;&#125;; ENCODE_START宏写入标头 说明version和 compat_version（初值均为 1）。每当对encode进行更改时，version就会增加。仅当更改会影响decode时compat_version才会增加 - 比如新结构体只在尾部添加字段，不会影响旧结构体的解析，因此在结构末尾添加字段的更改不需要增加 compat_version。DECODE_START宏采用一个参数，指定encode代码可以处理的最新消息版本。这与消息中编码的 compat_version 进行比较，如果消息太新，则会抛出异常。因为对 compat_verison 的更改很少，所以在添加字段时通常不需要担心。 Ceph序列化的方式序列化（在 Ceph 中称为 encode）的目的是将数据结构表示为二进制流，以便通过网络传输或保存在磁盘等存储介质上。其逆过程称为反序列化（在 Ceph 中称为 decode）。例如，对于字符串“abc”，其序列化结果为7个字节（bytes）：03 00 00 00 61 62 63，其中前四个字节（03 00 00 00）表示字符串的长度为3个字符，后三个字节（61 62 63）分别是字符“abc”的 ASCII 码的十六进制表示。Ceph 采用 little-endian 的序列化方式，即低地址存放最低有效字节，因此32位整数0x12345678的序列化结果为78 56 34 12。 由于序列化在整个 Ceph 系统中是非常基础且常用的功能，Ceph 将其序列化方式设计为统一的结构，即任何支持序列化的数据结构都必须提供一对定义在全局命名空间中的序列化&#x2F;反序列化（encode&#x2F;decode）函数。例如，如果我们定义了一个结构体 inode，就必须在全局命名空间中定义以下两个方法： encode(struct inode, bufferlist bl); decode(struct inode, bufferlist::iterator bl); 在此基础上，序列化的使用变得非常简单。对于任意可序列化的类型 T 的实例 instance_T，可以通过如下语句将 instance_T 序列化并保存到 bufferlist 类的实例 instance_bufferlist 中。 bufferlist类（定义于include&#x2F;buffer.h）是ceph核心的缓存类，用于保存序列化结果、数据缓存、网络通信等，能够将bufferlist理解为一个可变长度的char数组。 如下代码演示了将一个时间戳以及一个inode序列化到一个bufferlist中。 12345utime_t timestamp;inode_t inode;bufferlist bl;::encode(timetamp, bl)::encode(inode, bl); 序列化后的数据能够经过反序列化方法读取，例如如下代码片断从一个bufferlist中反序列化一个时间戳和一个inode（前提是该bl中已经被序列化了一个utime_t和一个inode，不然会报错）。 123bufferlist::iterator bl;::decode(timetamp, bl)::decode(inode, bl); 各种数据类型的序列化Ceph为其全部用到数据类型提供了序列化方法或反序列化方法，这些数据类型包括了绝大部分基础数据类型（int、bool等）、结构体类型的序列化（ceph_mds_request_head等）、集合类型（vector、list、set、map等）、以及自定义的复杂数据类型（例如表示inode的inode_t等），如下分别介绍不一样数据类型的序列化实现方式。 1、基本数据类型的序列化基本数据类型的序列化结果基本就是该类型在内存中的表示形式。基本数据类型的序列化方法使用手工编写，定义在include&#x2F;encoding.h中，包括如下类型： 12345__u8, __s8, char, boolceph_le64, ceph_le32, ceph_le16,float, double,uint64_t, int64_t, uint32_t, int32_t, uint16_t, int16_t,string, char* 在手工编写encode方法过程当中，为了不重复代码，借助了WRITE_RAW_ENCODER和WRITE_INTTYPE_ENCODER两个宏。 2、结构体类型的序列化结构体类型的序列化方法与基本数据类型的序列化方法一致，即便用结构体的内存布局做为序列化的形式。在结构体定义完成后，经过调用WRITE_RAW_ENCODER宏函数生成结构体的全局encode方法，例如结构体ceph_mds_request_head相关结构实现以下。 1234567891011struct ceph_mds_request_head &#123; __le64 oldest_client_tid; __le32 mdsmap_epoch; __le32 flags; __u8 num_retry, num_fwd; __le16 num_releases; __le32 op; __le32 caller_uid, caller_gid; __le64 ino;&#125; __attribute__ ((packed));WRITE_RAW_ENCODER(ceph_mds_request_head) 其中： ceph_mds_request_head结构体定义在include&#x2F;ceph_fs.h . WRITE_RAW_ENCODER(ceph_mds_request_head)语句位于include&#x2F;types.h WRITE_RAW_ENCODER宏函数定义在include&#x2F;encoding.h WRITE_RAW_ENCODER宏函数其实是经过调用encode_raw实现的，而encode_raw调用bufferlist的append的方法，经过内存拷贝，将数据结构放入到bufferlist中。相关代码为： 12345678910template&lt;class T&gt;inline void encode_raw(const T&amp; t, bufferlist&amp; bl)&#123; bl.append((char*)&amp;t, sizeof(t));&#125;template&lt;class T&gt;inline void decode_raw(T&amp; t, bufferlist::iterator &amp;p)&#123; p.copy(sizeof(t), (char*)&amp;t);&#125; 3、集合数据类型的序列化集合数据类型序列化的基本思路包括两步： 序列化集合大小， 序列化集合内的全部元素 例如vector&amp; v的序列化方法：其中元素的序列化经过调用该元素的encode方法实现。 12345678template&lt;class T&gt;inline void encode(const std::vector&lt;T&gt;&amp; v, bufferlist&amp; bl)&#123; __u32 n = v.size(); encode(n, bl); for (typename std::vector&lt;T&gt;::const_iterator p = v.begin(); p != v.end(); ++p) encode(*p, bl);&#125; 经常使用集合数据类型的序列化已经由Ceph实现，位于include&#x2F;encoding.h中，包括如下集合类型：pair, triple, list, set, vector, map, multimap, hash_map, hash_set, deque。集合类型的序列化方法皆为基于泛型（模板类）的实现方式，适用于全部泛型派生类。 4、复杂数据类型的序列化除以上两种业务无关的数据类型外，其它数据类型的序列化实现包括两部分： 在类型内部现实encode方法，将类型内部的encode方法重定义为全局方法。如下以utime_t类为例：utime_t内部实现了encode和decode两个方法，WRITE_CLASS_ENCODER宏函数将这两个方法转化为全局方法。 1234567891011121314class utime_t &#123; struct &#123; __u32 tv_sec, tv_nsec; &#125; tv; void encode(bufferlist &amp;bl) const &#123; ::encode(tv.tv_sec, bl); ::encode(tv.tv_nsec, bl); &#125; void decode(bufferlist::iterator &amp;p) &#123; ::decode(tv.tv_sec, p); ::decode(tv.tv_nsec, p); &#125;&#125;;WRITE_CLASS_ENCODER(utime_t) 复杂数据结构内部的encode方法的实现方式一般是调用其内部主要数据结构的encode方法，例如utime_t类的encode方法其实是序列化内部的tv.tv_sec和tv.tv_nsec两个成员。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph相关数据结构","slug":"Ceph相关数据结构","date":"2021-07-02T15:33:02.000Z","updated":"2024-07-27T14:36:43.411Z","comments":true,"path":"Ceph相关数据结构/","permalink":"https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"Ceph 相关数据结构要想深入到Ceph的源码底层，就必须对代码通用库里的一些关键，常见的数据结构进行学习，这样才能更好的理解源代码。从最高的逻辑层次为Pool的概念，然后是PG的概念。其次是OSDＭap记录了集群的所有的配置信息。数据结构OSDOp是一个操作上下文的封装。结构object_info_t保存了一个元数据信息和访问信息。对象ObjectState是在object_info_t基础上添加了一些内存的状态信息。SnapSetContext和ObjectContext分别保存了快照和对象上下文相关的信息。Session保存了一个端到端的链接相关的上下文。 PoolPool是整个集群层面定义的一个逻辑的存储池。对一个Pool可以设置相应的数据冗余类型，目前有副本和纠删码两种实现。数据结构pg_pool_t用于保存Pool的相关信息。Pool的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150struct pg_pool_t &#123; static const char *APPLICATION_NAME_CEPHFS; static const char *APPLICATION_NAME_RBD; static const char *APPLICATION_NAME_RGW; enum &#123; TYPE_REPLICATED = 1, // replication 副本 //TYPE_RAID4 = 2, // raid4 (never implemented) 从来没实现的raid4 TYPE_ERASURE = 3, // erasure-coded 纠删码 &#125;; enum &#123; FLAG_HASHPSPOOL = 1&lt;&lt;0, // hash pg seed and pool together (instead of adding) FLAG_FULL = 1&lt;&lt;1, // pool is full FLAG_EC_OVERWRITES = 1&lt;&lt;2, // enables overwrites, once enabled, cannot be disabled FLAG_INCOMPLETE_CLONES = 1&lt;&lt;3, // may have incomplete clones (bc we are/were an overlay) FLAG_NODELETE = 1&lt;&lt;4, // pool can&#x27;t be deleted FLAG_NOPGCHANGE = 1&lt;&lt;5, // pool&#x27;s pg and pgp num can&#x27;t be changed FLAG_NOSIZECHANGE = 1&lt;&lt;6, // pool&#x27;s size and min size can&#x27;t be changed FLAG_WRITE_FADVISE_DONTNEED = 1&lt;&lt;7, // write mode with LIBRADOS_OP_FLAG_FADVISE_DONTNEED FLAG_NOSCRUB = 1&lt;&lt;8, // block periodic scrub FLAG_NODEEP_SCRUB = 1&lt;&lt;9, // block periodic deep-scrub FLAG_FULL_QUOTA = 1&lt;&lt;10, // pool is currently running out of quota, will set FLAG_FULL too FLAG_NEARFULL = 1&lt;&lt;11, // pool is nearfull FLAG_BACKFILLFULL = 1&lt;&lt;12, // pool is backfillfull FLAG_SELFMANAGED_SNAPS = 1&lt;&lt;13, // pool uses selfmanaged snaps FLAG_POOL_SNAPS = 1&lt;&lt;14, // pool has pool snaps FLAG_CREATING = 1&lt;&lt;15, // initial pool PGs are being created &#125;; utime_t create_time; //Pool创建时间 uint64_t flags; ///&lt; FLAG_* Pool的相关标志 __u8 type; ///&lt; TYPE_* 类型 __u8 size, min_size; ///&lt;Pool的size和min_size，即副本数和至少保证的副本数 __u8 crush_rule; ///&lt; crush placement rule rule的编号 __u8 object_hash; ///&lt; hash mapping object name to ps 对象映射的hash函数 __u8 pg_autoscale_mode; ///&lt; PG_AUTOSCALE_MODE_ PG数自动增减模式private: __u32 pg_num = 0, pgp_num = 0; ///&lt; pg、pgp的数量 __u32 pg_num_pending = 0; ///&lt; pg_num we are about to merge down to __u32 pg_num_target = 0; ///&lt; pg_num we should converge toward __u32 pgp_num_target = 0; ///&lt; pgp_num we should converge towardpublic: map&lt;string,string&gt; properties; ///&lt; OBSOLETE string erasure_code_profile; ///&lt; name of the erasure code profile in OSDMap epoch_t last_change; ///&lt; most recent epoch changed, exclusing snapshot changes /// last epoch that forced clients to resend epoch_t last_force_op_resend = 0; /// last epoch that forced clients to resend (pre-nautilus clients only) epoch_t last_force_op_resend_prenautilus = 0; /// last epoch that forced clients to resend (pre-luminous clients only) epoch_t last_force_op_resend_preluminous = 0; /// metadata for the most recent PG merge pg_merge_meta_t last_pg_merge_meta; snapid_t snap_seq; ///&lt; seq for per-pool snapshot epoch_t snap_epoch; ///&lt; osdmap epoch of last snap uint64_t auid; ///&lt; who owns the pg uint64_t quota_max_bytes; ///&lt; maximum number of bytes for this pool uint64_t quota_max_objects; ///&lt; maximum number of objects for this pool /* * Pool snaps (global to this pool). These define a SnapContext for * the pool, unless the client manually specifies an alternate * context. */ map&lt;snapid_t, pool_snap_info_t&gt; snaps; /* * Alternatively, if we are defining non-pool snaps (e.g. via the * Ceph MDS), we must track @removed_snaps (since @snaps is not * used). Snaps and removed_snaps are to be used exclusive of each * other! */ interval_set&lt;snapid_t&gt; removed_snaps; unsigned pg_num_mask, pgp_num_mask; // Tier cache : Base Storage = N : 1 // ceph osd tier add &#123;data_pool&#125; &#123;cache pool&#125; set&lt;uint64_t&gt; tiers; ///&lt; pools that are tiers of us int64_t tier_of; ///&lt; pool for which we are a tier // Note that write wins for read+write ops // WriteBack mode, read_tier is same as write_tier. Both are cache pool. // Diret mode. cache pool is read_tier, not write_tier. // ceph osd tier set-overlay &#123;data_pool&#125; &#123;cache_pool&#125; int64_t read_tier; ///&lt; pool/tier for objecter to direct reads to int64_t write_tier; ///&lt; pool/tier for objecter to direct writes to // Set cache mode // ceph osd tier cache-mode &#123;cache-pool&#125; &#123;cache-mode&#125; cache_mode_t cache_mode; ///&lt; cache pool mode uint64_t target_max_bytes; ///&lt; tiering: target max pool size uint64_t target_max_objects; ///&lt; tiering: target max pool size // 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据 uint32_t cache_target_dirty_ratio_micro; ///&lt; cache: fraction of target to leave dirty // 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据 uint32_t cache_target_dirty_high_ratio_micro; ///&lt; cache: fraction of target to flush with high speed // 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰 uint32_t cache_target_full_ratio_micro; ///&lt; cache: fraction of target to fill before we evict in earnest // 对象在 cache 中被刷入到 storage 层的最小时间 uint32_t cache_min_flush_age; ///&lt; minimum age (seconds) before we can flush // 对象在 cache 中被淘汰的最小时间 uint32_t cache_min_evict_age; ///&lt; minimum age (seconds) before we can evict // HitSet 相关参数 HitSet::Params hit_set_params; ///&lt; The HitSet params to use on this pool // 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的h缓存统计信息 uint32_t hit_set_period; ///&lt; periodicity of HitSet segments (seconds) // 记录系统保存最近的多少个 hit_set 记录 uint32_t hit_set_count; ///&lt; number of periods to retain // hitset archive 对象的命名规则 bool use_gmt_hitset; ///&lt; use gmt to name the hitset archive object uint32_t min_read_recency_for_promote; ///&lt; minimum number of HitSet to check before promote on read uint32_t min_write_recency_for_promote; ///&lt; minimum number of HitSet to check before promote on write uint32_t hit_set_grade_decay_rate; ///&lt; current hit_set has highest priority on objects ///&lt; temperature count,the follow hit_set&#x27;s priority decay ///&lt; by this params than pre hit_set //当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数 uint32_t hit_set_search_last_n; ///&lt; accumulate atmost N hit_sets for temperature 为温度累积最多N次hit_sets uint32_t stripe_width; ///&lt; erasure coded stripe size in bytes uint64_t expected_num_objects; ///&lt; expected number of objects on this pool, a value of 0 indicates ///&lt; user does not specify any expected value bool fast_read; ///&lt; whether turn on fast read on the pool or not pool_opts_t opts; ///&lt; options /// application -&gt; key/value metadata map&lt;string, std::map&lt;string, string&gt;&gt; application_metadata;private: vector&lt;uint32_t&gt; grade_table;public: uint32_t get_grade(unsigned i) const &#123; if (grade_table.size() &lt;= i) return 0; return grade_table[i]; &#125; void calc_grade_table() &#123; unsigned v = 1000000; grade_table.resize(hit_set_count); // hit_set_count记录系统保存最近的多少个 hit_set 记录 for (unsigned i = 0; i &lt; hit_set_count; i++) &#123; v = v * (1 - (hit_set_grade_decay_rate / 100.0)); grade_table[i] = v; &#125; &#125;&#125;; 数据结构pg_pool_t的成员变量和方法较多，不一一介绍了。 PGPG可以认为是一组对象的集合，该集合里的对象有共同特征：副本都分布在相同的OSD列表中。结构体pg_t只是一个PG的静态描述信息（只有三个成员变量），类PG及其子类ReplicatedPG都是和PG相关的处理。pg_t的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h） 12345678struct pg_t &#123; uint64_t m_pool; //pg所在的pool uint32_t m_seed; //pg的序号 static const uint8_t calc_name_buf_size = 36; // max length for max values len(&quot;18446744073709551615.ffffffff&quot;) + future suffix len(&quot;_head&quot;) + &#x27;\\0&#x27; hobject_t get_hobj_start() const; hobject_t get_hobj_end(unsigned pg_num) const; static void generate_test_instances(list&lt;pg_t*&gt;&amp; o);&#125;; OSDMapOSDMap类定义了Ceph整个集群的全局信息。它由Monitor实现管理，并以全量或者增量的方式向整个集群扩散。每一个epoch对应的OSDMap都需要持久化保存在meta下对应对象的omap属性中。内部类Incremental以增量的形式保存了OSDMap新增的信息。OSDMap包含了四类信息：首先是集群的信息，其次是pool的信息，然后是临时PG相关信息，最后就是所有OSD的状态信息。OSDMap类的数据结构如下：（src&#x2F;osd&#x2F;OSDMap.h） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889class OSDMap &#123;public: MEMPOOL_CLASS_HELPERS(); typedef interval_set&lt; snapid_t, mempool::osdmap::flat_map&lt;snapid_t,snapid_t&gt;&gt; snap_interval_set_t; class Incremental &#123; public: MEMPOOL_CLASS_HELPERS(); //系统相关的信息 /// feature bits we were encoded with. the subsequent OSDMap /// encoding should match. uint64_t encode_features; uuid_d fsid; //当前集群的fsid值 epoch_t epoch; //当前集群的epoch值 new epoch; we are a diff from epoch-1 to epoch utime_t modified; //创建修改的时间戳 int64_t new_pool_max; //incremented by the OSDMonitor on each pool create int32_t new_flags; int8_t new_require_osd_release = -1; // full (rare) bufferlist fullmap; // in lieu of below. bufferlist crush;......private: //集群相关的信息 uuid_d fsid; //当前集群的fsid值 epoch_t epoch; //当前集群的epoch值 what epoch of the osd cluster descriptor is this utime_t created, modified; //创建、修改的时间戳 epoch start time int32_t pool_max; //最大的pool数量 the largest pool num, ever uint32_t flags; //一些标志信息 //OSD相关的信息 int num_osd; //OSD的总数量 not saved; see calc_num_osds int num_up_osd; //处于up状态的OSD的数量 not saved; see calc_num_osds int num_in_osd; //处于in状态的OSD的数量 not saved; see calc_num_osds int32_t max_osd; //OSD的最大数目 vector&lt;uint32_t&gt; osd_state; //OSD的状态 mempool::osdmap::map&lt;int32_t,uint32_t&gt; crush_node_flags; // crush node -&gt; CEPH_OSD_* flags mempool::osdmap::map&lt;int32_t,uint32_t&gt; device_class_flags; // device class -&gt; CEPH_OSD_* flags utime_t last_up_change, last_in_change; // These features affect OSDMap[::Incremental] encoding, or the // encoding of some type embedded therein (CrushWrapper, something // from osd_types, etc.). static constexpr uint64_t SIGNIFICANT_FEATURES = CEPH_FEATUREMASK_PGID64 | CEPH_FEATUREMASK_PGPOOL3 | CEPH_FEATUREMASK_OSDENC | CEPH_FEATUREMASK_OSDMAP_ENC | CEPH_FEATUREMASK_OSD_POOLRESEND | CEPH_FEATUREMASK_NEW_OSDOP_ENCODING | CEPH_FEATUREMASK_MSG_ADDR2 | CEPH_FEATUREMASK_CRUSH_TUNABLES5 | CEPH_FEATUREMASK_CRUSH_CHOOSE_ARGS | CEPH_FEATUREMASK_SERVER_LUMINOUS | CEPH_FEATUREMASK_SERVER_MIMIC | CEPH_FEATUREMASK_SERVER_NAUTILUS; struct addrs_s &#123; mempool::osdmap::vector&lt;std::shared_ptr&lt;entity_addrvec_t&gt; &gt; client_addrs; mempool::osdmap::vector&lt;std::shared_ptr&lt;entity_addrvec_t&gt; &gt; cluster_addrs; mempool::osdmap::vector&lt;std::shared_ptr&lt;entity_addrvec_t&gt; &gt; hb_back_addrs; mempool::osdmap::vector&lt;std::shared_ptr&lt;entity_addrvec_t&gt; &gt; hb_front_addrs; &#125;; std::shared_ptr&lt;addrs_s&gt; osd_addrs; //OSD的地址 entity_addrvec_t _blank_addrvec; mempool::osdmap::vector&lt;__u32&gt; osd_weight; //OSD的权重 16.16 fixed point, 0x10000 = &quot;in&quot;, 0 = &quot;out&quot; mempool::osdmap::vector&lt;osd_info_t&gt; osd_info; //OSD 的基本信息 std::shared_ptr&lt; mempool::osdmap::vector&lt;uuid_d&gt; &gt; osd_uuid; //OSD对应的uuid mempool::osdmap::vector&lt;osd_xinfo_t&gt; osd_xinfo; //OSD一些扩展信息 //PG相关的信息 std::shared_ptr&lt;PGTempMap&gt; pg_temp; // temp pg mapping (e.g. while we rebuild) std::shared_ptr&lt; mempool::osdmap::map&lt;pg_t,int32_t &gt; &gt; primary_temp; // temp primary mapping (e.g. while we rebuild) std::shared_ptr&lt; mempool::osdmap::vector&lt;__u32&gt; &gt; osd_primary_affinity; ///&lt; 16.16 fixed point, 0x10000 = baseline // remap (post-CRUSH, pre-up) mempool::osdmap::map&lt;pg_t,mempool::osdmap::vector&lt;int32_t&gt;&gt; pg_upmap; ///&lt; remap pg mempool::osdmap::map&lt;pg_t,mempool::osdmap::vector&lt;pair&lt;int32_t,int32_t&gt;&gt;&gt; pg_upmap_items; ///&lt; remap osds in up set //pool的相关信息 mempool::osdmap::map&lt;int64_t,pg_pool_t&gt; pools; //pool的id到pg_pool_t的映射 mempool::osdmap::map&lt;int64_t,string&gt; pool_name; //pool的id到pool的名字的映射 mempool::osdmap::map&lt;string,map&lt;string,string&gt; &gt; erasure_code_profiles; //pool的EC相关信息 mempool::osdmap::map&lt;string,int64_t&gt; name_pool; //pool的名字到pool的id的映射 Op结构体Op封装了完成一个操作的相关上下文信息，包括target地址信息(op_target_t)、链接信息(session)等 123456789101112131415161718192021222324252627282930313233343536//Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。 struct Op : public RefCountedObject &#123; OSDSession *session; //OSD相关的Session信息 int incarnation; //引用次数 op_target_t target; //地址信息 ConnectionRef con; // for rx buffer only uint64_t features; // explicitly specified op features vector&lt;OSDOp&gt; ops; // 对应多个操作的封装 snapid_t snapid; //快照的ID SnapContext snapc; //pool层级的快照信息 ceph::real_time mtime; bufferlist *outbl; //输出的bufferlist vector&lt;bufferlist*&gt; out_bl; //每个操作对应的bufferlist vector&lt;Context*&gt; out_handler; //每个操作对应的回调函数 vector&lt;int*&gt; out_rval; //每个操作对应的输出结果 int priority; Context *onfinish; uint64_t ontimeout; ceph_tid_t tid; int attempts; version_t *objver; epoch_t *reply_epoch; ceph::coarse_mono_time stamp; epoch_t map_dne_bound; int budget; /// true if we should resend this message on failure bool should_resend; /// true if the throttle budget is get/put on a series of OPs, /// instead of per OP basis, when this flag is set, the budget is /// acquired before sending the very first OP of the series and /// released upon receiving the last OP reply. bool ctx_budgeted; int *data_offset; osd_reqid_t reqid; // explicitly setting reqid ZTracer::Trace trace; op_target_t数据结构op_target_t封装了对象所在的PG，以及PG对应的OSD列表等地址信息。 12345678910111213141516171819202122232425262728293031//封装了对象所在的PG，以及PG对应的OSD列表等地址信息 struct op_target_t &#123; int flags = 0; //标志 epoch_t epoch = 0; ///&lt; latest epoch we calculated the mapping object_t base_oid; //读取的对象 object_locator_t base_oloc; //对象的pool信息 object_t target_oid; //最终读取的目标对象 object_locator_t target_oloc; //最终目标对象的pool信息 ///&lt; true if we are directed at base_pgid, not base_oid bool precalc_pgid = false; ///&lt; true if we have ever mapped to a valid pool bool pool_ever_existed = false; ///&lt; explcit pg target, if any pg_t base_pgid; pg_t pgid; ///&lt; last (raw) pg we mapped to spg_t actual_pgid; ///&lt; last (actual) spg_t we mapped to unsigned pg_num = 0; ///&lt; last pg_num we mapped to unsigned pg_num_mask = 0; ///&lt; last pg_num_mask we mapped to unsigned pg_num_pending = 0; ///&lt; last pg_num we mapped to vector&lt;int&gt; up; ///&lt; set of up osds for last pg we mapped to vector&lt;int&gt; acting; ///&lt; set of acting osds for last pg we mapped to int up_primary = -1; ///&lt; last up_primary we mapped to int acting_primary = -1; ///&lt; last acting_primary we mapped to int size = -1; ///&lt; the size of the pool when were were last mapped int min_size = -1; ///&lt; the min size of the pool when were were last mapped bool sort_bitwise = false; ///&lt; whether the hobject_t sort order is bitwise bool recovery_deletes = false; ///&lt; whether the deletes are performed during recovery instead of peering bool used_replica = false; bool paused = false; int osd = -1; ///&lt; the final target osd, or -1 epoch_t last_force_resend = 0; CRUSH Map123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146struct crush_rule_step &#123; __u32 op; //操作类型 __s32 arg1; //操作数1 __s32 arg2; //操作数2&#125;;enum crush_opcodes &#123; CRUSH_RULE_NOOP = 0, CRUSH_RULE_TAKE = 1, /* arg1 = value to start with */ CRUSH_RULE_CHOOSE_FIRSTN = 2, /* arg1 = num items to pick */ /* arg2 = type */ CRUSH_RULE_CHOOSE_INDEP = 3, /* same */ CRUSH_RULE_EMIT = 4, /* no args */ CRUSH_RULE_CHOOSELEAF_FIRSTN = 6, CRUSH_RULE_CHOOSELEAF_INDEP = 7, CRUSH_RULE_SET_CHOOSE_TRIES = 8, /* override choose_total_tries */ CRUSH_RULE_SET_CHOOSELEAF_TRIES = 9, /* override chooseleaf_descend_once */ CRUSH_RULE_SET_CHOOSE_LOCAL_TRIES = 10, CRUSH_RULE_SET_CHOOSE_LOCAL_FALLBACK_TRIES = 11, CRUSH_RULE_SET_CHOOSELEAF_VARY_R = 12, CRUSH_RULE_SET_CHOOSELEAF_STABLE = 13&#125;;/* * 用于指定相对于传递给 do_rule 的 max 参数的选择 num (arg1) */#define CRUSH_CHOOSE_N 0#define CRUSH_CHOOSE_N_MINUS(x) (-(x))/* * 规则掩码用于描述规则的用途。 * 给定规则集和输出集的大小，我们在规则列表中搜索匹配的 rule_mask。 */struct crush_rule_mask &#123; __u8 ruleset; //ruleId __u8 type; //多副本还是纠删码 __u8 min_size; //副本数大于等于时适用 __u8 max_size; //副本数小于等于时适用&#125;;struct crush_rule &#123; __u32 len; //steps数组的长度 struct crush_rule_mask mask; //releset相关的配置参数 struct crush_rule_step steps[0]; //step集合&#125;;#define crush_rule_size(len) (sizeof(struct crush_rule) + \\ (len)*sizeof(struct crush_rule_step))/* * A bucket is a named container of other items (either devices or * other buckets). * 桶是其他item（设备或其他存储桶）的命名容器 *//** * 使用三种算法中的一种来选择的，这些算法代表了性能和重组效率之间的权衡。 * 如果您不确定要使用哪种存储桶类型，我们建议您使用 ::CRUSH_BUCKET_STRAW2。 * 该表总结了在添加或删除item时每个选项的速度如何与映射稳定性相比较。 * Bucket Alg Speed Additions Removals * ------------------------------------------------ * uniform O(1) poor poor * list O(n) optimal poor * straw2 O(n) optimal optimal */enum crush_algorithm &#123; CRUSH_BUCKET_UNIFORM = 1, CRUSH_BUCKET_LIST = 2, CRUSH_BUCKET_TREE = 3, CRUSH_BUCKET_STRAW = 4, CRUSH_BUCKET_STRAW2 = 5,&#125;;extern const char *crush_bucket_alg_name(int alg);#define CRUSH_LEGACY_ALLOWED_BUCKET_ALGS ( \\ (1 &lt;&lt; CRUSH_BUCKET_UNIFORM) | \\ (1 &lt;&lt; CRUSH_BUCKET_LIST) | \\ (1 &lt;&lt; CRUSH_BUCKET_STRAW))struct crush_bucket &#123; __s32 id; //bucket的编号。小于0 /*!&lt; bucket identifier, &lt; 0 and unique within a crush_map */ __u16 type; //bucket的类型/*!&lt; &gt; 0 bucket type, defined by the caller */ __u8 alg; //使用的crush算法/*!&lt; the item selection ::crush_algorithm */ __u8 hash; //使用的hash算法/* which hash function to use, CRUSH_HASH_* */ __u32 weight; //权重 /*!&lt; 16.16 fixed point cumulated children weight */ __u32 size; //items的数量/*!&lt; size of the __items__ array */ __s32 *items; //子bucket/*!&lt; array of children: &lt; 0 are buckets, &gt;= 0 items */&#125;;struct crush_weight_set &#123; __u32 *weights; /*!&lt; 16.16 fixed point weights in the same order as items */ __u32 size; /*!&lt; size of the __weights__ array */&#125;;struct crush_choose_arg &#123; __s32 *ids; /*!&lt; values to use instead of items */ __u32 ids_size; /*!&lt; size of the __ids__ array */ struct crush_weight_set *weight_set; /*!&lt; weight replacements for a given position */ __u32 weight_set_positions; /*!&lt; size of the __weight_set__ array */&#125;;struct crush_choose_arg_map &#123; struct crush_choose_arg *args; /*!&lt; replacement for each bucket in the crushmap */ __u32 size; /*!&lt; size of the __args__ array */&#125;;struct crush_bucket_uniform &#123; struct crush_bucket h; /*!&lt; generic bucket information */ __u32 item_weight; /*!&lt; 16.16 fixed point weight for each item */&#125;;struct crush_bucket_list &#123; struct crush_bucket h; /*!&lt; generic bucket information */ __u32 *item_weights; /*!&lt; 16.16 fixed point weight for each item */ __u32 *sum_weights; /*!&lt; 16.16 fixed point sum of the weights */&#125;;struct crush_bucket_tree &#123; struct crush_bucket h; /* note: h.size is _tree_ size, not number of actual items */ __u8 num_nodes; __u32 *node_weights;&#125;;struct crush_bucket_straw &#123; struct crush_bucket h; __u32 *item_weights; /* 16-bit fixed point */ __u32 *straws; /* 16-bit fixed point */&#125;;struct crush_bucket_straw2 &#123; struct crush_bucket h; /*!&lt; generic bucket information */ __. /*!&lt; 16.16 fixed point weight for each item */&#125;;struct crush_map &#123; struct crush_bucket **buckets; **类型，所有的bucket都存在这里 /*! 一个大小为__max_rules__ 的crush_rule 指针数组。 * 如果规则被删除，数组的一个元素可能为NULL（没有API 可以这样做，但将来可能会有一个）。 * 规则必须使用crunch_add_rule() 添加。 */ struct crush_rule **rules; //**类型，多层嵌套的rules __s32 max_buckets; /*!&lt; the size of __buckets__ */ // bucket的总数 __u32 max_rules; /*!&lt; the size of __rules__ */ // rule的总数 __s32 max_devices; // osd的总数 __u32 choose_local_tries; //选择的总次数 __u32 choose_local_fallback_tries; __u32 choose_total_tries; __u32 chooseleaf_descend_once; __u8 chooseleaf_vary_r; __u8 chooseleaf_stable; /* 该值是在构建器解码或构建后计算的。 它在此处公开（而不是具有“构建 CRUSH 工作空间”功能），以便调用者可以保留静态缓冲区、在堆栈上分配空间，或者在需要时避免调用堆分配器。 工作空间的大小取决于映射，而传递给映射器的临时向量的大小取决于所需结果集的大小。尽管如此，没有什么能阻止调用者在一个膨胀 foop 中分配两个点并传递两个点。 */ size_t working_size;","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph源码编译调试","slug":"Ceph源码编译调试","date":"2021-06-20T07:24:13.000Z","updated":"2024-07-27T14:38:39.225Z","comments":true,"path":"Ceph源码编译调试/","permalink":"https://watsonlu6.github.io/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95/","excerpt":"","text":"对于一个ceph开发人员来说编译源码以及打rpm是其必备技能。无论是fix bug还是向社区提交pull request都离不开编译源码。 编译环境环境介绍 ceph version: N版 14.2.16 硬件环境：Centos7虚拟机 网络环境与源加速 12345678910111213141516171819202122232425262728293031323334353637383940414243# 额外软件源、生成新的缓存yum -y install centos-release-sclyum -y install epel-release yum clean all &amp;&amp; yum makecacheyum listyum update# 更换pip源，创建 .pip 目录mkdir ~/.pip cd ~/.pip vi pip.conf# 写入以下配置[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com#配置yum源vim /etc/yum.repos.d/ceph.repo[norch]name=norchbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/enabled=1gpgcheck=0[x86_64]name=x86 64baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/enabled=1gpgcheck=0[SRPMS]name=SRPMSbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS/enabled=1gpgcheck=0[aarch64]name=aarch64baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/aarch64/enabled=1gpgcheck=0 安装编译环境及依赖包 123456789101112131415yum -y install rdma-core-devel systemd-devel keyutils-libs-devel openldap-devel leveldb-devel snappy-devel lz4-devel curl-devel nss-develyum -y install libzstd zstd gcc cmake make git wgetyum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils # 安装gcc 7.2scl enable devtoolset-7 bash #临时生效source /opt/rh/devtoolset-7/enableecho &quot;source /opt/rh/devtoolset-7/enable&quot; &gt;&gt;/etc/profile #长期生效gcc -v #查看环境gcc版本wget https://github.com/Kitware/CMake/releases/download/v3.18.2/cmake-3.18.2.tar.gz #安装cmake3tar -zxvf cmake-3.18.2.tar.gzcd cmake-3.18.2 yum -y install ncurses-devel openssl-devel./bootstrapgmake &amp;&amp; gmake installln -s /usr/local/share/cmake /usr/bin/cmake -version 安装 ccache 加速编译 1234567891011121314151617181920# 下载安装包并解压mkdir /home/ccache cd /home/ccachewget https://github.com/ccache/ccache/releases/download/v4.0/ccache-4.0.tar.gztar -zxvf ccache-4.0.tar.gzcd ccache-4.0# 编译安装mkdir build cd buildcmake -DCMAKE_BUILD_TYPE=Release -DZSTD_FROM_INTERNET=ON ..make -j12make install# 修改配置mkdir -p /root/.config/ccache/ vi /root/.config/ccache/ccache.confmax_size = 16Gsloppiness = time_macrosrun_second_cpp = true 编译ceph代码1234567891011121314151617181920212223242526272829303132## 下载Ceph源码一mkdir /home/cephcd /home/cephgit clone git://github.com/ceph/ceph.git #(git clone https://github.com/ceph/ceph.git)cd cephgit checkout nautilus #切换分支，这里以 N 版本为例git submodule update --init --recursive #进入ceph目录，下载ceph代码依赖 ## 下载Ceph源码二wget https://mirrors.aliyun.com/ceph/debian-nautilus/pool/main/c/ceph/ceph_14.2.22.orig.tar.gztar -zxvf ceph_14.2.22.orig.tar.gzcd ceph_14.2.2./install-deps.sh #执行依赖安装脚本，ceph 自带的解决依赖的脚本## 修改cmake参数，因为后面需要使用gdb debug客户端程序，客户端程序会依赖librados库，所以我们必须以debug的模式去编译ceph，否则编译器会优化掉很多参数，导致很多信息缺失，需要修改一下ceph cmake的参数。如图所示vim do_cmake.sh $&#123;CMAKE&#125; -DCMAKE_C_FLAGS=&quot;-O0 -g3 -gdwarf-4&quot; -DCMAKE_CXX_FLAGS=&quot;-O0 -g3 -gdwarf-4&quot; -DBOOST_J=$(nproc) $ARGS &quot;$@&quot; ..# 可以看到这里修改了cmake的参数，增加了两个配置项，稍微解释一下# CMAKE_C_FLAGS=“-O0 -g3 -gdwarf-4” ： c 语言编译配置# CMAKE_CXX_FLAGS=“-O0 -g3 -gdwarf-4” ：c++ 编译配置# -O0 : 关闭编译器的优化，如果没有，使用GDB追踪程序时，大多数变量被优化,无法显示, 生产环境必须关掉# -g3 : 意味着会产生大量的调试信息# -gdwarf-4 : dwarf 是一种调试格式，dwarf-4 版本为4 ./do_cmake.sh -DWITH_MANPAGE=OFF -DWITH_BABELTRACE=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DCMAKE_BUILD_TYPE=RelWithDebInfo -DWITH_CCACHE=ON --DWITH_PYTHON3=ON --DMGR_PYTHON_VERSION=3# 执行 cmake，解释一下，DWITH_MGR_DASHBOARD_FRONTEND=OFF 主要是因为 ceph dashboard 用到了一些国外的 nodejs源，国内无法下载，会导致编译失败超时。-DWITH_CCACHE=ON 如果你没有安装 步骤 2-2 的 ccache 的话，可以去掉这个参数。 cd buildmake -j20 #（线程数等于cpu core的2倍，可以提高编译的速度，20核CPU、32G内存的服务器） 修改do_cmake.sh编译进度 自此已经编译完ceph源代码！ 运行测试集群发行版的 ceph 安装包安装的集群默认是没有办法debug调试。这里推荐 ceph 内置的debug调试——vstart，非常方便模仿特殊场景进行debug调试。 12345678cd /home/watson/ceph/build # 进入build目录make vstart # 编译模拟启动环境（make help 查看有哪些target可以单独编译）MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore # (模拟启动，指令前半部分的MDS=0 RGW=1之类的就是设定你想要模拟的集群结构（集群的配置文件在ceph/build/ceph.conf）)# 启动完成后，可以在模拟集群环境下执行各种 ceph 指令(模拟集群所有的指令都在 build/bin 目录)bin/ceph -s # 查看 ceph 集群状态bin/radosgw-admin user list # 查看用户../src/stop.sh # 关闭测试集群 编译vstasrt环境启动vstart环境查看 ceph 集群状态查看Ceph用户 运行单元测试用例更改了代码准备提交到公司内部repo或者社区repo都需要先执行一下最小测试集，看看自己修改的代码有没有影响到别的模块(社区也会进行同样的测试)。 1234567cd buildmake #修改代码后先编译，可以模块编译man ctest #查看ctest的功能ctest -j20 #运行所有测试（使用所有处理器并行）ctest -R [regex matching test name(s)] #运行部分模块测试，使用 -R（正则表达式匹配）ctest -V -R [regex matching test name(s)] #使用 -V（详细）标志运行ctest -j20 -V -R [regex matching test name(s)] #运行正则表达式匹配的模块测试，显示详细信息，并发进行 注意：许多从 src&#x2F;test 构建的目标不是使用ctest运行的。以 “unittest” 开头的目标在其中运行make check，因此可以使用运行ctest。以 “ceph_test” 开头的目标不能，应该手动运行。发生故障时，请在 build&#x2F;Testing&#x2F;Temporary 中查找日志。 开发编译测试过程 1231. 编写保存源代码2. make -j20 unittest_crush #模块编译3. ctest -j20 -V -R unittest_crush #模块测试 通过librados客户端调试CRUSH算法编写客户端代码调用librados 库写入数据 运行librados代码 12yum install librados2-devel libradospp libradosstriper-devel -y #安装相关开发包（C/C++开发包）gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib #编译客户端程序 rados_write.c 这里解释一下gcc 几个参数，首先需要理解的是c程序在编译时依赖的库和运行时依赖库是分开指定的，也就是说，编译的时候使用的库，不一定就是运行时使用的库 g : 允许gdb调试 lrados : -l 指定依赖库的名字为rados L : 指定编译时依赖库的的路径， 如果不指定将在系统目录下寻找 o : 编译的二进制文件名 Wl : 指定编译时参数 rpath : 指定运行时依赖库的路径， 如果不指定将在系统目录下寻找 运行客户端程序 12./rados_writebin/rados ls -p default.rgw.meta #在集群中确认一下是否写入数据 运行rados_write程序确认写入数据 ceph的开发者模式是测试ceph功能和调试代码非常方便的途径，因为集群默认开启了debug模式，所有的日志都会详细的输出，并且为了调试的方便，在正式环境中的多线程多队列，在这都会简化。 使用GDB调试分析Object至OSD映射1234567yum install -y gdb #安装gdbgcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib #编译客户端程序 rados_write.cgdb ./rados_write #使用gdb 调试 rados_write 程序#启动程序后，需要设置断点，这里选择的是 crush_do_rule 函数，因为这个函数是 object–&gt;到PG 流程的终点b crush_do_rule #在crush_do_rule 函数设置断点bt #查看当前的函数堆栈 gdb调试raodos_wirte程序设置调试断点查看当前函数栈 得到的函数流程如下 12345678910111213#0 crush_do_rule at /home/watson/ceph/src/crush/mapper.c:904#1 do_rule at /home/watson/ceph/src/crush/CrushWrapper.h:1570#2 OSDMap::_pg_to_raw_osds at /home/watson/ceph/src/osd/OSDMap.cc:2340#3 OSDMap::_pg_to_up_acting_osds at /home/watson/ceph/src/osd/OSDMap.cc:2586#4 pg_to_up_acting_osds at /home/watson/ceph/src/osd/OSDMap.h:1209#5 Objecter::_calc_target at /home/watson/ceph/src/osdc/Objecter.cc:2846#6 Objecter::_op_submit at /home/watson/ceph/src/osdc/Objecter.cc:2367#7 Objecter::_op_submit_with_budget at /home/watson/ceph/src/osdc/Objecter.cc:2284#8 Objecter::op_submit at /home/watson/ceph/src/osdc/Objecter.cc:2251#9 librados::IoCtxImpl::operate at /home/watson/ceph/src/librados/IoCtxImpl.cc:690#10 librados::IoCtxImpl::write at /home/watson/ceph/src/librados/IoCtxImpl.cc:623#11 rados_write at /home/watson/ceph/src/librados/librados_c.cc:1133#12 main at rados_write.c:73 不关心librados是如何封装请求，只关心object到pg的计算过程，所以这里决定从 Objecter::_calc_target 函数开始debug 整个过程，重新开始，然后再次设置断点。重新开始，计算 object的hash值 ps 1b Objecter::_calc_target #断点 卡住在断点处，现在我们打开tui模式跟踪代码， crtl + x + a 可以切换到tui界面这里按 n 逐行debug代码， 这里我想显示打印 pg_pool_t *p 和 op_target_t *t 的信息其中 pg_pool_t 是pool的结构体，包含pool相关的所有信息 1p *pi #查看pi的数据结构 而 op_target_t 则是整个写入操作封装的结构信息，包含对象的名字，写入pool的id继续 n 单步调试，这里我们会进去 osdmap-&gt;object_locator_to_pg 函数。然后一步一步调试……object到PG的函数流程图PG映射到OSD函数流程图crush_choose_firstn选择的过程 使用VScode远程调试Ceph以ceph osd部分为例，为您演示通过第三方社区提供的vscode 编辑软件，对ceph osd进行进行图形化单步调试以及配置操作。vscode是微软公司一个开源的编译器具备轻量的特点，通过插件安装方式提供了丰富的调试功能。通常 Linux环境的c&#x2F;c++软件开发使用GDB进行命令行调试，命令行操方式极其不方便。使用vscode 的图形化界面可替代gdb 命令行 ，整个开发调试过程更加便捷。Ceph源码路径在&#x2F;home&#x2F;watson&#x2F;ceph目录下，其编译运行文件在&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;build&#x2F;bin当中。启动调试前需要停止本地的osd运行服务。下载安装windows的vscode和ssh在以下地址下载vscode: https://code.visualstudio.com/安装openssh (一般情况不用自己手动安装)如果需要远程开发，Windows机器也需要支持openssh，如果本机没有，会报错。可以到微软官网上下载ssh。在vscode安装Remote Development和Remote-SSH在安装完成之后，点击左侧的Remote-SSH选项卡，再将鼠标移向CONNECTIONS栏，点击出现的configure：填写linux服务器的ssh端口和用户名（如果是默认的22端口可不用填写）按下ctrl + s 保存 然后连接（&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;）输入密码，总共有多次输入密码的流程留意窗口变化打开远程服务器的文件夹 远程连接遇到的问题以及技巧 因为ceph工程文件数量众多会出现无法在这个大型工作区中监视文件更改。请按照说明链接来解决此问题的问题。原因：工作区很大并且文件很多，导致VS Code文件观察程序的句柄达到上限。解决方法：编辑linux服务器中的 &#x2F;etc&#x2F;sysctl.conf；将以下一行添加到文件末尾，可以将限制增加到最大值 fs.inotify.max_user_watches=524288 保存之后终端窗口 输入sysctl -p可解决。远程调试首先前提Linux服务器已经安装了GDB，否则会提示出错。在ceph工程目录下添加launch.json文件。在最左上栏运行(R) -&gt; 添加配置 ，注意一定要在ceph当前工程目录。修改配置launch.json中的program、args选项。 12345678910111213141516171819202122232425262728launch.json&#123; // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;ceph-debug&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/build/bin/unittest_crush&quot;, &quot;args&quot;: [&quot;-d&quot;, &quot;--cluster&quot;, &quot;ceph&quot;,&quot;--id&quot;, &quot;0&quot;, &quot;--setuser&quot;, &quot;root&quot;, &quot;--setgroup&quot;, &quot;root&quot;], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125; ] &#125; ]&#125; 按照下图点击就可以开始调试之路 报错记录报错1 1234RPC failed; result=35, HTTP code = 0 fatal: The remote end hung up unexpectedly无法克隆 &#x27;https://github.com/xxxx/xxxxxxxx.git&#x27; 到子模组路径 &#x27;xxxxxxxxx&#x27;解决： 通过设置Git的http缓存大小，解决了这个问题，在当前工程目录下运行如下命令： git config --global http.postBuffer 20M (如果20M不行就50M) 报错2 12编译出现了一个问题，卡在5%Built target rocksdb_ext这里 原因：国外网络太慢，下载boost_1_72_0.tar.bz2太慢了，换网络或者在先用本地下载再传到服务器上（ceph/build/boost/src目录下） 报错3 12No Package found for python-scipyvim ceph.spec.in 报错4 1234&quot;Error: Package: golang-github-prometheus-2.26.1-2.el7.x86_64 (epel) Requires: /usr/bin/systemd-sysusers&quot;, 去掉该需求vim ~/ceph-14.2.16/ceph.spec.in# 内容#BuildRequires: golang-github-prometheus","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph_librados_api使用","slug":"Ceph_librados_api使用","date":"2021-06-18T06:28:31.000Z","updated":"2024-07-27T14:37:33.694Z","comments":true,"path":"Ceph_librados_api使用/","permalink":"https://watsonlu6.github.io/Ceph_librados_api%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Librados API概述Ceph存储集群提供基本的存储服务，Ceph以独特的方式将对象、块和文件存储集成到一个存储系统中。基于RADOS，可以不限于RESTful或POSIX接口，使用librados API能够创建自定义的Ceph存储集群接口（除了块存储、对象存储和文件系统存储外）。librados API能够与Ceph存储集群中的两种类型的守护进程进行交互： Ceph Mon守护进程，维护集群映射的主副本 Ceph OSD守护进程，它将数据作为对象存储在存储节点上要使用 API，您需要一个正在运行的 Ceph 存储集群。（本教程教程使用ceph编译的vstart启动的开发编程环境）编译模拟启动环境1234make vstart #模拟启动MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore #模拟集群所有的指令都在 build/bin 目录bin/ceph -s #查看 ceph 集群状态../src/stop.sh #停止模拟集群 第 1 步：获取libradosCeph客户端应用必须绑定librados才能连接Ceph存储集群。在写使用librados的ceph客户端应用前，要安装librados及其依赖包。librados API本身是用C++实现，也有C、Python、Java和PHP的API。（本教程仅限于librados C&#x2F;C++API）获取C&#x2F;C++的librados 要在 Debian&#x2F;Ubuntu 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令： sudo apt-get install librados-dev 要在 RHEL&#x2F;CentOS 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令： sudo yum install librados2-devel 安装librados 后，可以在&#x2F;usr&#x2F;include&#x2F;rados 下找到 C&#x2F;C++所需的头文件 ls /usr/include/rados 第 2 步：配置集群句柄一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用libradosAPI连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它会创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。Ceph存储集群手柄封装客户端配置，包括： 基于用户ID的rados_create() 或者基于用户名的rados_create2()(首选) cephx认证密钥 Mon ID和IP地址 日志记录级别 调试级别 因此，Ceph客户端应用程序使用Ceph群集的步骤： 创建一个集群句柄，客户端应用将使用该句柄连接到存储集群中； 使用该手柄进行连接。要连接到集群的客户端应用必须提供Mon地址，用户名和认证密钥（默认启用cephx）。提示：与不同的 Ceph 存储集群或与具有不同用户的同一个集群通信需要不同的集群句柄。RADOS 提供了多种设置所需值的方法。对于Mon和加密密钥设置，处理它们的一种简单方法是确保 Ceph 配置文件包含密钥环文件的密钥环路径和至少一个Mon地址（例如mon host）。例如:123[global]mon host = 192.168.1.1keyring = /etc/ceph/ceph.client.admin.keyring 创建句柄后，读取 Ceph 配置文件来配置句柄。可以将参数传递给客户端应用程序并使用解析命令行参数的函数（例如rados_conf_parse_argv()）或解析 Ceph 环境变量（例如rados_conf_parse_env()）来解析它们。 连接后，客户端应用程序可以调用仅使用集群句柄影响整个集群的函数。例如，一旦有了集群句柄，就可以： • 获取集群统计信息 • 使用池操作（存在、创建、列出、删除） • 获取和设置配置 Ceph 的强大功能之一是能够绑定到不同的池。每个池可能有不同数量的归置组、对象副本和复制策略。例如，可以将池设置为使用 SSD 存储常用对象的“热”池或使用纠删码的“冷”池。各种语言的librados 绑定的主要区别在于 C 与C++、Java 和 Python 的面向对象绑定之间。面向对象的绑定使用对象来表示集群句柄、IO 上下文、迭代器、异常等。 C调用librados 示例对于 C，使用管理员用户创建一个简单的集群句柄，配置它并连接到集群如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;rados/librados.h&gt;int main(int argc,const char* argv[])&#123; rados_t cluster; char cluster_name[] = &quot;ceph&quot;; char user_name[] = &quot;client.admin&quot;; char conf_flie[] = &quot;/home/watson/ceph/build/ceph.conf&quot;; uint64_t flags; int err; err = rados_create2(&amp;cluster,cluster_name,user_name,flags); if(err &lt; 0) &#123; fprintf(stderr,&quot;%s: Couldn&#x27;t create the cluster handle!%s\\n&quot;,argv[0],strerror(-err)); exit(0); &#125;else&#123; printf(&quot;Create a cluster handle!!!\\n&quot;); &#125; err = rados_conf_read_file(cluster,conf_flie); if(err &lt; 0) &#123; fprintf(stderr,&quot;%s: cannot read config file: %s\\n&quot;,argv[0],strerror(-err)); exit(0); &#125;else&#123; printf(&quot;Read the config flie\\n&quot;); &#125; err = rados_conf_parse_argv(cluster,argc,argv); if(err &lt; 0) &#123; fprintf(stderr,&quot;%s: cannot parse command line arguments: %s\\n&quot;,argv[0],strerror(-err)); exit(0); &#125;else&#123; printf(&quot;Read the command line arguments\\n&quot;); &#125; err = rados_connect(cluster); if(err &lt; 0) &#123; fprintf(stderr,&quot;%s: cannot connect to cluster: %s\\n&quot;,argv[0],strerror(-err)); exit(0); &#125;else&#123; printf(&quot;Connected to the cluster\\n&quot;); &#125; return 0;&#125; 使用-lrados编译客户端应用代码并链接到librados，如下： 1gcc ceph-client.c -lrados -o ceph-client ceph源码开发vstart环境下的编译，如下： 1gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib C++调用librados示例Ceph项目在ceph&#x2F;examples&#x2F;librados目录中提供了一个 C++ 示例。对于 C++，使用管理员用户的简单集群句柄需要初始化librados::Rados集群句柄对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;rados/librados.hpp&gt;/* *通过librados::Rados句柄处理整个RADOS系统层面以及pool层面的管理。*/int main(int argc,const char* argv[])&#123; int ret = 0; librados::Rados cluster; //定义一个操控集群的句柄对象 char cluster_name[] = &quot;ceph&quot;; //集群名字 char user_name[] = &quot;client.admin&quot;; //集群用户名 char conf_flie[] = &quot;/home/watson/ceph/build/ceph.conf&quot;; //集群配置文件 uint64_t flags; ret = cluster.init2(user_name,cluster_name,flags); //初始化句柄对象 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t initialize the cluster handle! error: &quot;&lt;&lt;ret&lt;&lt;std::endl; return 1; &#125;else&#123; std::cout&lt;&lt;&quot;Create a cluster handle.&quot;&lt;&lt;std::endl; &#125; ret = cluster.conf_read_file(conf_flie); //读配置文件获取Mon的信息 if(ret &lt; 0 ) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t read the ceph configuration file! error&quot;&lt;&lt;ret&lt;&lt;std::endl; return 1; &#125;else&#123; std::cout&lt;&lt;&quot;Read the ceph configuration file.&quot;&lt;&lt;std::endl; &#125; ret = cluster.conf_parse_argv(argc,argv); //解析命令行输入的参数 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t parsed command line options!error&quot;&lt;&lt;ret&lt;&lt;std::endl; return 1; &#125;else&#123; std::cout&lt;&lt;&quot;Parsed command line options.&quot;&lt;&lt;std::endl; &#125; ret = cluster.connect(); //连接集群 if(ret &lt; 0 ) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t connect to cluster! error&quot;&lt;&lt;ret&lt;&lt;std::endl; return 1; &#125;else&#123; std::cout&lt;&lt;&quot;Connected to the cluster.&quot;&lt;&lt;std::endl; &#125; cluster.pool_create(&quot;testpool&quot;); //创建存储池 std::list&lt;std::string&gt; poolList; cluster.pool_list(poolList); //获取存储池列表 for(auto iter : poolList)&#123; std::cout&lt;&lt;iter&lt;&lt;std::endl; &#125; return 0;&#125; 编译源码，然后，使用-lrados链接librados，如下： 12g++ -g -c ceph-client.cc -o ceph-client.o g++ -g ceph-client.o -lrados -o ceph-client ceph源码开发vstart环境下的编译，如下： 1g++ -g librados_rados.cpp -lrados -L/home/watson/ceph/build/lib -o librados_rados -Wl,-rpath,/home/watson/ceph/build/lib 第 3 步：创建 I&#x2F;O 上下文一旦客户端应用程序拥有集群句柄并连接到 Ceph 存储集群，就可以创建 I&#x2F;O 上下文并开始读取和写入数据。I&#x2F;O 上下文将连接绑定到特定池。用户必须具有适当的CAPS权限才能访问指定的池。例如，具有读取权限但没有写入权限的用户将只能读取数据。I&#x2F;O 上下文功能包括： 写入&#x2F;读取数据和扩展属性 列出并迭代对象和扩展属性 快照池、列表快照等RADOS 使客户端应用程序能够进行同步和异步交互。一旦应用程序具有 I&#x2F;O 上下文，读&#x2F;写操作只需要知道对象&#x2F;xattr 名称。librados中封装的 CRUSH 算法使用Cluster map来选择合适的 OSD。OSD 守护进程自动处理副本。librados库将对象映射到归置组。以下示例使用默认数据池。但是，也可以使用 API 列出池、确保它们存在或创建和删除池。对于写操作，示例说明了如何使用同步模式。对于读取操作，示例说明了如何使用异步模式。(提示：使用此 API 删除池时要小心。如果删除池，则该池和池中的所有数据都将丢失。)C创建Ceph IO上下文示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;rados/librados.h&gt;int main(int argc,const char* argv[])&#123; rados_t cluster; //集群句柄 rados_ioctx_t io; //io上下文 char cluster_name[] = &quot;ceph&quot;; char user_name[] = &quot;client.admin&quot;; char conf_flie[] = &quot;/home/watson/ceph/build/ceph.conf&quot;; char poolname[] = &quot;testpool&quot;; uint64_t flags; int err; /* 为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！ */ err = rados_create2(&amp;cluster,cluster_name,user_name,flags); err = rados_conf_read_file(cluster,conf_flie); err = rados_conf_parse_argv(cluster,argc,argv); err = rados_connect(cluster); if(err &lt; 0) //检查是否连接到集群上 &#123; fprintf(stderr,&quot;%s: Cannot connect to cluster: %s\\n&quot;,argv[0],strerror(-err)); exit(0); &#125;else&#123; printf(&quot;Connected to the cluster......\\n&quot;); &#125; //err = rados_pool_delete(cluster,poolname); int poolID = rados_pool_lookup(cluster,poolname); //通过poolname获取pool的ID，若池不存在返回-ENOENT if(poolID == -ENOENT) &#123; printf(&quot;this pool does not exist,and create the pool...... \\n&quot;); rados_pool_create(cluster,poolname); &#125; err = rados_ioctx_create(cluster,poolname,&amp;io); //初始化io上下文 char obj_name[] = &quot;obj&quot;; char obj_content[] = &quot;Hello librados&quot;; err = rados_write(io,obj_name,obj_content,strlen(obj_content),0); //往集群写入对象 if(err == 0) &#123; printf(&quot;rados_write success......\\n&quot;); &#125; char xattr[] = &quot;en_US&quot;; err = rados_setxattr(io,obj_name,&quot;lang&quot;,xattr,5); //给对象设置属性 if(err == 0) &#123; printf(&quot;Set object xattr success......\\n&quot;); &#125; rados_completion_t comp; err = rados_aio_create_completion(NULL,NULL,NULL,&amp;comp); //异步读 char read_ret[1024]; err = rados_aio_read(io,obj_name,comp,read_ret,sizeof(read_ret),0); rados_aio_wait_for_complete(comp); if( err == 0) &#123; printf(&quot;%s\\&#x27;s content is %s\\n&quot;,obj_name,read_ret); &#125;else&#123; printf(&quot;read_aio_read: err\\n&quot;); &#125; rados_aio_release(comp); err = rados_read(io,obj_name,read_ret,sizeof(read_ret),0); //同步读 if( err &gt; 0) &#123; printf(&quot;%s\\&#x27;s content is %s\\n&quot;,obj_name,read_ret); &#125;else&#123; printf(&quot;read_read: err\\n&quot;); &#125; char xattr_ret[100]; err = rados_getxattr(io,obj_name,&quot;lang&quot;,xattr_ret,6); //获取对象属性 if( err &gt; 0) &#123; printf(&quot;Read %s\\&#x27;s xattr \\&quot;lang\\&quot; is %s\\n&quot;,obj_name,xattr_ret); &#125;else&#123; printf(&quot;rados_getxattr: err\\n&quot;); &#125; err = rados_rmxattr(io,obj_name,&quot;lang&quot;); //删除对象属性 err = rados_remove(io,obj_name); //删除对象 rados_ioctx_destroy(io); //释放io上下文 rados_shutdown(cluster); //关闭集群句柄 return 0;&#125; C++创建Ceph IO上下文示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;rados/librados.hpp&gt;int main(int argc,const char* argv[])&#123; librados::Rados cluster; librados::IoCtx io_ctx; char cluster_name[] = &quot;ceph&quot;; char user_name[] = &quot;client.admin&quot;; char conf_flie[] = &quot;/home/watson/ceph/build/ceph.conf&quot;; char poolname[] = &quot;testpool&quot;; uint64_t flags; int ret; /* 为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！ */ ret = cluster.init2(user_name,cluster_name,flags); ret = cluster.conf_read_file(conf_flie); ret = cluster.conf_parse_argv(argc,argv); ret = cluster.connect(); if(ret &lt; 0 ) //测试集群连接情况 &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t connect to cluster! error&quot;&lt;&lt;ret&lt;&lt;std::endl; return 1; &#125;else&#123; std::cout&lt;&lt;&quot;Connected to the cluster.&quot;&lt;&lt;std::endl; &#125; int poolID = cluster.pool_lookup(poolname); //通过pool名检测是否存在pool if(poolID == -ENOENT) &#123; printf(&quot;this pool does not exist,and create the pool...... \\n&quot;); cluster.pool_create(poolname); &#125;else&#123; std::cout&lt;&lt;&quot;pool &quot;&lt;&lt;poolID&lt;&lt;&quot; is using......&quot;&lt;&lt;std::endl; &#125; ret = cluster.ioctx_create(poolname,io_ctx); //初始化io_ctx char obj_name[] = &quot;obj&quot;; librados::bufferlist bl; bl.append(&quot;Hello Librados!&quot;); ret = io_ctx.write_full(obj_name,bl); //往集群写入数据 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t write object! error&quot;&lt;&lt;ret&lt;&lt;std::endl; exit(EXIT_FAILURE); &#125;else&#123; std::cout&lt;&lt;&quot;Write success......&quot;&lt;&lt;std::endl; &#125; librados::bufferlist lang_bl; lang_bl.append(&quot;en_US&quot;); ret = io_ctx.setxattr(obj_name,&quot;lang&quot;,lang_bl); //给对象设置属性 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t write object xattr! error&quot;&lt;&lt;ret&lt;&lt;std::endl; exit(EXIT_FAILURE); &#125;else&#123; std::cout&lt;&lt;&quot;Set xattr success......&quot;&lt;&lt;std::endl; &#125; librados::bufferlist read_bl; //异步读 int read_len = 1024; librados::AioCompletion *read_completion = librados::Rados::aio_create_completion(); ret = io_ctx.aio_read(obj_name,read_completion,&amp;read_bl,read_len,0); if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t read object! error&quot;&lt;&lt;ret&lt;&lt;std::endl; exit(EXIT_FAILURE); &#125; read_completion-&gt;wait_for_complete(); //等待异步完成 ret = read_completion-&gt;get_return_value(); //获取返回值 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t read object! error&quot;&lt;&lt;ret&lt;&lt;std::endl; exit(EXIT_FAILURE); &#125;else&#123; std::cout&lt;&lt;read_bl.c_str()&lt;&lt;std::endl; &#125; librados::bufferlist lang_res; ret = io_ctx.getxattr(obj_name,&quot;lang&quot;,lang_res); //获取属性 if(ret &lt; 0) &#123; std::cerr&lt;&lt;&quot;Couldn&#x27;t read object xattr! error&quot;&lt;&lt;ret&lt;&lt;std::endl; exit(EXIT_FAILURE); &#125;else&#123; std::cout&lt;&lt;lang_res.c_str()&lt;&lt;std::endl; &#125; ret = io_ctx.rmxattr(obj_name,&quot;lang&quot;); //删除对象属性 ret = io_ctx.remove(obj_name); //删除对象 io_ctx.close(); //关闭io cluster.shutdown(); //关闭集群句柄 return 0;&#125; 第 4 步：结束会话一旦客户端应用程序完成了 I&#x2F;O 上下文和集群句柄，应用程序应该关闭连接并关闭句柄。对于异步 I&#x2F;O，应用程序还应确保挂起的异步操作已完成。C结束会话示例 12rados_ioctx_destroy(io); rados_shutdown(cluster); C++结束会话示例 12io_ctx.close(); cluster.shutdown(); 补充：查看pool下的object对象 –all 显示所有namespace的object 1rados ls -p pool --all LIBRADOS常用接口 集群配置：提供了获取和设置配置值的方法，读取Ceph配置文件，并解析参数。 Rados.conf_get(option) Rados.conf_set(option, val) Rados.conf_read_file(path) Rados.conf_parse_argv(args) Rados.version() 连接管理：连接到集群、检查集群、检索集群的统计数据，并从集群断开连接。也可以断言集群句柄处于一个特定的状态（例如，”配置”，”连接”等等）。 Rados.connect(timeout) Rados.shutdown() Rados.get_fsid() Rados.get_cluster_stats() 池操作：列出可用的池，创建一个池，检查一个池是否存在，并删除一个池。 Rados.list_pools() Rados.create_pool(pool_name, crush_rule, auid) Rados.pool_exists(pool_name) Rados.delete_pool(pool_name) CLI 命令：Ceph CLI命令在内部使用以下librados Python绑定方法。 Rados.mon_command(cmd, inbuf, timeout, target) Rados.osd_command(osdid, cmd, inbuf, timeout) Rados.mgr_command(cmd, inbuf, timeout, target) Rados.pg_command(pgid, cmd, inbuf, timeout) I&#x2F;O上下文：为了将数据写入Ceph对象存储和从Ceph对象存储读取数据，必须创建一个输入&#x2F;输出上下文（ioctx）。Rados类提供了open_ioctx()和open_ioctx2()方法。其余的操作涉及调用Ioctx和其他类的方法。 Rados.open_ioctx(ioctx_name) Ioctx.require_ioctx_open() Ioctx.get_stats() Ioctx.get_last_version() Ioctx.close() 对象操作：同步或异步地读和写对象。一个对象有一个名称（或键）和数据。 Ioctx.aio_write(object_name, to_write, offset, oncomplete, onsafe) Ioctx.aio_write_full(object_name, to_write, oncomplete, onsafe) Ioctx.aio_append(object_name, to_append, oncomplete, onsafe) Ioctx.write(key, data, offset) Ioctx.write_full(key, data) Ioctx.aio_flush() Ioctx.set_locator_key(loc_key) Ioctx.aio_read(object_name, length, offset, oncomplete) Ioctx.read(key, length, offset) Ioctx.stat(key) Ioctx.trunc(key, size) Ioctx.remove_object(key) 对象扩展属性：在一个对象上设置扩展属性(XATTRs)。 Ioctx.set_xattr(key, xattr_name, xattr_value) Ioctx.get_xattrs(oid) XattrIterator.next() Ioctx.get_xattr(key, xattr_name) Ioctx.rm_xattr(key, xattr_name) 对象接口：从一个池中检索一个对象的列表，并对它们进行迭代。提供的对象接口使每个对象看起来像一个文件，可以对对象进行同步操作。对于异步操作，应该使用I&#x2F;O上下文的方法。 Ioctx.list_objects() ObjectIterator.next() Object.read(length&#x3D;1024 * 1024) Object.write(string_to_write) Object.get_xattrs() Object.get_xattr(xattr_name) Object.set_xattr(xattr_name, xattr_value) Object.rm_xattr(xattr_name) Object.stat() Object.remove()","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph_librados介绍","slug":"Ceph_librados介绍","date":"2021-06-05T06:15:14.000Z","updated":"2024-07-27T14:37:27.947Z","comments":true,"path":"Ceph_librados介绍/","permalink":"https://watsonlu6.github.io/Ceph_librados%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"Ceph Librados介绍Ceph Librados 概述一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用librados，连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它要创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。 Ceph客户端主要是实现了接口，对外提供了访问的功能。上层可以通过接口访问Ceph存储。Ceph的客户端通过一套名为librados的接口进行集群的访问，这里的访问包括对集群的整体访问和对象的访问两类接口。这套接口（API）包括C、C++和Python常见语言的实现，接口通过网络实现对Ceph集群的访问。在用户层面，可以在自己的程序中调用该接口，从而集成Ceph集群的存储功能，或者在监控程序中实现对Ceph集群状态的监控。所谓集群的整体访问包括连接集群、创建存储池、删除存储池和获取集群状态等等。所谓对象访问是之对存储池中对象的访问，包括创建删除对象、向对象写数据或者追加数据和读对象数据等接口。 客户端基本架构概述librados客户端基本架构如下图所示，主要包括4层，分别是API层、IO处理层、对象处理层和消息收发层。 API层是一个抽象层，为上层提供统一的接口。API层提供的原生接口包括C和C++两种语言的实现外，还有Python的实现。 IO处理层用于实现IO的简单封装，其通过一个名为ObjectOperation类实现，该类主要包括的是读写操作的数据信息。之后在IO处理层在IoCtxImpl::operate函数中将ObjectOperation转换为Objecter::Op类的对象，并将该对象提交到对象处理层进行进一步的处理。 对象处理层包括了Ceph对象处理所需要的信息，包括通信管道、OSDMap和MonMap等内容。因此，在这里，根据对象的信息可以计算出对象存储的具体位置，最终找到客户端与OSD的连接信息（Session）。 消息收发层的接口会被对象处理层调用，此时消息会传递到本层，并且通过本层的线程池发送到具体的OSD。这里需要注意的是，消息收发层与服务端的消息收发公用Messager的代码。 核心流程图先根据配置文件调用librados创建Rados，接下来为这个Rados创建一个RadosClient，RadosClient包含3个主要模块(finisher、Messenger、Objecter)。再根据pool创建对应的ioctx，在ioctx中能够找到RadosClient。再调用OSDC生成对应的OSD请求，与OSD进行通信响应请求。这从大体上叙述了librados与osdc在整个Ceph中的作用。 具体细节可以按照该流程读对应源代码理解。在这个流程中需要注意的是_op_submit函数会调用_calc_target和_get_session两个函数，两个函数的作用分别是获取目的OSD和对应的Session（连接），这个是后面发送数据的基础。 Librados与OSDC的关系Librados与OSDC位于ceph客户端中比较底层的位置。 Librados模块是RADOS对象存储系统访问的接口，它提供了pool的创建、删除、对象的创建、删除、读写等基本操作接口。类RadosClient是librados模块的核心管理类，处理整个RADOS系统层面以及pool层面的管理。类ioctxlmpl实现单个pool层的对象读写等操作。 OSDC模块实现了请求的封装和通过网络模块发送请求的逻辑，其核心类Object完成对象的地址计算、消息的发送和处理超时等工作。librados模块包含两个部分，分别是RadosClient 模块和IoctxImpl。RadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。 Librados模块类RadosClientRadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class librados::RadosClient : public Dispatcher //继承Dispatcher(消息分发类)&#123; //unique_ptr智能指针 std::unique_ptr&lt;CephContext,std::function&lt;void(CephContext*)&gt; &gt; cct_deleter;public: using Dispatcher::cct; const ConfigProxy&amp; conf; //配置文件private: enum &#123; DISCONNECTED, CONNECTING, CONNECTED, &#125; state; //Monitor的网络连接状态 MonClient monclient; //Monitor客户端 MgrClient mgrclient; //MGR客户端 Messenger *messenger; //网络消息接口 uint64_t instance_id; //rados客户端实例的ID //相关消息分发 Dispatcher类的函数重写 bool _dispatch(Message *m); bool ms_dispatch(Message *m) override; bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer) override; void ms_handle_connect(Connection *con) override; bool ms_handle_reset(Connection *con) override; void ms_handle_remote_reset(Connection *con) override; bool ms_handle_refused(Connection *con) override; Objecter *objecter; //OSDC模块中用于发送封装好的OP消息 Mutex lock; Cond cond; SafeTimer timer; //定时器 int refcnt; //引用计算 version_t log_last_version; rados_log_callback_t log_cb; rados_log_callback2_t log_cb2; void *log_cb_arg; string log_watch; bool service_daemon = false; string daemon_name, service_name; map&lt;string,string&gt; daemon_metadata; int wait_for_osdmap(); Finisher finisher; //用于执行回调函数的finisher类 explicit RadosClient(CephContext *cct_); ~RadosClient() override; int ping_monitor(string mon_id, string *result); int connect(); //RadosClient的初始化函数、 连接 void shutdown(); int watch_flush(); int async_watch_flush(AioCompletionImpl *c); uint64_t get_instance_id(); int get_min_compatible_osd(int8_t* require_osd_release); int get_min_compatible_client(int8_t* min_compat_client,int8_t* require_min_compat_client); int wait_for_latest_osdmap(); //创建一个pool相关的上下文信息IoCtxImpl对象（根据pool名字或Id创建ioctx） int create_ioctx(const char *name, IoCtxImpl **io); int create_ioctx(int64_t, IoCtxImpl **io); int get_fsid(std::string *s); //用于查找pool int64_t lookup_pool(const char *name); bool pool_requires_alignment(int64_t pool_id); int pool_requires_alignment2(int64_t pool_id, bool *requires); uint64_t pool_required_alignment(int64_t pool_id); int pool_required_alignment2(int64_t pool_id, uint64_t *alignment); int pool_get_name(uint64_t pool_id, std::string *name, bool wait_latest_map = false); //用于列出所有的pool int pool_list(std::list&lt;std::pair&lt;int64_t, string&gt; &gt;&amp; ls); //用于获取pool的统计信息 int get_pool_stats(std::list&lt;string&gt;&amp; ls, map&lt;string,::pool_stat_t&gt; *result,bool *per_pool); //用于获取系统的统计信息 int get_fs_stats(ceph_statfs&amp; result); bool get_pool_is_selfmanaged_snaps_mode(const std::string&amp; pool); //pool的同步创建 int pool_create(string&amp; name, int16_t crush_rule=-1); //pool的异步创建 int pool_create_async(string&amp; name, PoolAsyncCompletionImpl *c,int16_t crush_rule=-1); int pool_get_base_tier(int64_t pool_id, int64_t* base_tier); //同步删除pool int pool_delete(const char *name); //异步删除pool int pool_delete_async(const char *name, PoolAsyncCompletionImpl *c); int blacklist_add(const string&amp; client_address, uint32_t expire_seconds); //处理Mon相关命令,调用monclient.start_mon_command 把命令发送给Mon处理 int mon_command(const vector&lt;string&gt;&amp; cmd, const bufferlist &amp;inbl,bufferlist *outbl, string *outs); void mon_command_async(………); int mon_command(int rank,const vector&lt;string&gt;&amp; cmd, const bufferlist &amp;inbl,bufferlist *outbl, string *outs); int mon_command(string name,const vector&lt;string&gt;&amp; cmd, const bufferlist &amp;inbl,bufferlist *outbl, string *outs); int mgr_command(const vector&lt;string&gt;&amp; cmd, const bufferlist &amp;inbl, bufferlist *outbl, string *outs); //处理OSD相关命令 int osd_command(int osd, vector&lt;string&gt;&amp; cmd, const bufferlist&amp; inbl,bufferlist *poutbl, string *prs); //处理PG相关命令 int pg_command(pg_t pgid, vector&lt;string&gt;&amp; cmd, const bufferlist&amp; inbl,bufferlist *poutbl, string *prs); void handle_log(MLog *m); int monitor_log(const string&amp; level, rados_log_callback_t cb,rados_log_callback2_t cb2, void *arg); void get(); bool put(); void blacklist_self(bool set); std::string get_addrs() const; int service_daemon_register( const std::string&amp; service, ///&lt; service name (e.g., &#x27;rgw&#x27;) const std::string&amp; name, ///&lt; daemon name (e.g., &#x27;gwfoo&#x27;) const std::map&lt;std::string,std::string&gt;&amp; metadata); ///&lt; static metadata about daemon int service_daemon_update_status(std::map&lt;std::string,std::string&gt;&amp;&amp; status); mon_feature_t get_required_monitor_features() const; int get_inconsistent_pgs(int64_t pool_id, std::vector&lt;std::string&gt;* pgs);&#125;; 类IoctxImpl类IoctxImpl是对于其中的某一个pool进行管理，如对 对象的读写等操作的控制。该类是pool的上下文信息，一个pool对应一个IoctxImpl对象。librados中所有关于io操作的API都设计在librados::IoCtx中，接口的真正实现在ioCtxImpl中，它的处理过程如下： 把请求封装成ObjectOperation类(osdc类中) 把相关的pool信息添加到里面，封装成Object::Op对象 调用响应的函数object-&gt;op_submit发送给相应的OSD 操作完成后，调用相应的回调函数。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138struct librados::IoCtxImpl &#123; std::atomic&lt;uint64_t&gt; ref_cnt = &#123; 0 &#125;; RadosClient *client; int64_t poolid; snapid_t snap_seq; ::SnapContext snapc; uint64_t assert_ver; version_t last_objver; uint32_t notify_timeout; object_locator_t oloc; Mutex aio_write_list_lock; ceph_tid_t aio_write_seq; Cond aio_write_cond; xlist&lt;AioCompletionImpl*&gt; aio_write_list; map&lt;ceph_tid_t, std::list&lt;AioCompletionImpl*&gt; &gt; aio_write_waiters; Objecter *objecter; IoCtxImpl(); IoCtxImpl(RadosClient *c, Objecter *objecter,int64_t poolid, snapid_t s); void dup(const IoCtxImpl&amp; rhs); void set_snap_read(snapid_t s); int set_snap_write_context(snapid_t seq, vector&lt;snapid_t&gt;&amp; snaps); void get(); void put(); void queue_aio_write(struct AioCompletionImpl *c); void complete_aio_write(struct AioCompletionImpl *c); void flush_aio_writes_async(AioCompletionImpl *c); void flush_aio_writes(); int64_t get_id(); string get_cached_pool_name(); int get_object_hash_position(const std::string&amp; oid, uint32_t *hash_position); int get_object_pg_hash_position(const std::string&amp; oid, uint32_t *pg_hash_position); ::ObjectOperation *prepare_assert_ops(::ObjectOperation *op); // snaps int snap_list(vector&lt;uint64_t&gt; *snaps); int snap_lookup(const char *name, uint64_t *snapid); int snap_get_name(uint64_t snapid, std::string *s); int snap_get_stamp(uint64_t snapid, time_t *t); int snap_create(const char* snapname); int selfmanaged_snap_create(uint64_t *snapid); void aio_selfmanaged_snap_create(uint64_t *snapid, AioCompletionImpl *c); int snap_remove(const char* snapname); int rollback(const object_t&amp; oid, const char *snapName); int selfmanaged_snap_remove(uint64_t snapid); void aio_selfmanaged_snap_remove(uint64_t snapid, AioCompletionImpl *c); int selfmanaged_snap_rollback_object(const object_t&amp; oid,::SnapContext&amp; snapc, uint64_t snapid); // io int nlist(Objecter::NListContext *context, int max_entries); uint32_t nlist_seek(Objecter::NListContext *context, uint32_t pos); uint32_t nlist_seek(Objecter::NListContext *context, const rados_object_list_cursor&amp; cursor); rados_object_list_cursor nlist_get_cursor(Objecter::NListContext *context); void object_list_slice(……); int create(const object_t&amp; oid, bool exclusive); int write(const object_t&amp; oid, bufferlist&amp; bl, size_t len, uint64_t off); int append(const object_t&amp; oid, bufferlist&amp; bl, size_t len); int write_full(const object_t&amp; oid, bufferlist&amp; bl); int writesame(const object_t&amp; oid, bufferlist&amp; bl,size_t write_len, uint64_t offset); int read(const object_t&amp; oid, bufferlist&amp; bl, size_t len, uint64_t off); int mapext(const object_t&amp; oid, uint64_t off, size_t len,std::map&lt;uint64_t,uint64_t&gt;&amp; m); int sparse_read(const object_t&amp; oid, std::map&lt;uint64_t,uint64_t&gt;&amp; m,bufferlist&amp; bl, size_t len, uint64_t off); int checksum(……); int remove(const object_t&amp; oid); int remove(const object_t&amp; oid, int flags); int stat(const object_t&amp; oid, uint64_t *psize, time_t *pmtime); int stat2(const object_t&amp; oid, uint64_t *psize, struct timespec *pts); int trunc(const object_t&amp; oid, uint64_t size); int cmpext(const object_t&amp; oid, uint64_t off, bufferlist&amp; cmp_bl); int tmap_update(const object_t&amp; oid, bufferlist&amp; cmdbl); int exec(const object_t&amp; oid, const char *cls, const char *method, bufferlist&amp; inbl, bufferlist&amp; outbl); int getxattr(const object_t&amp; oid, const char *name, bufferlist&amp; bl); int setxattr(const object_t&amp; oid, const char *name, bufferlist&amp; bl); int getxattrs(const object_t&amp; oid, map&lt;string, bufferlist&gt;&amp; attrset); int rmxattr(const object_t&amp; oid, const char *name); int operate(const object_t&amp; oid, ::ObjectOperation *o, ceph::real_time *pmtime, int flags=0); int operate_read(const object_t&amp; oid, ::ObjectOperation *o, bufferlist *pbl, int flags=0); int aio_operate(……); int aio_operate_read(…………); struct C_aio_stat_Ack : public Context &#123;…… &#125;; struct C_aio_stat2_Ack : public Context &#123;…… &#125;; struct C_aio_Complete : public Context &#123;…… &#125;; int aio_read(……); int aio_read(………); int aio_sparse_read(………); int aio_cmpext(const object_t&amp; oid, AioCompletionImpl *c, uint64_t off,bufferlist&amp; cmp_bl); int aio_cmpext(………); int aio_write(………); int aio_append(const object_t &amp;oid, AioCompletionImpl *c,const bufferlist&amp; bl, size_t len); int aio_write_full(const object_t &amp;oid, AioCompletionImpl *c,const bufferlist&amp; bl); int aio_writesame(const object_t &amp;oid, AioCompletionImpl *c,const bufferlist&amp; bl, size_t write_len, uint64_t off); int aio_remove(const object_t &amp;oid, AioCompletionImpl *c, int flags=0); int aio_exec(………); int aio_exec(………); int aio_stat(const object_t&amp; oid, AioCompletionImpl *c, uint64_t *psize, time_t *pmtime); int aio_stat2(const object_t&amp; oid, AioCompletionImpl *c, uint64_t *psize, struct timespec *pts); int aio_getxattr(const object_t&amp; oid, AioCompletionImpl *c,const char *name, bufferlist&amp; bl); int aio_setxattr(const object_t&amp; oid, AioCompletionImpl *c, const char *name, bufferlist&amp; bl); int aio_getxattrs(const object_t&amp; oid, AioCompletionImpl *c,map&lt;string, bufferlist&gt;&amp; attrset); int aio_rmxattr(const object_t&amp; oid, AioCompletionImpl *c,const char *name); int aio_cancel(AioCompletionImpl *c); int hit_set_list(uint32_t hash, AioCompletionImpl *c,std::list&lt; std::pair&lt;time_t, time_t&gt; &gt; *pls); int hit_set_get(uint32_t hash, AioCompletionImpl *c, time_t stamp,bufferlist *pbl); int get_inconsistent_objects(………); int get_inconsistent_snapsets(………); void set_sync_op_version(version_t ver); int watch(………); int watch(………); int aio_watch(……); int aio_watch(……); int watch_check(uint64_t cookie); int unwatch(uint64_t cookie); int aio_unwatch(uint64_t cookie, AioCompletionImpl *c); int notify(……); int notify_ack(const object_t&amp; oid, uint64_t notify_id, uint64_t cookie,bufferlist&amp; bl); int aio_notify(………); int set_alloc_hint(……); version_t last_version(); void set_assert_version(uint64_t ver); void set_notify_timeout(uint32_t timeout); int cache_pin(const object_t&amp; oid); int cache_unpin(const object_t&amp; oid); int application_enable(const std::string&amp; app_name, bool force); void application_enable_async(const std::string&amp; app_name, bool force,PoolAsyncCompletionImpl *c); int application_list(std::set&lt;std::string&gt; *app_names); int application_metadata_get(const std::string&amp; app_name,const std::string &amp;key,std::string* value); int application_metadata_set(const std::string&amp; app_name,const std::string &amp;key,const std::string&amp; value); int application_metadata_remove(const std::string&amp; app_name,const std::string &amp;key); int application_metadata_list(const std::string&amp; app_name, std::map&lt;std::string, std::string&gt; *values);&#125;; librados主要接口 集群句柄创建librados::Rados对象是用来操纵ceph集群的句柄，使用init来创建RadosClient，之后读取指定的ceph配置文件，获取monitor的ip和端口号。RadosClient里面有与monitor通信的MonClient和用于与OSD通信的Messenger。 集群连接初始化集群句柄之后，就可以使用这个句柄来连接集群了RadosClient::connect完成了连接操作： a. 调用monclient.build_inital_monmap，从配置文件种检查是否有初始化的monitor的地址信息 b. 创建网络通信模块messenger，并设置相关的Policy信息 c. 创建Objecter对象并初始化 d. 调用monclient.init()函数初始化monclient e. Timer定时器初始化，Finisher对象初始化 IO上下文环境初始化使用句柄创建好存储池后，还需要创建与存储池相关的IO上下文句柄rados.ioctx_create(pool_name, io_ctx) 对象读写创建对象并写入数据：io_ctx.create_full(object_name,bl)读取对象中的数据到bufferlist中，对象读取有同步读取和异步读取两种接口：io_ctx.read和io_ctx.aio_read a. 同步读取：io_ctx.read(object_name,read_bl,read_len,0) b. 异步读取：需要指定完成读取数据后的回调，用于检查读取是否完成 librados::AioCompletion *read_completion &#x3D; librados::Rados::aio_create_completion(); io_ctx.aio_read(object_name,read_completion,&amp;read_buff,read_len,0) read_completion-&gt;wait_for_complete() 同时还要获取返回值，得到读取对象的字节数 IO上下文关闭io_ctx.close() 集群句柄关闭rados.shutdown()上述功能通过Rados和IoCtx两个类实现，两个类的主要函数如下图所示（这里仅是示例，实际接口数量要多很多，具体参考源代码）。 Ceph官方的示例代码为了了解如何使用这些API，这里给出一些代码片段。具体完整的代码大家可以参考Ceph官方的示例代码。 12345678910111213141516171819202122librados::IoCtx io_ctx;const char *pool_name = &quot;test&quot;;cluster.ioctx_create(pool_name, io_ctx); /* 创建进行IO处理的上下文，其实就是用于访问Ceph的对象 *//* 同步写对象 */librados::bufferlist bl;bl.append(&quot;Hello World!&quot;); /* 对象的内容 */ret = io_ctx.write_full(&quot;itworld123&quot;, bl); /*写入对象itworld123*//* 向对象添加属性，这里的属性与文件系统中文件的扩展属性类似。 */librados::bufferlist attr_bl;attr_bl.append(&quot;en_US&quot;);io_ctx.setxattr(&quot;itworld123&quot;, &quot;test_attr&quot;, attr_bl);/* 异步读取对象内容 */librados::bufferlist read_buf;int read_len = 1024;librados::AioCompletion *read_completion = librados::Rados::aio_create_completion(); /* 创建一个异步完成类对象 */io_ctx.aio_read(&quot;itworld123&quot;, read_completion, &amp;read_buf, read_len, 0); /* 发送读请求 */read_completion-&gt;wait_for_complete(); /* 等待请求完成 */read_completion-&gt;get_return_value(); librados::bufferlist attr_res;io_ctx.getxattr(&quot;itworld123&quot;, &quot;test_attr&quot;, attr_res); /* 读取对象属性 */io_ctx.rmxattr(&quot;itworld123&quot;, &quot;test_attr&quot;); /* 删除对象的属性 */io_ctx.remove(&quot;itworld123&quot;); /* 删除对象 */","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph数据读写过程","slug":"Ceph数据读写过程","date":"2021-05-19T09:06:37.000Z","updated":"2024-07-27T14:31:10.525Z","comments":true,"path":"Ceph数据读写过程/","permalink":"https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/","excerpt":"","text":"Ceph数据映射过程在一个大规模分布式存储系统中，需要解决两个核心问题：“我应该把数据写到哪里？”和“我之前把数据存储在了哪里？”。这就引出了数据寻址的问题。Ceph 的寻址流程可以如下描述。 File：此处的File就是用户需要存储或访问的文件。对于一个基于Ceph开发的对象存储应用而言，这个File也就对应于应用中的“对象” ，也就是用户直接操作的“对象” Object： 在 RADOS（Reliable Autonomic Distributed Object Store）中，”对象” 是指系统中存储的基本单位。与 File 的不同之处在于，Object 的最大尺寸受到 RADOS 的限制，通常为 2MB 或 4MB。这一限制是为了优化底层存储的管理和组织。因此，当上层应用向 RADOS 存储一个较大的 File 时，需要将其拆分成多个统一大小的 Object（最后一个 Object 的大小可能不同）进行存储。 PG（Placement Group）： 顾名思义，PG 用于组织对象的存储并映射其位置。具体来说，一个 PG 负责管理多个对象，而每个对象只能映射到一个 PG 中，即 PG 和对象之间是“一对多”的映射关系。同时，一个 PG 会被映射到多个 OSD（Object Storage Device）上，通常 n 至少为 2，而在生产环境中，n 通常至少为 3。每个 OSD 上会承载大量的 PG，可能达到数百个。PG 的数量设置直接影响数据的分布均匀性，因此在实际配置中需要谨慎考虑。 OSD（Object Storage Device）： OSD 是 Ceph 中用于存储数据的对象存储设备。OSD 的数量对系统的数据分布均匀性有直接影响，因此不宜过少。为了充分发挥 Ceph 系统的优势，通常需要配置至少数百个 OSD。 File → Object映射 这个映射过程的目的是将用户操作的 File 转换为 RADOS 能够处理的 Object。这个过程相对简单，本质上就是按照 Object 的最大尺寸对 File 进行切分，类似于磁盘阵列中的条带化（striping）过程。这种切分有两个主要好处： 将大小不定的 File 转换为具有一致最大尺寸的 Object，使得 RADOS 能够更高效地管理这些数据。 将对单一 File 的串行处理转变为对多个 Object 的并行处理，从而提高处理效率。 每一个切分后的 Object 将获得一个唯一的 Object ID (oid)，其生成方式非常简单，是一种线性映射。具体来说，ino 表示待操作 File 的元数据，可以简单理解为该 File 的唯一 ID；ono 则是由该 File 切分产生的某个 Object 的序号。而 oid 就是将这个序号简单地附加在该 File 的 ID 之后得到的。举个例子，如果一个 ID 为 filename 的 File 被切分成了 3 个 Object，那么其 Object 的序号依次为 0、1 和 2，最终得到的 oid 就依次为 filename0、filename1 和 filename2。 这里有一个隐含的问题，即 ino 的唯一性必须得到保证，否则后续的映射将无法正确进行。 Object → PG 映射 当一个 File 被映射为一个或多个 Object 后，需要将每个 Object 独立地映射到一个 PG 中。这个过程相对简单，具体计算过程如下： 1Hash(oid) &amp; mask -&gt; pgid 这个计算过程分为两步： 使用 Ceph 系统指定的静态哈希算法计算 oid 的哈希值，将 oid 转换为一个近似均匀分布的伪随机值。 将这个伪随机值与 mask 进行按位与操作，得到最终的 PG 序号 (pgid)。 根据 RADOS 的设计，PG 的总数为 m（m 应该为 2 的整数幂），则 mask 的值为 m - 1。哈希值计算和按位与操作的结果就是从所有 m 个 PG 中近似均匀地随机选择一个。这种机制保证了在大量 Object 和大量 PG 存在的情况下，Object 和 PG 之间的映射近似均匀。由于 Object 是由 File 切分而来，大部分 Object 的尺寸相同，因此这一映射最终保证了各个 PG 中存储的 Object 的总数据量的近似均匀性。 这里强调“大量”是因为，只有在 Object 和 PG 数量较多时，这种伪随机关系的近似均匀性才有效，Ceph 的数据存储均匀性才能得到保障。为了确保这一点，一方面，Object 的最大尺寸应该被合理配置，以使得相同数量的 File 能被切分成更多的 Object；另一方面，Ceph 建议 PG 的总数应为 OSD 总数的数百倍，以确保有足够数量的 PG 供映射使用。 PG → OSD 映射 第三次映射是将作为对象逻辑组织单元的 PG 映射到实际存储单元 OSD 上。RADOS 使用了一种称为 CRUSH（Controlled Replication Under Scalable Hashing）的算法，将 pgid 代入其中，然后得到一组包含 n 个 OSD。这 n 个 OSD 共同负责存储和维护一个 PG 中的所有对象。通常，n 的值根据实际应用中的可靠性需求而定，在生产环境下通常为 3。具体到每个 OSD，由其上运行的 OSD Daemon 负责执行映射到本地的对象在本地文件系统中的存储、访问、元数据维护等操作。 与对象到 PG 的映射中采用的哈希算法不同，CRUSH 算法的结果并非绝对不变，而会受到其他因素的影响，主要有两个： 当前系统状态：即集群运行图。当系统中的 OSD 状态或数量发生变化时，集群运行图可能会改变，这将影响 PG 与 OSD 之间的映射关系。 存储策略配置：这与数据的安全性相关。系统管理员可以通过策略配置指定承载同一个 PG 的 3 个 OSD 分别位于数据中心的不同服务器或机架上，从而提高存储的可靠性。 因此，只有在系统状态和存储策略都不发生变化时，PG 和 OSD 之间的映射关系才是固定的。在实际使用中，策略配置通常一经设定就不会改变。而系统状态的变化可能是由于设备损坏或存储集群规模的扩大。好在 Ceph 提供了对这些变化的自动化支持，因此，即便 PG 与 OSD 之间的映射关系发生变化，也不会对应用产生影响。实际上，Ceph 利用 CRUSH 算法的动态特性，可以根据需要将一个 PG 动态迁移到不同的 OSD 组合上，从而自动实现高可靠性和数据分布再平衡等特性。 选择 CRUSH 算法而非其他哈希算法的原因有两点： 可配置性：CRUSH 算法具有可配置特性，可以根据管理员的配置参数决定 OSD 的物理位置映射策略。 稳定性：CRUSH 算法具有特殊的“稳定性”，即当系统中加入新的 OSD 导致系统规模增大时，大部分 PG 与 OSD 之间的映射关系不会改变，只有少部分 PG 的映射关系会发生变化并引发数据迁移。这种特性使得系统在扩展时能够保持相对稳定，避免了普通哈希算法可能带来的大规模数据迁移问题。 至此为止，Ceph通过3次映射，完成了从File到Object、Object到PG、PG再到OSD的整个映射过程。从整个过程可以看到，这里没有任何的全局性查表操作需求。至于唯一的全局性数据结构：集群运行图。它的维护和操作都是轻量级的，不会对系统的可扩展性、性能等因素造成影响。 接下来的一个问题是:为什么需要引人PG并在Object与OSD之间增加一层映射呢？可以想象一下，如果没有 PG 这一层的映射，会是什么情况？在这种情况下，需要采用某种算法将 Object 直接映射到一组 OSD 上。如果这种算法是某种固定映射的哈希算法，这就意味着一个 Object 将被固定映射在一组 OSD 上。当其中一个或多个 OSD 损坏时，Object 无法自动迁移到其他 OSD 上（因为映射函数不允许），而当系统为了扩容新增 OSD 时，Object 也无法被再平衡到新的 OSD 上（同样因为映射函数不允许）。这些限制违背了 Ceph 系统高可靠性和高自动化的设计初衷。 即便使用一个动态算法（如 CRUSH 算法）来完成这一映射，似乎可以避免静态映射带来的问题。但这样会导致各个 OSD 处理的本地元数据量大幅增加，计算复杂度和维护工作量也会大幅上升。 例如，在 Ceph 的现有机制中，一个 OSD 通常需要与其他承载同一个 PG 的 OSD 交换信息，以确定各自是否工作正常或是否需要进行维护。由于每个 OSD 承载约数百个 PG，而每个 PG 通常有 3 个 OSD，因此，在一定时间内，一个 OSD 大约需要进行数百次至数千次的信息交换。 然而，如果没有 PG 存在，一个 OSD 需要与其他承载同一个 Object 的 OSD 交换信息。由于每个 OSD 可能承载高达数百万个 Object，在同样时间内，一个 OSD 大约需要进行数百万次甚至数千万次的信息交换。这种状态维护成本显然过高。 综上所述，引入 PG 有至少两方面的好处：一方面，实现了 Object 和 OSD 之间的动态映射，为 Ceph 的可靠性和自动化等特性的实现提供了可能；另一方面，有效简化了数据的存储组织，大大降低了系统的维护和管理成本。 Ceph数据读写过程Ceph的读&#x2F;写操作采用Primary-Replica模型，客户端只向Object所对应OSD set的Primary OSD发起读&#x2F;写请求，这保证了数据的强一致性。当Primary OSD收到Object的写请求时，它负责把数据发送给其他副本，只有这个数据被保存在所有的OSD上时，Primary OSD才应答Object的写请求，这保证了副本的一致性。 写入数据这里以Object写入为例，假定一个PG被映射到3个OSD上。Object写入流程如图所示。 当某个客户端需要向Ceph集群写入一个File时，首先需要在本地完成前面所述的寻址流程，将File变为一个Object，然后找出存储该Object的一组共3个OSD，这3个OSD具有各自不同的序号，序号最靠前的那个OSD就是这一组中的Primary OSD，而后两个则依次Secondary OSD和Tertiary OSD。找出3个OSD后，客户端将直接和Primary OSD进行通信，发起写入操作(步骤1)。 Primary OSD收到请求后，分别向Secondary OSD和Tertiary OSD发起写人操作(步骤2和步骤3)。当Secondary OSD和Tertiary OSD各自完成写入操作后，将分别向Primary OSD发送确认信息(步骤4和步骤5)。当Primary OSD确认其他两个OSD的写入完成后，则自己也完成数据写入，并向客户端确认Object写入操作完成(步骤6)。之所以采用这样的写入流程，本质上是为了保证写入过程中的可靠性，尽可能避免出现数据丢失的情况。同时，由于客户端只需要向Primary OSD发送数据，因此在互联网使用场景下的外网带宽和整体访问延迟又得到了一定程度的优化。当然，这种可靠性机制必然导致较长的延迟，特别是，如果等到所有的OSD都将数据写入磁盘后再向客户端发送确认信号，则整体延迟可能难以忍受。因此， Ceph可以分两次向客户端进行确认。当各个OSD都将数据写入内存缓冲区后，就先向客户端发送一次确认，此时客户端即可以向下执行。待各个OSD都将数据写入磁盘后，会向客户端发送一个最终确认信号，此时客户端可以根据需要删除本地数据。分析上述流程可以看出，在正常情况下，客户端可以独立完成OSD寻址操作，而不必依赖于其他系统模块。因此，大量的客户端可以同时和大量的OSD进行并行操作。同时，如果一个File被切分成多个Object，这多个Object也可被并行发送至多个OSD上。从OSD的角度来看，由于同一个OSD在不同的PG中的角色不同，因此，其工作压力也可以被尽可能均匀地分担，从而避免单个OSD变成性能瓶颈。 读取数据如果需要读取数据，客户端只需完成同样的寻址过程，并直接和Primary OSD联系。在目前的Ceph设计中，被读取的数据默认由Primary OSD提供，但也可以设置允许从其他OSD中获取，以分散读取压力从而提高性能。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph相关配置","slug":"Ceph相关配置","date":"2021-05-12T05:36:31.000Z","updated":"2024-08-18T12:38:42.554Z","comments":true,"path":"Ceph相关配置/","permalink":"https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/","excerpt":"","text":"当 Ceph 服务启动时，初始化过程会激活一组在后台运行的守护进程。Ceph 存储集群的运行时间 Ceph相关守护进程： Ceph监视器 (ceph-mon) Ceph管理器 (ceph-mgr) Ceph OSD守护进程 (ceph-osd) Ceph元数据服务器 （ceph-mds） Ceph RADOS网关守护进程 (radosgw) 每个守护进程都有多个配置选项，每个选项都有一个默认值。通过更改这些配置选项可以调整系统的行为。在覆盖默认值之前，请确保了解其后果，因为不当配置可能会显著降低集群的性能和稳定性。默认值有时会在不同版本之间发生变化。因此，最好查看适用于您 Ceph 版本的文档版本。 每个 Ceph 守护进程、进程和库从以下一个或多个来源获取其配置。列表中后出现的来源会覆盖前面出现的来源（当两者都存在时）。 编译时默认值 监视器集群的集中配置数据库 存储在本地主机上的配置文件 环境变量 命令行参数 管理员设置的运行时覆盖Ceph 进程启动时的第一件事之一是解析通过命令行、环境和本地配置文件提供的配置选项。接下来，进程会联系MON集群以获取集中存储的整个集群配置。在获得完整的配置视图后，守护进程或进程的启动将开始。 网络和通信配置参考 mon_host：每个MON守护程序都配置为绑定到特定的IP地址。这些地址通常由部署工具配置。其他组件在Ceph集群中，通过配置发现MON，通常在文件的部分中指定mon_host。 public_network_interface：指定用于绑定到public_network的网络接口名称；必须同时指定public_network。 public_network：公共网络的IP地址和子网掩码（例如，192.168.0.0&#x2F;24）。在[global]中设置。可以指定用逗号分隔的子网列表，格式为 &#123;ip地址&#125;/&#123;子网掩码&#125; [, &#123;ip地址&#125;/&#123;子网掩码&#125;]。 public_addr：每个守护进程在公共网络中的IP地址。 cluster_network_interface：指定用于绑定到cluster_network的网络接口名称；必须同时指定cluster_network。 cluster_network：集群网络的IP地址和子网掩码（例如，10.0.0.0&#x2F;24）。在[global]中设置。可以指定用逗号分隔的子网列表，格式为 &#123;ip地址&#125;/&#123;子网掩码&#125; [, &#123;ip地址&#125;/&#123;子网掩码&#125;]。 cluster_addr：每个守护进程在集群网络中的IP地址。 ms_bind_port_min：OSD或MDS守护进程绑定的最小端口号。 ms_bind_port_max：OSD或MDS守护进程绑定的最大端口号。 ms_bind_ipv4：启用Ceph守护进程绑定到IPv4地址。 ms_bind_ipv6：启用Ceph守护进程绑定到IPv6地址。 public_bind_addr：在某些动态部署中，Ceph MON守护进程可能会在本地绑定到一个与在网络中广告给其他节点的public_addr不同的IP地址。如果设置了public_bind_addr，Ceph监视器守护进程将本地绑定到此地址，并在monmaps中使用public_addr来向其他节点广告其地址。此行为仅限于监视器守护进程。 ms_tcp_nodelay：Ceph启用了ms_tcp_nodelay，以便每个请求立即发送（无缓冲）。禁用Nagle算法会增加网络流量，可能引入延迟。如果遇到大量的小数据包，您可以尝试禁用ms_tcp_nodelay。 ms_tcp_rcvbuf：网络连接接收端的套接字缓冲区大小。默认情况下禁用。 ms_type：Async Messenger使用的传输类型。可以是async+posix、async+dpdk或async+rdma。Posix使用标准的TCP&#x2F;IP网络，是默认选项。其他传输类型可能是实验性的，支持可能有限。 ms_async_op_threads：每个Async Messenger实例使用的初始工作线程数。应至少等于最高副本数，但如果CPU核心数量较少和&#x2F;或在单台服务器上托管了大量OSD，可以减少此值。 ms_initial_backoff：在发生故障后重新连接之前的初始等待时间。 ms_max_backoff：在发生故障后重新连接之前的最长等待时间。 ms_dispatch_throttle_bytes：限制等待调度的消息总大小。 ms_cluster_mode：用于Ceph守护进程之间的集群内通信的连接模式（或允许的模式）。如果列出了多个模式，则优先使用列出的模式。 ms_service_mode：客户端连接到集群时允许使用的模式列表。 ms_client_mode：客户端在与Ceph集群通信时使用（或允许）的连接模式列表，按优先顺序排列。 ms_mon_cluster_mode：监视器之间使用的连接模式（或允许的模式）。 ms_mon_service_mode：客户端或其他Ceph守护进程连接到监视器时允许使用的模式列表。 ms_mon_client_mode：客户端或非监视器守护进程连接到监视器时使用的连接模式列表，按优先顺序排列。 ms_compress_secure：将加密与压缩结合使用会降低消息之间安全性的水平。如果启用了加密和压缩，则会忽略压缩设置，消息将不会被压缩。可以通过此设置覆盖此行为。 ms_osd_compress_mode：在Messenger中与OSD通信时使用的压缩策略。 ms_osd_compress_min_size：符合在线压缩条件的最小消息大小。 ms_osd_compression_algorithm：与OSD连接时优先顺序中的压缩算法。默认值为snappy，也可以接受列表（如snappy zlib zstd等）。 CEPHX 配置参考 auth_cluster_required：如果启用了此配置设置，则Ceph存储集群守护进程（即ceph-mon、ceph-osd、ceph-mds和ceph-mgr）必须相互认证。有效的设置为cephx或none。 auth_service_required：如果启用了此配置设置，则Ceph客户端只能在通过认证后访问Ceph服务。有效的设置为cephx或none。 auth_client_required：如果启用了此配置设置，则Ceph客户端与Ceph存储集群之间的通信只能在Ceph存储集群对Ceph客户端进行认证后建立。有效的设置为cephx或none。 cephx_require_signatures：如果此配置设置为true，Ceph要求在Ceph客户端和Ceph存储集群之间以及集群内守护进程之间的所有消息通信上使用签名。 cephx_cluster_require_signatures：如果此配置设置为true，Ceph要求在Ceph存储集群内部守护进程之间的所有消息通信上使用签名。 cephx_service_require_signatures：如果此配置设置为true，Ceph要求在Ceph客户端和Ceph存储集群之间的所有消息通信上使用签名。 cephx_sign_messages：如果此配置设置为true，并且Ceph版本支持消息签名，则Ceph将对所有消息进行签名，以提高其防伪性。 auth_service_ticket_ttl：当Ceph存储集群向Ceph客户端发送认证票据时，Ceph存储集群为该票据分配一个生存时间（TTL）。 MON配置参考 mon_force_quorum_join：强制监视器加入仲裁，即使它之前已从映射中移除。 fsid：集群ID。每个集群一个。如果未指定，可以由部署工具生成。 mon_initial_members：启动期间集群中的初始监视器ID。如果指定，Ceph要求形成初始仲裁的监视器数为奇数（例如3个）。 mon_data_size_warn：当监视器的数据存储增长到大于此大小时，触发HEALTH_WARN状态，默认15GB。 mon_data_avail_warn：当存放监视器数据存储的文件系统报告其可用容量小于或等于此百分比时，触发HEALTH_WARN状态。 mon_data_avail_crit：当存放监视器数据存储的文件系统报告其可用容量小于或等于此百分比时，触发HEALTH_ERR状态。 mon_warn_on_crush_straw_calc_version_zero：当CRUSH straw_calc_version为0时，触发HEALTH_WARN。 mon_warn_on_legacy_crush_tunables：当CRUSH tunables过旧（早于mon_min_crush_required_version）时，触发HEALTH_WARN。 mon_crush_min_required_version：集群要求的最低可调配置文件。 mon_warn_on_osd_down_out_interval_zero：当mon_osd_down_out_interval为0时，触发HEALTH_WARN。在领导者上将此选项设置为0的效果类似于noout标志。没有设置noout标志的集群很难诊断问题，因此在这种情况下报告警告。 mon_warn_on_slow_ping_ratio：当OSD之间的任何心跳超过osd_heartbeat_grace的mon_warn_on_slow_ping_ratio时，触发HEALTH_WARN。 mon_warn_on_slow_ping_time：用具体值覆盖mon_warn_on_slow_ping_ratio。如果OSD之间的任何心跳超过mon_warn_on_slow_ping_time毫秒，触发HEALTH_WARN。默认值为0（禁用）。 mon_warn_on_pool_no_redundancy：如果任何池配置为没有副本，触发HEALTH_WARN。 mon_cache_target_full_warn_ratio：在池的cache_target_full和target_max_object之间的位置开始警告。 mon_health_to_clog：启用定期将健康摘要发送到集群日志。 mon_health_to_clog_tick_interval：监视器将健康摘要发送到集群日志的频率（以秒为单位）（非正数禁用）。如果当前健康摘要为空或与上次相同，监视器将不会将其发送到集群日志。 mon_health_to_clog_interval：监视器将健康摘要发送到集群日志的频率（以秒为单位）（非正数禁用）。无论当前健康摘要是否与上次不同，监视器总是会将摘要发送到集群日志。 mon_osd_full_ratio：OSD被视为已满的设备空间利用率的阈值百分比，默认值为0.95。 mon_osd_backfillfull_ratio：设备空间利用率的阈值，当OSD被认为太满以至于无法回填时。默认值为0.90。 mon_osd_nearfull_ratio：设备空间利用率的阈值，当OSD被认为接近满时。默认值为0.85。 mon_sync_timeout：监视器在放弃并重新启动之前等待其同步提供程序的下一条更新消息的秒数。默认值为1分钟。 mon_sync_max_payload_size：同步负载的最大大小（以字节为单位）。默认值为1MiB。 paxos_max_join_drift：在必须首先同步监视器数据存储之前，Paxos迭代的最大次数。当一个监视器发现其对等体远远领先时，它将首先与数据存储同步，然后再继续。默认值为10。 paxos_stash_full_interval：保存PaxosService状态的完整副本的频率（以提交次数计）。目前此设置仅影响mds、mon、auth和mgr的PaxosServices。默认值为25。 paxos_propose_interval：在提议地图更新之前收集更新的时间间隔。 paxos_min：保留的最小Paxos状态数。 paxos_min_wait：在一段不活动时间后收集更新的最短时间。 paxos_trim_min：在修剪前允许的额外提议次数。 paxos_trim_max：一次修剪时允许修剪的最大额外提议次数。 paxos_service_trim_min：触发修剪的最小版本数量（0表示禁用）。 paxos_service_trim_max：在单个提议期间修剪的最大版本数量（0表示禁用）。 paxos_service_trim_max_multiplier：当修剪大小较大时，paxos_service_trim_max将被乘以的因子，以获得新的上限（0表示禁用）。 mon_mds_force_trim_to：强制监视器修剪到但不包括此FSMap纪元。值为0时禁用（默认值）。此命令可能有危险，请谨慎使用。 mon_osd_force_trim_to：osdmaps缓存的大小，不依赖于底层存储的缓存。 mon_election_timeout：在选举提议者上，所有ACK的最长等待时间（以秒为单位）。 mon_lease：监视器版本的租约长度（以秒为单位）。 mon_lease_renew_interval_factor：mon_lease * mon_lease_renew_interval_factor将是Leader更新其他监视器租约的时间间隔。因子应小于1.0。 mon_lease_ack_timeout_factor：Leader将等待mon_lease * mon_lease_ack_timeout_factor的时间，以便提供者确认租约扩展。 mon_accept_timeout_factor：Leader将等待mon_lease * mon_accept_timeout_factor的时间，以便请求者接受Paxos更新。在Paxos恢复阶段也会用于类似目的。 mon_min_osdmap_epochs：始终保留的最小OSD地图纪元数。 mon_max_log_epochs：监视器应保留的最大日志纪元数。 mon_tick_interval：监视器的tick间隔时间（以秒为单位）。 mon_clock_drift_allowed：在发出健康警告之前允许的监视器之间的时钟漂移（以秒为单位）。 mon_clock_drift_warn_backoff：在集群日志中记录时钟漂移警告的指数退避因子。 mon_timecheck_interval：Leader的时间检查间隔（时钟漂移检查）（以秒为单位）。 mon_timecheck_skew_interval：在存在偏差时，Leader的时间检查间隔（时钟漂移检查）（以秒为单位）。 mon_client_hunt_interval：客户端每N秒尝试连接新的监视器，直到建立连接为止。 mon_client_ping_interval：客户端每N秒ping一次监视器。 mon_client_max_log_entries_per_message：监视器每个客户端消息生成的最大日志条目数。 mon_client_bytes：允许在内存中保留的客户端消息数据量（以字节为单位）。 mon_allow_pool_delete：监视器是否应允许删除池，而不考虑池标志的设置？ osd_pool_default_ec_fast_read：是否启用池的快速读取功能。如果在创建时未指定fast_read，则它将用作新创建的纠删码池的默认设置。 osd_pool_default_flag_hashpspool：在新池上设置hashpspool（更好的哈希方案）标志。 osd_pool_default_flag_nodelete：在新池上设置nodelete标志，防止删除池。 osd_pool_default_flag_nopgchange：在新池上设置nopgchange标志。不允许更改PG数量。 osd_pool_default_flag_nosizechange：在新池上设置nosizechange标志。不允许更改大小。 mon_max_osd：集群中允许的最大OSD数量。 mon_globalid_prealloc：为集群中的客户端和守护程序预分配的全局ID数量。 mon_subscribe_interval：订阅刷新间隔（以秒为单位）。订阅机制允许获取集群地图和日志信息。 mon_stat_smooth_intervals：Ceph将在过去N个PG地图上平滑统计数据。 mon_probe_timeout：监视器在引导之前等待找到对等体的秒数。 mon_daemon_bytes：元数据服务器和OSD消息的消息内存上限（以字节为单位）。 mon_max_log_entries_per_event：每个事件的最大日志条目数。 mon_osd_prime_pg_temp：在外部OSD重新加入集群时，启用或禁用使用先前的OSD来预热PGMap。如果设置为true，客户端将继续使用先前的OSD，直到PG的新加入OSD完成对等。 mon_osd_prime_pg_temp_max_time：在外部OSD重新加入集群时，监视器应花费多少时间（以秒为单位）尝试预热PGMap。 mon_osd_prime_pg_temp_max_estimate：在并行预热所有PG之前，我们在每个PG上花费的最大估计时间。 mon_mds_skip_sanity：跳过FSMap的安全断言（在我们希望继续的bug情况下）。如果FSMap完整性检查失败，监视器将终止，但我们可以通过启用此选项来禁用它。 mon_max_mdsmap_epochs：在单个提议期间修剪的最大mdsmap纪元数。 mon_config_key_max_entry_size：配置密钥条目的最大大小（以字节为单位）。 mon_scrub_interval：监视器通过比较存储的校验和与所有存储密钥的计算校验和来清理其存储的频率（0表示禁用，危险，请谨慎使用）。 mon_scrub_max_keys：每次清理的最大密钥数量。 mon_compact_on_start：在ceph-mon启动时压缩Ceph监视器存储使用的数据库。手动压缩有助于缩小监视器数据库并提高其性能，如果常规压缩无法正常工作。 mon_compact_on_bootstrap：在引导时压缩Ceph监视器存储使用的数据库。监视器在引导后相互探测以建立仲裁。如果监视器在加入仲裁之前超时，它将重新启动并再次引导。 mon_compact_on_trim：修剪旧状态时压缩某个前缀（包括paxos）。 mon_cpu_threads：执行监视器上CPU密集型工作的线程数。 mon_osd_mapping_pgs_per_chunk：我们按块计算从放置组到OSD的映射。此选项指定每块的放置组数量。 mon_session_timeout：监视器将在超过此时间限制的闲置会话期间终止非活动会话。 mon_osd_cache_size_min：为osd监视器缓存保持映射在内存中的最小字节数。 mon_memory_target：与启用缓存自动调整相关的OSD监视器缓存和KV缓存保持映射在内存中的字节数。 mon_memory_autotune：自动调整OSD监视器和KV数据库使用的缓存内存。 mon_dns_srv_name：用于查询监视器主机&#x2F;地址的DNS服务名称。 MON&#x2F;OSD交互配置参考 mon_osd_min_up_ratio：在Ceph将Ceph OSD守护进程标记为“已宕机”之前，Ceph OSD守护进程的最小正常比例。 mon_osd_min_in_ratio：在Ceph将Ceph OSD守护进程标记为“已剔除”之前，Ceph OSD守护进程的最小在场比例。 mon_osd_laggy_halflife：滞后估计的衰减时间（以秒为单位）。 mon_osd_laggy_weight：在滞后估计衰减中用于新样本的权重。 mon_osd_laggy_max_interval：滞后估计中滞后间隔的最大值（以秒为单位）。监视器使用自适应方法来评估特定OSD的滞后间隔。此值将用于计算该OSD的宽限时间。 mon_osd_adjust_heartbeat_grace：如果设置为true，Ceph将根据滞后估计进行缩放。 mon_osd_adjust_down_out_interval：如果设置为true，Ceph将根据滞后估计进行缩放。 mon_osd_auto_mark_in：Ceph将自动标记任何启动中的Ceph OSD守护进程为集群中的。 mon_osd_auto_mark_auto_out_in：Ceph将自动标记启动中的Ceph OSD守护进程为集群中的，而不是标记为已剔除。 mon_osd_auto_mark_new_in：Ceph将自动标记启动中的新Ceph OSD守护进程为集群中的。 mon_osd_down_out_interval：Ceph在标记一个Ceph OSD守护进程为“已宕机”或“已剔除”之前等待的时间（以秒为单位）。 mon_osd_down_out_subtree_limit：Ceph不会自动标记的最小CRUSH单元类型。例如，如果设置为host，并且一个主机上的所有OSD都宕机，Ceph将不会自动标记这些OSD。 mon_osd_report_timeout：在声明未响应的Ceph OSD守护进程为“已宕机”之前的宽限时间（以秒为单位）。 mon_osd_min_down_reporte：报告一个“已宕机”Ceph OSD守护进程所需的最小Ceph OSD守护进程数量。 mon_osd_reporter_subtree_level：报告者计数的父桶层级。OSD在发现某个对等体未响应时，会将故障报告发送给监视器。监视器在宽限期后将报告的OSD标记为“已剔除”，然后标记为“已宕机”。 osd_heartbeat_interval：Ceph OSD守护进程向其对等体发送心跳的频率（以秒为单位）。 osd_heartbeat_grace：Ceph OSD守护进程未显示心跳时，被Ceph存储集群视为“已宕机”的时间。这一设置必须在[mon]和[osd]或[global]部分中设置，以便监视器和OSD守护进程都能读取。 osd_mon_heartbeat_interval：如果Ceph OSD守护进程没有Ceph OSD对等体，它向Ceph监视器发送心跳的频率。 osd_mon_heartbeat_stat_stale：停止报告未更新心跳时间的统计信息的秒数。设置为零以禁用此操作。 osd_mon_report_interval：Ceph OSD守护进程从启动或其他可报告事件开始，等待的秒数，之后向Ceph监视器报告。 OSD 配置参考 osd_uuid: Ceph OSD守护进程的全局唯一标识符（UUID）。 osd_data: OSD数据的路径。部署Ceph时必须创建此目录。建议在此挂载点上挂载用于OSD数据的驱动器，不推荐更改默认值。 osd_max_write_size: 写入的最大大小（以MB为单位）。 osd_max_object_size: RADOS对象的最大大小（以字节为单位）。 osd_client_message_size_cap: 允许在内存中存储的最大客户端数据消息大小。 osd_class_dir: RADOS类插件的类路径。 osd_mkfs_options {fs-type}: 创建新Ceph Filestore OSD时使用的选项，类型为{fs-type}。 osd_mount_options {fs-type}: 挂载Ceph Filestore OSD时使用的选项，类型为{fs-type}。 osd_journal: OSD日志的路径。可以是文件或块设备（如SSD的分区）。如果是文件，则必须创建包含该文件的目录。建议在osd_data驱动器是HDD时使用单独的快速设备。 osd_journal_size: 日志的大小（以MB为单位）。 osd_max_scrubs: 允许同时进行的最大扫描操作数。 osd_scrub_begin_hour: 限制扫描操作的开始小时。与osd_scrub_end_hour一起定义了扫描的时间窗口。设置为0和0允许全天扫描。 osd_scrub_end_hour: 限制扫描操作的结束小时。与osd_scrub_begin_hour一起定义了扫描的时间窗口。设置为0和0允许全天扫描。 osd_scrub_begin_week_day: 限制扫描操作的开始周天。0 &#x3D; 星期天，1 &#x3D; 星期一，依此类推。与osd_scrub_end_week_day一起定义了扫描的时间窗口。设置为0和0允许全天扫描。 osd_scrub_end_week_day: 限制扫描操作的结束周天。0 &#x3D; 星期天，1 &#x3D; 星期一，依此类推。与osd_scrub_begin_week_day一起定义了扫描的时间窗口。设置为0和0允许全天扫描。 osd_scrub_during_recovery: 允许在恢复过程中进行扫描。设置为false将禁用在活动恢复时调度新的扫描（和深度扫描），已运行的扫描将继续进行。 osd_scrub_load_threshold: 归一化的最大负载。系统负载（按getloadavg() &#x2F; 在线CPU数量定义）高于此值时，Ceph将不会进行扫描。默认值为0.5。 osd_scrub_min_interval: 当Ceph存储集群负载较低时，OSD扫描的最小间隔（以秒为单位）。 osd_scrub_max_interval: 无论集群负载如何，OSD扫描的最大间隔（以秒为单位）。 osd_scrub_chunk_min: 每次操作扫描的最小对象存储块数量。扫描期间Ceph会阻塞对单个块的写入。 osd_scrub_chunk_max: 每次操作扫描的最大对象存储块数量。 osd_scrub_sleep: 在扫描下一组块之前的等待时间。增加此值将减慢整体扫描速度，以减少对客户端操作的影响。 osd_deep_scrub_interval: “深度”扫描的间隔（完全读取所有数据）。osd_scrub_load_threshold不影响此设置。 osd_scrub_interval_randomize_ratio: 在为PG调度下一个扫描作业时，添加一个随机延迟。延迟是小于osd_scrub_min_interval * osd_scrub_interval_randomized_ratio的随机值。默认设置将扫描分散到[1, 1.5] * osd_scrub_min_interval的允许时间窗口中。 osd_deep_scrub_stride: 执行深度扫描时的读取大小。 osd_scrub_auto_repair: 如果设置为true，扫描或深度扫描发现错误时将启用自动PG修复。如果发现的错误超过osd_scrub_auto_repair_num_errors，则不执行修复。 osd_scrub_auto_repair_num_errors: 如果发现的错误超过此值，则不会进行自动修复。 osd_op_num_shards: 为给定OSD分配的分片数量。每个分片有自己的处理队列。OSD上的PG均匀分配到各个分片。此设置会覆盖_ssd和_hdd设置（如果非零）。 osd_op_num_shards_hdd: 为给定OSD（针对旋转介质）分配的分片数量。 osd_op_num_shards_ssd: 为给定OSD（针对固态介质）分配的分片数量。 osd_op_queue: 设置用于在每个OSD内优先处理操作的队列类型。两种队列都有一个严格的子队列，严格子队列在正常队列之前出队。正常队列在不同的实现中有所不同。WeightedPriorityQueue (wpq) 根据操作的优先级出队，以防止队列的饥饿。mClockQueue (mclock_scheduler) 根据操作所属的类别（恢复、扫描、snaptrim、客户端操作、osd子操作）优先处理操作。此设置需要重新启动。 osd_op_queue_cut_off: 选择将哪些优先级操作发送到严格队列与正常队列。低设置将所有复制操作及更高优先级操作发送到严格队列，高设置仅将复制确认操作及更高优先级操作发送到严格队列。设置为高有助于在一些OSD非常繁忙时，尤其是结合wpq设置时，减少客户端流量的饥饿现象。此设置需要重新启动。 osd_client_op_priority: 客户端操作的优先级。相对于下面的osd_recovery_op_priority值。默认值强烈偏向客户端操作而非恢复。 osd_recovery_op_priority: 恢复操作与客户端操作的优先级（如果池的recovery_op_priority未指定）。默认值优先处理客户端操作（见上文）而非恢复操作。您可以通过降低此值以增加客户端操作的优先级，或者提高此值以偏向恢复。 osd_scrub_priority: 池未指定scrub_priority值时，默认的工作队列优先级。可以提升到osd_client_op_priority值，当扫描阻塞客户端操作时使用。 osd_requested_scrub_priority: 用户请求的扫描在工作队列中的优先级。如果此值小于osd_client_op_priority，则可以提升到osd_client_op_priority值，当扫描阻塞客户端操作时使用。 osd_snap_trim_priority: 快照修剪工作队列的优先级。 osd_snap_trim_sleep: 下一个快照修剪操作之前的等待时间（以秒为单位）。增加此值将减慢快照修剪过程，此选项覆盖特定后端的变体。 osd_snap_trim_sleep_hdd: HDD上下一个快照修剪操作之前的等待时间（以秒为单位）。 osd_snap_trim_sleep_ssd: SSD（包括NVMe）上下一个快照修剪操作之前的等待时间（以秒为单位）。 osd_snap_trim_sleep_hybrid: 当OSD数据在HDD上，而OSD日志或WAL+DB在SSD上时，下一次快照修剪操作之前的等待时间（以秒为单位）。 osd_op_thread_timeout: Ceph OSD守护进程操作线程超时时间（以秒为单位）。 osd_op_complaint_time: 操作在指定的秒数后变得需要投诉。 osd_op_history_size: 跟踪的最大已完成操作数。 osd_op_history_duration: 跟踪的最旧已完成操作。 osd_op_log_threshold: 一次显示的操作日志数量。 osd_async_recovery_min_cost: 当前日志条目差异和历史丢失对象的混合度量值，超过此值时适当切换到异步恢复。 osd_push_per_object_cost: 提供推送操作的开销。 osd_mclock_scheduler_client_res: 为每个客户端保留的IO比例（默认值）。 osd_mclock_scheduler_client_wgt: 每个客户端的IO份额（默认值），超过保留比例。 osd_mclock_scheduler_client_lim: 每个客户端的IO限制（默认值），超过保留比例。 osd_mclock_scheduler_background_recovery_res:为后台恢复保留的IO比例（默认值）。 osd_mclock_scheduler_background_recovery_wgt: 背景恢复的IO份额（默认值），超过保留比例。 osd_mclock_scheduler_background_recovery_lim: 背景恢复的IO限制（默认值），超过保留比例。 osd_mclock_scheduler_background_best_effort_res: 为后台最佳努力保留的IO比例（默认值）。 osd_mclock_scheduler_background_best_effort_wgt: 每个后台最佳努力的IO份额（默认值），超过保留比例。 osd_mclock_scheduler_background_best_effort_lim: 背景最佳努力的IO限制（默认值），超过保留比例。 osd_max_backfills: 允许到单个OSD的最大回填数量。注意，此设置对读取和写入操作分别应用。 osd_backfill_scan_min: 每个回填扫描的最小对象数量。 osd_backfill_scan_max: 每个回填扫描的最大对象数量。 osd_backfill_retry_interval: 在重试回填请求之前等待的秒数。 osd_map_dedup: 启用OSD映射中的重复项删除。 osd_map_cache_size: 保留的OSD映射数量。 osd_map_message_max: 每个MOSDMap消息允许的最大映射条目数。 osd_recovery_delay_start: 在peering完成后，Ceph将在开始恢复RADOS对象之前延迟指定的秒数。 osd_recovery_max_active: 每次最多允许的活动恢复请求数量。更多请求将加速恢复，但会增加集群负载。 osd_recovery_max_active_hdd: 如果主设备为旋转设备，则每个OSD允许的活动恢复请求数量。 osd_recovery_max_active_ssd: 如果主设备为非旋转设备（如SSD），则每个OSD允许的活动恢复请求数量。 osd_recovery_max_chunk: 恢复操作可以承载的数据块的最大总大小。 osd_recovery_max_single_start: 当OSD正在恢复时，每个OSD允许新启动的恢复操作的最大数量。 osd_recover_clone_overlap: 在恢复过程中保留克隆重叠。应始终设置为true。 osd_recovery_sleep: 下一次恢复或回填操作之前的等待时间（以秒为单位）。增加此值将减慢恢复操作的速度，同时减少对客户端操作的影响。 osd_recovery_sleep_hdd: 下一次恢复或回填操作之前的等待时间（以秒为单位），适用于HDD。 osd_recovery_sleep_ssd: 下一次恢复或回填操作之前的等待时间（以秒为单位），适用于SSD。 osd_recovery_sleep_hybrid: 当OSD数据在HDD上，而OSD日志或WAL+DB在SSD上时，下一次恢复或回填操作之前的等待时间（以秒为单位）。 osd_recovery_priority: 恢复工作队列的默认优先级。不与池的recovery_priority相关。 osd_agent_max_ops: 高速模式下每个分层代理的最大同时刷新操作数。 osd_agent_max_low_ops: 低速模式下每个分层代理的最大同时刷新操作数。 osd_default_notify_timeout: OSD默认通知超时时间（以秒为单位）。 osd_check_for_log_corruption: 检查日志文件是否损坏。可能会计算开销很大。 osd_delete_sleep: 下一次删除事务之前的等待时间（以秒为单位）。此设置会限制PG删除过程的速度。 osd_delete_sleep_hdd: 下一次删除事务之前的等待时间（以秒为单位），适用于HDD。 osd_delete_sleep_ssd: 下一次删除事务之前的等待时间（以秒为单位），适用于SSD。 osd_delete_sleep_hybrid: 当OSD数据在HDD上，而OSD日志或WAL+DB在SSD上时，下一次删除事务之前的等待时间（以秒为单位）。 osd_command_max_records: 限制返回的丢失对象数量。 osd_fast_fail_on_connection_refused: 如果启用此选项，崩溃的OSD会被连接的对等体和MON立即标记为不可用（假设崩溃的OSD主机仍然存在）。禁用它将恢复旧的行为，但可能会在OSD在I&#x2F;O操作中崩溃时造成长时间的I&#x2F;O延迟。 MCLOCK 配置参考 osd_mclock_profile：设置用于根据不同类别操作（如背景恢复、擦洗、快照修剪、客户端操作、OSD 子操作）提供服务质量（QoS）的 mClock 配置类型。一旦启用了内置配置文件，低级 mClock 资源控制参数（[预留、权重、限制]）和一些 Ceph 配置参数将自动设置。请注意，这不适用于自定义配置文件。 osd_mclock_max_capacity_iops_hdd：每个 OSD 的最大随机写入 IOPS 容量（以 4 KiB 块大小为单位），适用于旋转介质（HDD）。 osd_mclock_max_capacity_iops_ssd：每个 OSD 的最大随机写入 IOPS 容量（以 4 KiB 块大小为单位），适用于固态介质（SSD）。 osd_mclock_max_sequential_bandwidth_hdd：每个 OSD 的最大顺序带宽（以字节&#x2F;秒为单位），适用于旋转介质（HDD）。 osd_mclock_max_sequential_bandwidth_ssd：每个 OSD 的最大顺序带宽（以字节&#x2F;秒为单位），适用于固态介质（SSD）。 osd_mclock_force_run_benchmark_on_init：强制在 OSD 初始化或启动时运行 OSD 基准测试。 osd_mclock_override_recovery_settings：启用此选项将允许 mClock 调度器覆盖由 osd_recovery_max_active_hdd、osd_recovery_max_active_ssd 和 osd_max_backfills 选项定义的恢复&#x2F;回填限制。 osd_mclock_iops_capacity_threshold_hdd：超过此阈值的 IOPS 容量（以 4 KiB 块大小为单位），将忽略 OSD 基准测试结果，适用于旋转介质（HDD）。 osd_mclock_iops_capacity_threshold_ssd：超过此阈值的 IOPS 容量（以 4 KiB 块大小为单位），将忽略 OSD 基准测试结果，适用于固态介质（SSD）。 bluestore配置参考 bluestore_cache_autotune：自动调整分配给各种 BlueStore 缓存的空间比例，同时尊重最小值。 osd_memory_target：当 TCMalloc 可用且启用了缓存自动调优时，尝试保持此数量的字节映射在内存中。注意：这可能与进程的 RSS 内存使用情况不完全匹配。尽管进程映射的堆内存总量通常应接近此目标，但内核是否实际回收已取消映射的内存没有保证。在初期开发中发现，一些内核导致 OSD 的 RSS 内存超出映射内存最多 20%。不过，假设内核在内存压力较大时通常可能会更积极地回收未映射的内存。实际情况可能有所不同。 bluestore_cache_autotune_interval：启用缓存自动调优时，重新平衡之间的等待秒数。bluestore_cache_autotune_interval 设置 Ceph 重新计算各种缓存分配比例的速度。注意：将此间隔设置得过小可能导致高 CPU 使用率和性能下降。 osd_memory_base：当启用 TCMalloc 和缓存自动调优时，估算 OSD 需要的最小内存量（以字节为单位）。这用于帮助自动调优器估算缓存的预期总内存消耗。 osd_memory_expected_fragmentation：当启用 TCMalloc 和缓存自动调优时，估算内存碎片的百分比。这用于帮助自动调优器估算缓存的预期总内存消耗。 osd_memory_cache_min：当启用 TCMalloc 和缓存自动调优时，设置用于缓存的最小内存量。注意：将此值设置得过低可能导致显著的缓存抖动。 osd_memory_cache_resize_interval：当启用 TCMalloc 和缓存自动调优时，在调整缓存大小之间等待的秒数。此设置改变 BlueStore 可用于缓存的总内存量。注意：将此间隔设置得过小可能导致内存分配器抖动和性能下降。 bluestore_cache_size：BlueStore 将用于其缓存的内存量。如果为零，则使用 bluestore_cache_size_hdd 或 bluestore_cache_size_ssd。 bluestore_cache_size_hdd：当 BlueStore 由 HDD 支持时，默认用于缓存的内存量。 bluestore_cache_size_ssd：当 BlueStore 由 SSD 支持时，默认用于缓存的内存量。 bluestore_cache_meta_ratio：分配给元数据的 bluestore 缓存比例。 bluestore_cache_kv_ratio：分配给键值数据库（RocksDB）的 bluestore 缓存比例。 bluestore_csum_type：使用的默认校验和算法。有效选择：none、crc32c、crc32c_16、crc32c_8、xxhash32、xxhash64。 bluestore_compression_algorithm：如果没有设置每池属性 compression_algorithm，则使用的默认压缩器。注意，由于压缩少量数据时 CPU 开销较高，zstd 不推荐用于 BlueStore。有效选择：snappy、zlib、zstd、lz4。 bluestore_compression_mode：如果没有设置每池属性 compression_mode，则使用的默认压缩策略。none 表示从不使用压缩。passive 表示在客户端提示数据可以压缩时使用压缩。aggressive 表示除非客户端提示数据不可压缩，否则使用压缩。force 表示在所有情况下使用压缩，即使客户端提示数据不可压缩。有效选择：none、passive、aggressive、force。 bluestore_compression_required_ratio：压缩后数据块大小与原始大小的比例必须至少小于此值才能存储压缩版本。 bluestore_compression_min_blob_size：小于此值的块从不压缩。每池属性 compression_min_blob_size 将覆盖此设置。 bluestore_compression_min_blob_size_hdd：旋转介质（HDD）的默认 BlueStore 压缩最小 blob 大小值。 bluestore_compression_min_blob_size_ssd：非旋转介质（固态介质）的默认 BlueStore 压缩最小 blob 大小值。 bluestore_compression_max_blob_size：大于此值的块在压缩前被拆分成最多 bluestore_compression_max_blob_size 字节的小 blob。每池属性 compression_max_blob_size 将覆盖此设置。 bluestore_compression_max_blob_size_hdd：旋转介质（HDD）的默认 BlueStore 压缩最大 blob 大小值。 bluestore_compression_max_blob_size_ssd：非旋转介质（SSD、NVMe）的默认 BlueStore 压缩最大 blob 大小值。 bluestore_rocksdb_cf：启用 BlueStore 的 RocksDB 分片。设置为 true 时，使用 bluestore_rocksdb_cfs。仅在 OSD 执行 --mkfs 时应用。 bluestore_rocksdb_cfs：BlueStore RocksDB 分片的定义。最佳值取决于多个因素，不建议修改。此设置仅在 OSD 执行 --mkfs 时使用。OSD 的下一次运行将从磁盘检索分片。 bluestore_throttle_bytes：在限制 IO 提交之前的最大飞行字节数。 bluestore_throttle_deferred_bytes：在限制 IO 提交之前的最大延迟写入字节数。 bluestore_throttle_cost_per_io：每次 IO 交易增加的开销（以字节为单位）。 bluestore_throttle_cost_per_io_hdd：旋转介质（HDD）的默认 bluestore_throttle_cost_per_io。 bluestore_throttle_cost_per_io_ssd：非旋转介质（固态介质）的默认 bluestore_throttle_cost_per_io。 bluestore_min_alloc_size：较小的分配大小通常意味着在触发写时复制操作（例如，当写入最近快照的内容时）时，读取和重写的数据更少。类似地，在执行覆盖写入之前，日志中记录的数据也更少（小于 min_alloc_size 的写入必须首先通过 BlueStore 日志）。较大的 min_alloc_size 减少了描述磁盘上布局所需的元数据量，并减少了总体碎片化。 bluestore_min_alloc_size_hdd：旋转介质（HDD）的默认 min_alloc_size 值。 bluestore_min_alloc_size_ssd：非旋转介质（固态介质）的默认 min_alloc_size 值。 bluestore_use_optimal_io_size_for_min_alloc_size：发现介质的最佳 IO 大小并用于 min_alloc_size。 日志配置参考 journal_dio：启用直接 I&#x2F;O（Direct I&#x2F;O）到日志。这要求 journal_block_align 设置为 true。 journal_aio：启用使用 libaio 进行异步写入日志。这要求 journal_dio 设置为 true。版本 0.61 及更高版本为 true，版本 0.60 及更早版本为 false。 journal_block_align：将写操作对齐到块。dio 和 aio 都需要此设置。 journal_max_write_bytes：日志一次最多写入的字节数。 journal_max_write_entries：日志一次最多写入的条目数。 journal_align_min_size：对大于指定最小值的数据有效负载进行对齐。 journal_zero_on_create：在 mkfs 期间将整个日志用 0 覆盖。 POOL&#x2F;PG&#x2F;CRUSH配置参考 mon_max_pool_pg_num：每个池的最大 placement group 数量。 mon_pg_stuck_threshold：PG 被视为卡住的秒数阈值。 mon_pg_warn_min_per_osd：如果每个 OSD 平均 PG 数量低于此值，则触发 HEALTH_WARN。非正值将禁用此警告。 mon_pg_warn_min_objects：如果集群中 RADOS 对象总数低于此值，则不发出警告。 mon_pg_warn_min_pool_objects：如果池中 RADOS 对象数量低于此值，则不发出警告。 mon_pg_check_down_all_threshold：下线 OSD 的百分比阈值，超过此阈值时我们检查所有 PG 是否过时。 mon_pg_warn_max_object_skew：如果任何池的每个 PG 的平均 RADOS 对象数大于所有池的每个 PG 平均 RADOS 对象数的 mon_pg_warn_max_object_skew 倍，则触发 HEALTH_WARN。零或非正值将禁用此警告。注意此选项适用于 ceph-mgr 守护进程。 mon_delta_reset_interval：在重置 PG delta 为 0 之前的非活动秒数。我们跟踪每个池的使用空间 delta，例如，这有助于理解恢复进度或缓存层性能。如果某个池没有活动报告，我们将重置该池的 delta 历史记录。 osd_crush_chooseleaf_type：CRUSH 规则中 chooseleaf 使用的桶类型。使用序号而非名称。 osd_crush_initial_weight：新添加的 OSD 的初始 CRUSH 权重。此选项的默认值为新添加的 OSD 的大小（以 TB 为单位）。默认情况下，新添加的 OSD 的初始 CRUSH 权重设置为其设备大小（以 TB 为单位）。有关详细信息，请参见权重桶项。 osd_pool_default_crush_rule：创建复制池时使用的默认 CRUSH 规则。默认值 -1 表示“选择具有最低数值 ID 的规则并使用该规则”。这是为了在没有规则 0 的情况下使池创建正常工作。 osd_pool_erasure_code_stripe_unit：设置默认的擦除编码池对象条带的大小（以字节为单位）。每个大小为 S 的对象将存储为 N 条带，每条数据块接收条带单位字节。每个条带 N * 条带单位字节将单独编码&#x2F;解码。此选项可以被擦除编码配置文件中的 stripe_unit 设置覆盖。 osd_pool_default_size：设置池中对象的副本数量。默认值与 ceph osd pool set &#123;pool-name&#125; size &#123;size&#125; 相同。 osd_pool_default_min_size：设置池中对象写入副本的最小数量，以便确认 I&#x2F;O 操作。如果未达到最低数量，Ceph 将不会确认 I&#x2F;O 操作，这可能导致数据丢失。此设置确保在降级模式下具有最小副本数量。默认值为 0，表示没有特定的最小值。如果为 0，最小值为 size - (size / 2)。 osd_pool_default_pg_num：池的默认 placement group 数量。默认值与 pg_num 和 mkpool 相同。 osd_pool_default_pgp_num：池的 placement group 数量的默认值。默认值与 pgp_num 和 mkpool 相同。PG 和 PGP 应该相等（目前）。注意：除非禁用自动扩展，否则不应设置此值。 osd_pool_default_pg_autoscale_mode：默认值为启用时，自动扩展器以 1 个 PG 启动新池，除非用户指定了 pg_num。 osd_pool_default_flags：新池的默认标志。 osd_max_pgls：最大 placement group 列表数。请求大量列表的客户端可能会占用 Ceph OSD 守护进程。 osd_min_pg_log_entries：修剪日志文件时要维护的最小 placement group 日志条目数。 osd_max_pg_log_entries：修剪日志文件时要维护的最大 placement group 日志条目数。 osd_default_data_pool_replay_window：OSD 等待客户端重放请求的时间（以秒为单位）。 osd_max_pg_per_osd_hard_ratio：集群允许的每个 OSD 的 PG 数量比率，超过此比率时 OSD 将拒绝创建新的 PG。如果 OSD 服务的 PG 数量超过 osd_max_pg_per_osd_hard_ratio * mon_max_pg_per_osd，则 OSD 停止创建新的 PG。 常规配置参考 admin_socket：用于执行守护进程的管理命令的套接字，无论 Ceph Monitor 是否已建立法定人数。 pid_file：mon、osd 或 mds 将其 PID 写入的文件。例如，/var/run/$cluster/$type.$id.pid 将为运行在 ceph 集群中的 ID 为 a 的 mon 创建 /var/run/ceph/mon.a.pid。当守护进程正常停止时，PID 文件会被删除。如果进程没有被守护进程化（即使用 -f 或 -d 选项运行），则不会创建 PID 文件。 chdir：Ceph 守护进程启动并运行后切换到的目录。推荐使用默认值 &#x2F; 目录。 atal_signal_handlers：如果设置，将安装 SEGV、ABRT、BUS、ILL、FPE、XCPU、XFSZ、SYS 信号的信号处理程序，以生成有用的日志消息。 max_open_files：如果设置，当 Ceph 存储集群启动时，Ceph 会在操作系统级别设置最大打开文件描述符数（即最大文件描述符数）。适当大的值可以防止 Ceph 守护进程用尽文件描述符。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph硬件要求","slug":"Ceph硬件要求","date":"2021-05-09T08:37:13.000Z","updated":"2024-08-18T12:38:47.171Z","comments":true,"path":"Ceph硬件要求/","permalink":"https://watsonlu6.github.io/Ceph%E7%A1%AC%E4%BB%B6%E8%A6%81%E6%B1%82/","excerpt":"","text":"Ceph 设计用于在普通硬件上运行，这使得构建和维护PB级数据集群变得灵活且经济可行。在规划集群的硬件时，仍需要平衡多个考虑因素，包括故障域、成本和性能。硬件规划应包括将 Ceph 守护进程和使用 Ceph 的其他进程分布在多个主机上。通常，建议在配置为特定类型守护进程的主机上运行该类型的 Ceph 守护进程。每个 Ceph 集群的需求各不相同，但以下是一些通用指南。 CPU MON节点和MGR节点对 CPU 的要求不高，只需要适度的处理器。如果主机除了运行 Ceph 守护进程之外还要运行 CPU 密集型进程，请确保有足够的处理能力来同时运行这些 CPU 密集型进程和 Ceph 守护进程。建议将非 Ceph 的 CPU 密集型进程运行在独立的主机上（即不在MON节点和MGR节点上），以避免资源竞争。如果集群部署了 Ceph 对象网关，RGW 守护进程可以与MON和MGR服务共存在于资源充足的节点上。 OSD节点需要足够的处理能力来运行 RADOS 服务，计算 CRUSH 数据放置，复制数据，并维护自身的集群映射副本。在早期的 Ceph 版本中，我们会根据每个 OSD 的核心数量来制定硬件建议，但这种每 OSD 核心数的指标现在不如每 IOP 的周期数和每 OSD 的 IOPS 数量有用。例如，使用 NVMe OSD 驱动器时，Ceph 可以轻松利用真实集群中的五到六个核心，并在单个 OSD 中达到大约十四个核心。因此，每 OSD 的核心数不再像以前那样成为主要问题。选择硬件时，应选择每核心的 IOPS 数量。 MDS节点对 CPU 要求很高。它们是单线程的，具有高时钟速率 (GHz) 的 CPU 表现最佳。除非 MDS 服务器还托管其他服务（例如用于 CephFS 元数据池的 SSD OSD），否则它们不需要大量的 CPU 内核。 内存 MON节点和MGR节点：一般来说，更多的 RAM 更好。对于一个适中的集群，可能用 64GB 就足够了；对于一个拥有数百个 OSD 的大型集群，建议使用 128GB。MON和MGR守护进程的内存使用量会随着集群规模的扩大而增加。请注意，在启动时、拓扑更改和恢复期间，这些守护进程需要的内存会比在稳定运行状态下更多，因此需要计划应对峰值使用量。对于非常小的集群，32GB 的内存就足够了。对于最多 300 个 OSD 的集群，建议使用 64GB。对于构建中或将要扩展到更多 OSD 的集群，应配备 128GB 的内存。您还可能需要考虑调整以下设置：mon_osd_cache_size和rocksdb_cache_size。 OSD节点：Bluestore 使用其自己的内存来缓存数据，而不是依赖操作系统的页面缓存。在 Bluestore 中，可以通过更改 osd_memory_target 配置选项来调整 OSD 尝试消耗的内存量，默认值为 4GB。不建议将 osd_memory_target 设置低于 2GB。Ceph 可能无法将内存消耗控制在 2GB 以下，可能会导致极其缓慢的性能。将内存目标设置在 2GB 到 4GB 之间通常能正常工作，但可能会导致性能下降：如果活动数据集相对较大，元数据可能需要从磁盘读取。4GB 是当前 osd_memory_target 的默认值。这一默认值适用于典型用例，旨在平衡 RAM 成本和 OSD 性能。将 osd_memory_target 设置高于 4GB 可以在处理大量（小）对象或大型（256GB&#x2F;OSD 或更多）数据集时提高性能。特别是在使用快速 NVMe OSD 时，这种效果尤为显著。 OSD 内存管理是“尽力而为”的。虽然 OSD 可能会解除内存映射以允许内核回收内存，但不能保证内核会在特定时间框架内实际回收释放的内存。这一点在旧版本的 Ceph 中尤其明显，因为透明大页面可能会阻止内核回收从碎片化的大页面中释放的内存。现代版本的 Ceph 在应用级别禁用了透明大页面，以避免这种情况，但这并不能保证内核会立即回收未映射的内存。OSD 仍然有可能在某些时候超出其内存目标。因此，我们建议在系统上预留至少 20% 的额外内存，以防止 OSD 在临时内存峰值或由于内核回收释放页面的延迟而发生 OOM（内存不足）。具体所需的 20% 值可能会因系统的确切配置而有所不同。 MDS节点：CephFS 元数据守护进程的内存利用率取决于其缓存的配置大小。对于大多数系统，建议至少配置 1 GB 的内存。相关设置为 mds_cache_memory_limit。 不建议通过为操作系统配置交换空间来为守护进程提供额外的虚拟内存。这样做可能会导致性能下降。 磁盘 在规划数据存储时需要考虑显著的成本和性能权衡。操作系统的并发操作和多个守护进程对单个驱动器进行读写操作的请求可能会影响性能。OSD 需要大量的存储驱动器空间来存储 RADOS 数据。我们建议至少使用 1 TB 的驱动器。小于 1 TB 的 OSD 驱动器会将相当大一部分容量用于元数据，小于 100 GB 的驱动器效果更差，几乎不具备有效性。强烈建议为 Ceph MON和 Ceph Mgr主机、CephFS MDS元数据池和 Ceph RGW索引池配置企业级 SSD。 硬盘驱动器: 仔细考虑更大磁盘的每 GB 成本优势。我们建议将磁盘驱动器的价格除以其容量来得出每 GB 成本，因为较大的驱动器可能对每 GB 成本产生显著影响。例如，一个价格为 75 美元的 1 TB 硬盘，其每 GB 成本为 0.07 美元（即 75 美元 &#x2F; 1024 GB &#x3D; 0.0732 美元&#x2F;GB）。相比之下，一个价格为 150 美元的 3 TB 硬盘，其每 GB 成本为 0.05 美元（即 150 美元 &#x2F; 3072 GB &#x3D; 0.0488 美元&#x2F;GB）。在上述示例中，使用 1 TB 磁盘通常会使每 GB 成本增加 40%，从而使您的集群在成本效率上显著降低。不建议在单个 SAS&#x2F;SATA HDD 上托管多个 OSD。最好只托管一个 OSD 并直接访问磁盘（即 OSD 在非 LVM 上），因为 LVM 和其他抽象层可能会显着降低性能。 固态硬盘 (SSD): 使用固态硬盘 (SSD) 时，Ceph 的性能得到显著提升。SSD 减少了随机访问时间和延迟，同时增加了吞吐量。虽然 SSD 的每 GB 成本高于 HDD，但 SSD 通常提供至少比 HDD 快 100 倍的访问时间。SSD 可以避免热点问题和繁忙集群中的瓶颈问题，并且在综合评估总拥有成本 (TCO) 时，它们可能提供更好的经济效益。尤其是在给定 IOPS 数量的情况下，SSD 的摊销驱动器成本远低于 HDD。SSD 不会遭受旋转或寻道延迟，除了改进客户端性能外，它们还大幅提高了集群变化（包括 OSD 或监视器的增加、移除或故障）时的速度和对客户端的影响。由于 SSD 没有移动机械部件，因此它们不受 HDD 的许多限制。但 SSD 也有一些重要的限制。在评估 SSD 时，必须考虑顺序和随机读写的性能。 网络 Ceph 是一个高吞吐量、低延迟的分布式存储系统，对网络配置有较高的要求。集群网络的吞吐量和延迟对 Ceph 集群的性能有直接影响。因此，在配置 Ceph 网络时，应尽量选择高性能、低延迟的网络设备和网络拓扑。 对于 Ceph 集群的网络配置，建议使用 10GbE 或更高速率的网络设备，并配置两个网络，一个用于 Ceph 集群的内部通信（cluster network），一个用于 Ceph 客户端与 Ceph 集群之间的通信（public network）。这种网络配置可以有效地隔离 Ceph 集群的内部通信和外部通信，从而提高网络的性能和安全性。 在 1 Gb&#x2F;s 网络上复制 1 TB 数据需要 3 个小时，在 1 Gb&#x2F;s 网络上复制 10 TB 数据需要 30 个小时。但在 10 Gb&#x2F;s 网络上复制 1 TB 数据仅需 20 分钟，在 10 Gb&#x2F;s 网络上复制 10 TB 数据仅需 1 个小时。 最低硬件建议Ceph 可以运行在廉价的通用硬件上。小型生产集群和开发集群可以在配置适中的硬件上成功运行。正如我们之前提到的，当我们讨论 CPU 核心时，在启用超线程 (HT) 的情况下，我们指的是逻辑线程。每个现代物理 x64 CPU 核心通常提供两个逻辑 CPU 线程；其他 CPU 架构可能有所不同。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"Ceph体系架构","slug":"Ceph体系架构","date":"2021-05-07T02:19:42.000Z","updated":"2024-07-27T14:30:54.244Z","comments":true,"path":"Ceph体系架构/","permalink":"https://watsonlu6.github.io/Ceph%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/","excerpt":"","text":"Ceph 官方定义Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.(Ceph 是一种为优秀的性能、可靠性和可扩展性而设计的统一的、分布式的存储系统。) Ceph 设计思路 充分发挥存储设备自身的计算能力。 采用具有计算能力的设备作为存储系统的存储节点。 去除所有的中心点。 解决单点故障点和当系统规模扩大时出现的规模和性能瓶颈问题。 Ceph的设计哲学 每个组件必须可扩展 不存在单点故障 解决方案必须是基于软件的 可摆脱专属硬件的束缚即可运行在常规硬件上 推崇自我管理 Ceph体系结构首先作为一个存储系统，Ceph在物理上必然包含一个存储集群，以及这个存储集群的应用或客户端。Ceph客户端又需要一定的协议与Ceph存储集群进行交互，Ceph的逻辑层次演化如图所示。OSD：主要功能包括存储数据，处理数据的复制、恢复、回补、平衡数据分布，并将一些相关数据提供给Ceph Monitor。一个Ceph的存储集群，至少需要两个Ceph OSD来实现active+clean健康状态和有效的保存数据的双副本。一旦应用程序向ceph集群发出写操作，数据就以对象的形式存储在OSD中，OSD是Ceph集群中存储实际用户数据的唯一组件。通常，一个OSD守护进程绑定到集群中的一个物理磁盘。因此，通常来说，Ceph集群中物理磁盘的总数与在每个物理磁盘上存储用户数据的OSD守护进程的总数相同。 MON：Ceph的监控器，主要功能是维护整个集群健康状态，提供一致性的决策。 MDS：主要保存的是Ceph文件系统的元数据。（Ceph的块存储和对象存储都不需要Ceph MDS） RADOS：Ceph基于可靠的、自动化的、分布式的对象存储(Reliabl,Autonomous,Distributed Object Storage, RADOS )提供了一个可无限扩展的存储集群，RADOS是Ceph最为关键的技术，它是一个支持海量存储对象的分布式对象存储系统。RADOS层本身就是一个完整的对象存储系统，事实上，所有存储在Ceph系统中的用户数据最终都是由这一层来存储。RADOS层确保数据始终保持一致，他执行数据复制、故障检测和恢复，以及跨集群节点的数据迁移和再平衡。 RADOS集群主要由两种节点组成：为数众多的OSD，负责完成数据存储和维护；若干个Monitor，负责完成系统状态检测和维护。OSD和Monion之间互相传递节点的状态信息，共同得出系统的总体运行状态，并保存在一个全局数据结构中，即所谓的集群运行图(Cluster Map )里。集群运行图与RADOS提供的特定算法相配合，便实现了Ceph的许多优秀特性。 Librados：Librados库实际上是对RADOS进行抽象和封装，并向上层提供API，支持PHP、Ruby、Java、Python、C和C++编程语言。它为Ceph存储集群（RADOS）提供了本机接口，并为其他服务提供基础，如RBD、RGW和CephFS，这些服务构建在Librados之上，Librados还支持从应用程序直接访问RADOS，没有HTTP开销。 RBD：RBD提供了一个标准的块设备接口，常用于在虚拟化的场景下为虚拟机创建存储卷，Red Hat已经将RBD驱动集成在QEMU&#x2F;KVM中，以提高虚拟机的访问性能。 RADOS GW：Ceph对象网关RADOS GW提供对象存储服务，是一个构建在Librados库之上的对象存储接口，为应用访问Ceph集群提供了一个与Amazon S3和OpenStack Swift兼容的RESTful风格的 网关。 Ceph FS：Ceph文件系统提供了一个符合posix标准的文件系统，它使用Ceph存储集群在文件系统上存储用户数据。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"ansible搭建Ceph集群","slug":"Ceph集群搭建","date":"2021-05-05T14:08:55.000Z","updated":"2024-07-29T14:45:54.603Z","comments":true,"path":"Ceph集群搭建/","permalink":"https://watsonlu6.github.io/Ceph%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"环境准备共计20台服务器，单台前置热插拔硬盘位10T * 10（业务盘）+2T * 2（系统盘）或10T * 10（业务盘）+4T * 2（系统盘），其中两块系统盘配置为RAID 1，安装CentOS 7系统，分布如下图。 Ceph01 - Ceph20依次对应IP地址：172.25.7.201 - 172.25.7.220其中，Ceph01、Ceph02、Ceph03、Ceph11、Ceph12为Monitor节点，其余为OSD节点。业务盘不配置RAID，每块业务盘作为一个OSD，资源池数据使用单副本。 环境配置hosts配置 （所有节点执行）hostnamectl –static set-hostname 节点对应主机名echo -e “127.0.0.1\\tlocalhost localhost.localdomain localhost4 localhost4.localdomain4::1\\tlocalhost localhost.localdomain localhost6 localhost6.localdomain6172.25.7.201\\tceph-node1-mon1172.25.7.202\\tceph-node2-mon2172.25.7.203\\tceph-node3-mon3172.25.7.204\\tceph-node4172.25.7.205\\tceph-node5172.25.7.206\\tceph-node6172.25.7.207\\tceph-node7172.25.7.208\\tceph-node8172.25.7.209\\tceph-node9172.25.7.210\\tceph-node10172.25.7.211\\tceph-node11-mon4172.25.7.212\\tceph-node12-mon5172.25.7.213\\tceph-node13172.25.7.214\\tceph-node14172.25.7.215\\tceph-node15172.25.7.216\\tceph-node16172.25.7.217\\tceph-node17172.25.7.218\\tceph-node18172.25.7.219\\tceph-node19172.25.7.220\\tceph-node20” &gt; &#x2F;etc&#x2F;hosts 配置SSH免密登陆（在ceph-ansible节点上执行）ssh-keygen -t rsassh-copy-id root@ceph-node1-mon1ssh-copy-id root@ceph-node2-mon2ssh-copy-id root@ceph-node3-mon3ssh-copy-id root@ceph-node4ssh-copy-id root@ceph-node5ssh-copy-id root@ceph-node6ssh-copy-id root@ceph-node7ssh-copy-id root@ceph-node8ssh-copy-id root@ceph-node9ssh-copy-id root@ceph-node10ssh-copy-id root@ceph-node11-mon4ssh-copy-id root@ceph-node12-mon5ssh-copy-id root@ceph-node13ssh-copy-id root@ceph-node14ssh-copy-id root@ceph-node15ssh-copy-id root@ceph-node16ssh-copy-id root@ceph-node17ssh-copy-id root@ceph-node18ssh-copy-id root@ceph-node19ssh-copy-id root@ceph-node20验证各节点ssh是否能免密登陆 关闭SELINUX和防火墙（所有节点执行）sed -i “s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;g” &#x2F;etc&#x2F;selinux&#x2F;configsystemctl stop firewalldsystemctl disable firewalldsystemctl status firewalldreboot 配置时间同步所有节点执行yum -y install ntp ntpdatecd &#x2F;etc &amp;&amp; mv ntp.conf ntp.conf.bak 在ceph-ansible节点执行编辑ntpd配置文件vi &#x2F;etc&#x2F;ntp.conf 12345restrict 127.0.0.1restrict ::1restrict 172.25.7.0 mask 255.255.255.0server 127.127.1.0fudge 127.127.1.0 stratum 8 启动ntpd 12systemctl start ntpdsystemctl enable ntpd 其余节点执行编辑ntp服务vi &#x2F;etc&#x2F;ntp.conf 1server 172.25.7.201 启动ntp，同步时间 123456ntpdate ceph-node1-mon1hwclock -wcrontab -e#键入*/10 * * * * /usr/sbin/ntpdate 172.25.7.201 配置Ceph源(所有节点)编辑ceph源 1234567891011121314151617181920212223242526272829vi /etc/yum.repos.d/ceph.repo#键入[Ceph]name=Ceph packages for $basearchbaseurl=http://download.ceph.com/rpm-nautilus/el7/$basearchenabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascpriority=1[Ceph-noarch]name=Ceph noarch packagesbaseurl=http://download.ceph.com/rpm-nautilus/el7/noarchenabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascpriority=1[ceph-source]name=Ceph source packagesbaseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMSenabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascpriority=1 更新ceph源 12yum -y install epel-releaseyum clean all &amp;&amp; yum makecache Ceph-ansible配置（仅在ceph-ansible节点安装）安装ansible安装ansible，并修改&#x2F;etc&#x2F;ansible&#x2F;hostsyum -y install ansible注意对应的版本号参考官网文档：https://docs.ceph.com/projects/ceph-ansible/en/latest/ 检测是否成功安装ansibleansible --version 修改&#x2F;etc&#x2F;ansible&#x2F;hosts 1234567891011121314151617181920212223242526272829303132333435363738394041424344vi /etc/ansible/hosts#添加以下内容[mons]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5[mgrs]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5[osds]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node4ceph-node5ceph-node6ceph-node7ceph-node8ceph-node9ceph-node10ceph-node11-mon4ceph-node12-mon5ceph-node13ceph-node14ceph-node15ceph-node16ceph-node17ceph-node18ceph-node19ceph-node20[grafana-server]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5 测试ansible是否能正常运行：ansible all -m ping 安装ceph-absible确保环境上安装了git，可通过一下方式安装 yum -y install git 配置“http.sslVerify”参数为“false”，跳过系统证书。 git config --global http.sslVerify false 下载Ceph-ansible，注意ceph N版的版本号是stable-4.0 git clone -b stable-4.0 https://github.com/ceph/ceph-ansible.git --recursive 安装 Ceph-ansible 依赖 1234yum install -y python-pip #安装python-pippip install --upgrade pip # 将pip更新到最新版本cd /root/ceph-ansible/ #进入ceph-ansible目录pip install -r requirements.txt #检查并安装需要的软件版本 在ceph-ansible目录内新建hosts文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344vi /root/ceph-ansible/hosts[mons]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5[mgrs]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5[osds]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node4ceph-node5ceph-node6ceph-node7ceph-node8ceph-node9ceph-node10ceph-node11-mon4ceph-node12-mon5ceph-node13ceph-node14ceph-node15ceph-node16ceph-node17ceph-node18ceph-node19ceph-node20[grafana-server]ceph-node1-mon1ceph-node2-mon2ceph-node3-mon3ceph-node11-mon4ceph-node12-mon5 使用Ceph-ansible提供的ansible变量用来设置ceph集群的配置。所有选项及默认配置放在group_vars目录下，每种ceph进程对应相关的配置文件。 1234567cp mons.yml.sample mons.ymlcp mgrs.yml.sample mgrs.ymlcp mdss.yml.sample mdss.ymlcp rgws.yml.sample rgws.ymlcp osds.yml.sample osds.ymlcp clients.yml.sample clients.ymlcp all.yml.sample all.yml 修改group_vars&#x2F;all.yml文件（注意网络接口） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465vi group_vars/all.ymlceph_origin: repositoryceph_repository: communityceph_mirror: http://download.ceph.comceph_stable_release: nautilusceph_stable_repo: &quot;&#123;&#123; ceph_mirror &#125;&#125;/rpm-&#123;&#123; ceph_stable_release &#125;&#125;&quot;ceph_stable_redhat_distro: el7journal_size: 5120monitor_interface: p1p1public_network: &quot;172.25.7.0/24&quot;cluster_network: &quot;172.25.7.0/24&quot;mon_host: 172.25.7.201, 172.25.7.202, 172.25.7.203, 172.25.7.211, 172.25.7.212osd_objectstore: bluestoredashboard_enabled: Truedashboard_protocol: httpdashboard_port: 8443dashboard_admin_user: admindashboard_admin_password: admingrafana_admin_user: admingrafana_admin_password: admingrafana_uid: 472grafana_datasource: Dashboardgrafana_dashboard_version: nautilusgrafana_port: 3000grafana_allow_embedding: Truegrafana_crt: &#x27;&#x27;grafana_key: &#x27;&#x27;grafana_container_image: &quot;grafana/grafana:5.2.4&quot;grafana_container_cpu_period: 100000grafana_container_cpu_cores: 2grafana_container_memory: 4grafana_dashboards_path: &quot;/etc/grafana/dashboards/ceph-dashboard&quot;grafana_dashboard_files: - ceph-cluster.json - cephfs-overview.json - host-details.json - hosts-overview.json - osd-device-details.json - osds-overview.json - pool-detail.json - pool-overview.json - radosgw-detail.json - radosgw-overview.json - rbd-overview.jsongrafana_plugins: - vonage-status-panel - grafana-piechart-panelprometheus_container_image: &quot;prom/prometheus:v2.7.2&quot;prometheus_container_cpu_period: 100000prometheus_container_cpu_cores: 2prometheus_container_memory: 4prometheus_data_dir: /var/lib/prometheusprometheus_conf_dir: /etc/prometheusprometheus_user_id: &#x27;65534&#x27; prometheus_port: 9092ceph_conf_overrides: global:osd_pool_default_pg_num: 64 osd_pool_default_pgp_num: 64 osd_pool_default_size: 2 mon: mon_allow_pool_create: true 修改group_vars&#x2F;osds.yml文件在osds.yml添加以下内容 12345678910111213vi group_vars/osds.ymldevices: - /dev/sda - /dev/sdb - /dev/sdc - /dev/sdd - /dev/sde - /dev/sdf - /dev/sdg - /dev/sdh - /dev/sdi - /dev/sdj 修改site.yml文件 12cp site.yml.sample site.ymlvi site.yml Ceph 集群部署执行命令：ansible-playbook -i hosts site.yml执行结束，在执行页面会有相关的提示，如图所示，所有节点显示failed&#x3D;0，则处于部署过程中。 如果是过程出错，先清空集群，在进行部署 12cp infrastructure-playbooks/purge-cluster.yml purge-cluster.yml # 必须copy到项目根目录下ansible-playbook -i hosts purge-cluster.yml Rados性能测试工具创建pool ceph osd pool create testbench 100 100清除缓存 echo 3 &gt; /proc/sys/vm/drop_caches 4M写入测试 rados bench -p testbench 180 write -t 32 --no-cleanup 4k写入测试 rados bench -p testbench 180 write -t 32 -b 4096 --no-cleanup 4K顺序读 rados bench -p testbench 180 seq -t 32 --no-cleanup 4K随机读 rados bench -p testbench 180 rand -t 32 --no-cleanup 清除数据 rados -p testbench cleanup 参数说明格式：rados bench -p -b -t –no-cleanup pool-name：测试存储池名称 seconds：测试时间，单位秒 mode：操作模式，write：写，seq：顺序读；rand：随机读 -b：block size，块大小，默认为 4M,单位字节，只有在写的时候有效。 -t：读&#x2F;写并行数，默认为 16 –no-cleanup 表示测试完成后不删除测试用数据。注意：在测试之前要执行一次命令加–no-cleanup产生数据 部署过程的问题 执行完ansible-playbook -i hosts site.yml 命令后，前面无报错但某些节点不正常解决方法：属于正常现象，再执行ansible-playbook -i hosts site.yml命令可显示正常状态。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"}]},{"title":"块存储_文件系统存储_对象存储的区别","slug":"块存储-文件存储-对象存储的区别","date":"2021-04-23T08:29:15.000Z","updated":"2024-07-27T14:30:41.200Z","comments":true,"path":"块存储-文件存储-对象存储的区别/","permalink":"https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"定义角度 块存储指以扇区为基础，一个或者连续的扇区组成一个块，也叫物理块。它是在文件系统与块设备(例如：磁盘驱动器)之间。利用多个物理硬盘的并发能力。关注的是写入偏移位置。 文件系统存储文件系统存储也称为文件级存储或基于文件的存储，数据会以单条信息的形式存储在文件夹中。当需要访问该数据时，计算机需要知道相应的查找路径，存储在文件中的数据会根据数量有限的元数据来进行整理和检索，这些元数据会告诉计算机文件所在的确切位置。它就像是数据文件的库卡目录。 对象存储对象存储，也称为基于对象的存储，是一种扁平结构，其中的文件被拆分成多个部分并散布在多个硬件间。在对象存储中，数据会被分解为称为“对象”的离散单元，并保存在单个存储库中，而不是作为文件夹中的文件或服务器上的块来保存。 使用角度 块存储生活中常见的块存储设备（也叫“块设备”）比如，插在你本地电脑上的U盘、硬盘，你电脑连接的iSCSI等。从使用上来说，块级的存储如果是第一次使用，那么必须需要进行一次格式化的操作，创建出一个文件系统，然后才可以使用。例如新买的U盘、硬盘、或者新发现的iSCSI设备等，首次使用的时候都需要进行一次格式化操作，创建出一个文件系统，然后才可以将你的文件拷贝到U盘、硬盘、或者新发现的iSCSI设备中。 文件系统存储文件系统存储是最常见的一种文件内系统，我们日常对操作系使用中，基本上能够直接接触到的都就是这种，能够直接访问的C、D、E盘，电脑里的一个目录，网上邻居的空间都是文件级的存储。块级的存储设备经过格式化以及挂载（win 会自动挂载）之后，你就将一个块级的存储变成了文件级的存储。 对象存储对象存储一般来说并不是给我们人直接去使用的，从使用者角度来说，它更适合用用于给程序使用。平时最常见的一般就是百度网盘，其后端对接的就是对象存储。还有就网页上的图片、视频，其本身也是存储在对象存储的文件系统中的。如果要直接使用对象级的存储，你会发现对象级的存储本身是非常的简单的（但是对人来说不方便），它只有简单的几种命令如上传、下载、删除，并且你只需要知道某个文件的编号（如：”d5t35e6tdud725dgs6u2hdsh27dh27d7” 这不是名字）就可以直接对它进行上传、下载、删除等操作，不需要像文件级那样，直到文件的具体的路径（如:D:\\photo\\1.jpg），并且他也只有这几种操作，如果你想编辑文件，那只能将文件下载下来编辑好之后在进行上传（这也是它对人来说不方便的原因之一） 技术角度块级、文件级、对象级技术上的区别，首先要明白两个概念第一，无论是那个级别的存储系统，其数据都是会存储在物理的存储设备上的，这些存储设备现在常见的基本上就两种机械硬盘、固态硬盘。第二，任何数据都是由两部”数据“分组成的，一部分是”数据本身”(下文中“数据”指”数据本身“)，另一部分就是这些“数据”的”元数据“。所谓的”元数据”就是用来描述”数据”的”数据”。包括数据所在的位置，文件的长度（大小），文件的访问权限、文件的时间戳（创建时间、修改时间….），元数据本身也是数据。 块存储对于块级来说，如果要通过块设备来访问一段数据的话，你自己需要知道这些数据具体是存在于那个存储设备上的位置上，例如如果你要从块设备上读取一张照片，你就要高速存储设备：我要从第2块硬盘中的从A位置开始到B位置的数据，硬盘的驱动就会将这个数据给你。读取照片的过程中照片的具体位置就是元数据，也就是说块级的存储中要求程序自己保存元数据。 文件系统存储如果需要自己保存元数据的话就太麻烦了，上文也说了，元数据本身也是数据，实际上元数据也是存储在硬盘上的，那么如何访问元数据这个数据呢其实，文件级的元数据是存储在固定位置的，存储的位置和方式是大家事先约定好的，这个约定就叫做文件系统，例如EXT4、FAT32、XFS、NTFS等。借助于这些约定，我们就不用自己去维护一个表去记录每一份数据的具体存储位置了。我们只需要直到我们存储的文件的路径和名字就好了，例如我们想要 D:\\1.jpg 这个文件，那么你只需要告诉文件系统 D:\\1.jpg 这个位置就可以了，去硬盘的哪里找D:\\1.jpg 数据的真身，就是文件系统的工作了 对象存储对象级存储，文件级的元数据实际上是和数据放在一起的，就像一本书每本书都有一个目录，这个目录描述的是这本书上内容的索引，目录就是书内容的“元数据”，而对象存储，会有一本书只放目录（元数据），其他更多的书只有内容，并且内容都是被拆分好的一段一段的，就是说你会看每本书上面的内容完全是混在在一起的，这一页的前两行是书A的某句话，后面就跟的是书D的某句话，如果只放目录（元数据）那本书，你根本不知道这里写的是啥。对象及存储将一切的文件都视作对象，并且将对象按照固定的”形式”组合或拆分的存储在存储设备中，并且将数据的元数据部分完全的独立出来，进行单独的管理。 对比 从距离（io路径） 上来说（相对于传统的存储），块存储的使用者距离最底层实际存储数据的存储设备是最近的，对象级是最远的。 从使用上来说，块存储需要使用者自己直到数据的真是位置，需要自己管理记录这些数据，所以使用上是最复杂的，而对象存储的接口最简单，基本上只有上传、下载、删除，并且不需要自己保存元数据，也不需要直到文件的索引路径，所以使用上是最简单的。但是从方便角度来讲还是文件存储最方便。 从性能上来说，综合的来讲（在特定的应用场合）性能最好的是块存储，它主要用在数据库、对延时要求非常高的场景中，对象存储多用于互联网，因为扩展性好，容量可以做的非常的大。对于人类来说，如果不借助特定的客户端、APP，使用文件存储是最友好最简单的。 应用场景 块存储： 要求高性能的应用，如数据库需要高IO，用块存储比较合适。 文件系统存储： 需局域网共享的应用，如文件共享，视频处理，动画渲染&#x2F;高性能计算。 对象存储： 互联网领域的存储，如点播&#x2F;视频监控的视频存储、图片存储、网盘存储、静态网页存储等，以及异地备份存储&#x2F;归档等。 为什么块级的存储性能最好&emsp;&emsp;首先要明确一点，要明确，每次在发生数据读取访问的时候，实际上对应系统的底层是发生了多次IO的（主要是要对元数据进行访问），例如，你要打开文件1.txt ，操作系统回去进行文件是否存在的查询，以及读写权限的查询等操作，这些操作实际上都是对于元数据的访问。&emsp;&emsp;然后，相对于其它的存储方式，块存储的元数据是有操作系统自己管理的，也就是说整个文件系统（元数据）是存在在操做系统的内存中的，这样操作系统在进行元数据管理的时候可以直和自己的内存打交道。而文件系统存储和对象存储，它的文件系统是存在于另一台服务器上的，这样在进行元数据访问时就需要从网络进行访问，这样要比从内存访问慢得多。&emsp;&emsp;总结来讲，就是块级存储的元数据在系统本机中，在进行元数据访问（每次读写文件实际都会在操作系统底层发生），会更快，因为其它的级别的存储元数据都要通过网络访问。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}]},{"title":"云存储概述","slug":"云存储概述","date":"2021-04-18T15:09:26.000Z","updated":"2024-07-27T14:30:28.553Z","comments":true,"path":"云存储概述/","permalink":"https://watsonlu6.github.io/%E4%BA%91%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/","excerpt":"","text":"云存储概述 云存储的概述云存储是指通过网络，将分布在不同地方的多种存储设备，通过应用软件集合起来共同对外提供数据存储和业务访问功能的一个系统。云存储是云计算系统中的一种新型网络存储技术。云存储对外提供的存储能力以统一、简单的数据服务接口来提供和展现。用户不用关心数据具体存放在哪个设备、哪个区域，甚至不知道数据到底是怎么保存的，他们只需要关心需要多少存储空间、什么时间能够拿到数据、数据存放的安全性和可用性如何即可。 云存储的实现模式云存储的实现模式有多种，云存储的架构可以由传统的存储架构延伸而来，也可以采用全新的云计算架构。云存储的实现可以是软件的，也可以是硬件的。云存储的实现模式可以是块存储、文件存储和对象存储。 块存储 块存储：最接近底层的存储，可以对数据进行任意格式化操作，可以在上面运行数据库等性能要求高的应用。可以给虚拟机使用。 文件存储 文件存储：对数据以文件的形式进行存储，支持复杂的文件操作，适合共享文件和协作工作。典型应用场景：NAS。 对象存储 对象存储：将数据以对象形式存储，通过唯一的对象ID进行访问，适合存储大规模非结构化数据，支持RESTful API接口。典型应用场景：云存储服务，视频、图片存储。 为什么需要多元化存储？由于不同的应用场景对存储的需求不同，单一的存储类型无法满足所有需求。大规模存储系统需要支持多种存储类型和多种存储协议，比如NFS、iSCSI、HDFS、S3等。多元化存储可以更好地适应各种应用场景，提高存储系统的灵活性和适应性。 文件如何通过分布式存储在许多服务器中分布式存储系统将数据分散存储在多个物理设备上。文件被切分成多个小块，存储在不同的服务器上。通过分布式哈希表（DHT）等算法确定数据块的位置，实现数据的快速定位和访问。通过数据复制和纠删码技术提高数据的可靠性和可用性。 文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？元数据服务器（MDS）存储文件系统的元数据，包括文件名、文件大小、数据块位置等信息。客户端请求文件时，首先查询MDS获取元数据，然后根据元数据访问对应的数据块。分布式文件系统中常用的元数据管理技术包括分布式哈希表（DHT）、目录树、名称节点（NameNode）等。 如果文件丢失怎么办？由于分布式存储系统的特性，单一数据副本的丢失不会导致数据不可恢复。分布式存储系统采用数据冗余和副本机制，常见的冗余技术包括数据复制和纠删码。数据复制是将同一份数据存储在多个节点上，副本数通常为3个或更多。纠删码是一种冗余编码技术，通过增加校验数据，在数据块丢失的情况下，可以通过校验数据恢复原始数据。分布式存储系统在后台自动检测数据块的健康状态，发现数据丢失或损坏时，自动启动数据恢复机制，确保数据的完整性和可用性。 存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？存储系统的数据可靠性和可用性通过多种技术手段来保证。RAID技术通过数据条带化、镜像、奇偶校验等方法，提高单一存储设备的数据可靠性。分布式存储系统通过数据复制和纠删码技术，在多个节点上存储数据副本，提高数据的可靠性和可用性。高可用性通过冗余设计实现，常见的高可用架构包括双机热备、集群等。通过负载均衡技术，将用户请求分散到多个节点上，提高系统的可用性。 写入的数据是如何被保护的？数据写入时，采用多副本机制，确保数据的一致性和可靠性。写时复制（Copy-On-Write，COW）是一种常见的技术，通过在写入数据前复制一份旧数据，确保数据写入过程中的一致性。在分布式存储系统中，数据写入时，通常会先写入多个副本，只有所有副本写入成功后，才算写入成功。数据写入过程中的故障检测和处理机制，确保数据的可靠性和一致性。 多人多设备协作时，如何保证远程协作时数据的一致性？分布式存储系统通过分布式一致性协议（如Paxos、Raft）确保数据的一致性。在多个节点之间进行数据写入时，一致性协议保证数据的一致性和正确性。冲突检测和处理机制，在多人协作时，检测并解决数据冲突。分布式锁和事务机制，确保数据的一致性和完整性。 节省存储空间存储系统采用数据压缩和数据去重技术，减少存储空间占用。数据压缩通过减少数据的冗余，提高存储空间的利用率。数据去重通过检测和删除重复数据，节省存储空间。在大规模存储系统中，数据压缩和去重技术可以显著降低存储成本，提高存储效率。 避免存储固定的文件存储系统采用分级存储和冷热数据分离策略，提高存储资源的利用率。根据数据的访问频率和重要性，将数据存储在不同的存储介质上。频繁访问的数据存储在高速存储设备上，减少访问延迟。较少访问的数据存储在低成本存储设备上，降低存储成本。通过冷热数据分离，优化存储资源的使用，提高存储系统的性能和效率。 IO速度要有保证存储系统通过多种技术手段保证IO速度。使用高速缓存技术，将热点数据缓存到内存或SSD中，减少数据访问延迟。采用预取技术，在数据请求到达前提前加载数据，提高数据访问速度。使用QoS（Quality of Service）技术，为不同的应用场景和用户提供不同的IO优先级和带宽保障。负载均衡技术，将IO请求分散到多个存储节点上，避免单点瓶颈，提高IO性能。 版本控制存储系统提供版本控制功能，允许用户对数据进行版本管理。在数据修改前，保存一份旧版本的数据，用户可以根据需要回滚到旧版本。版本控制功能确保数据的可追溯性和可恢复性，防止数据丢失和误操作。在分布式存储系统中，版本控制功能通过元数据管理和数据快照技术实现。元数据管理记录数据的版本信息和变更历史，数据快照技术保存数据的不同版本。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}]},{"title":"Linux存储栈","slug":"Linux存储栈","date":"2021-04-06T12:24:56.000Z","updated":"2024-07-27T03:55:23.469Z","comments":true,"path":"Linux存储栈/","permalink":"https://watsonlu6.github.io/Linux%E5%AD%98%E5%82%A8%E6%A0%88/","excerpt":"","text":"Linux存储栈Linux存储系统包括用户接口和存储设备接口两个部分，前者以流形式处理数据，后者以块形式处理数据，文件系统在中间起到承上启下的作用。应用程序通过系统调用发出写请求，文件系统定位请求位置并转换成块设备所需的块，然后发送到设备上。内存在此过程中作为磁盘缓冲，将上下两部分隔离成异步运行的两个过程，避免频繁的磁盘同步。当数据需要从页面缓存同步到磁盘时，请求被包装成包含多个bio的request，每个bio包含需要同步的数据页。磁盘在执行写操作时，需要通过IO请求调度合理安排顺序，减少磁头的频繁移动，提高磁盘性能。 用户视角的数据流接口 应用程序通过系统调用（如write、read等）与操作系统交互。这些调用使得数据以流的形式被处理。 存储设备的块接口 数据在底层存储设备（如硬盘、SSD等）中以块（通常是512字节或4096字节）为单位进行读写操作。 文件系统的中间角色 位置定位：文件系统负责将用户的读写请求定位到存储设备的具体块位置。 数据转换：将数据流转换为存储设备所需的块结构，并将这些块组织成bio（block I&#x2F;O）请求。 内存作为缓冲 页面缓存：内存中的页面缓存（Page Cache）用于暂时存储数据，以减少频繁的磁盘I&#x2F;O操作。 异步运行：将用户操作与底层存储设备的实际写操作异步化，提升系统效率。对于用户态程序来说，数据尽量保留在内存中，这样可以减少频繁的数据同步。 I&#x2F;O请求调度 请求封装：从页面缓存同步到磁盘的请求被封装成request，每个request包含多个bio，而每个bio又包含具体的数据页。 调度策略：操作系统会对I&#x2F;O请求进行调度，优化执行顺序，尽量减少磁盘磁头的来回移动，提高磁盘的读写效率。 Linux数据写入流程 应用程序发出写请求：比如，应用程序通过write系统调用写入数据。 文件系统处理：文件系统接收请求，找到对应的文件位置，将数据写入页面缓存。 内存缓冲处理：数据暂存在内存的页面缓存中，以等待后续的写入操作。 请求调度与封装：页面缓存的数据需要同步到磁盘时，被封装成bio和request。 I&#x2F;O调度执行：调度器优化I&#x2F;O请求的执行顺序，减少磁头移动，提高写入效率。 数据写入磁盘：最终，数据从页面缓存同步到磁盘的指定位置，完成写操作。通过以上流程，Linux存储系统在保证数据一致性的同时，最大限度地提高了性能和效率。 系统调用&emsp;&emsp;用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用。在内核和应用程序交叉的地方，内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。用户可以通过文件系统相关的调用请求系统打开问价、关闭文件和读写文件。&emsp;&emsp;内核提供的这组系统调用称为系统调用接口层。系统调用接口把应用程序的请求传达给内核，待内核处理完请求后再将处理结果返回给应用程序。&emsp;&emsp;32位Linux，CPU能访问4GB的虚拟空间，其中低3GB的地址是应用层的地址空间，高地址的1GB是留给内核使用的。内核中所有线程共享这1GB的地址空间，而每个进程可以有自己的独立的3GB的虚拟空间，互不干扰。&emsp;&emsp;当一个进程运行的时候，其用到文件的代码段，数据段等都是映射到内存地址区域的，这个功能是通过系统调用mmap()来完成的。mmap()将文件（由文件句柄fd所指定）从偏移offset的位置开始的长度为length的一个块映射到内存区域中，从而把文件的某一段映射到进程的地址空间，这样程序就可以通过访问内存的方式访问文件了。与read()&#x2F;write()相比，使用mmap的方式对文件进行访问，带来的一个显著好处就是可以减少一次用户空间到内核空间的复制，在某些场景下，如音频、视频等大文件，可以带来性能的提升。 文件系统&emsp;&emsp;Linux文件系统的体系结构是一个对复杂系统进行抽象化，通过使用一组通用的API函数，Linux就可以在多种存储设备上支持多种文件系统，使得它拥有了与其他操作系统和谐共存的能力。&emsp;&emsp;Linux中文件的概念并不局限于普通的磁盘文件，而是由字节序列构成的信息载体，I&#x2F;O设备、socket等也被包括在内。因为有了文件的存在，所以需要衍生文件系统去进行组织和管理文件，而为了支持各种各样的文件系统，所以有了虚拟文件系统的出现。文件系统是一种对存储设备上的文件、数据进行存储和组织的机制。&emsp;&emsp;虚拟文件系统通过在各种具体的文件系统上建立了一个抽象层，屏蔽了不同文件系统间的差异，通过虚拟文件系统分层架构，在对文件进行操作时，便不需要去关心相关文件所在的具体文件系统细节。通过系统调用层，可以在不同文件系统之间复制和移动数据，正是虚拟文件系统使得这种跨越不同存储设备和不同文件系统的操作成为了可能。 虚拟文件系统象类型 超级块（Super Block）超级块对象代表了一个已经安装的文件系统，用于存储该文件系统的相关信息，如文件系统的类型、大小、状态等。对基于磁盘的文件系统， 这类对象通常存放在磁盘特定的扇区上。对于并非基于磁盘的文件系统，它们会现场创建超级块对象并将其保存在内存中。 索引节点（Inode）索引节点对象代表存储设备上的一个实际物理文件，用于存储该文件的有关信息。Linux将文件的相关信息（如访问权限、大小、创建时间等）与文件本身区分开。文件的相关信息又被称为文件的元数据。 目录项（Dentry) 目录项对象描述了文件系统的层次结构，一个路径的各个组成部分，不管是目录（虚拟文件系统将目录当作文件来处理）还是普通文件，都是一个目录项对象。 文件 文件对象代表已经被进程打开的文件，主要用于建立进程和文件之间的对应关系。它由open()系统调用创建，由close()系统调用销毁，当且仅当进程访问文件期间存在于内存中，同一个物理文件可能存在多个对应的文件对象，但其对应的索引节点对象是唯一的。 Page Cache&emsp;&emsp;Page Cache，通常也称为文件缓存，使用内存Page Cache文件的逻辑内容，从而提高对磁盘文件的访问速度。Page Cache是以物理页为单位对磁盘文件进行缓存的。&emsp;&emsp;应用程序尝试读取某块数据的时候，会首先查找Page Cache，如果这块数据已经存放在Page Cache中，那么就可以立即返回给应用程序，而不需要再进行实际的物理磁盘操作。如果不能在Page Cache中发现要读取的数据，那么就需要先将数据从磁盘读取到Page Cache中，同样，对于写操作来说，应用程序也会将数据写到Page Cache中，再根据所采用的写操作机制，判断数据是否应该立即被写到磁盘上 Direct I&#x2F;O和Buffered I&#x2F;O进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条 标准I&#x2F;O： 也称为Buffered I&#x2F;O；Linux会将I&#x2F;O的数据缓存在Page Cache中，也就是说，数据会先被复制到内核的缓冲区，再从内核的缓冲区复制到应用程序的用户地址空间。在Buffered I&#x2F;O机制中，在没有CPU干预的情况下，可以通过DMA操作在磁盘和Page Cache之间直接进行数据的传输，在一定程度上分离了应用程序和物理设备，但是没有方法能直接在应用程序的地址空间和磁盘之间进行数据传输，数据在传输过程中需要在用户空间和Page Cache之间进行多次数据复制操作，这将带来较大的CPU开销。 Direct I&#x2F;O： 可以省略使用Buffered I&#x2F;O中的内核缓冲区，数据可以直接在用户空间和磁盘之间进行传输，从而使得缓存应用程序可以避开复杂系统级别的缓存结构，执行自定义的数据读写管理，从而降低系统级别的管理对应用程序访问数据的影响。如果在块设备中执行Direct I&#x2F;O，那么进程必须在打开文件的时候将对文件的访问模式设置为O_DIRECT，这样就等于告诉Linux进程在接下来将使用Direct I&#x2F;O方式去读写文件，且传输的数据不经过内核中的Page Cache。Direct I&#x2F;O最主要的优点就是通过减少内核缓冲区和用户空间的数据复制次数，降低文件读写时所带来的CPU负载能力及内存带宽的占用率。如果传输的数据量很大，使用Direct IO的方式将会大大提高性能。然而，不经过内湖缓冲区直接进行磁盘的读写，必然会引起阻塞，因此通常Direct IO和AIO（异步IO）一起使用。 块层（Block Layer）&emsp;&emsp;块设备访问时，需要在介质的不同区间前后移动，对于内核来说，管理块设备要比管理字符设备复杂得多。&emsp;&emsp;系统调用read()触发相应的虚拟文件系统函数，虚拟文件系统判断请求是否已经在内核缓冲区里，如果不在，则判断如何执行读操作。如果内核必须从块设备上读取数据，就必须要确定数据在物理设备上的位置。这由映射层，即磁盘文件系统来完成。文件系统将文件访问映射为设备访问。在通用块层中，使用bio结构体来描述一个I&#x2F;O请求在上层文件系统与底层物理磁盘之间的关系。而到了Linux驱动，则是使用request结构体来描述向块设备发出的I&#x2F;O请求的。对于慢速的磁盘而言，请求的处理速度很慢，这是内核就提供一种队列的机制把这些I&#x2F;O请求添加到队列中，使用request_queue结构体来描述。&emsp;&emsp;bio和request是块层最核心的两个数据结构，其中，bio描述了磁盘里要真实操作的位置和Page Cache中的映射关系。作为Linux I&#x2F;O请求的基本单元，bio结构贯穿块层对I&#x2F;O请求处理的始终，每个bio对应磁盘里面一块连续的位置，bio结构中的bio_vec是一个bio的数据容器，专门用来保存bio的数据，包含一块数据所在页，以及页内的偏移及长度信息，通过这些信息就可以很清晰地描述数据具体什么位置。request用来描述单次I&#x2F;O请求，request_queue用来描述与设备相关的请求队列，每个块设备在块层都有一个request_queue与之对应，所有对该块设备的I&#x2F;O请求最后都会流经request_queue。块层正是借助bio、bio_vec、request、request_queue这几个结构将I&#x2F;O请求在内核I&#x2F;O子系统各个层次的处理过程联系起来。 I&#x2F;O调度算法： noop算法（不调度算法）、deadline算法（改良的电梯算法）、CFQ算法（完全公平调度算法，对于通用的服务器来说，CFQ是较好的选择，从Linux2.6.18版本开始，CFQ成为了默认的IO调度算法）。 I&#x2F;O合并： 将符合条件的多个IO请求合并成单个IO请求进行一并处理，从而提升IO请求的效率。进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条，无论哪一条路径，在bio结构转换为request结构进行IO调度前都需要进入Plug队列进行蓄流（部分Direct IO产生的请求不需要经过蓄流），所以对IO请求来说，能够进行合并的位置主要有Page Cache、Plug List、IO调度器3个。而在块层中，Plug将块层的IO请求聚集起来，使得零散的请求有机会进行合并和排序，最终达到高效利用存储设备的目的。每个进程都有一个私有的Plug队列，进程在向通用块层派发IO派发请求之前如果开始蓄流的功能，那么IO请求在被发送给IO调度器之前都被保存在Plug队列中，直到泄流的时候才被批量交给调度器。蓄流主要是为了增加请求合并的机会，bio在进入Plug队列之前会尝试与Plug队列保存的request进行合并。当应用需要发多个bio请求的时候，比较好的办法是先蓄流，而不是一个个单独发给最终的硬盘。 LVM&emsp;&emsp;LVM，即Logical Volume Manager，逻辑卷管理器，是一种硬盘的虚拟化技术，可以允许用户的硬盘资源进行灵活的调整和动态管理。&emsp;&emsp;LVM是Linux系统对于硬盘分区管理的一种机制，诞生是为了解决硬盘设备在创建分区后不易修改分区大小的缺陷。尽管对硬盘的强制性扩容和缩容理论上是可行的，但是却可能造成数据丢失。LVM技术是通过在硬盘分区和文件系统之间增加一个逻辑层，提供了一个抽象的卷组，就可以把多块硬盘设备、硬盘分区，甚至RAID整体进行卷则合并。并可以根据情况进行逻辑上的虚拟分割，这样一来，用户不用关心物理硬盘设备的底层架构和布局，就可以实现对硬盘分区设备的动态调整。&emsp;&emsp;LVM通过在操作系统与物理存储资源之间引入逻辑卷（Logical Volume）的抽象，来解决传统磁盘分区管理工具的问题。LVM将众多不同的物理存储器资源（物理卷，Physical Volume）组成卷组（Volume Group），该卷组可以理解为普通系统的物理磁盘，但是卷组上不能创建或者安装文件系统，而是需要LVM先在卷组中创建一个逻辑卷，然后将ext3等文件系统安装在这个逻辑卷上，可以在不重新引导系统的前提下通过在卷组划分额外的空间，来为这个逻辑卷动态扩容。LVM的架构体系中，有三个很重要的概念： PV，物理卷，即实际存在的硬盘、分区或者RAID VG，卷组，是由多个物理卷组合形成的大的整体的卷组 LV，逻辑卷，是从卷组上分割出来的，可以使用使用的逻辑存储设备 条带化&emsp;&emsp;大多数磁盘系统都对访问次数（每秒的 I&#x2F;O 操作，IOPS）和数据传输率（每秒传输的数据量，TPS）有限制。当达到这些限制时，后面需要访问磁盘的进程就需要等待，这时就是所谓的磁盘冲突。避免磁盘冲突是优化 I&#x2F;O 性能的一个重要目标，而 I&#x2F;O 性能的优化与其他资源（如CPU和内存）的优化有着很大的区别 ,I&#x2F;O 优化最有效的手段是将 I&#x2F;O 最大限度的进行平衡。条带化技术就是一种自动的将 I&#x2F;O 的负载均衡到多个物理磁盘上的技术，条带化技术就是将一块连续的数据分成很多小部分并把他们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分而不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的 I&#x2F;O 并行能力，从而获得非常好的性能。很多操作系统、磁盘设备供应商、各种第三方软件都能做到条带化。","categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"}]},{"title":"个人感悟","slug":"个人感悟","date":"2021-04-06T08:18:06.000Z","updated":"2024-08-18T12:36:04.796Z","comments":true,"path":"个人感悟/","permalink":"https://watsonlu6.github.io/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/","excerpt":"","text":"论学习 多花点时间在自己专业上，不要分心旁骛太多。 先做好本份工作，行有余力，再自学 。 及时总结心得经验。记录，总结做过的项目，能总结多少就多少。如果有扎实的理论基础，深刻的理解能力，坚强的毅力，无论什么新技术新东西都能很快学会，但最宝贵的东西——经验，解决问题的钥匙。是无法学会的，只能慢慢体会,慢慢总结。 技术不求新，涉及哪方面的技术&#x2F;知识，就去学习，想办法精通。先有深度，再求广度。 论生活 生活应该简单，但不应该单调。电影，音乐，都是不错的消遣。适当放松，有不足才有期待。 跑步能让我很开心，多去跑步。 别被一些俗事打乱了生活的节奏，要懂得把握生活的节奏。 每星期总结一周的活动。 维持7.5小时睡眠。 抓住该努力的时间去努力，该松弛的时候去松弛。 运动能使人变得开朗，有特长能使人变得自信。 论做人 自视高谓之骄，怀激愤谓之躁。做人应该尽量避免骄傲，浮躁。 要在3年达到别人10年才能达到的高度，就意味着3年内要承受10年的苦。请你衡量。 不要拿社会标准来衡量自己的价值，而应该用心灵的意义去裁决。 实验室很浮躁，越是浮躁的地方，越要扎实下来，厚积薄发。 调整自己的心态，不要太在乎一得一失。你目前所努力的，其实不是为了成功，而是为了当成功的机会来临时，你能把握住而已。为了成功和为了成功把握机会，两者的区别很重要。 做人应该谦虚，而且不要有自虐狂的心理，并不是每个人都会针对你。 高手是别人认为的。不是自封的，不要自大。 坚持理想，理想不难，难的是坚持 论心理 烦恼和焦虑：烦恼和焦虑表示你为一些事情担心着，而你目前并没有付出能够解决这些问题的努力。 宽容面对自己的缺陷和不足。 把自己的消极想法都记下，逐点去分析，攻破。分析问题所在，制定方法去解决（生活与心理都是） 知足常乐 论工作 对待补贴：不管导师发不发补贴，只要你还在这个实验室一天，就请努力专心的做事。 对待每一件事：努力认真去做好每一件事。只要你想做，总有法子可以做到的。 做好本分工作。技术人员有时候对PM分配自己一些较没技术含量的工作会很不满。记住，都是做事而已。无论怎样，分配到你的工作，请你做好。孔子尚且养过马，薛仁贵尚且当过伙头军。我认为，做好一个茶叶蛋，比做砸了原子弹更有意义。不以技术难度定优劣，都是做事而已。 团队的交流,配合开发： a. 别人的失误要及时指出，当然了，语气要婉转。这样才能调整进度，别发现了错误隐瞒不报。 b. 对于自己不懂的环节，勇敢承认自己的缺点，大胆去估计进度，并认真学习。 c. 如果可能，每天汇报进度，也许只是几分钟，让PM看看你的构思，你的代码，你的成果。PM是最熟悉业务的，他能指出你的程序流是否正确，页面是否恰当。根据这些，你和他才能估计进度，这样，整个项目的进度才算可控。 d. 学会承担更多的责任。把困难的任务交给你，通常意味着只有你才能完成。请你好好享受这种”唯一”的乐趣。 出了问题，努力想办法去解决。别人或者不在意你的能力，但很在意你的态度。 最佳印象 早到。早到就显得你很重视这份工作。 不要过于固执。工作时时在扩展，不要老是以“这不是我份内的工作”为由来逃避责任。当前额外的工作指派到你头上时，不妨视之为考验。 苦中求乐。不管你接受的工作多么艰巨，鞠躬尽瘁也要做好，千万别表现出你做不来或不知从何入手的样子。 立刻动手。接到工作要立刻动手，迅速准确及时完成，反应敏捷给人的印象是金钱买不到的。 谨言。职务上的机密必须守口如瓶。 听从上司的临时指派。上司的时间比你的时间宝贵，不管他临时指派了什么工作给你，都比你手头上的工作来得重要。 荣耀归于上司。即让上司在人前人后永远光鲜。 保持冷静。面对任何状况都能处之泰然的人，一开始就取得了优势。老板、客户不仅钦佩那些面对危机声色不变的人，更欣赏能妥善解决问题的人。 别存在太多的希望。千万别期盼所有的事情都会照你的计划而行。相反，你得时时为可能产生的错误做准备。 敢于做出果断决定。遇事犹豫不决或过度依赖他人意见的人，是一辈子注定要被打入冷宫的。 广收资讯。要想成为一个成功的人，光是从影音媒体取得资讯是不够的，多看报章杂志才是最直接的知识来源。","categories":[{"name":"个人生活","slug":"个人生活","permalink":"https://watsonlu6.github.io/categories/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"个人生活","slug":"个人生活","permalink":"https://watsonlu6.github.io/tags/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-04-01T15:09:26.000Z","updated":"2024-07-27T03:58:36.598Z","comments":true,"path":"hello-world/","permalink":"https://watsonlu6.github.io/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"云存储/Ceph","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"},{"name":"存储基础","slug":"云存储/存储基础","permalink":"https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"},{"name":"个人生活","slug":"个人生活","permalink":"https://watsonlu6.github.io/categories/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"云存储","slug":"云存储","permalink":"https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"},{"name":"Ceph","slug":"Ceph","permalink":"https://watsonlu6.github.io/tags/Ceph/"},{"name":"存储基础","slug":"存储基础","permalink":"https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"},{"name":"个人生活","slug":"个人生活","permalink":"https://watsonlu6.github.io/tags/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/"}]}