<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Ceph PG介绍 | watson Lu&#39;blogs</title>
  <meta name="description" content="Ceph并不是直接通过CRUSH算法将数据对象一一映射到OSD中的，这样做将非常复杂与低效。而且，Ceph用户并不需要了解实际的CRUSH算法是怎么运行的，只需要关心数据保存在哪里即可。Ceph通过存储池Pool和放置组Placement Groups (PGs)来实现CRUSH算法进行数据寻址。PG聚合了池中的对象。按对象跟踪 RADOS 对象的位置和元数据在计算上是昂贵的。对于具有数百万个 R">
<meta property="og:type" content="article">
<meta property="og:title" content="Ceph PG介绍">
<meta property="og:url" content="https://watsonlu6.github.io/Storage/Ceph/ceph-PG%E4%BB%8B%E7%BB%8D/index.html">
<meta property="og:site_name" content="watson&#39;blogs">
<meta property="og:description" content="Ceph并不是直接通过CRUSH算法将数据对象一一映射到OSD中的，这样做将非常复杂与低效。而且，Ceph用户并不需要了解实际的CRUSH算法是怎么运行的，只需要关心数据保存在哪里即可。Ceph通过存储池Pool和放置组Placement Groups (PGs)来实现CRUSH算法进行数据寻址。PG聚合了池中的对象。按对象跟踪 RADOS 对象的位置和元数据在计算上是昂贵的。对于具有数百万个 R">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://watsonlu6.github.io/images/PG%E4%BB%8B%E7%BB%8D_1.png">
<meta property="og:image" content="https://watsonlu6.github.io/images/PG%E4%BB%8B%E7%BB%8D_2.png">
<meta property="article:published_time" content="2021-11-10T10:22:25.000Z">
<meta property="article:modified_time" content="2024-09-01T13:29:00.495Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="云存储">
<meta property="article:tag" content="Ceph">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://watsonlu6.github.io/images/PG%E4%BB%8B%E7%BB%8D_1.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://watsonlu6.github.io/Storage/Ceph/ceph-PG%E4%BB%8B%E7%BB%8D/index.html">
  
    <link rel="alternate" href="/atom.xml" title="watson&#39;blogs" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 7.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/watsonLu6/" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">watson</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Cloud computing development engineer</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> BeiJing, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/watsonLu6/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/">个人生活</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%91%E5%AD%98%E5%82%A8/">云存储</a><span class="category-list-count">29</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/">Ceph</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/">存储基础</a><span class="category-list-count">5</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><span class="category-list-count">13</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a><span class="category-list-count">13</span></li></ul></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ceph/" rel="tag">Ceph</a><span class="tag-list-count">24</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/libvirt/" rel="tag">libvirt</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/" rel="tag">个人生活</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%91%E5%AD%98%E5%82%A8/" rel="tag">云存储</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" rel="tag">云计算</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/" rel="tag">存储基础</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Ceph/" style="font-size: 13.75px;">Ceph</a> <a href="/tags/libvirt/" style="font-size: 13.5px;">libvirt</a> <a href="/tags/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/" style="font-size: 13px;">个人生活</a> <a href="/tags/%E4%BA%91%E5%AD%98%E5%82%A8/" style="font-size: 14px;">云存储</a> <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 13.5px;">云计算</a> <a href="/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/" style="font-size: 13.25px;">存储基础</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">四月 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">十月 2022</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">七月 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a>
              </p>
              <p class="item-title">
                <a href="/libvirt%E6%96%87%E6%A1%A3/13-virsh%E4%BD%BF%E7%94%A8/" class="title">1 libvirt概述</a>
              </p>
              <p class="item-date">
                <time datetime="2024-04-01T07:50:26.000Z" itemprop="datePublished">2024-04-01</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a>
              </p>
              <p class="item-title">
                <a href="/libvirt%E6%96%87%E6%A1%A3/12-libvirt%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" class="title">12 libvirt使用示例</a>
              </p>
              <p class="item-date">
                <time datetime="2024-03-12T07:50:26.000Z" itemprop="datePublished">2024-03-12</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a>
              </p>
              <p class="item-title">
                <a href="/libvirt%E6%96%87%E6%A1%A3/11-libvirt%E8%B0%83%E8%AF%95%E4%B8%8E%E6%97%A5%E5%BF%97/" class="title">11 libvirt调试与日志</a>
              </p>
              <p class="item-date">
                <time datetime="2024-03-11T07:50:26.000Z" itemprop="datePublished">2024-03-11</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a>
              </p>
              <p class="item-title">
                <a href="/libvirt%E6%96%87%E6%A1%A3/10-libvirt%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F/" class="title">10 libvirt安全模式</a>
              </p>
              <p class="item-date">
                <time datetime="2024-03-10T07:50:26.000Z" itemprop="datePublished">2024-03-10</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/libvirt/">libvirt</a>
              </p>
              <p class="item-title">
                <a href="/libvirt%E6%96%87%E6%A1%A3/9-libvirt%E4%BA%8B%E4%BB%B6%E5%92%8C%E8%AE%A1%E6%97%B6%E5%99%A8%E5%A4%84%E7%90%86/" class="title">9 libvirt事件和计时器处理</a>
              </p>
              <p class="item-date">
                <time datetime="2024-03-09T07:50:26.000Z" itemprop="datePublished">2024-03-09</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-Storage/Ceph/ceph-PG介绍" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      Ceph PG介绍
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/Storage/Ceph/ceph-PG%E4%BB%8B%E7%BB%8D/" class="article-date">
	  <time datetime="2021-11-10T10:22:25.000Z" itemprop="datePublished">2021-11-10</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E4%BA%91%E5%AD%98%E5%82%A8/">云存储</a>►<a class="article-category-link" href="/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/">Ceph</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/Ceph/" rel="tag">Ceph</a>, <a class="article-tag-link-link" href="/tags/%E4%BA%91%E5%AD%98%E5%82%A8/" rel="tag">云存储</a>
  </span>


        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/Storage/Ceph/ceph-PG%E4%BB%8B%E7%BB%8D/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <p>Ceph并不是直接通过CRUSH算法将数据对象一一映射到OSD中的，这样做将非常复杂与低效。而且，Ceph用户并不需要了解实际的CRUSH算法是怎么运行的，只需要关心数据保存在哪里即可。Ceph通过存储池Pool和放置组Placement Groups (PGs)来实现CRUSH算法进行数据寻址。<br><img src="/images/PG%E4%BB%8B%E7%BB%8D_1.png" alt="Cache Tier"><br>PG聚合了池中的对象。按对象跟踪 RADOS 对象的位置和元数据在计算上是昂贵的。对于具有数百万个 RADOS 对象的系统，按对象跟踪位置是不切实际的。Ceph 客户端计算一个 RADOS 对象应位于哪个 PG。作为计算的一部分，客户端会对对象 ID 进行哈希处理，并执行涉及池中 PG 数量和池 ID 的操作。</p>
<p>属于 PG 的 RADOS 对象的内容存储在一组 OSD 中。例如，在一个大小为 2 的复制池中，每个 PG 将在两个 OSD 上存储对象，如下所示：<br><img src="/images/PG%E4%BB%8B%E7%BB%8D_2.png" alt="Cache Tier"><br>如果 OSD #2 发生故障，另一个 OSD 将被分配到 Placement Group #1，然后用 OSD #1 中所有对象的副本填充。如果池大小从 2 更改为 3，将分配一个额外的 OSD 到 PG，并接收 PG 中所有对象的副本。<br>分配给 PG 的 OSD 并不是专门属于该 PG 的；相反，OSD 也与来自同一池或其他池的其他 PG 共享。在我们的例子中，OSD #2 由 Placement Group #1 和 Placement Group #2 共享。如果 OSD #2 发生故障，那么 Placement Group #2 必须恢复对象副本（利用 OSD #3）。</p>
<p>PG是 Ceph 中的逻辑池的子集。PG 执行将对象（作为一组）放置到 OSDs 中的功能。Ceph 以 PG 为单位管理数据, 这比管理单个 RADOS 对象更具扩展性。在集群中拥有较多的 PG的集群，相比具有较少 PG 的相同集群，数据分布更均衡。每个 Ceph 的内部 RADOS 对象都会映射到特定的 PG，而每个 PG 又只属于一个 Ceph 池。</p>
<p>当 PG 数量增加时，会发生几个后果。新的 PG 被分配到 OSD。CRUSH 函数的结果发生变化，这意味着一些来自已经存在的 PG 的对象被复制到新的 PG 中，并从旧的 PG 中删除。</p>
<p>在理想条件下，对象会在PG之间均匀分布。由于CRUSH计算每个对象的PG，但不知道每个与PG关联的OSD中存储了多少数据，因此PG和OSD的数量比例可能对数据分布产生显著影响。</p>
<p>例如，假设在一个有三个副本的池中，只有一个PG分配给十个OSD。在这种情况下，由于CRUSH没有其他选择，只会使用三个OSD。然而，如果有更多PG可用，RADOS对象更有可能在OSD之间均匀分布。CRUSH会尽力使OSD在所有现有PG之间均匀分布。</p>
<p>只要PG的数量比OSD多一个或两个数量级，分布通常会比较均匀。例如：3个OSD对应256个PG，10个OSD对应512个PG，或者10个OSD对应1024个PG。</p>
<p>但是，不均匀的数据分布可能由于PG与OSD比例之外的因素而出现。例如，由于CRUSH不考虑RADOS对象的大小，一些非常大的RADOS对象的存在可能会造成不平衡。例如，假设有一百万个4 KB的RADOS对象，总计4 GB，均匀分布在10个OSD的1024个PG中。这些RADOS对象将会在每个OSD上消耗4 GB &#x2F; 10 &#x3D; 400 MB。如果再往池中添加一个400 MB的RADOS对象，则在该RADOS对象所在的PG的三个OSD上，每个OSD将被填充到400 MB + 400 MB &#x3D; 800 MB，而其他七个OSD仍然只有400 MB。</p>
<p><strong>每个PG对OSD和MON增加了内存、网络和CPU的需求</strong>。这些需求必须始终得到满足，并在恢复期间增加。实际上，PG的主要作用之一是通过将对象聚集在一起分担这些开销。<br>因此，减少PG的数量可以节省大量资源。</p>
<h2 id="自动缩放PG"><a href="#自动缩放PG" class="headerlink" title="自动缩放PG"></a>自动缩放PG</h2><p>PG是 Ceph 用于分配数据的内部实现细节。自动缩放提供了一种管理 PG，特别是管理不同池中 PG 数量的方法。当启用 pg-autoscaling 时，集群可以根据预期的集群和池使用情况，对每个池的 PG 数量（pgp_num）进行建议或自动调整。<br>每个池都有一个 <code>pg_autoscale_mode</code> 属性，可以设置为以下值：</p>
<ul>
<li><strong>off</strong>：禁用该池的自动缩放。管理员需要为每个池选择合适的 <code>pgp_num</code>。有关更多信息，请参见选择 PG 数量。</li>
<li><strong>on</strong>：启用对给定池的 PG 数量的自动调整。</li>
<li><strong>warn</strong>：当 PG 数量需要调整时发出健康检查警告。</li>
</ul>
<p>要设置现有池的自动缩放模式，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &lt;pool-name&gt; pg_autoscale_mode &lt;mode&gt;</span><br></pre></td></tr></table></figure>

<p>对于在集群初始设置后创建的池，也有一个 <code>pg_autoscale_mode</code> 设置。要更改此设置，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set global osd_pool_default_pg_autoscale_mode &lt;mode&gt;</span><br></pre></td></tr></table></figure>

<p>可以使用 <code>noautoscale</code> 标志来禁用或启用所有池的自动缩放。默认情况下，该标志设置为 <code>off</code>，但可以通过以下命令将其设置为 <code>on</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set noautoscale</span><br></pre></td></tr></table></figure>

<p>要将 <code>noautoscale</code> 标志设置为 <code>off</code>，请运行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool unset noautoscale</span><br></pre></td></tr></table></figure>

<p>要获取标志的值，请运行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get noautoscale</span><br></pre></td></tr></table></figure>

<p><strong>查看 PG 缩放状态</strong><br>要查看每个池、其相对利用率以及对 PG 数量的任何推荐更改，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool autoscale-status</span><br></pre></td></tr></table></figure>
<p>输出将类似于：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">POOL    SIZE  TARGET SIZE  RATE  RAW CAPACITY   RATIO  TARGET RATIO  EFFECTIVE RATIO BIAS PG_NUM  NEW PG_NUM  AUTOSCALE BULK</span><br><span class="line">a     12900M                3.0        82431M  0.4695                                          8         128  warn      True</span><br><span class="line">c         0                 3.0        82431M  0.0000        0.2000           0.9884  1.0      1          64  warn      True</span><br><span class="line">b         0        953.6M   3.0        82431M  0.0347                                          8              warn      False</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>POOL</strong>：池的名称。</li>
<li><strong>SIZE</strong>：池中存储的数据量。</li>
<li><strong>TARGET SIZE</strong>（如果存在）：预计池中存储的数据量，由管理员指定。系统使用两个值中的较大者进行计算。</li>
<li><strong>RATE</strong>：池的倍数，决定了消耗多少原始存储容量。例如，一个三副本池的比例为 3.0，一个 k&#x3D;4 m&#x3D;2 的纠删编码池的比例为 1.5。</li>
<li><strong>RAW CAPACITY</strong>：负责存储池数据（以及可能的其他池数据）的特定 OSD 上的总原始存储容量。</li>
<li><strong>RATIO</strong>：池使用的存储量与总原始存储容量的比率。换句话说，RATIO 定义为 (SIZE * RATE) &#x2F; RAW CAPACITY。</li>
<li><strong>TARGET RATIO</strong>（如果存在）：池的预期存储（即管理员指定的池预计消耗的存储量）与设置了目标比例的所有其他池的预期存储之比。如果同时指定了 <code>target_size_bytes</code> 和 <code>target_size_ratio</code>，则 <code>target_size_ratio</code> 优先。</li>
<li><strong>EFFECTIVE RATIO</strong>：对目标比例进行两次调整后的结果：<ul>
<li>减去预期被使用的目标容量。</li>
<li>在设置了目标比例的池之间对目标比例进行归一化，以便它们集体瞄准集群容量。例如，四个目标比例为 1.0 的池将具有 0.25 的有效比例。</li>
</ul>
</li>
<li><strong>BIAS</strong>：用作倍数，根据之前有关特定池应有多少 PG 的信息手动调整池的 PG 数量。</li>
<li><strong>PG_NUM</strong>：池当前的 PG 数量，或如果正在进行 pg_num 更改，则为池正在努力达到的 PG 数量。</li>
<li><strong>NEW PG_NUM</strong>（如果存在）：系统建议的池的 pg_num 值。它始终是 2 的幂，并且仅在推荐值与当前值的差异大于默认的 3 倍时出现。</li>
<li><strong>AUTOSCALE</strong>：池的 <code>pg_autoscale_mode</code>，设置为 <code>on</code>、<code>off</code> 或 <code>warn</code>。</li>
<li><strong>BULK</strong>：确定池是否是批量池。它的值为 True 或 False。批量池预计会很大，应该最初具有大量 PG，以避免性能问题。另一方面，非批量池预计会很小（例如，一个 .mgr 池或元数据池）。</li>
</ul>
<p><em>注意</em><br>如果 <code>ceph osd pool autoscale-status</code> 命令没有返回任何输出，可能至少有一个池跨越了多个 CRUSH 根。这种“跨越池”问题可能发生在以下场景中：当新部署自动在默认 CRUSH 根上创建 .mgr 池时，后续池的创建规则将它们约束到特定的阴影 CRUSH 树。例如，如果您创建一个限制为 <code>deviceclass = ssd</code> 的 RBD 元数据池和一个限制为 <code>deviceclass = hdd</code> 的 RBD 数据池，您将遇到此问题。要解决此问题，将跨越池约束到仅一个设备类。在上述场景中，可能会有一个 <code>replicated-ssd</code> CRUSH 规则生效，可以通过运行以下命令将 .mgr 池约束到 ssd 设备：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set .mgr crush_rule replicated-ssd</span><br></pre></td></tr></table></figure>
<p>此干预将导致少量的回填，但通常这些流量很快就会完成。</p>
<p><strong>自动扩缩容</strong><br>在最简单的自动扩缩容方法中，集群允许根据使用情况自动调整 <code>pgp_num</code>。Ceph 会考虑整个系统的总可用存储和目标 PG 数量，考虑每个池中存储的数据量，并相应地分配 PG。系统采取保守的方法，仅在当前 PG 数量（pg_num）与推荐数量的差异超过 3 倍时，才对池进行更改。<br>每个 OSD 的目标 PG 数量由 <code>mon_target_pg_per_osd</code> 参数确定（默认值：100），可以通过以下命令调整：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set global mon_target_pg_per_osd 100</span><br></pre></td></tr></table></figure>

<p>自动缩放器会分析池并在每个子树基础上进行调整。由于每个池可能映射到不同的 CRUSH 规则，每条规则可能将数据分配到不同的设备，Ceph 将独立考虑层次结构中每个子树的利用率。例如，映射到 ssd OSD 的池和映射到 hdd OSD 的池将根据这两种不同设备类型的数量来确定各自的最佳 PG 数量。<br>如果一个池使用了两个或更多 CRUSH 根（例如，同时包含 ssd 和 hdd 设备的阴影树），自动缩放器会在管理器日志中发出警告。警告中会列出池的名称和重叠的根集。自动缩放器不会对具有重叠根的池进行扩缩容，因为这种情况可能会导致扩缩容过程出现问题。我们建议将每个池约束到仅一个根（即一个 OSD 类别），以消除警告并确保扩缩容过程成功。</p>
<p><strong>管理标记为批量的池</strong><br>如果一个池被标记为批量池，则自动缩放器会为池分配完整的 PG 数量，然后仅在池的使用比例不均时才缩减 PG 数量。然而，如果一个池未被标记为批量池，则自动缩放器会以最小 PG 数量启动池，仅在池中使用量增加时才创建额外的 PG。<br>要创建一个标记为批量池的池，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &lt;pool-name&gt; --bulk</span><br></pre></td></tr></table></figure>

<p>要设置或取消设置现有池的批量标志，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &lt;pool-name&gt; bulk &lt;true/false/1/0&gt;</span><br></pre></td></tr></table></figure>

<p>要获取现有池的批量标志，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get &lt;pool-name&gt; bulk</span><br></pre></td></tr></table></figure>

<p><strong>指定预期池大小</strong><br>当集群或池首次创建时，它只消耗了集群总容量的一小部分，并且系统认为它只需要少量 PG。然而，在某些情况下，集群管理员知道哪些池在长期内可能会消耗大部分系统容量。当 Ceph 提供了这些信息时，可以从一开始就使用更合适的 PG 数量，从而避免后续更改 <code>pg_num</code> 和相关的数据迁移开销。</p>
<p>池的目标大小可以通过两种方式指定：一种是与池的绝对大小（以字节为单位）相关，另一种是作为与所有其他设置了 <code>target_size_ratio</code> 的池的权重关系。</p>
<p>例如，要告诉系统 <code>mypool</code> 预计将消耗 100 TB 的容量，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set mypool target_size_bytes 100T</span><br></pre></td></tr></table></figure>
<p>或者，要告诉系统 <code>mypool</code> 预计将消耗相对于设置了 <code>target_size_ratio</code> 的其他池的 1.0 比例，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set mypool target_size_ratio 1.0</span><br></pre></td></tr></table></figure>

<p>如果 <code>mypool</code> 是集群中唯一的池，则预计它将使用集群总容量的 100%。然而，如果集群中包含一个目标比例设置为 1.0 的第二个池，则两个池都预计将使用集群总容量的 50%。</p>
<p><code>ceph osd pool create</code> 命令具有两个命令行选项，可以在创建池时设置目标大小：<code>--target-size-bytes &lt;bytes&gt;</code> 和 <code>--target-size-ratio &lt;ratio&gt;</code>。</p>
<p>注意，如果指定的目标大小值不合理（例如，大于集群总容量），则会引发健康检查（POOL_TARGET_SIZE_BYTES_OVERCOMMITTED）。</p>
<p>如果为池同时指定了 <code>target_size_ratio</code> 和 <code>target_size_bytes</code>，则会忽略后者，前者将用于系统计算，并会引发健康检查（POOL_HAS_TARGET_SIZE_BYTES_AND_RATIO）。</p>
<p><strong>指定池的 PG 范围</strong></p>
<p>可以指定池的 PG 最小值和最大值。</p>
<p><strong>设置 PG 的最小值和最大值</strong></p>
<p>如果设置了最小值，则 Ceph 不会自行将 PG 数量减少（也不会建议减少）到低于配置值的水平。设置最小值是为了在 I&#x2F;O 期间即使池大部分为空时，也能为客户端提供一定程度的并行性。</p>
<p>如果设置了最大值，则 Ceph 不会自行将 PG 数量增加（也不会建议增加）到高于配置值的水平。</p>
<p>要设置池的 PG 最小值，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &lt;pool-name&gt; pg_num_min &lt;num&gt;</span><br></pre></td></tr></table></figure>

<p>要设置池的 PG 最大值，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &lt;pool-name&gt; pg_num_max &lt;num&gt;</span><br></pre></td></tr></table></figure>

<p>此外，<code>ceph osd pool create</code> 命令具有两个命令行选项，可用于在创建池时指定池的最小或最大 PG 数量：<code>--pg-num-min &lt;num&gt;</code> 和 <code>--pg-num-max &lt;num&gt;</code>。</p>
<h2 id="预选择PG-NUM"><a href="#预选择PG-NUM" class="headerlink" title="预选择PG_NUM"></a>预选择PG_NUM</h2><p>在创建池时，可以通过以下命令预选择 <code>pg_num</code> 参数的值：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &#123;pool-name&#125; [pg_num]</span><br></pre></td></tr></table></figure>

<p>如果在命令中选择不指定 <code>pg_num</code>，集群会使用 PG 自动缩放器根据池中存储的数据量自动配置该参数（见上文的自动扩缩容部分）。<br>无论是否在创建时指定 <code>pg_num</code>，都不会影响集群之后是否会自动调整该参数。PG 自动缩放的启用或禁用可以通过以下命令设置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &#123;pool-name&#125; pg_autoscale_mode (on|off|warn)</span><br></pre></td></tr></table></figure>

<p>没有平衡器时，建议的目标是在每个 OSD 上大约 100 个 PG 副本。使用平衡器时，初始目标是每个 OSD 上大约 50 个 PG 副本。<br>自动缩放器尝试满足以下条件：</p>
<ul>
<li>每个 OSD 上的 PG 数量应与池中的数据量成正比。</li>
<li>每个池应有 50-100 个 PG，考虑到每个 PG 副本在 OSD 之间的复制开销或纠删编码扩展。</li>
</ul>
<h2 id="指定-PG-NUM-的相关因素"><a href="#指定-PG-NUM-的相关因素" class="headerlink" title="指定 PG_NUM 的相关因素"></a>指定 PG_NUM 的相关因素</h2><p>在某种程度上，数据高可用和在 OSD 之间均匀分配的标准倾向于更高的 PG 数量。另一方面，节省 CPU 资源和最小化内存使用的标准则倾向于较低的 PG 数量。<br><strong>数据高可用</strong><br>当一个 OSD 发生故障时，数据丢失的风险增加，直到恢复到配置的复制水平。为了说明这一点，假设以下场景导致一个 PG 的永久数据丢失：</p>
<ol>
<li>OSD 发生故障，所有其包含的对象副本丢失。对于 PG 中的每个对象，其副本数量从三降到两。</li>
<li>Ceph 开始为这个 PG 选择一个新的 OSD，以重新创建每个对象的第三个副本。</li>
<li>在新的 OSD 完全填充第三个副本之前，另一个 OSD 在同一 PG 内发生故障。某些对象将只有一个剩余副本。</li>
<li>Ceph 选择另一个 OSD 并继续复制对象，以恢复所需的副本数量。</li>
<li>在恢复完成之前，PG 内的第三个 OSD 发生故障。如果这个 OSD 恰好包含对象的唯一剩余副本，则对象将永久丢失。</li>
</ol>
<p>在一个包含 10 个 OSD 的集群中，具有 512 个 PG 和三副本池的情况下，CRUSH 会将每个 PG 分配给三个 OSD。因此，当第一个 OSD 发生故障时，将同时为所有 150 个 PG 开始恢复。<br>被恢复的 150 个 PG 可能会均匀分布在 9 个剩余的 OSD 上。每个剩余的 OSD 因此可能会将对象副本发送到所有其他 OSD，并且还可能接收一些新对象，因为它已成为新的 PG 的一部分。</p>
<p>恢复完成所需的时间取决于 Ceph 集群的架构。比较两种设置：<br>（1）每个 OSD 由一台机器上的 1 TB SSD 托管，所有 OSD 连接到 10 Gb&#x2F;s 交换机，单个 OSD 的恢复在一定时间内完成。<br>（2）每台机器上有两个 OSD，使用 HDD，没有 SSD WAL+DB 和 1 Gb&#x2F;s 交换机。在第二种设置中，恢复将慢至少一个数量级。</p>
<p>在这样的集群中，PG 数量对数据高可用几乎没有影响。无论每个 OSD 有 128 个 PG 还是 8192 个 PG，恢复不会更快或更慢。<br>然而，增加 OSD 的数量可以提高恢复速度。假设我们的 Ceph 集群从 10 个 OSD 扩展到 20 个 OSD。每个 OSD 现在只参与大约 75 个 PG，而不是大约 150 个 PG。所有 19 个剩余的 OSD 仍然需要复制相同数量的对象以进行恢复。但现在有 20 个 OSD 必须复制仅 50 GB 的每个对象，而不是 10 个 OSD 复制 100 GB 的每个对象。如果网络以前是瓶颈，则恢复现在的速度加倍。</p>
<p>类似地，假设我们的集群增长到 40 个 OSD。每个 OSD 仅托管大约 38 个 PG。如果 OSD 发生故障，恢复将比以前更快，除非被其他瓶颈阻碍。然而，假设我们的集群增长到 200 个 OSD。每个 OSD 将只托管大约 7 个 PG。如果 OSD 发生故障，恢复将在最多 7 个 OSD 上进行，这意味着恢复时间将比 40 个 OSD 时长。因此，应该增加 PG 数量。</p>
<p>无论恢复时间多么短，在恢复过程中始终有额外 OSD 失败的可能性。考虑上面的 10 个 OSD 的集群：如果任何 OSD 失败，则大约 150 除以 9 的 PG 将只有一个剩余副本。如果剩余的 8 个 OSD 中的任何一个失败，则大约 17 除以 8 的 PG 可能会丢失其剩余的对象。这是为什么设置 <code>size=2</code> 是有风险的一个原因。</p>
<p>当集群中的 OSD 数量增加到 20 时，损失3个OSD 会显著减少损坏的 PG 数量。第二个 OSD 的损失仅导致大约 17 除以 8 个 PG 损坏，而第三个 OSD 的损失仅导致如果它是包含剩余副本的 4 个 OSD 之一，则才会丢失数据。这意味着——假设恢复期间失去一个 OSD 的概率是 0.0001%——在 10 个 OSD 的集群中丢失三个 OSD 的概率为 <code>X</code>，而在 20 个 OSD 的集群中为 <code>Y</code>。<br>总之，OSD 数量越多，恢复速度越快，因级联故障而永久丢失 PG 的风险越低。就数据高可用而言，在少于 50 个 OSD 的集群中，512 或 4096 个 PG 的数量差异几乎没有影响。</p>
<p><em>注意</em><br>最近添加到集群中的 OSD 可能需要较长时间来填充分配给它的 PG。但是，这一过程的缓慢不会导致对象退化或对数据耐用性产生影响，因为 Ceph 会在从旧 PG 中移除数据之前，将数据填充到新的 PG 中。</p>
<h2 id="选择PG的数量"><a href="#选择PG的数量" class="headerlink" title="选择PG的数量"></a>选择PG的数量</h2><p>如果OSD数量超过50个，我们建议每个OSD大约设置50-100个PG，以平衡资源使用、数据耐久性和数据分布。如果OSD数量少于50个，请参阅预选择部分的指导。对于单个池，使用以下公式获取基线值：<br>[<br>\text{Total PGs} &#x3D; \text{OSD数量} \times \text{池大小}<br>]</p>
<p>其中池大小是复制池的副本数量或编码池的K+M总和。要检索这个总和，请运行命令 <code>ceph osd erasure-code-profile get</code>。</p>
<p>接下来，检查结果的基线值是否与您设计Ceph集群的方式一致，以最大化数据耐久性和对象分布，并最小化资源使用。</p>
<p>这个值应四舍五入到最接近的2的幂。</p>
<p>每个池的 <code>pg_num</code> 应该是2的幂。其他值可能会导致数据在OSD之间分布不均。最好只在可行且期望的情况下增加 <code>pg_num</code> 到下一个最高的2的幂。注意，这个2的幂规则是针对每个池的；对所有池的 <code>pg_num</code> 的总和对齐到2的幂既不是必要的，也不容易。</p>
<p>例如，如果您有一个200个OSD的集群和一个副本大小为3的单个池，估算PG的数量如下：<br>[<br>\text{Total PGs} &#x3D; 200 \times 3 &#x3D; 600<br>]</p>
<p>四舍五入到最接近的2的幂：8192。</p>
<p>当使用多个数据池存储对象时，确保平衡每个池的PG数量和每个OSD的PG数量，以便得到一个合理的PG总数。找到一个为每个OSD提供合理低方差的数字，而不会对系统资源造成过大压力或使配对过程过慢是很重要的。</p>
<p>例如，假设您有一个包含10个池的集群，每个池有512个PG，分布在10个OSD上。这意味着总共有5120个PG分布在10个OSD上，每个OSD上有512个PG。这种集群不会使用过多的资源。然而，在一个包含1000个池的集群中，每个池有512个PG，OSD将处理大约50000个PG。这种集群将需要显著更多的资源和更多的配对时间。</p>
<h2 id="设置PG的数量"><a href="#设置PG的数量" class="headerlink" title="设置PG的数量"></a>设置PG的数量</h2><p>设置池中初始PG数量必须在创建池时进行。然而，即使在池创建之后，如果未使用 <code>pg_autoscaler</code> 管理 <code>pg_num</code> 值，您仍然可以通过运行以下命令更改PG数量：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &#123;pool-name&#125; pg_num &#123;pg_num&#125;</span><br></pre></td></tr></table></figure>

<p>如果您增加PG数量，集群将不会重新平衡，直到您增加用于放置的PG数量（<code>pgp_num</code>）。<code>pgp_num</code> 参数指定了CRUSH算法在放置时要考虑的PG数量。增加 <code>pg_num</code> 会拆分集群中的PG，但数据不会迁移到新的PG，直到 <code>pgp_num</code> 被增加。<code>pgp_num</code> 参数应与 <code>pg_num</code> 参数相等。要增加用于放置的PG数量，请运行以下命令：<br>shell</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &#123;pool-name&#125; pgp_num &#123;pgp_num&#125;</span><br></pre></td></tr></table></figure>

<p>如果您减少PG数量，则 <code>pgp_num</code> 会自动调整。在Nautilus及以后的版本中，当未使用 <code>pg_autoscaler</code> 时，<code>pgp_num</code> 会自动调整以匹配 <code>pg_num</code>。这个过程表现为PG的重新映射和回填，这是正常的预期行为。</p>
<h2 id="获取PG数量"><a href="#获取PG数量" class="headerlink" title="获取PG数量"></a>获取PG数量</h2><p>要获取池中的PG数量，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get &#123;pool-name&#125; pg_num</span><br></pre></td></tr></table></figure>

<h2 id="获取集群的PG统计信息"><a href="#获取集群的PG统计信息" class="headerlink" title="获取集群的PG统计信息"></a>获取集群的PG统计信息</h2><p>要查看集群中PG的详细信息，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump [--format &#123;format&#125;]</span><br></pre></td></tr></table></figure>
<p>有效的格式有plain（默认）和json。</p>
<h2 id="获取卡住PG的统计信息"><a href="#获取卡住PG的统计信息" class="headerlink" title="获取卡住PG的统计信息"></a>获取卡住PG的统计信息</h2><p>要查看所有处于指定状态的卡住PG的统计信息，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump_stuck inactive|unclean|stale|undersized|degraded [--format &lt;format&gt;] [-t|--threshold &lt;seconds&gt;]</span><br></pre></td></tr></table></figure>

<p>Inactive PGs 不能处理读写操作，因为它们在等待足够的OSD来获得最新的数据。</p>
<p>Undersized PGs 包含未被复制到所需次数的对象。在正常情况下，可以假设这些PG正在恢复。</p>
<p>Stale PGs 处于未知状态 — 托管它们的OSD在一定时间内（由 <code>mon_osd_report_timeout</code> 决定）没有向监视集群报告。</p>
<p>有效的格式有plain（默认）和json。阈值定义PG卡住的最少秒数，超过该时间PG会被包括在返回的统计信息中（默认：300秒）。</p>
<h2 id="获取PG映射"><a href="#获取PG映射" class="headerlink" title="获取PG映射"></a>获取PG映射</h2><p>要获取特定PG的映射，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg map &#123;pg-id&#125;</span><br></pre></td></tr></table></figure>
<p>Ceph会返回PG映射、PG和OSD状态。输出类似于以下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">osdmap e13 pg 1.6c (1.6c) -&gt; up [1,0] acting [1,0]</span><br></pre></td></tr></table></figure>

<h2 id="获取PG的统计信息"><a href="#获取PG的统计信息" class="headerlink" title="获取PG的统计信息"></a>获取PG的统计信息</h2><p>要查看特定PG的统计信息，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg &#123;pg-id&#125; query</span><br></pre></td></tr></table></figure>

<h2 id="对PG进行清理"><a href="#对PG进行清理" class="headerlink" title="对PG进行清理"></a>对PG进行清理</h2><p>要对PG进行清理，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg scrub &#123;pg-id&#125;</span><br></pre></td></tr></table></figure>

<p>Ceph检查主OSD和副本OSD，生成PG中所有对象的目录，并将对象进行对比，以确保没有对象丢失或不匹配，并且其内容是一致的。如果副本全部匹配，则进行最终的语义扫描，以确保所有与快照相关的对象元数据一致。错误会记录在日志中。</p>
<p>要对特定池中的所有PG进行清理，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool scrub &#123;pool-name&#125;</span><br></pre></td></tr></table></figure>

<h2 id="优先恢复-回填PG"><a href="#优先恢复-回填PG" class="headerlink" title="优先恢复&#x2F;回填PG"></a>优先恢复&#x2F;回填PG</h2><p>如果遇到多个PG需要恢复或回填的情况，但某些PG中的数据比其他PG中的数据更重要（例如，有些PG包含正在运行的机器使用的镜像数据，而其他PG用于非活动机器，包含的数据不太相关），您可能希望优先恢复或回填特别重要的数据所在的PG，以便尽快恢复集群的性能和数据的可用性。要将特定PG标记为恢复优先，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg force-recovery &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...]</span><br></pre></td></tr></table></figure>

<p>要将特定PG标记为回填优先，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg force-backfill &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...]</span><br></pre></td></tr></table></figure>

<p>这些命令指示Ceph在处理</p>
<p>其他PG之前，优先对指定的PG进行恢复或回填。优先级不会中断当前的回填或恢复，但会将指定的PG置于队列顶部，以便下一个被处理。如果您改变主意或意识到优先级设置错误，请运行以下命令之一：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph pg cancel-force-recovery &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...]</span><br><span class="line">ceph pg cancel-force-backfill &#123;pg-id&#125; [&#123;pg-id #2&#125;] [&#123;pg-id #3&#125; ...]</span><br></pre></td></tr></table></figure>

<p>这些命令会从指定PG中移除强制标记，使PG按常规顺序处理。与添加强制标记的情况一样，这只会影响那些仍在排队的PG，而不会影响当前正在恢复的PG。</p>
<p>强制标记会在PG的恢复或回填完成后自动清除。</p>
<p>同样，要指示Ceph优先处理指定池中的所有PG（即，首先对这些PG进行恢复或回填），请运行以下命令之一：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool force-recovery &#123;pool-name&#125;</span><br><span class="line">ceph osd pool force-backfill &#123;pool-name&#125;</span><br></pre></td></tr></table></figure>

<p>这些命令也可以被取消。要恢复到默认顺序，请运行以下命令之一：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool cancel-force-recovery &#123;pool-name&#125;</span><br><span class="line">ceph osd pool cancel-force-backfill &#123;pool-name&#125;</span><br></pre></td></tr></table></figure>


<h2 id="警告"><a href="#警告" class="headerlink" title="警告"></a>警告</h2><p>这些命令可能会打破Ceph内部优先级计算的顺序，因此使用时请小心！如果您有多个池当前共享相同的底层OSD，并且某些池中的数据比其他池中的数据更重要，则建议运行以下命令来为所有池安排自定义恢复&#x2F;回填优先级：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set &#123;pool-name&#125; recovery_priority &#123;value&#125;</span><br></pre></td></tr></table></figure>

<p>例如，如果您有二十个池，您可以将最重要的池的优先级设为20，次重要的池设为19，以此类推。<br>另一种选择是仅为适当的池子子集设置恢复&#x2F;回填优先级。在这种情况下，可能会将三个重要的池都分配为优先级1，而所有其他池将没有分配恢复&#x2F;回填优先级。另一种可能性是选择三个重要的池，并将它们的恢复&#x2F;回填优先级分别设置为3、2和1。</p>
<h2 id="重要"><a href="#重要" class="headerlink" title="重要"></a>重要</h2><p>使用 <code>ceph osd pool set &#123;pool-name&#125; recovery_priority &#123;value&#125;</code> 设置恢复&#x2F;回填优先级时，数值越大优先级越高。例如，优先级为30的池比优先级为15的池具有更高的优先级。</p>
<h2 id="恢复丢失的RADOS对象"><a href="#恢复丢失的RADOS对象" class="headerlink" title="恢复丢失的RADOS对象"></a>恢复丢失的RADOS对象</h2><p>如果集群丢失了一个或多个RADOS对象，并且您决定放弃对丢失数据的搜索，您必须将未找到的对象标记为丢失。</p>
<p>如果已经查询了所有可能的位置，并且所有OSD都正常，但某些RADOS对象仍然丢失，您可能不得不放弃这些对象。当罕见和异常的故障组合允许集群了解到在写入操作恢复之前执行的写入时，可能会出现这种情况。</p>
<p>标记RADOS对象丢失的命令只有一个支持的选项：revert。revert选项将回滚到RADOS对象的先前版本（如果它足够旧以拥有先前版本），或者完全忽略它（如果它太新而没有先前版本）。要标记“未找到”的对象为丢失，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg &#123;pg-id&#125; mark_unfound_lost revert|delete</span><br></pre></td></tr></table></figure>

<h2 id="平衡模块"><a href="#平衡模块" class="headerlink" title="平衡模块"></a>平衡模块</h2><p>平衡模块可以优化放置组（PG）在OSD之间的分配，以实现平衡分布。平衡器可以自动操作，也可以在监督下操作。</p>
<h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h4><p>要检查平衡器的当前状态，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer status</span><br></pre></td></tr></table></figure>

<h4 id="自动平衡"><a href="#自动平衡" class="headerlink" title="自动平衡"></a>自动平衡</h4><p>当平衡器处于 upmap 模式时，自动平衡功能默认启用。要禁用平衡器，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer off</span><br></pre></td></tr></table></figure>

<p>平衡器模式可以从 upmap 模式更改为 crush-compat 模式。crush-compat 模式与较旧的客户端向后兼容。在 crush-compat 模式下，平衡器会自动对数据分布进行小的调整，以确保 OSD 被均等利用。</p>
<h4 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h4><p>如果集群处于降级状态（即，OSD 已失败且系统尚未自愈），则平衡器不会对 PG 分布进行任何调整。</p>
<p>当集群处于健康状态时，平衡器将逐步移动一小部分不平衡的 PG，以改善分布。这个比例不会超过默认的 5% 阈值。要调整这个 target_max_misplaced_ratio 阈值设置，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr target_max_misplaced_ratio .07   # 7%</span><br></pre></td></tr></table></figure>

<p>平衡器在运行之间会休眠。要设置此休眠间隔的秒数，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/sleep_interval 60</span><br></pre></td></tr></table></figure>

<p>要设置自动平衡开始的时间（HHMM 格式），请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/begin_time 0000</span><br></pre></td></tr></table></figure>

<p>要设置自动平衡结束的时间（HHMM 格式），请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/end_time 2359</span><br></pre></td></tr></table></figure>

<p>自动平衡可以限制在特定的星期几。要将其限制为特定的星期几或之后的时间（如 crontab 中，0 是星期天，1 是星期一，以此类推），请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/begin_weekday 0</span><br></pre></td></tr></table></figure>

<p>要限制自动平衡为特定的星期几或之前的时间（同样，0 是星期天，1 是星期一，以此类推），请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/end_weekday 6</span><br></pre></td></tr></table></figure>

<p>自动平衡可以限制在特定的池。默认情况下，这个设置的值是空字符串，这样所有池都会自动平衡。要将自动平衡限制到特定的池，请获取它们的数字池 ID（通过运行 <code>ceph osd pool ls detail</code> 命令），然后运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config set mgr mgr/balancer/pool_ids 1,2,3</span><br></pre></td></tr></table></figure>

<h4 id="模式"><a href="#模式" class="headerlink" title="模式"></a>模式</h4><p>支持两种平衡器模式：</p>
<ol>
<li><strong>crush-compat</strong>：此模式使用兼容权重集功能（在 Luminous 中引入）来管理 CRUSH 层次结构中设备的备用权重集。当平衡器在此模式下运行时，正常权重应保持为设备的大小，以反映计划存储在设备上的数据量。然后，平衡器将优化权重集值，通过小的增量进行调整，以实现尽可能接近目标分布的分布。（由于 PG 放置是伪随机过程，因此会受到自然变异的影响；优化权重有助于对抗这种自然变异。）<ul>
<li>请注意，此模式与较旧的客户端完全向后兼容：当 OSD Map 和 CRUSH 图与较旧的客户端共享时，Ceph 将优化后的权重呈现为“真实”权重。</li>
<li>此模式的主要限制是，平衡器无法处理具有不同放置规则的多个 CRUSH 层次结构，如果层次结构的子树共享任何 OSD。（这种 OSD 共享是不典型的，并且由于管理共享 OSD 上的空间利用的困难，通常不推荐。）</li>
</ul>
</li>
<li><strong>upmap</strong>：在 Luminous 及更高版本中，OSDMap 可以存储对单个 OSD 的显式映射，作为正常 CRUSH 放置计算的例外。这些 upmap 条目提供了对 PG 映射的细粒度控制。此平衡器模式优化单个 PG 的放置，以实现平衡分布。在大多数情况下，结果分布几乎是完美的：即，每个 OSD 上的 PG 数量相等（±1 PG，因为总数可能无法均匀分割）。<ul>
<li>要使用 upmap，所有客户端必须是 Luminous 或更高版本。</li>
<li>默认模式是 upmap。可以通过运行以下命令将模式更改为 crush-compat： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer mode crush-compat</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="监控优化"><a href="#监控优化" class="headerlink" title="监控优化"></a>监控优化</h4><p>监督使用平衡器可以分为三个不同的阶段：</p>
<ol>
<li><strong>制定计划</strong></li>
<li><strong>评估数据分布的质量，无论是当前的 PG 分布还是执行计划后将产生的 PG 分布</strong></li>
<li><strong>执行计划</strong></li>
</ol>
<p>要评估当前分布，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer eval</span><br></pre></td></tr></table></figure>

<p>要评估单个池的分布，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer eval &lt;pool-name&gt;</span><br></pre></td></tr></table></figure>

<p>要详细查看评估，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer eval-verbose ...</span><br></pre></td></tr></table></figure>

<p>要指示平衡器生成一个计划（使用当前配置的模式），为计划起个名字（任何有用的标识字符串），并运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer optimize &lt;plan-name&gt;</span><br></pre></td></tr></table></figure>

<p>要查看计划的内容，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer show &lt;plan-name&gt;</span><br></pre></td></tr></table></figure>

<p>要显示所有计划，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer ls</span><br></pre></td></tr></table></figure>

<p>要丢弃旧的计划，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer rm &lt;plan-name&gt;</span><br></pre></td></tr></table></figure>

<p>要查看当前记录的计划，请检查以下状态命令的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer status</span><br></pre></td></tr></table></figure>

<p>要评估执行特定计划后将产生的分布，请运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer eval &lt;plan-name&gt;</span><br></pre></td></tr></table></figure>

<p>如果计划预计会改善分布（即计划的评分低于当前集群状态的评分），可以通过运行以下命令执行该计划：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph balancer execute &lt;plan-name&gt;</span><br></pre></td></tr></table></figure>
      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://watsonlu6.github.io/Storage/Ceph/ceph-PG%E4%BB%8B%E7%BB%8D/" title="Ceph PG介绍" target="_blank" rel="external">https://watsonlu6.github.io/Storage/Ceph/ceph-PG介绍/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/watsonLu6/" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/watsonLu6/" target="_blank"><span class="text-dark">watson</span><small class="ml-1x">Cloud computing development engineer</small></a></h3>
        <div>内心要狂热，头脑要冷静，四肢要发达</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/Storage/%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/" title="存储系统缓存/分层相关论文"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/Storage/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/" title="存储性能测试工具"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  


</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/watsonLu6/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: '',
    appKey: '',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     







</body>
</html>